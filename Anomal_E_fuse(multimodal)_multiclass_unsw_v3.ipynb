{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Hjc3iIihKLn-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from dgl.data import DGLDataset\n",
    "import dgl\n",
    "import time\n",
    "import networkx as nx\n",
    "import category_encoders as ce\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "from typing import *\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SvWHb_BpKsLq"
   },
   "outputs": [],
   "source": [
    "file_name = \"NF-UNSW-NB15-v3.parquet\"\n",
    "# file_name = \"final.csv\"\n",
    "data = pd.read_parquet(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "fqly1y-LMwYS",
    "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    2151027\n",
       "1      91904\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3t4OREvSM33h"
   },
   "outputs": [],
   "source": [
    "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
    "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
    "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
    "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bTtHq0XqNXxI"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUNIP-8zNkn9",
    "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Fuzzers', 'Exploits', 'Backdoor', 'Generic', 'DoS',\n",
       "       'Reconnaissance', 'Shellcode', 'Analysis', 'Worms'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Attack.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    91904\n",
       "0    43021\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the dataset based on your needs (machine capacity) ideally ~500k rows\n",
    "\n",
    "# data = data.groupby(by='Attack').sample(frac=0.1, random_state=13)\n",
    "data_attack = data[data['Label'] == 1]\n",
    "data_benign = data[data['Label'] == 0].sample(frac=0.02, random_state=13)\n",
    "data = pd.concat([data_attack, data_benign], axis=0)\n",
    "data = data.sample(frac=1, random_state=13).reset_index(drop=True)\n",
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "lcfAP6ViOp-J",
    "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLOW_START_MILLISECONDS</th>\n",
       "      <th>FLOW_END_MILLISECONDS</th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>...</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>SRC_TO_DST_IAT_MIN</th>\n",
       "      <th>SRC_TO_DST_IAT_MAX</th>\n",
       "      <th>SRC_TO_DST_IAT_AVG</th>\n",
       "      <th>SRC_TO_DST_IAT_STDDEV</th>\n",
       "      <th>DST_TO_SRC_IAT_MIN</th>\n",
       "      <th>DST_TO_SRC_IAT_MAX</th>\n",
       "      <th>DST_TO_SRC_IAT_AVG</th>\n",
       "      <th>DST_TO_SRC_IAT_STDDEV</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Analysis</th>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>...</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Backdoor</th>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>...</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>...</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS</th>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>...</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exploits</th>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>...</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuzzers</th>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>...</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generic</th>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>...</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reconnaissance</th>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>...</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shellcode</th>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>...</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Worms</th>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                FLOW_START_MILLISECONDS  FLOW_END_MILLISECONDS  IPV4_SRC_ADDR  \\\n",
       "Attack                                                                          \n",
       "Analysis                           1226                   1226           1226   \n",
       "Backdoor                           3451                   3451           3451   \n",
       "Benign                            43021                  43021          43021   \n",
       "DoS                                5050                   5050           5050   \n",
       "Exploits                          38816                  38816          38816   \n",
       "Fuzzers                           25588                  25588          25588   \n",
       "Generic                            4760                   4760           4760   \n",
       "Reconnaissance                    11291                  11291          11291   \n",
       "Shellcode                          1586                   1586           1586   \n",
       "Worms                               136                    136            136   \n",
       "\n",
       "                IPV4_DST_ADDR  PROTOCOL  L7_PROTO  IN_BYTES  IN_PKTS  \\\n",
       "Attack                                                                 \n",
       "Analysis                 1226      1226      1226      1226     1226   \n",
       "Backdoor                 3451      3451      3451      3451     3451   \n",
       "Benign                  43021     43021     43021     43021    43021   \n",
       "DoS                      5050      5050      5050      5050     5050   \n",
       "Exploits                38816     38816     38816     38816    38816   \n",
       "Fuzzers                 25588     25588     25588     25588    25588   \n",
       "Generic                  4760      4760      4760      4760     4760   \n",
       "Reconnaissance          11291     11291     11291     11291    11291   \n",
       "Shellcode                1586      1586      1586      1586     1586   \n",
       "Worms                     136       136       136       136      136   \n",
       "\n",
       "                OUT_BYTES  OUT_PKTS  ...  FTP_COMMAND_RET_CODE  \\\n",
       "Attack                               ...                         \n",
       "Analysis             1226      1226  ...                  1226   \n",
       "Backdoor             3451      3451  ...                  3451   \n",
       "Benign              43021     43021  ...                 43021   \n",
       "DoS                  5050      5050  ...                  5050   \n",
       "Exploits            38816     38816  ...                 38816   \n",
       "Fuzzers             25588     25588  ...                 25588   \n",
       "Generic              4760      4760  ...                  4760   \n",
       "Reconnaissance      11291     11291  ...                 11291   \n",
       "Shellcode            1586      1586  ...                  1586   \n",
       "Worms                 136       136  ...                   136   \n",
       "\n",
       "                SRC_TO_DST_IAT_MIN  SRC_TO_DST_IAT_MAX  SRC_TO_DST_IAT_AVG  \\\n",
       "Attack                                                                       \n",
       "Analysis                      1226                1226                1226   \n",
       "Backdoor                      3451                3451                3451   \n",
       "Benign                       43021               43021               43021   \n",
       "DoS                           5050                5050                5050   \n",
       "Exploits                     38816               38816               38816   \n",
       "Fuzzers                      25588               25588               25588   \n",
       "Generic                       4760                4760                4760   \n",
       "Reconnaissance               11291               11291               11291   \n",
       "Shellcode                     1586                1586                1586   \n",
       "Worms                          136                 136                 136   \n",
       "\n",
       "                SRC_TO_DST_IAT_STDDEV  DST_TO_SRC_IAT_MIN  DST_TO_SRC_IAT_MAX  \\\n",
       "Attack                                                                          \n",
       "Analysis                         1226                1226                1226   \n",
       "Backdoor                         3451                3451                3451   \n",
       "Benign                          43021               43021               43021   \n",
       "DoS                              5050                5050                5050   \n",
       "Exploits                        38816               38816               38816   \n",
       "Fuzzers                         25588               25588               25588   \n",
       "Generic                          4760                4760                4760   \n",
       "Reconnaissance                  11291               11291               11291   \n",
       "Shellcode                        1586                1586                1586   \n",
       "Worms                             136                 136                 136   \n",
       "\n",
       "                DST_TO_SRC_IAT_AVG  DST_TO_SRC_IAT_STDDEV  Label  \n",
       "Attack                                                            \n",
       "Analysis                      1226                   1226   1226  \n",
       "Backdoor                      3451                   3451   3451  \n",
       "Benign                       43021                  43021  43021  \n",
       "DoS                           5050                   5050   5050  \n",
       "Exploits                     38816                  38816  38816  \n",
       "Fuzzers                      25588                  25588  25588  \n",
       "Generic                       4760                   4760   4760  \n",
       "Reconnaissance               11291                  11291  11291  \n",
       "Shellcode                     1586                   1586   1586  \n",
       "Worms                          136                    136    136  \n",
       "\n",
       "[10 rows x 52 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=\"Attack\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FqRx5xCPOuv8"
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Attack\", \"Label\", \"FLOW_START_MILLISECONDS\", \"FLOW_END_MILLISECONDS\",\n",
    "                       \"SRC_TO_DST_IAT_MIN\", \"SRC_TO_DST_IAT_MAX\", \"SRC_TO_DST_IAT_AVG\",\n",
    "                       \"SRC_TO_DST_IAT_STDDEV\", \"DST_TO_SRC_IAT_MIN\", \"DST_TO_SRC_IAT_MAX\",\n",
    "                       \"DST_TO_SRC_IAT_AVG\", \"DST_TO_SRC_IAT_STDDEV\"])\n",
    "y = data[[\"Attack\", \"Label\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=13, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bPfakXplPGGx"
   },
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
    "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
    "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
    "                                  'FTP_COMMAND_RET_CODE'])\n",
    "encoder.fit(X_train, y_train.Label)\n",
    "\n",
    "# Transform on training set\n",
    "X_train = encoder.transform(X_train)\n",
    "\n",
    "# Transform on testing set\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ibyOfV-8PouK"
   },
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "asDnsSIWPee0"
   },
   "outputs": [],
   "source": [
    "# (Modified)\n",
    "scaler = Normalizer()\n",
    "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
    "scaler.fit(X_train[cols_to_norm])\n",
    "\n",
    "# Transform on training set\n",
    "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
    "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
    "X_train['id'] = X_train.index\n",
    "\n",
    "# Transform on testing set\n",
    "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
    "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
    "X_test['id'] = X_test.index\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "hErQbsnrPluV",
    "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>h</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460141</th>\n",
       "      <td>175.45.176.1</td>\n",
       "      <td>149.171.126.14</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.594677e-06</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.179076</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048430</td>\n",
       "      <td>0.048430</td>\n",
       "      <td>2.926896e-06</td>\n",
       "      <td>2.927499e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>[2.147881759341033e-06, 2.594677439115478e-06,...</td>\n",
       "      <td>460141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331121</th>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>149.171.126.12</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>2.614421e-05</td>\n",
       "      <td>0.023412</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.098712</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487988</td>\n",
       "      <td>0.487988</td>\n",
       "      <td>2.936818e-05</td>\n",
       "      <td>2.938642e-05</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>[2.1642257961737377e-05, 2.6144213116305557e-0...</td>\n",
       "      <td>331121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603484</th>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>149.171.126.19</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>8.373461e-06</td>\n",
       "      <td>0.144476</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137182</td>\n",
       "      <td>0.137182</td>\n",
       "      <td>1.608996e-06</td>\n",
       "      <td>1.622462e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>[6.08403937818468e-06, 8.373461389523251e-06, ...</td>\n",
       "      <td>603484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199805</th>\n",
       "      <td>59.166.0.2</td>\n",
       "      <td>149.171.126.5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.363477e-10</td>\n",
       "      <td>0.027949</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018132</td>\n",
       "      <td>0.031731</td>\n",
       "      <td>3.617282e-07</td>\n",
       "      <td>3.617282e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>[2.274586239684794e-06, 6.363476555465527e-10,...</td>\n",
       "      <td>2199805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730879</th>\n",
       "      <td>175.45.176.1</td>\n",
       "      <td>149.171.126.12</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>2.271349e-05</td>\n",
       "      <td>0.022462</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.479822</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423953</td>\n",
       "      <td>0.423953</td>\n",
       "      <td>2.587759e-05</td>\n",
       "      <td>2.587759e-05</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>[1.880229519156918e-05, 2.271349012811647e-05,...</td>\n",
       "      <td>730879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        IPV4_SRC_ADDR   IPV4_DST_ADDR  PROTOCOL      L7_PROTO  IN_BYTES  \\\n",
       "460141   175.45.176.1  149.171.126.14  0.000002  2.594677e-06  0.002873   \n",
       "331121   175.45.176.3  149.171.126.12  0.000022  2.614421e-05  0.023412   \n",
       "603484   175.45.176.3  149.171.126.19  0.000006  8.373461e-06  0.144476   \n",
       "2199805    59.166.0.2   149.171.126.5  0.000002  6.363477e-10  0.027949   \n",
       "730879   175.45.176.1  149.171.126.12  0.000019  2.271349e-05  0.022462   \n",
       "\n",
       "          IN_PKTS  OUT_BYTES  OUT_PKTS  TCP_FLAGS  CLIENT_TCP_FLAGS  ...  \\\n",
       "460141   0.000047   0.179076  0.000154   0.000001          0.000001  ...   \n",
       "331121   0.000298   0.098712  0.000298   0.000013          0.000014  ...   \n",
       "603484   0.000167   0.002813  0.000067   0.000008          0.000008  ...   \n",
       "2199805  0.000044   0.001002  0.000019   0.000001          0.000001  ...   \n",
       "730879   0.000311   0.479822  0.000569   0.000012          0.000012  ...   \n",
       "\n",
       "         TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT     ICMP_TYPE  ICMP_IPV4_TYPE  \\\n",
       "460141         0.048430         0.048430  2.926896e-06    2.927499e-06   \n",
       "331121         0.487988         0.487988  2.936818e-05    2.938642e-05   \n",
       "603484         0.137182         0.137182  1.608996e-06    1.622462e-06   \n",
       "2199805        0.018132         0.031731  3.617282e-07    3.617282e-07   \n",
       "730879         0.423953         0.423953  2.587759e-05    2.587759e-05   \n",
       "\n",
       "         DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \\\n",
       "460141       0.000002        0.000002             0.0              0.000002   \n",
       "331121       0.000021        0.000021             0.0              0.000021   \n",
       "603484       0.000006        0.000006             0.0              0.000006   \n",
       "2199805      0.000002        0.000002             0.0              0.000002   \n",
       "730879       0.000018        0.000018             0.0              0.000018   \n",
       "\n",
       "                                                         h       id  \n",
       "460141   [2.147881759341033e-06, 2.594677439115478e-06,...   460141  \n",
       "331121   [2.1642257961737377e-05, 2.6144213116305557e-0...   331121  \n",
       "603484   [6.08403937818468e-06, 8.373461389523251e-06, ...   603484  \n",
       "2199805  [2.274586239684794e-06, 6.363476555465527e-10,...  2199805  \n",
       "730879   [1.880229519156918e-05, 2.271349012811647e-05,...   730879  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d_tLtK4WPtrF"
   },
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "lab_enc.fit(data[\"Attack\"])\n",
    "\n",
    "# Transform on training set\n",
    "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
    "\n",
    "# Transform on testing set\n",
    "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8yaicjecP1fZ"
   },
   "outputs": [],
   "source": [
    "# Training graph (Modified)\n",
    "\n",
    "train['id'] = train.index\n",
    "\n",
    "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "           [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "train_g = train_g.to_directed()\n",
    "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
    "train_g.edata['h'].shape[1]])\n",
    "train_g.ndata['h'] = nfeat_weight\n",
    "\n",
    "test['id'] = test.index\n",
    "\n",
    "# Testing graph\n",
    "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "            [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "# print(test_g)\n",
    "test_g = test_g.to_directed()\n",
    "# print(test_g)\n",
    "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
    "test_g.edata['h'].shape[1]])\n",
    "test_g.ndata['h'] = nfeat_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PUV6DgJ9QRaP"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import tqdm\n",
    "import gc\n",
    "\n",
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "      super(SAGELayer, self).__init__()\n",
    "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
    "      self.activation = F.relu\n",
    "      self.W_edge = nn.Linear(128 * 2, 256)\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      gain = nn.init.calculate_gain('relu')\n",
    "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "      return {'m':  edges.data['h']}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "      with g_dgl.local_scope():\n",
    "        g = g_dgl\n",
    "        g.ndata['h'] = nfeats\n",
    "        g.edata['h'] = efeats\n",
    "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "\n",
    "        # Compute edge embeddings\n",
    "        u, v = g.edges()\n",
    "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
    "        return g.ndata['h'], edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_xo-3K4QRGqc"
   },
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
    "      super(SAGE, self).__init__()\n",
    "      self.layers = nn.ModuleList()\n",
    "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
    "\n",
    "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
    "      if corrupt:\n",
    "        e_perm = torch.randperm(g.number_of_edges())\n",
    "        #n_perm = torch.randperm(g.number_of_nodes())\n",
    "        efeats = efeats[e_perm]\n",
    "        #nfeats = nfeats[n_perm]\n",
    "      for i, layer in enumerate(self.layers):\n",
    "        #nfeats = layer(g, nfeats, efeats)\n",
    "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
    "      #return nfeats.sum(1)\n",
    "      return nfeats.sum(1), e_feats.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6uuxRtLuRJQL"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "      super(Discriminator, self).__init__()\n",
    "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def uniform(self, size, tensor):\n",
    "      bound = 1.0 / math.sqrt(size)\n",
    "      if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      size = self.weight.size(0)\n",
    "      self.uniform(size, self.weight)\n",
    "\n",
    "    def forward(self, features, summary):\n",
    "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
    "      return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZPbVjlCyRUco"
   },
   "outputs": [],
   "source": [
    "class DGI(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
    "      super(DGI, self).__init__()\n",
    "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
    "      #self.discriminator = Discriminator(128)\n",
    "      self.discriminator = Discriminator(256)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "\n",
    "      positive = positive[1]\n",
    "      negative = negative[1]\n",
    "\n",
    "      summary = torch.sigmoid(positive.mean(dim=0))\n",
    "\n",
    "      positive = self.discriminator(positive, summary)\n",
    "      negative = self.discriminator(negative, summary)\n",
    "\n",
    "      l1 = self.loss(positive, torch.ones_like(positive))\n",
    "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
    "\n",
    "      return l1 + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sKnfpWFMR19u"
   },
   "outputs": [],
   "source": [
    "ndim_in = train_g.ndata['h'].shape[1]\n",
    "hidden_features = 128\n",
    "ndim_out = 128\n",
    "num_layers = 1\n",
    "edim = train_g.edata['h'].shape[1]\n",
    "learning_rate = 1e-3\n",
    "epochs = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "aSl_9qY8SbA0"
   },
   "outputs": [],
   "source": [
    "dgi = DGI(ndim_in,\n",
    "    ndim_out,\n",
    "    edim,\n",
    "    F.relu)\n",
    "\n",
    "dgi = dgi.to('cuda')\n",
    "\n",
    "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
    "                lr=1e-3,\n",
    "                weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9K6_cOiWSdJA"
   },
   "outputs": [],
   "source": [
    "# Format node and edge features for E-GraphSAGE\n",
    "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
    "                                   (train_g.ndata['h'].shape[0], 1,\n",
    "                                    train_g.ndata['h'].shape[1]))\n",
    "\n",
    "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
    "                                   (train_g.edata['h'].shape[0], 1,\n",
    "                                    train_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "O44auIyWSexg"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "train_g = train_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gZtafIdxSheN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Time(s) nan | Loss 1.6100 | ETputs(KTEPS) nan\n",
      "Epoch 00050 | Time(s) 0.0994 | Loss 1.2811 | ETputs(KTEPS) 1899.63\n",
      "Epoch 00100 | Time(s) 0.0973 | Loss 0.2667 | ETputs(KTEPS) 1942.05\n",
      "Epoch 00150 | Time(s) 0.0967 | Loss 0.0204 | ETputs(KTEPS) 1953.21\n",
      "Epoch 00200 | Time(s) 0.0963 | Loss 0.0090 | ETputs(KTEPS) 1961.48\n",
      "Epoch 00250 | Time(s) 0.0959 | Loss 0.0052 | ETputs(KTEPS) 1969.99\n",
      "Epoch 00300 | Time(s) 0.0955 | Loss 0.0046 | ETputs(KTEPS) 1977.97\n",
      "Epoch 00350 | Time(s) 0.0952 | Loss 0.0026 | ETputs(KTEPS) 1983.45\n",
      "Epoch 00400 | Time(s) 0.0950 | Loss 0.0019 | ETputs(KTEPS) 1987.57\n",
      "Epoch 00450 | Time(s) 0.0949 | Loss 0.0019 | ETputs(KTEPS) 1991.13\n",
      "Epoch 00500 | Time(s) 0.0947 | Loss 0.0016 | ETputs(KTEPS) 1994.50\n",
      "Epoch 00550 | Time(s) 0.0946 | Loss 0.0015 | ETputs(KTEPS) 1996.83\n",
      "Epoch 00600 | Time(s) 0.0945 | Loss 0.0012 | ETputs(KTEPS) 1998.12\n",
      "Epoch 00650 | Time(s) 0.0945 | Loss 0.0007 | ETputs(KTEPS) 1999.59\n",
      "Epoch 00700 | Time(s) 0.0944 | Loss 0.0008 | ETputs(KTEPS) 2000.72\n",
      "Epoch 00750 | Time(s) 0.0944 | Loss 0.0007 | ETputs(KTEPS) 2001.84\n",
      "Epoch 00800 | Time(s) 0.0943 | Loss 0.0007 | ETputs(KTEPS) 2003.01\n",
      "Epoch 00850 | Time(s) 0.0943 | Loss 0.0004 | ETputs(KTEPS) 2003.73\n",
      "Epoch 00900 | Time(s) 0.0942 | Loss 0.0004 | ETputs(KTEPS) 2004.20\n",
      "Epoch 00950 | Time(s) 0.0942 | Loss 0.0003 | ETputs(KTEPS) 2004.95\n",
      "Epoch 01000 | Time(s) 0.0942 | Loss 0.0006 | ETputs(KTEPS) 2005.38\n",
      "Epoch 01050 | Time(s) 0.0942 | Loss 0.0004 | ETputs(KTEPS) 2005.60\n",
      "Epoch 01100 | Time(s) 0.0942 | Loss 0.0003 | ETputs(KTEPS) 2006.02\n",
      "Epoch 01150 | Time(s) 0.0941 | Loss 0.0003 | ETputs(KTEPS) 2006.32\n",
      "Epoch 01200 | Time(s) 0.0941 | Loss 0.0002 | ETputs(KTEPS) 2006.60\n",
      "Epoch 01250 | Time(s) 0.0941 | Loss 0.0007 | ETputs(KTEPS) 2006.93\n",
      "Epoch 01300 | Time(s) 0.0941 | Loss 0.0004 | ETputs(KTEPS) 2007.40\n",
      "Epoch 01350 | Time(s) 0.0941 | Loss 0.0002 | ETputs(KTEPS) 2007.60\n",
      "Epoch 01400 | Time(s) 0.0941 | Loss 0.0002 | ETputs(KTEPS) 2007.89\n",
      "Epoch 01450 | Time(s) 0.0941 | Loss 0.0008 | ETputs(KTEPS) 2007.94\n",
      "Epoch 01500 | Time(s) 0.0941 | Loss 0.0008 | ETputs(KTEPS) 2008.13\n",
      "Epoch 01550 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2008.01\n",
      "Epoch 01600 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2007.98\n",
      "Epoch 01650 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2008.19\n",
      "Epoch 01700 | Time(s) 0.0941 | Loss 0.0003 | ETputs(KTEPS) 2008.17\n",
      "Epoch 01750 | Time(s) 0.0941 | Loss 0.0005 | ETputs(KTEPS) 2008.10\n",
      "Epoch 01800 | Time(s) 0.0941 | Loss 0.0009 | ETputs(KTEPS) 2008.12\n",
      "Epoch 01850 | Time(s) 0.0941 | Loss 0.0003 | ETputs(KTEPS) 2008.10\n",
      "Epoch 01900 | Time(s) 0.0941 | Loss 0.0002 | ETputs(KTEPS) 2008.06\n",
      "Epoch 01950 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2008.14\n",
      "Epoch 02000 | Time(s) 0.0941 | Loss 0.0002 | ETputs(KTEPS) 2008.23\n",
      "Epoch 02050 | Time(s) 0.0941 | Loss 0.0002 | ETputs(KTEPS) 2008.18\n",
      "Epoch 02100 | Time(s) 0.0941 | Loss 0.0010 | ETputs(KTEPS) 2008.24\n",
      "Epoch 02150 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2008.29\n",
      "Epoch 02200 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2008.25\n",
      "Epoch 02250 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2008.21\n",
      "Epoch 02300 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2008.20\n",
      "Epoch 02350 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2008.21\n",
      "Epoch 02400 | Time(s) 0.0941 | Loss 0.0006 | ETputs(KTEPS) 2008.25\n",
      "Epoch 02450 | Time(s) 0.0941 | Loss 0.0003 | ETputs(KTEPS) 2008.07\n",
      "Epoch 02500 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2008.01\n",
      "Epoch 02550 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2007.98\n",
      "Epoch 02600 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2008.01\n",
      "Epoch 02650 | Time(s) 0.0941 | Loss 0.0010 | ETputs(KTEPS) 2007.96\n",
      "Epoch 02700 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2007.92\n",
      "Epoch 02750 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2007.96\n",
      "Epoch 02800 | Time(s) 0.0941 | Loss 0.0007 | ETputs(KTEPS) 2007.99\n",
      "Epoch 02850 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2008.00\n",
      "Epoch 02900 | Time(s) 0.0941 | Loss 0.0001 | ETputs(KTEPS) 2008.05\n",
      "Epoch 02950 | Time(s) 0.0941 | Loss 0.0002 | ETputs(KTEPS) 2008.10\n",
      "Epoch 03000 | Time(s) 0.0941 | Loss 0.0002 | ETputs(KTEPS) 2008.17\n",
      "Epoch 03050 | Time(s) 0.0941 | Loss 0.0013 | ETputs(KTEPS) 2008.26\n",
      "Epoch 03100 | Time(s) 0.0941 | Loss 0.0002 | ETputs(KTEPS) 2008.38\n",
      "Epoch 03150 | Time(s) 0.0940 | Loss 0.0000 | ETputs(KTEPS) 2008.47\n",
      "Epoch 03200 | Time(s) 0.0940 | Loss 0.0000 | ETputs(KTEPS) 2008.55\n",
      "Epoch 03250 | Time(s) 0.0940 | Loss 0.0002 | ETputs(KTEPS) 2008.53\n",
      "Epoch 03300 | Time(s) 0.0940 | Loss 0.0006 | ETputs(KTEPS) 2008.55\n",
      "Epoch 03350 | Time(s) 0.0940 | Loss 0.0001 | ETputs(KTEPS) 2008.54\n",
      "Epoch 03400 | Time(s) 0.0940 | Loss 0.0001 | ETputs(KTEPS) 2008.50\n",
      "Epoch 03450 | Time(s) 0.0940 | Loss 0.0000 | ETputs(KTEPS) 2008.51\n",
      "Epoch 03500 | Time(s) 0.0940 | Loss 0.0011 | ETputs(KTEPS) 2008.54\n",
      "Epoch 03550 | Time(s) 0.0940 | Loss 0.0000 | ETputs(KTEPS) 2008.59\n",
      "Epoch 03600 | Time(s) 0.0940 | Loss 0.0003 | ETputs(KTEPS) 2008.61\n",
      "Epoch 03650 | Time(s) 0.0940 | Loss 0.0001 | ETputs(KTEPS) 2008.58\n",
      "Epoch 03700 | Time(s) 0.0940 | Loss 0.0000 | ETputs(KTEPS) 2008.63\n",
      "Epoch 03750 | Time(s) 0.0940 | Loss 0.0000 | ETputs(KTEPS) 2008.68\n",
      "Epoch 03800 | Time(s) 0.0940 | Loss 0.0018 | ETputs(KTEPS) 2008.66\n",
      "Epoch 03850 | Time(s) 0.0940 | Loss 0.0001 | ETputs(KTEPS) 2008.63\n",
      "Epoch 03900 | Time(s) 0.0940 | Loss 0.0000 | ETputs(KTEPS) 2008.69\n",
      "Epoch 03950 | Time(s) 0.0940 | Loss 0.0002 | ETputs(KTEPS) 2008.67\n"
     ]
    }
   ],
   "source": [
    "cnt_wait = 0\n",
    "best = 1e9\n",
    "best_t = 0\n",
    "dur = []\n",
    "node_features = train_g.ndata['h'] \n",
    "edge_features = train_g.edata['h']\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    dgi.train()\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    dgi_optimizer.zero_grad()\n",
    "    loss = dgi(train_g, node_features, edge_features)\n",
    "    loss.backward()\n",
    "    dgi_optimizer.step()\n",
    "\n",
    "    if loss < best:\n",
    "        best = loss\n",
    "        best_t = epoch\n",
    "        cnt_wait = 0\n",
    "        torch.save(dgi.state_dict(), 'best_dgi_UNSW_v3.pkl')\n",
    "    else:\n",
    "        cnt_wait += 1\n",
    "\n",
    "  # if cnt_wait == patience:\n",
    "  #     print('Early stopping!')\n",
    "  #     break\n",
    "\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "\n",
    "        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "            \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
    "              loss.item(),\n",
    "              train_g.num_edges() / np.mean(dur) / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RZ2HAQDAF-4c",
    "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgi.load_state_dict(torch.load('best_dgi_UNSW_v3.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6Ek16GkRStKP"
   },
   "outputs": [],
   "source": [
    "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
    "training_emb = training_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-FwaBlOdS4ep"
   },
   "outputs": [],
   "source": [
    "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
    "                                   (test_g.ndata['h'].shape[0], 1,\n",
    "                                    test_g.ndata['h'].shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
    "                                   (test_g.edata['h'].shape[0], 1,\n",
    "                                    test_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SBa-rdivS6cQ"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "test_g = test_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "W12WLjslS-kx"
   },
   "outputs": [],
   "source": [
    "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
    "testing_emb = testing_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal (Fusion) Learning\n",
    "\n",
    "df_train = pd.DataFrame(training_emb,)\n",
    "# map the id to the original data\n",
    "df_train['id'] = train_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "df_raw_train = pd.DataFrame(X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_fuse_train = pd.merge(df_train, df_raw_train, on='id', how='left')\n",
    "df_fuse_train = df_fuse_train.drop(columns=[\"id\"])\n",
    "df_fuse_train[\"Attacks\"] = train_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
    "\n",
    "df_test = pd.DataFrame(testing_emb,)\n",
    "# map the id to the original data\n",
    "df_test['id'] = test_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "df_raw_test = pd.DataFrame(X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_raw_test = pd.merge(df_test, df_raw_test, on='id', how='left')\n",
    "df_fuse_test = df_raw_test.drop(columns=[\"id\"])\n",
    "df_fuse_test[\"Attacks\"] = test_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ScEk1y_TzzX"
   },
   "source": [
    "# Embeddings CBLOF  Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ZYABKzdrTGas"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pyod.models.cblof import CBLOF\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_fuse_train_samples = df_fuse_train[df_fuse_train.Label == 0].drop(columns=[\"Label\", \"Attacks\"])\n",
    "normal_fuse_train_samples = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"])\n",
    "\n",
    "fuse_train_labels = df_fuse_train[\"Label\"]\n",
    "fuse_test_labels = df_fuse_test[\"Label\"]\n",
    "\n",
    "fuse_test_samples = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_512_TO_1024_BYTES</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.120290</td>\n",
       "      <td>0.033143</td>\n",
       "      <td>0.199002</td>\n",
       "      <td>0.138511</td>\n",
       "      <td>0.153536</td>\n",
       "      <td>0.230251</td>\n",
       "      <td>0.206177</td>\n",
       "      <td>0.051485</td>\n",
       "      <td>0.173025</td>\n",
       "      <td>-0.019700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.444604</td>\n",
       "      <td>0.444604</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.120290</td>\n",
       "      <td>0.033143</td>\n",
       "      <td>0.199002</td>\n",
       "      <td>0.138511</td>\n",
       "      <td>0.153536</td>\n",
       "      <td>0.230251</td>\n",
       "      <td>0.206177</td>\n",
       "      <td>0.051485</td>\n",
       "      <td>0.173025</td>\n",
       "      <td>-0.019700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.635577</td>\n",
       "      <td>0.635577</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.120290</td>\n",
       "      <td>0.033143</td>\n",
       "      <td>0.199002</td>\n",
       "      <td>0.138511</td>\n",
       "      <td>0.153536</td>\n",
       "      <td>0.230251</td>\n",
       "      <td>0.206177</td>\n",
       "      <td>0.051485</td>\n",
       "      <td>0.173025</td>\n",
       "      <td>-0.019700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.573235</td>\n",
       "      <td>0.573235</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.120290</td>\n",
       "      <td>0.033143</td>\n",
       "      <td>0.199002</td>\n",
       "      <td>0.138511</td>\n",
       "      <td>0.153536</td>\n",
       "      <td>0.230251</td>\n",
       "      <td>0.206177</td>\n",
       "      <td>0.051485</td>\n",
       "      <td>0.173025</td>\n",
       "      <td>-0.019700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.551344</td>\n",
       "      <td>0.551344</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120290</td>\n",
       "      <td>0.033143</td>\n",
       "      <td>0.199002</td>\n",
       "      <td>0.138511</td>\n",
       "      <td>0.153536</td>\n",
       "      <td>0.230251</td>\n",
       "      <td>0.206177</td>\n",
       "      <td>0.051485</td>\n",
       "      <td>0.173025</td>\n",
       "      <td>-0.019700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.528801</td>\n",
       "      <td>0.528801</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80951</th>\n",
       "      <td>0.240966</td>\n",
       "      <td>0.036713</td>\n",
       "      <td>0.211662</td>\n",
       "      <td>0.092804</td>\n",
       "      <td>0.070580</td>\n",
       "      <td>0.213698</td>\n",
       "      <td>0.248727</td>\n",
       "      <td>-0.035184</td>\n",
       "      <td>0.200285</td>\n",
       "      <td>0.023412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80952</th>\n",
       "      <td>0.240966</td>\n",
       "      <td>0.036713</td>\n",
       "      <td>0.211662</td>\n",
       "      <td>0.092804</td>\n",
       "      <td>0.070580</td>\n",
       "      <td>0.213698</td>\n",
       "      <td>0.248727</td>\n",
       "      <td>-0.035184</td>\n",
       "      <td>0.200285</td>\n",
       "      <td>0.023412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80953</th>\n",
       "      <td>0.241003</td>\n",
       "      <td>0.036675</td>\n",
       "      <td>0.211645</td>\n",
       "      <td>0.092855</td>\n",
       "      <td>0.070612</td>\n",
       "      <td>0.213661</td>\n",
       "      <td>0.248740</td>\n",
       "      <td>-0.035199</td>\n",
       "      <td>0.200298</td>\n",
       "      <td>0.023366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80954</th>\n",
       "      <td>0.241003</td>\n",
       "      <td>0.036675</td>\n",
       "      <td>0.211645</td>\n",
       "      <td>0.092855</td>\n",
       "      <td>0.070612</td>\n",
       "      <td>0.213661</td>\n",
       "      <td>0.248740</td>\n",
       "      <td>-0.035199</td>\n",
       "      <td>0.200298</td>\n",
       "      <td>0.023366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80955</th>\n",
       "      <td>0.241003</td>\n",
       "      <td>0.036675</td>\n",
       "      <td>0.211645</td>\n",
       "      <td>0.092855</td>\n",
       "      <td>0.070612</td>\n",
       "      <td>0.213661</td>\n",
       "      <td>0.248740</td>\n",
       "      <td>-0.035199</td>\n",
       "      <td>0.200298</td>\n",
       "      <td>0.023366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80956 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.120290  0.033143  0.199002  0.138511  0.153536  0.230251  0.206177   \n",
       "1      0.120290  0.033143  0.199002  0.138511  0.153536  0.230251  0.206177   \n",
       "2      0.120290  0.033143  0.199002  0.138511  0.153536  0.230251  0.206177   \n",
       "3      0.120290  0.033143  0.199002  0.138511  0.153536  0.230251  0.206177   \n",
       "4      0.120290  0.033143  0.199002  0.138511  0.153536  0.230251  0.206177   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "80951  0.240966  0.036713  0.211662  0.092804  0.070580  0.213698  0.248727   \n",
       "80952  0.240966  0.036713  0.211662  0.092804  0.070580  0.213698  0.248727   \n",
       "80953  0.241003  0.036675  0.211645  0.092855  0.070612  0.213661  0.248740   \n",
       "80954  0.241003  0.036675  0.211645  0.092855  0.070612  0.213661  0.248740   \n",
       "80955  0.241003  0.036675  0.211645  0.092855  0.070612  0.213661  0.248740   \n",
       "\n",
       "              7         8         9  ...  NUM_PKTS_512_TO_1024_BYTES  \\\n",
       "0      0.051485  0.173025 -0.019700  ...                         0.0   \n",
       "1      0.051485  0.173025 -0.019700  ...                         0.0   \n",
       "2      0.051485  0.173025 -0.019700  ...                         0.0   \n",
       "3      0.051485  0.173025 -0.019700  ...                         0.0   \n",
       "4      0.051485  0.173025 -0.019700  ...                         0.0   \n",
       "...         ...       ...       ...  ...                         ...   \n",
       "80951 -0.035184  0.200285  0.023412  ...                         0.0   \n",
       "80952 -0.035184  0.200285  0.023412  ...                         0.0   \n",
       "80953 -0.035199  0.200298  0.023366  ...                         0.0   \n",
       "80954 -0.035199  0.200298  0.023366  ...                         0.0   \n",
       "80955 -0.035199  0.200298  0.023366  ...                         0.0   \n",
       "\n",
       "       NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
       "0                          0.00000        0.444604         0.444604   \n",
       "1                          0.00000        0.635577         0.635577   \n",
       "2                          0.00007        0.573235         0.573235   \n",
       "3                          0.00000        0.551344         0.551344   \n",
       "4                          0.00000        0.528801         0.528801   \n",
       "...                            ...             ...              ...   \n",
       "80951                      0.00000        0.000000         0.000000   \n",
       "80952                      0.00000        0.000000         0.000000   \n",
       "80953                      0.00000        0.000000         0.000000   \n",
       "80954                      0.00000        0.000000         0.000000   \n",
       "80955                      0.00000        0.000000         0.000000   \n",
       "\n",
       "       ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "0       0.000024        0.000024      0.000019        0.000019   \n",
       "1       0.000035        0.000035      0.000028        0.000028   \n",
       "2       0.000034        0.000034      0.000025        0.000025   \n",
       "3       0.000024        0.000024      0.000024        0.000024   \n",
       "4       0.000029        0.000029      0.000023        0.000023   \n",
       "...          ...             ...           ...             ...   \n",
       "80951   0.000002        0.000002      0.000004        0.000004   \n",
       "80952   0.000002        0.000002      0.000004        0.000004   \n",
       "80953   0.000002        0.000002      0.000004        0.000004   \n",
       "80954   0.000002        0.000002      0.000004        0.000004   \n",
       "80955   0.000002        0.000002      0.000004        0.000004   \n",
       "\n",
       "       DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \n",
       "0                 0.0              0.000019  \n",
       "1                 0.0              0.000027  \n",
       "2                 0.0              0.000025  \n",
       "3                 0.0              0.000024  \n",
       "4                 0.0              0.000023  \n",
       "...               ...                   ...  \n",
       "80951             0.0              0.000004  \n",
       "80952             0.0              0.000004  \n",
       "80953             0.0              0.000004  \n",
       "80954             0.0              0.000004  \n",
       "80955             0.0              0.000004  \n",
       "\n",
       "[80956 rows x 295 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuse_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "62BUDLtO4mla"
   },
   "outputs": [],
   "source": [
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2i48uLj74mla",
    "outputId": "a0dd33ee-824d-4328-a960-e656e3aaf0ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [02:41<02:37,  9.86s/it]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fa0da177850>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kienho/.local/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      " 53%|█████▎    | 16/30 [03:03<02:26, 10.45s/it]"
     ]
    }
   ],
   "source": [
    "n_est = [5,6,7,9,10] # cant be lower than 5 or 4\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    try:\n",
    "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
    "        clf_if.fit(benign_fuse_train_samples)\n",
    "    except Exception as e:\n",
    "        print(n_est)\n",
    "        continue\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rK-Rng9q4mla",
    "outputId": "1796db22-cfb8-4bf8-9004-6420c08c3399"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:13<00:00, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'con': 0.2}\n",
      "0.7246850923456903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9713    0.8682    0.9168    374702\n",
      "           1     0.4050    0.7773    0.5325     43236\n",
      "\n",
      "    accuracy                         0.8588    417938\n",
      "   macro avg     0.6881    0.8228    0.7247    417938\n",
      "weighted avg     0.9127    0.8588    0.8771    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,6,7,9,10]\n",
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    try:\n",
    "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
    "        clf_if.fit(normal_fuse_train_samples)\n",
    "    except Exception as e:\n",
    "        print(n_est)\n",
    "        continue\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nd0-H7UT4mlc"
   },
   "outputs": [],
   "source": [
    "# HBOS  Embeddings+Raw (Multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDquxErU4mld"
   },
   "outputs": [],
   "source": [
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLBIT-Rc4mld",
    "outputId": "8162929e-4879-40e2-a040-afc57eafe7c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [05:45<00:00,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'con': 0.05}\n",
      "0.8471039149382792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9177    0.9571    374702\n",
      "           1     0.5837    1.0000    0.7371     43236\n",
      "\n",
      "    accuracy                         0.9262    417938\n",
      "   macro avg     0.7918    0.9588    0.8471    417938\n",
      "weighted avg     0.9569    0.9262    0.9343    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "n_est = [5,10,15,20,25,30]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    \n",
    "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDcX0mma4mld",
    "outputId": "a2b64cfc-d413-4ba0-9f24-b4935343c315"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [06:05<00:00, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'con': 0.1}\n",
      "0.8471039149382792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9177    0.9571    374702\n",
      "           1     0.5837    1.0000    0.7371     43236\n",
      "\n",
      "    accuracy                         0.9262    417938\n",
      "   macro avg     0.7918    0.9588    0.8471    417938\n",
      "weighted avg     0.9569    0.9262    0.9343    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,10,15,20,25,30]\n",
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    \n",
    "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbDOqrcy4mle"
   },
   "outputs": [],
   "source": [
    "##  PCA  Emb+Raw (Multimodal/Fusion) Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nga82Fw_4mle",
    "outputId": "0fe52043-af21-45c1-a404-040ab5845efc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [05:07<00:00,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'con': 0.1}\n",
      "0.8207887532486517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8987    0.9466    374702\n",
      "           1     0.5325    1.0000    0.6949     43236\n",
      "\n",
      "    accuracy                         0.9092    417938\n",
      "   macro avg     0.7662    0.9493    0.8208    417938\n",
      "weighted avg     0.9516    0.9092    0.9206    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.pca import PCA\n",
    "n_est = [5,10,15,20,25,30]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = PCA(n_components=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sg6AcAUW4mlf",
    "outputId": "a9949458-96cf-44dc-b4f6-c73458cb2719"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [05:49<00:00,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 15, 'con': 0.2}\n",
      "0.8085873162698853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8893    0.9414    374702\n",
      "           1     0.5103    1.0000    0.6758     43236\n",
      "\n",
      "    accuracy                         0.9007    417938\n",
      "   macro avg     0.7552    0.9446    0.8086    417938\n",
      "weighted avg     0.9493    0.9007    0.9139    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,10,15,20,25,30]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = PCA(n_components=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yi8SO3tL4mlg"
   },
   "outputs": [],
   "source": [
    "##  IF  Emb+Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(benign_fuse_train_samples.columns)):\n",
    "    benign_fuse_train_samples.rename(columns={benign_fuse_train_samples.columns[i]: f\"feature {i}\"}, inplace=True)\n",
    "\n",
    "for i in range(len(normal_fuse_train_samples.columns)):\n",
    "    normal_fuse_train_samples.rename(columns={normal_fuse_train_samples.columns[i]: f\"feature {i}\"}, inplace=True)\n",
    "\n",
    "for i in range(len(fuse_test_samples.columns)):\n",
    "    fuse_test_samples.rename(columns={fuse_test_samples.columns[i]: f\"feature {i}\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9D0m4vb04mlg",
    "outputId": "bd5a55e6-ac70-4943-9b28-92474b5fb9e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "  4%|▍         | 1/24 [00:02<00:54,  2.36s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "  8%|▊         | 2/24 [00:04<00:51,  2.34s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 12%|█▎        | 3/24 [00:07<00:48,  2.33s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 17%|█▋        | 4/24 [00:09<00:46,  2.31s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 21%|██        | 5/24 [00:11<00:44,  2.32s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 25%|██▌       | 6/24 [00:13<00:40,  2.27s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 29%|██▉       | 7/24 [00:16<00:43,  2.56s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 33%|███▎      | 8/24 [00:20<00:44,  2.77s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 38%|███▊      | 9/24 [00:23<00:43,  2.90s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 42%|████▏     | 10/24 [00:26<00:41,  2.99s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 46%|████▌     | 11/24 [00:29<00:39,  3.06s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 50%|█████     | 12/24 [00:32<00:37,  3.11s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 54%|█████▍    | 13/24 [00:38<00:41,  3.78s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 58%|█████▊    | 14/24 [00:43<00:42,  4.22s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 62%|██████▎   | 15/24 [00:48<00:40,  4.50s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 67%|██████▋   | 16/24 [00:53<00:36,  4.58s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 71%|███████   | 17/24 [00:58<00:33,  4.81s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 75%|███████▌  | 18/24 [01:03<00:29,  4.91s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 79%|███████▉  | 19/24 [01:10<00:27,  5.50s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 83%|████████▎ | 20/24 [01:17<00:23,  5.85s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 21/24 [01:24<00:18,  6.10s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 22/24 [01:30<00:12,  6.29s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 23/24 [01:37<00:06,  6.42s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "100%|██████████| 24/24 [01:44<00:00,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50, 'con': 0.1}\n",
      "0.820368662501618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8984    0.9465    374702\n",
      "           1     0.5317    1.0000    0.6943     43236\n",
      "\n",
      "    accuracy                         0.9089    417938\n",
      "   macro avg     0.7659    0.9492    0.8204    417938\n",
      "weighted avg     0.9516    0.9089    0.9204    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "n_est = [20, 50, 100, 150]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples.to_numpy())\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCj-3u4t4mlg",
    "outputId": "5f6b1720-9662-4704-ba96-dd57ee32a900"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:52<00:00,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 150, 'con': 0.2}\n",
      "0.802806141381684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9991    0.8861    0.9392    374702\n",
      "           1     0.5015    0.9928    0.6664     43236\n",
      "\n",
      "    accuracy                         0.8972    417938\n",
      "   macro avg     0.7503    0.9395    0.8028    417938\n",
      "weighted avg     0.9476    0.8972    0.9110    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "n_est = [20, 50, 100, 150]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised attack classification (Fusion)\n",
    "\n",
    "We now train a supervised classifier on the fused features to predict multi-class attack labels:\n",
    "- Features: embeddings + raw numeric features from `df_fuse_train`/`df_fuse_test` (without `Label`, `Attacks`).\n",
    "- Target: `Attacks` (encoded integer classes from earlier `LabelEncoder`).\n",
    "- Model: HistGradientBoostingClassifier (fast, strong on tabular data). Class imbalance handled via per-sample weights.\n",
    "- Metrics: macro F1, per-class report, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare supervised train/test for attack classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.utils import class_weight\n",
    "import pickle\n",
    "\n",
    "# Build train features/targets from already prepared fused DataFrames\n",
    "X_sup_train = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_sup_test = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights to mitigate class imbalance on training set\n",
    "classes = np.unique(y_sup_train)\n",
    "class_w = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes, y=y_sup_train\n",
    ")\n",
    "class_to_w = {c: w for c, w in zip(classes, class_w)}\n",
    "sample_weight = y_sup_train.map(class_to_w).values\n",
    "\n",
    "# Feature names to all str\n",
    "X_sup_train.columns = X_sup_train.columns.map(str)\n",
    "X_sup_test.columns = X_sup_test.columns.map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Methods (Fused Features)\n",
    "\n",
    "Now we'll compare multiple classification algorithms on the fused features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:29<00:00, 23.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 20}\n",
      "Best Macro F1: 0.5253\n",
      "Model saved to: best_rf_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2864    0.6929    0.4052       736\n",
      "           1     0.8247    0.1546    0.2604      2070\n",
      "           2     1.0000    0.9999    1.0000     25812\n",
      "           3     0.3801    0.2172    0.2764      3030\n",
      "           4     0.7450    0.7581    0.7515     23290\n",
      "           5     0.6743    0.8695    0.7596     15354\n",
      "           6     0.7319    0.3708    0.4922      2856\n",
      "           7     0.7181    0.5836    0.6439      6774\n",
      "           8     0.4727    0.3088    0.3736       952\n",
      "           9     0.2139    0.4512    0.2902        82\n",
      "\n",
      "    accuracy                         0.7862     80956\n",
      "   macro avg     0.6047    0.5407    0.5253     80956\n",
      "weighted avg     0.7906    0.7862    0.7757     80956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with Grid Search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            rf_clf = RandomForestClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            rf_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_rf = rf_clf.predict(X_sup_test)\n",
    "            rf_f1 = f1_score(y_sup_test, y_pred_rf, average='macro')\n",
    "            \n",
    "            if rf_f1 > score:\n",
    "                score = rf_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = rf_clf\n",
    "                # Save best model\n",
    "                with open('best_rf_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(rf_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_rf_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Random Forest: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [15:37:55] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "100%|██████████| 27/27 [19:16<00:00, 42.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.5647\n",
      "Model saved to: best_xgb_classifier_fused.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2907    0.4946    0.3662       736\n",
      "           1     0.3924    0.2256    0.2865      2070\n",
      "           2     0.9590    0.9999    0.9790     25812\n",
      "           3     0.3018    0.4026    0.3450      3030\n",
      "           4     0.8416    0.6337    0.7230     23290\n",
      "           5     0.6984    0.8761    0.7772     15354\n",
      "           6     0.5502    0.5753    0.5625      2856\n",
      "           7     0.6730    0.6519    0.6623      6774\n",
      "           8     0.4403    0.5032    0.4696       952\n",
      "           9     0.3952    0.5976    0.4757        82\n",
      "\n",
      "    accuracy                         0.7740     80956\n",
      "   macro avg     0.5543    0.5961    0.5647     80956\n",
      "weighted avg     0.7856    0.7740    0.7724     80956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with Grid Search\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    import pickle\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST CLASSIFIER (Fused Features)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            xgb_clf = XGBClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                learning_rate=lr,\n",
    "                random_state=13,\n",
    "                tree_method='hist', \n",
    "                device=\"cuda\"\n",
    "            )\n",
    "            \n",
    "            xgb_clf.fit(X_sup_train, y_sup_train, sample_weight=sample_weight)\n",
    "            y_pred_xgb = xgb_clf.predict(X_sup_test)\n",
    "            xgb_f1 = f1_score(y_sup_test, y_pred_xgb, average='macro')\n",
    "            \n",
    "            if xgb_f1 > score:\n",
    "                score = xgb_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = xgb_clf\n",
    "                # Save best model\n",
    "                xgb_clf.save_model('best_xgb_classifier_fused.json')\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_xgb_classifier_fused.json\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed. XGBoost might not support your GPU.\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CatBoost Grid Search (Expanded)...\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [14:50<00:00, 32.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BEST CATBOOST HYPERPARAMETERS (Fused Features):\n",
      "{'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.5445\n",
      "============================================================\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_fused.cbm\n",
      "\n",
      "============================================================\n",
      "FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2905    0.6658    0.4045       736\n",
      "           1     0.3632    0.2155    0.2705      2070\n",
      "           2     1.0000    0.9999    1.0000     25812\n",
      "           3     0.2759    0.4251    0.3346      3030\n",
      "           4     0.8403    0.6202    0.7137     23290\n",
      "           5     0.6961    0.8709    0.7738     15354\n",
      "           6     0.5030    0.5875    0.5420      2856\n",
      "           7     0.6874    0.6392    0.6624      6774\n",
      "           8     0.4241    0.5462    0.4775       952\n",
      "           9     0.1694    0.6220    0.2663        82\n",
      "\n",
      "    accuracy                         0.7712     80956\n",
      "   macro avg     0.5250    0.6192    0.5445     80956\n",
      "weighted avg     0.7953    0.7712    0.7744     80956\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost with Grid Search (Expanded, no l2_leaf_reg/border_count, fixed best score logic)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"Starting CatBoost Grid Search (Expanded)...\")\n",
    "    \n",
    "    # Expanded hyperparameter grid\n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'  # Use 'CPU' if GPU not available\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_cat = cat_clf.predict(X_sup_test)\n",
    "            cat_f1 = f1_score(y_sup_test, y_pred_cat, average='macro')\n",
    "            \n",
    "            if cat_f1 > best_score:\n",
    "                best_score = cat_f1\n",
    "                best_params = {\n",
    "                    'iterations': iterations,\n",
    "                    'depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for fused features\n",
    "                best_model_path = \"best_catboost_classifier_fused.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEST CATBOOST HYPERPARAMETERS (Fused Features):\")\n",
    "    print(best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    if best_model_path:\n",
    "        print(f\"\\nBest CatBoost model saved to: {best_model_path}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    y_pred_best = best_model.predict(X_sup_test)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_sup_test, y_pred_best, digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed. Install with: pip install catboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:54<00:00, 12.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 20}\n",
      "Best Macro F1: 0.4549\n",
      "Model saved to: best_et_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2938    0.5924    0.3928       736\n",
      "           1     0.5602    0.1932    0.2874      2070\n",
      "           2     1.0000    0.9999    1.0000     25812\n",
      "           3     0.2758    0.1525    0.1964      3030\n",
      "           4     0.7024    0.7274    0.7146     23290\n",
      "           5     0.6446    0.7480    0.6925     15354\n",
      "           6     0.6161    0.2034    0.3059      2856\n",
      "           7     0.5465    0.5650    0.5556      6774\n",
      "           8     0.2255    0.2784    0.2492       952\n",
      "           9     0.1070    0.2805    0.1549        82\n",
      "\n",
      "    accuracy                         0.7440     80956\n",
      "   macro avg     0.4972    0.4741    0.4549     80956\n",
      "weighted avg     0.7407    0.7440    0.7344     80956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            et_clf = ExtraTreesClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            et_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_et = et_clf.predict(X_sup_test)\n",
    "            et_f1 = f1_score(y_sup_test, y_pred_et, average='macro')\n",
    "            \n",
    "            if et_f1 > score:\n",
    "                score = et_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = et_clf\n",
    "                # Save best model\n",
    "                with open('best_et_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(et_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_et_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Extra Trees: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Features Classification (Comparison Baseline)\n",
    "\n",
    "Now we'll train classifiers on **raw features only** (without graph embeddings) to compare the benefit of multimodal fusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw feature shape - Train: (94447, 39), Test: (40478, 39)\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Prepare raw features (without embeddings)\n",
    "# Use only the original numeric features from X_train/X_test\n",
    "\n",
    "X_raw_train = X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_train = y_train[\"Attack\"].copy()\n",
    "\n",
    "X_raw_test = X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_test = y_test[\"Attack\"].copy()\n",
    "\n",
    "# Encode labels\n",
    "y_raw_train_encoded = lab_enc.transform(y_train[\"Attack\"])\n",
    "y_raw_test_encoded = lab_enc.transform(y_test[\"Attack\"])\n",
    "\n",
    "# Compute sample weights\n",
    "classes_raw = np.unique(y_raw_train_encoded)\n",
    "class_w_raw = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_raw, y=y_raw_train_encoded\n",
    ")\n",
    "class_to_w_raw = {c: w for c, w in zip(classes_raw, class_w_raw)}\n",
    "sample_weight_raw = pd.Series(y_raw_train_encoded).map(class_to_w_raw).values\n",
    "\n",
    "# Feature names to str\n",
    "X_raw_train.columns = X_raw_train.columns.map(str)\n",
    "X_raw_test.columns = X_raw_test.columns.map(str)\n",
    "\n",
    "print(f\"Raw feature shape - Train: {X_raw_train.shape}, Test: {X_raw_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_raw_train_encoded))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Raw Features Only)\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:51<00:00, 12.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 20}\n",
      "Best Macro F1: 0.5572\n",
      "Model saved to: best_rf_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2895    0.9457    0.4433       368\n",
      "           1     0.2491    0.1304    0.1712      1035\n",
      "           2     0.9997    0.9996    0.9997     12906\n",
      "           3     0.4437    0.2990    0.3573      1515\n",
      "           4     0.8183    0.7138    0.7625     11645\n",
      "           5     0.6760    0.8639    0.7585      7677\n",
      "           6     0.6817    0.5189    0.5893      1428\n",
      "           7     0.6685    0.5799    0.6210      3387\n",
      "           8     0.2902    0.4664    0.3578       476\n",
      "           9     0.4694    0.5610    0.5111        41\n",
      "\n",
      "    accuracy                         0.7839     40478\n",
      "   macro avg     0.5586    0.6079    0.5572     40478\n",
      "weighted avg     0.7918    0.7839    0.7812     40478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Raw Features Only)\")\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = rf_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Raw Features Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [04:19<00:00,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.5449\n",
      "Model saved to: best_xgb_classifier_raw.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2954    0.7690    0.4268       368\n",
      "           1     0.1755    0.2155    0.1934      1035\n",
      "           2     0.9998    0.9995    0.9997     12906\n",
      "           3     0.3183    0.3914    0.3511      1515\n",
      "           4     0.8634    0.6389    0.7344     11645\n",
      "           5     0.6915    0.8085    0.7455      7677\n",
      "           6     0.5131    0.5609    0.5360      1428\n",
      "           7     0.6188    0.6067    0.6127      3387\n",
      "           8     0.2737    0.5462    0.3647       476\n",
      "           9     0.4138    0.5854    0.4848        41\n",
      "\n",
      "    accuracy                         0.7606     40478\n",
      "   macro avg     0.5163    0.6122    0.5449     40478\n",
      "weighted avg     0.7909    0.7606    0.7683     40478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Raw Features Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='cuda'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_raw_train, y_raw_train_encoded, sample_weight=sample_weight_raw)\n",
    "        y_pred = xgb_clf.predict(X_raw_test)\n",
    "        f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_raw.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_raw.json\\n\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Raw Features Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [03:08<00:00,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.5070\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_raw.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2764    0.9810    0.4313       368\n",
      "           1     0.1601    0.2783    0.2032      1035\n",
      "           2     0.9992    0.9992    0.9992     12906\n",
      "           3     0.2831    0.4264    0.3403      1515\n",
      "           4     0.8977    0.5503    0.6823     11645\n",
      "           5     0.6909    0.7691    0.7279      7677\n",
      "           6     0.4755    0.5987    0.5301      1428\n",
      "           7     0.6651    0.5970    0.6292      3387\n",
      "           8     0.2060    0.6071    0.3076       476\n",
      "           9     0.1264    0.8049    0.2185        41\n",
      "\n",
      "    accuracy                         0.7338     40478\n",
      "   macro avg     0.4781    0.6612    0.5070     40478\n",
      "weighted avg     0.8001    0.7338    0.7500     40478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Raw Features Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "            y_pred = cat_clf.predict(X_raw_test)\n",
    "            f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for raw features\n",
    "                best_model_path = \"best_catboost_classifier_raw.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Raw Features Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:47<00:00,  5.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 30}\n",
      "Best Macro F1: 0.5375\n",
      "Model saved to: best_et_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2950    0.8234    0.4344       368\n",
      "           1     0.2037    0.1266    0.1561      1035\n",
      "           2     0.9998    0.9995    0.9997     12906\n",
      "           3     0.4144    0.2667    0.3245      1515\n",
      "           4     0.7563    0.7490    0.7526     11645\n",
      "           5     0.6738    0.7667    0.7173      7677\n",
      "           6     0.6123    0.4867    0.5423      1428\n",
      "           7     0.6152    0.5621    0.5875      3387\n",
      "           8     0.3540    0.3004    0.3250       476\n",
      "           9     0.6333    0.4634    0.5352        41\n",
      "\n",
      "    accuracy                         0.7685     40478\n",
      "   macro avg     0.5558    0.5544    0.5375     40478\n",
      "weighted avg     0.7654    0.7685    0.7640     40478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Raw Features Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = et_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Only Classification (Graph Features)\n",
    "\n",
    "Now we'll train classifiers on **embeddings only** (graph features without raw features) to isolate the value of graph-based learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape - Train: (188894, 256), Test: (80956, 256)\n",
      "Number of classes: 10\n",
      "Using only graph embeddings (no raw features)\n"
     ]
    }
   ],
   "source": [
    "# Prepare embeddings-only features (graph features without raw data)\n",
    "# Extract only the embedding columns (first 256 dimensions from graph encoder)\n",
    "\n",
    "# From the fused dataframes, extract only embedding columns\n",
    "# df_fuse_train has: [0-255] = embeddings, [256+] = raw features\n",
    "num_embedding_dims = 256  # Based on the DGI encoder output dimension\n",
    "\n",
    "X_emb_train = df_fuse_train.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_emb_test = df_fuse_test.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights\n",
    "classes_emb = np.unique(y_emb_train)\n",
    "class_w_emb = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_emb, y=y_emb_train\n",
    ")\n",
    "class_to_w_emb = {c: w for c, w in zip(classes_emb, class_w_emb)}\n",
    "sample_weight_emb = y_emb_train.map(class_to_w_emb).values\n",
    "\n",
    "# Feature names to str\n",
    "X_emb_train.columns = X_emb_train.columns.map(str)\n",
    "X_emb_test.columns = X_emb_test.columns.map(str)\n",
    "\n",
    "print(f\"Embeddings shape - Train: {X_emb_train.shape}, Test: {X_emb_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_emb_train))}\")\n",
    "print(f\"Using only graph embeddings (no raw features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:10<00:00,  7.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 30}\n",
      "Best Macro F1: 0.1977\n",
      "Model saved to: best_rf_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0447    0.7215    0.0841       736\n",
      "           1     0.0738    0.2097    0.1092      2070\n",
      "           2     1.0000    0.9999    1.0000     25812\n",
      "           3     0.0870    0.2472    0.1287      3030\n",
      "           4     0.4311    0.0888    0.1473     23290\n",
      "           5     0.3434    0.2265    0.2730     15354\n",
      "           6     0.0903    0.0196    0.0322      2856\n",
      "           7     0.1500    0.1029    0.1220      6774\n",
      "           8     0.0464    0.2363    0.0776       952\n",
      "           9     0.0016    0.0732    0.0032        82\n",
      "\n",
      "    accuracy                         0.4207     80956\n",
      "   macro avg     0.2268    0.2926    0.1977     80956\n",
      "weighted avg     0.5298    0.4207    0.4336     80956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = rf_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [11:28<00:00, 25.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.2059\n",
      "Model saved to: best_xgb_classifier_embeddings.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0505    0.4579    0.0910       736\n",
      "           1     0.0800    0.1783    0.1104      2070\n",
      "           2     0.9544    0.9999    0.9767     25812\n",
      "           3     0.0809    0.1888    0.1133      3030\n",
      "           4     0.4525    0.1630    0.2397     23290\n",
      "           5     0.3518    0.1820    0.2399     15354\n",
      "           6     0.0969    0.1250    0.1092      2856\n",
      "           7     0.1446    0.0977    0.1166      6774\n",
      "           8     0.0371    0.1639    0.0606       952\n",
      "           9     0.0009    0.0732    0.0018        82\n",
      "\n",
      "    accuracy                         0.4306     80956\n",
      "   macro avg     0.2250    0.2630    0.2059     80956\n",
      "weighted avg     0.5227    0.4306    0.4481     80956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Embeddings Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='gpu'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_emb_train, y_emb_train, sample_weight=sample_weight_emb)\n",
    "        y_pred = xgb_clf.predict(X_emb_test)\n",
    "        f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_embeddings.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_embeddings.json\\n\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Embeddings Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [09:39<00:00, 21.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.01}\n",
      "Best Macro F1: 0.2035\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_embeddings.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0503    0.2174    0.0817       736\n",
      "           1     0.0948    0.1715    0.1221      2070\n",
      "           2     1.0000    0.9999    1.0000     25812\n",
      "           3     0.0778    0.2983    0.1234      3030\n",
      "           4     0.4480    0.1015    0.1656     23290\n",
      "           5     0.3362    0.2824    0.3070     15354\n",
      "           6     0.0740    0.0739    0.0739      2856\n",
      "           7     0.1585    0.0449    0.0699      6774\n",
      "           8     0.0536    0.2647    0.0891       952\n",
      "           9     0.0012    0.1341    0.0024        82\n",
      "\n",
      "    accuracy                         0.4287     80956\n",
      "   macro avg     0.2294    0.2589    0.2035     80956\n",
      "weighted avg     0.5338    0.4287    0.4427     80956\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Embeddings Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_emb_train, y_emb_train)\n",
    "            y_pred = cat_clf.predict(X_emb_test)\n",
    "            f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for embeddings\n",
    "                best_model_path = \"best_catboost_classifier_embeddings.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:35<00:00,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 20}\n",
      "Best Macro F1: 0.1761\n",
      "Model saved to: best_et_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0314    0.6495    0.0599       736\n",
      "           1     0.0864    0.3353    0.1374      2070\n",
      "           2     1.0000    0.9999    1.0000     25812\n",
      "           3     0.0839    0.1089    0.0948      3030\n",
      "           4     0.4025    0.0296    0.0551     23290\n",
      "           5     0.3489    0.1781    0.2358     15354\n",
      "           6     0.0758    0.0466    0.0577      2856\n",
      "           7     0.1295    0.0359    0.0562      6774\n",
      "           8     0.0357    0.2616    0.0628       952\n",
      "           9     0.0009    0.0854    0.0018        82\n",
      "\n",
      "    accuracy                         0.3875     80956\n",
      "   macro avg     0.2195    0.2731    0.1761     80956\n",
      "weighted avg     0.5204    0.3875    0.3945     80956\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = et_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Comparison Table\n",
    "\n",
    "Create a comparison table of all methods (Fused vs Raw features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\n",
      "===============================================================================================\n",
      "\n",
      "Instructions:\n",
      "1. Run all cells above to get F1 scores for each method\n",
      "2. Record the best Macro F1 score for each method\n",
      "3. Compare three approaches:\n",
      "   - Fused Features: Embeddings + Raw (Multimodal)\n",
      "   - Embeddings Only: Graph features only\n",
      "   - Raw Features: Traditional features only\n",
      "\n",
      "Expected format:\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Method               Fused (Emb+Raw)           Embeddings Only           Raw Only                 \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Random Forest        [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "XGBoost              [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "CatBoost             [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "Extra Trees          [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysis:\n",
      "- Fused features should show best performance (multimodal learning)\n",
      "- Embeddings capture structural/graph patterns\n",
      "- Raw features provide traditional statistical information\n",
      "- Compare to understand the contribution of each modality\n"
     ]
    }
   ],
   "source": [
    "# Create a summary comparison table\n",
    "# NOTE: After running all cells above, manually collect the F1 scores and create a comparison\n",
    "\n",
    "print(\"=\"*95)\n",
    "print(\"PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\")\n",
    "print(\"=\"*95)\n",
    "print(\"\\nInstructions:\")\n",
    "print(\"1. Run all cells above to get F1 scores for each method\")\n",
    "print(\"2. Record the best Macro F1 score for each method\")\n",
    "print(\"3. Compare three approaches:\")\n",
    "print(\"   - Fused Features: Embeddings + Raw (Multimodal)\")\n",
    "print(\"   - Embeddings Only: Graph features only\")\n",
    "print(\"   - Raw Features: Traditional features only\")\n",
    "print(\"\\nExpected format:\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Method':<20} {'Fused (Emb+Raw)':<25} {'Embeddings Only':<25} {'Raw Only':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Random Forest':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'XGBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'CatBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'Extra Trees':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"- Fused features should show best performance (multimodal learning)\")\n",
    "print(\"- Embeddings capture structural/graph patterns\")\n",
    "print(\"- Raw features provide traditional statistical information\")\n",
    "print(\"- Compare to understand the contribution of each modality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights & Interpretation\n",
    "\n",
    "After running all experiments, analyze the results to answer:\n",
    "\n",
    "1. **Which approach performs best overall?**\n",
    "   - Fused features (multimodal) should ideally outperform single modalities\n",
    "   - Compare the magnitude of improvements\n",
    "\n",
    "2. **What is the value of graph embeddings?**\n",
    "   - Compare Embeddings-only vs Raw-only to see if graph structure helps\n",
    "   - If embeddings alone beat raw features, graph learning is beneficial\n",
    "\n",
    "3. **Is multimodal fusion effective?**\n",
    "   - Compare Fused vs (Embeddings + Raw separately)\n",
    "   - Synergy should provide additional gains beyond individual modalities\n",
    "\n",
    "4. **Which classifier is most suitable?**\n",
    "   - Identify the best performing algorithm for each feature type\n",
    "   - Consider computational cost vs accuracy trade-offs\n",
    "\n",
    "5. **Feature contribution analysis:**\n",
    "   - If Fused ≈ Embeddings > Raw: Graph structure dominates\n",
    "   - If Fused ≈ Raw > Embeddings: Traditional features dominate\n",
    "   - If Fused > Both: True synergy from multimodal learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
