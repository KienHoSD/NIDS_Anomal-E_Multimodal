{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hjc3iIihKLn-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kienho/projects/NIDS_Anomal-E_revision/.conda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn import preprocessing\n",
        "from dgl.data import DGLDataset\n",
        "import dgl\n",
        "import time\n",
        "import networkx as nx\n",
        "import category_encoders as ce\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "import torch\n",
        "import tqdm\n",
        "import math\n",
        "\n",
        "from typing import *\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "import socket\n",
        "import struct\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SvWHb_BpKsLq"
      },
      "outputs": [],
      "source": [
        "file_name = \"NF-UNSW-NB15-v3.parquet\"\n",
        "data = pd.read_parquet(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "fqly1y-LMwYS",
        "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Label\n",
              "0    2151027\n",
              "1      91904\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3t4OREvSM33h"
      },
      "outputs": [],
      "source": [
        "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
        "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
        "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
        "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
        "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bTtHq0XqNXxI"
      },
      "outputs": [],
      "source": [
        "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUNIP-8zNkn9",
        "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Benign', 'Fuzzers', 'Exploits', 'Backdoor', 'Generic', 'DoS',\n",
              "       'Reconnaissance', 'Shellcode', 'Analysis', 'Worms'], dtype=object)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Attack.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AlPa58fVN7gB"
      },
      "outputs": [],
      "source": [
        "data = data.groupby(by='Attack').sample(frac=0.1, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "lcfAP6ViOp-J",
        "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FLOW_START_MILLISECONDS</th>\n",
              "      <th>FLOW_END_MILLISECONDS</th>\n",
              "      <th>IPV4_SRC_ADDR</th>\n",
              "      <th>IPV4_DST_ADDR</th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>...</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>SRC_TO_DST_IAT_MIN</th>\n",
              "      <th>SRC_TO_DST_IAT_MAX</th>\n",
              "      <th>SRC_TO_DST_IAT_AVG</th>\n",
              "      <th>SRC_TO_DST_IAT_STDDEV</th>\n",
              "      <th>DST_TO_SRC_IAT_MIN</th>\n",
              "      <th>DST_TO_SRC_IAT_MAX</th>\n",
              "      <th>DST_TO_SRC_IAT_AVG</th>\n",
              "      <th>DST_TO_SRC_IAT_STDDEV</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Attack</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Analysis</th>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>...</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Backdoor</th>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>...</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Benign</th>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>...</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS</th>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>...</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exploits</th>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>...</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fuzzers</th>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>...</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Generic</th>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>...</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reconnaissance</th>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>...</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shellcode</th>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>...</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worms</th>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 52 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                FLOW_START_MILLISECONDS  FLOW_END_MILLISECONDS  IPV4_SRC_ADDR  \\\n",
              "Attack                                                                          \n",
              "Analysis                            123                    123            123   \n",
              "Backdoor                            345                    345            345   \n",
              "Benign                           215103                 215103         215103   \n",
              "DoS                                 505                    505            505   \n",
              "Exploits                           3882                   3882           3882   \n",
              "Fuzzers                            2559                   2559           2559   \n",
              "Generic                             476                    476            476   \n",
              "Reconnaissance                     1129                   1129           1129   \n",
              "Shellcode                           159                    159            159   \n",
              "Worms                                14                     14             14   \n",
              "\n",
              "                IPV4_DST_ADDR  PROTOCOL  L7_PROTO  IN_BYTES  IN_PKTS  \\\n",
              "Attack                                                                 \n",
              "Analysis                  123       123       123       123      123   \n",
              "Backdoor                  345       345       345       345      345   \n",
              "Benign                 215103    215103    215103    215103   215103   \n",
              "DoS                       505       505       505       505      505   \n",
              "Exploits                 3882      3882      3882      3882     3882   \n",
              "Fuzzers                  2559      2559      2559      2559     2559   \n",
              "Generic                   476       476       476       476      476   \n",
              "Reconnaissance           1129      1129      1129      1129     1129   \n",
              "Shellcode                 159       159       159       159      159   \n",
              "Worms                      14        14        14        14       14   \n",
              "\n",
              "                OUT_BYTES  OUT_PKTS  ...  FTP_COMMAND_RET_CODE  \\\n",
              "Attack                               ...                         \n",
              "Analysis              123       123  ...                   123   \n",
              "Backdoor              345       345  ...                   345   \n",
              "Benign             215103    215103  ...                215103   \n",
              "DoS                   505       505  ...                   505   \n",
              "Exploits             3882      3882  ...                  3882   \n",
              "Fuzzers              2559      2559  ...                  2559   \n",
              "Generic               476       476  ...                   476   \n",
              "Reconnaissance       1129      1129  ...                  1129   \n",
              "Shellcode             159       159  ...                   159   \n",
              "Worms                  14        14  ...                    14   \n",
              "\n",
              "                SRC_TO_DST_IAT_MIN  SRC_TO_DST_IAT_MAX  SRC_TO_DST_IAT_AVG  \\\n",
              "Attack                                                                       \n",
              "Analysis                       123                 123                 123   \n",
              "Backdoor                       345                 345                 345   \n",
              "Benign                      215103              215103              215103   \n",
              "DoS                            505                 505                 505   \n",
              "Exploits                      3882                3882                3882   \n",
              "Fuzzers                       2559                2559                2559   \n",
              "Generic                        476                 476                 476   \n",
              "Reconnaissance                1129                1129                1129   \n",
              "Shellcode                      159                 159                 159   \n",
              "Worms                           14                  14                  14   \n",
              "\n",
              "                SRC_TO_DST_IAT_STDDEV  DST_TO_SRC_IAT_MIN  DST_TO_SRC_IAT_MAX  \\\n",
              "Attack                                                                          \n",
              "Analysis                          123                 123                 123   \n",
              "Backdoor                          345                 345                 345   \n",
              "Benign                         215103              215103              215103   \n",
              "DoS                               505                 505                 505   \n",
              "Exploits                         3882                3882                3882   \n",
              "Fuzzers                          2559                2559                2559   \n",
              "Generic                           476                 476                 476   \n",
              "Reconnaissance                   1129                1129                1129   \n",
              "Shellcode                         159                 159                 159   \n",
              "Worms                              14                  14                  14   \n",
              "\n",
              "                DST_TO_SRC_IAT_AVG  DST_TO_SRC_IAT_STDDEV   Label  \n",
              "Attack                                                             \n",
              "Analysis                       123                    123     123  \n",
              "Backdoor                       345                    345     345  \n",
              "Benign                      215103                 215103  215103  \n",
              "DoS                            505                    505     505  \n",
              "Exploits                      3882                   3882    3882  \n",
              "Fuzzers                       2559                   2559    2559  \n",
              "Generic                        476                    476     476  \n",
              "Reconnaissance                1129                   1129    1129  \n",
              "Shellcode                      159                    159     159  \n",
              "Worms                           14                     14      14  \n",
              "\n",
              "[10 rows x 52 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.groupby(by=\"Attack\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqRx5xCPOuv8"
      },
      "outputs": [],
      "source": [
        "# X = data.drop(columns=[\"Attack\", \"Label\"])\n",
        "# calculate the distance miliseconds betweeen columns 2 and 1, put the new column name FLOW_TIME_DIFF (Modified)\n",
        "# data['FLOW_DIFF_MILISECONDS'] = (data['FLOW_END_MILLISECONDS'] - data['FLOW_START_MILLISECONDS'])\n",
        "X = data.drop(columns=[\"Attack\", \"Label\", \"FLOW_START_MILLISECONDS\", \"FLOW_END_MILLISECONDS\",\n",
        "                       \"SRC_TO_DST_IAT_MIN\", \"SRC_TO_DST_IAT_MAX\", \"SRC_TO_DST_IAT_AVG\",\n",
        "                       \"SRC_TO_DST_IAT_STDDEV\", \"DST_TO_SRC_IAT_MIN\", \"DST_TO_SRC_IAT_MAX\",\n",
        "                       \"DST_TO_SRC_IAT_AVG\", \"DST_TO_SRC_IAT_STDDEV\"])\n",
        "y = data[[\"Attack\", \"Label\"]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=13, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bPfakXplPGGx"
      },
      "outputs": [],
      "source": [
        "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
        "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
        "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
        "                                  'FTP_COMMAND_RET_CODE'])\n",
        "encoder.fit(X_train, y_train.Label)\n",
        "\n",
        "# Transform on training set\n",
        "X_train = encoder.transform(X_train)\n",
        "\n",
        "# Transform on testing set\n",
        "X_test = encoder.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ibyOfV-8PouK"
      },
      "outputs": [],
      "source": [
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "asDnsSIWPee0"
      },
      "outputs": [],
      "source": [
        "scaler = Normalizer()\n",
        "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
        "scaler.fit(X_train[cols_to_norm])\n",
        "\n",
        "# Transform on training set\n",
        "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
        "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
        "\n",
        "# Transform on testing set\n",
        "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
        "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
        "\n",
        "train = pd.concat([X_train, y_train], axis=1)\n",
        "test = pd.concat([X_test, y_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "hErQbsnrPluV",
        "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IPV4_SRC_ADDR</th>\n",
              "      <th>IPV4_DST_ADDR</th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>TCP_FLAGS</th>\n",
              "      <th>CLIENT_TCP_FLAGS</th>\n",
              "      <th>...</th>\n",
              "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
              "      <th>TCP_WIN_MAX_IN</th>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <th>ICMP_TYPE</th>\n",
              "      <th>ICMP_IPV4_TYPE</th>\n",
              "      <th>DNS_QUERY_ID</th>\n",
              "      <th>DNS_QUERY_TYPE</th>\n",
              "      <th>DNS_TTL_ANSWER</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>287406</th>\n",
              "      <td>59.166.0.8</td>\n",
              "      <td>149.171.126.4</td>\n",
              "      <td>4.732152e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.003486</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000317</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>1.505900e-09</td>\n",
              "      <td>1.611550e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>2.249372e-06</td>\n",
              "      <td>0.001493</td>\n",
              "      <td>0.002850</td>\n",
              "      <td>2.127056e-08</td>\n",
              "      <td>2.097309e-08</td>\n",
              "      <td>4.396601e-09</td>\n",
              "      <td>4.397286e-09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.240589e-09</td>\n",
              "      <td>[4.732152333835413e-09, 0.0, 0.003485589444774...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610356</th>\n",
              "      <td>59.166.0.9</td>\n",
              "      <td>149.171.126.6</td>\n",
              "      <td>6.932495e-10</td>\n",
              "      <td>7.976222e-09</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>9.621527e-10</td>\n",
              "      <td>9.621527e-10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.010061e-09</td>\n",
              "      <td>4.009943e-09</td>\n",
              "      <td>1.969528e-08</td>\n",
              "      <td>1.969835e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.899640e-08</td>\n",
              "      <td>[6.932494894241551e-10, 7.976221604219919e-09,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456518</th>\n",
              "      <td>59.166.0.2</td>\n",
              "      <td>149.171.126.2</td>\n",
              "      <td>6.381741e-07</td>\n",
              "      <td>2.401223e-07</td>\n",
              "      <td>0.060366</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>0.038930</td>\n",
              "      <td>0.000379</td>\n",
              "      <td>2.030844e-07</td>\n",
              "      <td>2.173323e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.183020</td>\n",
              "      <td>0.183020</td>\n",
              "      <td>4.321202e-07</td>\n",
              "      <td>4.840666e-07</td>\n",
              "      <td>5.929219e-07</td>\n",
              "      <td>5.930143e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.718822e-07</td>\n",
              "      <td>[6.381740567526722e-07, 2.40122348914616e-07, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2204716</th>\n",
              "      <td>59.166.0.0</td>\n",
              "      <td>149.171.126.0</td>\n",
              "      <td>1.390953e-08</td>\n",
              "      <td>2.334703e-08</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000476</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>4.426392e-09</td>\n",
              "      <td>4.736937e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.002792</td>\n",
              "      <td>0.003191</td>\n",
              "      <td>4.531849e-09</td>\n",
              "      <td>4.766241e-09</td>\n",
              "      <td>1.292322e-08</td>\n",
              "      <td>1.292524e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.246465e-08</td>\n",
              "      <td>[1.3909530687793816e-08, 2.334702611325599e-08...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1090799</th>\n",
              "      <td>59.166.0.1</td>\n",
              "      <td>149.171.126.3</td>\n",
              "      <td>4.602189e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001485</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>1.464542e-09</td>\n",
              "      <td>1.567291e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>9.114981e-07</td>\n",
              "      <td>0.001980</td>\n",
              "      <td>0.001320</td>\n",
              "      <td>8.530939e-11</td>\n",
              "      <td>8.530939e-11</td>\n",
              "      <td>4.275853e-09</td>\n",
              "      <td>4.276519e-09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.124125e-09</td>\n",
              "      <td>[4.602188564242696e-09, 0.0, 0.000212743645752...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 42 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        IPV4_SRC_ADDR  IPV4_DST_ADDR      PROTOCOL      L7_PROTO  IN_BYTES  \\\n",
              "287406     59.166.0.8  149.171.126.4  4.732152e-09  0.000000e+00  0.003486   \n",
              "610356     59.166.0.9  149.171.126.6  6.932495e-10  7.976222e-09  0.000215   \n",
              "1456518    59.166.0.2  149.171.126.2  6.381741e-07  2.401223e-07  0.060366   \n",
              "2204716    59.166.0.0  149.171.126.0  1.390953e-08  2.334703e-08  0.000405   \n",
              "1090799    59.166.0.1  149.171.126.3  4.602189e-09  0.000000e+00  0.000213   \n",
              "\n",
              "          IN_PKTS  OUT_BYTES  OUT_PKTS     TCP_FLAGS  CLIENT_TCP_FLAGS  ...  \\\n",
              "287406   0.000005   0.000317  0.000004  1.505900e-09      1.611550e-09  ...   \n",
              "610356   0.000002   0.000128  0.000002  9.621527e-10      9.621527e-10  ...   \n",
              "1456518  0.000354   0.038930  0.000379  2.030844e-07      2.173323e-07  ...   \n",
              "2204716  0.000006   0.000476  0.000004  4.426392e-09      4.736937e-09  ...   \n",
              "1090799  0.000003   0.001485  0.000003  1.464542e-09      1.567291e-09  ...   \n",
              "\n",
              "         NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
              "287406                  2.249372e-06        0.001493         0.002850   \n",
              "610356                  0.000000e+00        0.000000         0.000000   \n",
              "1456518                 0.000000e+00        0.183020         0.183020   \n",
              "2204716                 0.000000e+00        0.002792         0.003191   \n",
              "1090799                 9.114981e-07        0.001980         0.001320   \n",
              "\n",
              "            ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
              "287406   2.127056e-08    2.097309e-08  4.396601e-09    4.397286e-09   \n",
              "610356   4.010061e-09    4.009943e-09  1.969528e-08    1.969835e-08   \n",
              "1456518  4.321202e-07    4.840666e-07  5.929219e-07    5.930143e-07   \n",
              "2204716  4.531849e-09    4.766241e-09  1.292322e-08    1.292524e-08   \n",
              "1090799  8.530939e-11    8.530939e-11  4.275853e-09    4.276519e-09   \n",
              "\n",
              "         DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \\\n",
              "287406              0.0          4.240589e-09   \n",
              "610356              0.0          1.899640e-08   \n",
              "1456518             0.0          5.718822e-07   \n",
              "2204716             0.0          1.246465e-08   \n",
              "1090799             0.0          4.124125e-09   \n",
              "\n",
              "                                                         h  \n",
              "287406   [4.732152333835413e-09, 0.0, 0.003485589444774...  \n",
              "610356   [6.932494894241551e-10, 7.976221604219919e-09,...  \n",
              "1456518  [6.381740567526722e-07, 2.40122348914616e-07, ...  \n",
              "2204716  [1.3909530687793816e-08, 2.334702611325599e-08...  \n",
              "1090799  [4.602188564242696e-09, 0.0, 0.000212743645752...  \n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "d_tLtK4WPtrF"
      },
      "outputs": [],
      "source": [
        "lab_enc = preprocessing.LabelEncoder()\n",
        "lab_enc.fit(data[\"Attack\"])\n",
        "\n",
        "# Transform on training set\n",
        "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
        "\n",
        "# Transform on testing set\n",
        "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8yaicjecP1fZ"
      },
      "outputs": [],
      "source": [
        "# Training graph\n",
        "\n",
        "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
        "           [\"h\", \"Label\", \"Attack\"], create_using=nx.MultiGraph())\n",
        "train_g = train_g.to_directed()\n",
        "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label'])\n",
        "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
        "train_g.edata['h'].shape[1]])\n",
        "train_g.ndata['h'] = nfeat_weight\n",
        "\n",
        "# Testing graph\n",
        "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
        "            [\"h\", \"Label\", \"Attack\"], create_using=nx.MultiGraph())\n",
        "\n",
        "test_g = test_g.to_directed()\n",
        "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label'])\n",
        "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
        "test_g.edata['h'].shape[1]])\n",
        "test_g.ndata['h'] = nfeat_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PUV6DgJ9QRaP"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "import tqdm\n",
        "import gc\n",
        "\n",
        "class SAGELayer(nn.Module):\n",
        "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
        "      super(SAGELayer, self).__init__()\n",
        "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
        "      self.activation = F.relu\n",
        "      self.W_edge = nn.Linear(128 * 2, 256)\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      gain = nn.init.calculate_gain('relu')\n",
        "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
        "\n",
        "    def message_func(self, edges):\n",
        "      return {'m':  edges.data['h']}\n",
        "\n",
        "    def forward(self, g_dgl, nfeats, efeats):\n",
        "      with g_dgl.local_scope():\n",
        "        g = g_dgl\n",
        "        g.ndata['h'] = nfeats\n",
        "        g.edata['h'] = efeats\n",
        "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
        "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
        "\n",
        "        # Compute edge embeddings\n",
        "        u, v = g.edges()\n",
        "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
        "        return g.ndata['h'], edge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_xo-3K4QRGqc"
      },
      "outputs": [],
      "source": [
        "class SAGE(nn.Module):\n",
        "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
        "      super(SAGE, self).__init__()\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
        "\n",
        "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
        "      if corrupt:\n",
        "        e_perm = torch.randperm(g.number_of_edges())\n",
        "        #n_perm = torch.randperm(g.number_of_nodes())\n",
        "        efeats = efeats[e_perm]\n",
        "        #nfeats = nfeats[n_perm]\n",
        "      for i, layer in enumerate(self.layers):\n",
        "        #nfeats = layer(g, nfeats, efeats)\n",
        "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
        "      #return nfeats.sum(1)\n",
        "      return nfeats.sum(1), e_feats.sum(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6uuxRtLuRJQL"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, n_hidden):\n",
        "      super(Discriminator, self).__init__()\n",
        "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def uniform(self, size, tensor):\n",
        "      bound = 1.0 / math.sqrt(size)\n",
        "      if tensor is not None:\n",
        "        tensor.data.uniform_(-bound, bound)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      size = self.weight.size(0)\n",
        "      self.uniform(size, self.weight)\n",
        "\n",
        "    def forward(self, features, summary):\n",
        "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
        "      return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZPbVjlCyRUco"
      },
      "outputs": [],
      "source": [
        "class DGI(nn.Module):\n",
        "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
        "      super(DGI, self).__init__()\n",
        "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
        "      #self.discriminator = Discriminator(128)\n",
        "      self.discriminator = Discriminator(256)\n",
        "      self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, g, n_features, e_features):\n",
        "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
        "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
        "      self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, g, n_features, e_features):\n",
        "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
        "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
        "\n",
        "      positive = positive[1]\n",
        "      negative = negative[1]\n",
        "\n",
        "      summary = torch.sigmoid(positive.mean(dim=0))\n",
        "\n",
        "      positive = self.discriminator(positive, summary)\n",
        "      negative = self.discriminator(negative, summary)\n",
        "\n",
        "      l1 = self.loss(positive, torch.ones_like(positive))\n",
        "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
        "\n",
        "      return l1 + l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sKnfpWFMR19u"
      },
      "outputs": [],
      "source": [
        "ndim_in = train_g.ndata['h'].shape[1]\n",
        "hidden_features = 128\n",
        "ndim_out = 128\n",
        "num_layers = 1\n",
        "edim = train_g.edata['h'].shape[1]\n",
        "learning_rate = 1e-3\n",
        "epochs = 4000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aSl_9qY8SbA0"
      },
      "outputs": [],
      "source": [
        "dgi = DGI(ndim_in,\n",
        "    ndim_out,\n",
        "    edim,\n",
        "    F.relu)\n",
        "\n",
        "dgi = dgi.to('cuda')\n",
        "\n",
        "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
        "                lr=1e-3,\n",
        "                weight_decay=0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9K6_cOiWSdJA"
      },
      "outputs": [],
      "source": [
        "# Format node and edge features for E-GraphSAGE\n",
        "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
        "                                   (train_g.ndata['h'].shape[0], 1,\n",
        "                                    train_g.ndata['h'].shape[1]))\n",
        "\n",
        "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
        "                                   (train_g.edata['h'].shape[0], 1,\n",
        "                                    train_g.edata['h'].shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "O44auIyWSexg"
      },
      "outputs": [],
      "source": [
        "# Convert to GPU\n",
        "train_g = train_g.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gZtafIdxSheN"
      },
      "outputs": [],
      "source": [
        "# cnt_wait = 0\n",
        "# best = 1e9\n",
        "# best_t = 0\n",
        "# dur = []\n",
        "# node_features = train_g.ndata['h'] \n",
        "# edge_features = train_g.edata['h']\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#     dgi.train()\n",
        "#     if epoch >= 3:\n",
        "#         t0 = time.time()\n",
        "\n",
        "#     dgi_optimizer.zero_grad()\n",
        "#     loss = dgi(train_g, node_features, edge_features)\n",
        "#     loss.backward()\n",
        "#     dgi_optimizer.step()\n",
        "\n",
        "#     if loss < best:\n",
        "#         best = loss\n",
        "#         best_t = epoch\n",
        "#         cnt_wait = 0\n",
        "#         torch.save(dgi.state_dict(), 'best_dgi_UNSW_v3.pkl')\n",
        "#     else:\n",
        "#         cnt_wait += 1\n",
        "\n",
        "#   # if cnt_wait == patience:\n",
        "#   #     print('Early stopping!')\n",
        "#   #     break\n",
        "\n",
        "#     if epoch >= 3:\n",
        "#         dur.append(time.time() - t0)\n",
        "\n",
        "#     if epoch % 50 == 0:\n",
        "\n",
        "#         print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
        "#             \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
        "#               loss.item(),\n",
        "#               train_g.num_edges() / np.mean(dur) / 1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RZ2HAQDAF-4c",
        "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dgi.load_state_dict(torch.load('best_dgi_UNSW_v3.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6Ek16GkRStKP"
      },
      "outputs": [],
      "source": [
        "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
        "training_emb = training_emb.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-FwaBlOdS4ep"
      },
      "outputs": [],
      "source": [
        "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
        "                                   (test_g.ndata['h'].shape[0], 1,\n",
        "                                    test_g.ndata['h'].shape[1]))\n",
        "\n",
        "\n",
        "\n",
        "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
        "                                   (test_g.edata['h'].shape[0], 1,\n",
        "                                    test_g.edata['h'].shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "SBa-rdivS6cQ"
      },
      "outputs": [],
      "source": [
        "# Convert to GPU\n",
        "test_g = test_g.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "W12WLjslS-kx"
      },
      "outputs": [],
      "source": [
        "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
        "testing_emb = testing_emb.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ERsOAMjeS_D8"
      },
      "outputs": [],
      "source": [
        "df_train = pd.DataFrame(training_emb, )\n",
        "df_train[\"Attack\"] = lab_enc.inverse_transform(\n",
        "        train_g.edata['Attack'].detach().cpu().numpy())\n",
        "df_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
        "\n",
        "df_test = pd.DataFrame(testing_emb, )\n",
        "df_test[\"Attack\"] = lab_enc.inverse_transform(\n",
        "        test_g.edata['Attack'].detach().cpu().numpy())\n",
        "df_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "B8p79H9dat5T",
        "outputId": "0d6e82d8-5d02-49eb-a16f-d44e52ea3dff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>Attack</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.121418</td>\n",
              "      <td>0.007501</td>\n",
              "      <td>0.090197</td>\n",
              "      <td>0.078896</td>\n",
              "      <td>0.035713</td>\n",
              "      <td>0.041624</td>\n",
              "      <td>0.239117</td>\n",
              "      <td>0.190543</td>\n",
              "      <td>0.174904</td>\n",
              "      <td>0.032322</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021099</td>\n",
              "      <td>0.043224</td>\n",
              "      <td>-0.158824</td>\n",
              "      <td>0.032615</td>\n",
              "      <td>0.173656</td>\n",
              "      <td>0.117433</td>\n",
              "      <td>0.026014</td>\n",
              "      <td>0.211770</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.121418</td>\n",
              "      <td>0.007501</td>\n",
              "      <td>0.090197</td>\n",
              "      <td>0.078896</td>\n",
              "      <td>0.035713</td>\n",
              "      <td>0.041624</td>\n",
              "      <td>0.239117</td>\n",
              "      <td>0.190543</td>\n",
              "      <td>0.174904</td>\n",
              "      <td>0.032322</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021099</td>\n",
              "      <td>0.043224</td>\n",
              "      <td>-0.158824</td>\n",
              "      <td>0.032615</td>\n",
              "      <td>0.173656</td>\n",
              "      <td>0.117433</td>\n",
              "      <td>0.026014</td>\n",
              "      <td>0.211770</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.121418</td>\n",
              "      <td>0.007501</td>\n",
              "      <td>0.090197</td>\n",
              "      <td>0.078896</td>\n",
              "      <td>0.035713</td>\n",
              "      <td>0.041624</td>\n",
              "      <td>0.239117</td>\n",
              "      <td>0.190543</td>\n",
              "      <td>0.174904</td>\n",
              "      <td>0.032322</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021099</td>\n",
              "      <td>0.043224</td>\n",
              "      <td>-0.158824</td>\n",
              "      <td>0.032615</td>\n",
              "      <td>0.173656</td>\n",
              "      <td>0.117433</td>\n",
              "      <td>0.026014</td>\n",
              "      <td>0.211770</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.121418</td>\n",
              "      <td>0.007501</td>\n",
              "      <td>0.090197</td>\n",
              "      <td>0.078896</td>\n",
              "      <td>0.035713</td>\n",
              "      <td>0.041624</td>\n",
              "      <td>0.239117</td>\n",
              "      <td>0.190543</td>\n",
              "      <td>0.174904</td>\n",
              "      <td>0.032322</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021099</td>\n",
              "      <td>0.043224</td>\n",
              "      <td>-0.158824</td>\n",
              "      <td>0.032615</td>\n",
              "      <td>0.173656</td>\n",
              "      <td>0.117433</td>\n",
              "      <td>0.026014</td>\n",
              "      <td>0.211770</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.121418</td>\n",
              "      <td>0.007501</td>\n",
              "      <td>0.090197</td>\n",
              "      <td>0.078896</td>\n",
              "      <td>0.035713</td>\n",
              "      <td>0.041624</td>\n",
              "      <td>0.239117</td>\n",
              "      <td>0.190543</td>\n",
              "      <td>0.174904</td>\n",
              "      <td>0.032322</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021099</td>\n",
              "      <td>0.043224</td>\n",
              "      <td>-0.158824</td>\n",
              "      <td>0.032615</td>\n",
              "      <td>0.173656</td>\n",
              "      <td>0.117433</td>\n",
              "      <td>0.026014</td>\n",
              "      <td>0.211770</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314005</th>\n",
              "      <td>-0.034942</td>\n",
              "      <td>-0.142787</td>\n",
              "      <td>0.118079</td>\n",
              "      <td>-0.010222</td>\n",
              "      <td>0.083586</td>\n",
              "      <td>0.216002</td>\n",
              "      <td>0.172589</td>\n",
              "      <td>0.116556</td>\n",
              "      <td>0.038826</td>\n",
              "      <td>0.018499</td>\n",
              "      <td>...</td>\n",
              "      <td>0.057794</td>\n",
              "      <td>-0.034488</td>\n",
              "      <td>-0.035043</td>\n",
              "      <td>0.129560</td>\n",
              "      <td>0.253324</td>\n",
              "      <td>0.230403</td>\n",
              "      <td>0.117333</td>\n",
              "      <td>0.178448</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314006</th>\n",
              "      <td>-0.034942</td>\n",
              "      <td>-0.142787</td>\n",
              "      <td>0.118079</td>\n",
              "      <td>-0.010222</td>\n",
              "      <td>0.083586</td>\n",
              "      <td>0.216002</td>\n",
              "      <td>0.172589</td>\n",
              "      <td>0.116556</td>\n",
              "      <td>0.038826</td>\n",
              "      <td>0.018499</td>\n",
              "      <td>...</td>\n",
              "      <td>0.057794</td>\n",
              "      <td>-0.034488</td>\n",
              "      <td>-0.035043</td>\n",
              "      <td>0.129560</td>\n",
              "      <td>0.253324</td>\n",
              "      <td>0.230403</td>\n",
              "      <td>0.117333</td>\n",
              "      <td>0.178448</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314007</th>\n",
              "      <td>-0.035304</td>\n",
              "      <td>-0.134709</td>\n",
              "      <td>0.114296</td>\n",
              "      <td>-0.015308</td>\n",
              "      <td>0.088370</td>\n",
              "      <td>0.212577</td>\n",
              "      <td>0.170182</td>\n",
              "      <td>0.115769</td>\n",
              "      <td>0.038513</td>\n",
              "      <td>0.021948</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054432</td>\n",
              "      <td>-0.034924</td>\n",
              "      <td>-0.032609</td>\n",
              "      <td>0.128531</td>\n",
              "      <td>0.245631</td>\n",
              "      <td>0.230466</td>\n",
              "      <td>0.115084</td>\n",
              "      <td>0.177245</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314008</th>\n",
              "      <td>-0.035919</td>\n",
              "      <td>-0.132791</td>\n",
              "      <td>0.112944</td>\n",
              "      <td>-0.015819</td>\n",
              "      <td>0.091087</td>\n",
              "      <td>0.212746</td>\n",
              "      <td>0.170361</td>\n",
              "      <td>0.118652</td>\n",
              "      <td>0.041752</td>\n",
              "      <td>0.021718</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056433</td>\n",
              "      <td>-0.036609</td>\n",
              "      <td>-0.031549</td>\n",
              "      <td>0.124415</td>\n",
              "      <td>0.245755</td>\n",
              "      <td>0.229340</td>\n",
              "      <td>0.112841</td>\n",
              "      <td>0.176990</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314009</th>\n",
              "      <td>-0.035919</td>\n",
              "      <td>-0.132791</td>\n",
              "      <td>0.112944</td>\n",
              "      <td>-0.015819</td>\n",
              "      <td>0.091087</td>\n",
              "      <td>0.212746</td>\n",
              "      <td>0.170361</td>\n",
              "      <td>0.118652</td>\n",
              "      <td>0.041752</td>\n",
              "      <td>0.021718</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056433</td>\n",
              "      <td>-0.036609</td>\n",
              "      <td>-0.031549</td>\n",
              "      <td>0.124415</td>\n",
              "      <td>0.245755</td>\n",
              "      <td>0.229340</td>\n",
              "      <td>0.112841</td>\n",
              "      <td>0.176990</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>314010 rows × 258 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0         1         2         3         4         5         6  \\\n",
              "0       0.121418  0.007501  0.090197  0.078896  0.035713  0.041624  0.239117   \n",
              "1       0.121418  0.007501  0.090197  0.078896  0.035713  0.041624  0.239117   \n",
              "2       0.121418  0.007501  0.090197  0.078896  0.035713  0.041624  0.239117   \n",
              "3       0.121418  0.007501  0.090197  0.078896  0.035713  0.041624  0.239117   \n",
              "4       0.121418  0.007501  0.090197  0.078896  0.035713  0.041624  0.239117   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "314005 -0.034942 -0.142787  0.118079 -0.010222  0.083586  0.216002  0.172589   \n",
              "314006 -0.034942 -0.142787  0.118079 -0.010222  0.083586  0.216002  0.172589   \n",
              "314007 -0.035304 -0.134709  0.114296 -0.015308  0.088370  0.212577  0.170182   \n",
              "314008 -0.035919 -0.132791  0.112944 -0.015819  0.091087  0.212746  0.170361   \n",
              "314009 -0.035919 -0.132791  0.112944 -0.015819  0.091087  0.212746  0.170361   \n",
              "\n",
              "               7         8         9  ...       248       249       250  \\\n",
              "0       0.190543  0.174904  0.032322  ...  0.021099  0.043224 -0.158824   \n",
              "1       0.190543  0.174904  0.032322  ...  0.021099  0.043224 -0.158824   \n",
              "2       0.190543  0.174904  0.032322  ...  0.021099  0.043224 -0.158824   \n",
              "3       0.190543  0.174904  0.032322  ...  0.021099  0.043224 -0.158824   \n",
              "4       0.190543  0.174904  0.032322  ...  0.021099  0.043224 -0.158824   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "314005  0.116556  0.038826  0.018499  ...  0.057794 -0.034488 -0.035043   \n",
              "314006  0.116556  0.038826  0.018499  ...  0.057794 -0.034488 -0.035043   \n",
              "314007  0.115769  0.038513  0.021948  ...  0.054432 -0.034924 -0.032609   \n",
              "314008  0.118652  0.041752  0.021718  ...  0.056433 -0.036609 -0.031549   \n",
              "314009  0.118652  0.041752  0.021718  ...  0.056433 -0.036609 -0.031549   \n",
              "\n",
              "             251       252       253       254       255  Attack  Label  \n",
              "0       0.032615  0.173656  0.117433  0.026014  0.211770  Benign      0  \n",
              "1       0.032615  0.173656  0.117433  0.026014  0.211770  Benign      0  \n",
              "2       0.032615  0.173656  0.117433  0.026014  0.211770  Benign      0  \n",
              "3       0.032615  0.173656  0.117433  0.026014  0.211770  Benign      0  \n",
              "4       0.032615  0.173656  0.117433  0.026014  0.211770  Benign      0  \n",
              "...          ...       ...       ...       ...       ...     ...    ...  \n",
              "314005  0.129560  0.253324  0.230403  0.117333  0.178448  Benign      0  \n",
              "314006  0.129560  0.253324  0.230403  0.117333  0.178448  Benign      0  \n",
              "314007  0.128531  0.245631  0.230466  0.115084  0.177245  Benign      0  \n",
              "314008  0.124415  0.245755  0.229340  0.112841  0.176990  Benign      0  \n",
              "314009  0.124415  0.245755  0.229340  0.112841  0.176990  Benign      0  \n",
              "\n",
              "[314010 rows x 258 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ScEk1y_TzzX"
      },
      "source": [
        "# Embeddings CBLOF  Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZYABKzdrTGas"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import dgl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import gc\n",
        "\n",
        "from tqdm import tqdm\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "RkFS_-dcTJeK"
      },
      "outputs": [],
      "source": [
        "benign_train_samples = df_train[df_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "normal_train_samples = df_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "train_labels = df_train[\"Label\"]\n",
        "test_labels = df_test[\"Label\"]\n",
        "\n",
        "test_samples = df_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.120862</td>\n",
              "      <td>0.009952</td>\n",
              "      <td>0.089464</td>\n",
              "      <td>0.078869</td>\n",
              "      <td>0.037023</td>\n",
              "      <td>0.041781</td>\n",
              "      <td>0.239061</td>\n",
              "      <td>0.191186</td>\n",
              "      <td>0.174297</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>...</td>\n",
              "      <td>0.385405</td>\n",
              "      <td>0.090662</td>\n",
              "      <td>0.020782</td>\n",
              "      <td>0.042742</td>\n",
              "      <td>-0.158264</td>\n",
              "      <td>0.030908</td>\n",
              "      <td>0.173386</td>\n",
              "      <td>0.118791</td>\n",
              "      <td>0.025483</td>\n",
              "      <td>0.211854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.120862</td>\n",
              "      <td>0.009952</td>\n",
              "      <td>0.089464</td>\n",
              "      <td>0.078869</td>\n",
              "      <td>0.037023</td>\n",
              "      <td>0.041781</td>\n",
              "      <td>0.239061</td>\n",
              "      <td>0.191186</td>\n",
              "      <td>0.174297</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>...</td>\n",
              "      <td>0.385405</td>\n",
              "      <td>0.090662</td>\n",
              "      <td>0.020782</td>\n",
              "      <td>0.042742</td>\n",
              "      <td>-0.158264</td>\n",
              "      <td>0.030908</td>\n",
              "      <td>0.173386</td>\n",
              "      <td>0.118791</td>\n",
              "      <td>0.025483</td>\n",
              "      <td>0.211854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.120862</td>\n",
              "      <td>0.009952</td>\n",
              "      <td>0.089464</td>\n",
              "      <td>0.078869</td>\n",
              "      <td>0.037023</td>\n",
              "      <td>0.041781</td>\n",
              "      <td>0.239061</td>\n",
              "      <td>0.191186</td>\n",
              "      <td>0.174297</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>...</td>\n",
              "      <td>0.385405</td>\n",
              "      <td>0.090662</td>\n",
              "      <td>0.020782</td>\n",
              "      <td>0.042742</td>\n",
              "      <td>-0.158264</td>\n",
              "      <td>0.030908</td>\n",
              "      <td>0.173386</td>\n",
              "      <td>0.118791</td>\n",
              "      <td>0.025483</td>\n",
              "      <td>0.211854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.120862</td>\n",
              "      <td>0.009952</td>\n",
              "      <td>0.089464</td>\n",
              "      <td>0.078869</td>\n",
              "      <td>0.037023</td>\n",
              "      <td>0.041781</td>\n",
              "      <td>0.239061</td>\n",
              "      <td>0.191186</td>\n",
              "      <td>0.174297</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>...</td>\n",
              "      <td>0.385405</td>\n",
              "      <td>0.090662</td>\n",
              "      <td>0.020782</td>\n",
              "      <td>0.042742</td>\n",
              "      <td>-0.158264</td>\n",
              "      <td>0.030908</td>\n",
              "      <td>0.173386</td>\n",
              "      <td>0.118791</td>\n",
              "      <td>0.025483</td>\n",
              "      <td>0.211854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.120862</td>\n",
              "      <td>0.009952</td>\n",
              "      <td>0.089464</td>\n",
              "      <td>0.078869</td>\n",
              "      <td>0.037023</td>\n",
              "      <td>0.041781</td>\n",
              "      <td>0.239061</td>\n",
              "      <td>0.191186</td>\n",
              "      <td>0.174297</td>\n",
              "      <td>0.032827</td>\n",
              "      <td>...</td>\n",
              "      <td>0.385405</td>\n",
              "      <td>0.090662</td>\n",
              "      <td>0.020782</td>\n",
              "      <td>0.042742</td>\n",
              "      <td>-0.158264</td>\n",
              "      <td>0.030908</td>\n",
              "      <td>0.173386</td>\n",
              "      <td>0.118791</td>\n",
              "      <td>0.025483</td>\n",
              "      <td>0.211854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134570</th>\n",
              "      <td>-0.036482</td>\n",
              "      <td>-0.129115</td>\n",
              "      <td>0.111613</td>\n",
              "      <td>-0.015759</td>\n",
              "      <td>0.092214</td>\n",
              "      <td>0.212261</td>\n",
              "      <td>0.170611</td>\n",
              "      <td>0.119314</td>\n",
              "      <td>0.041390</td>\n",
              "      <td>0.022624</td>\n",
              "      <td>...</td>\n",
              "      <td>0.423801</td>\n",
              "      <td>0.053481</td>\n",
              "      <td>0.055481</td>\n",
              "      <td>-0.037401</td>\n",
              "      <td>-0.031056</td>\n",
              "      <td>0.121892</td>\n",
              "      <td>0.243400</td>\n",
              "      <td>0.231039</td>\n",
              "      <td>0.111731</td>\n",
              "      <td>0.177376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134571</th>\n",
              "      <td>-0.035830</td>\n",
              "      <td>-0.133259</td>\n",
              "      <td>0.113132</td>\n",
              "      <td>-0.015819</td>\n",
              "      <td>0.090947</td>\n",
              "      <td>0.212786</td>\n",
              "      <td>0.170340</td>\n",
              "      <td>0.118551</td>\n",
              "      <td>0.041846</td>\n",
              "      <td>0.021603</td>\n",
              "      <td>...</td>\n",
              "      <td>0.424760</td>\n",
              "      <td>0.054188</td>\n",
              "      <td>0.056568</td>\n",
              "      <td>-0.036497</td>\n",
              "      <td>-0.031627</td>\n",
              "      <td>0.124728</td>\n",
              "      <td>0.246042</td>\n",
              "      <td>0.229108</td>\n",
              "      <td>0.112977</td>\n",
              "      <td>0.176967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134572</th>\n",
              "      <td>-0.035830</td>\n",
              "      <td>-0.133259</td>\n",
              "      <td>0.113132</td>\n",
              "      <td>-0.015819</td>\n",
              "      <td>0.090947</td>\n",
              "      <td>0.212786</td>\n",
              "      <td>0.170340</td>\n",
              "      <td>0.118551</td>\n",
              "      <td>0.041846</td>\n",
              "      <td>0.021603</td>\n",
              "      <td>...</td>\n",
              "      <td>0.424760</td>\n",
              "      <td>0.054188</td>\n",
              "      <td>0.056568</td>\n",
              "      <td>-0.036497</td>\n",
              "      <td>-0.031627</td>\n",
              "      <td>0.124728</td>\n",
              "      <td>0.246042</td>\n",
              "      <td>0.229108</td>\n",
              "      <td>0.112977</td>\n",
              "      <td>0.176967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134573</th>\n",
              "      <td>-0.035830</td>\n",
              "      <td>-0.133259</td>\n",
              "      <td>0.113132</td>\n",
              "      <td>-0.015819</td>\n",
              "      <td>0.090947</td>\n",
              "      <td>0.212786</td>\n",
              "      <td>0.170340</td>\n",
              "      <td>0.118551</td>\n",
              "      <td>0.041846</td>\n",
              "      <td>0.021603</td>\n",
              "      <td>...</td>\n",
              "      <td>0.424760</td>\n",
              "      <td>0.054188</td>\n",
              "      <td>0.056568</td>\n",
              "      <td>-0.036497</td>\n",
              "      <td>-0.031627</td>\n",
              "      <td>0.124728</td>\n",
              "      <td>0.246042</td>\n",
              "      <td>0.229108</td>\n",
              "      <td>0.112977</td>\n",
              "      <td>0.176967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134574</th>\n",
              "      <td>-0.035312</td>\n",
              "      <td>-0.141824</td>\n",
              "      <td>0.112698</td>\n",
              "      <td>-0.006677</td>\n",
              "      <td>0.093540</td>\n",
              "      <td>0.219891</td>\n",
              "      <td>0.167841</td>\n",
              "      <td>0.113636</td>\n",
              "      <td>0.026307</td>\n",
              "      <td>0.019415</td>\n",
              "      <td>...</td>\n",
              "      <td>0.430399</td>\n",
              "      <td>0.054214</td>\n",
              "      <td>0.061350</td>\n",
              "      <td>-0.033797</td>\n",
              "      <td>-0.030178</td>\n",
              "      <td>0.129017</td>\n",
              "      <td>0.260804</td>\n",
              "      <td>0.231583</td>\n",
              "      <td>0.115644</td>\n",
              "      <td>0.169147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>134575 rows × 256 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2         3         4         5         6    \\\n",
              "0       0.120862  0.009952  0.089464  0.078869  0.037023  0.041781  0.239061   \n",
              "1       0.120862  0.009952  0.089464  0.078869  0.037023  0.041781  0.239061   \n",
              "2       0.120862  0.009952  0.089464  0.078869  0.037023  0.041781  0.239061   \n",
              "3       0.120862  0.009952  0.089464  0.078869  0.037023  0.041781  0.239061   \n",
              "4       0.120862  0.009952  0.089464  0.078869  0.037023  0.041781  0.239061   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "134570 -0.036482 -0.129115  0.111613 -0.015759  0.092214  0.212261  0.170611   \n",
              "134571 -0.035830 -0.133259  0.113132 -0.015819  0.090947  0.212786  0.170340   \n",
              "134572 -0.035830 -0.133259  0.113132 -0.015819  0.090947  0.212786  0.170340   \n",
              "134573 -0.035830 -0.133259  0.113132 -0.015819  0.090947  0.212786  0.170340   \n",
              "134574 -0.035312 -0.141824  0.112698 -0.006677  0.093540  0.219891  0.167841   \n",
              "\n",
              "             7         8         9    ...       246       247       248  \\\n",
              "0       0.191186  0.174297  0.032827  ...  0.385405  0.090662  0.020782   \n",
              "1       0.191186  0.174297  0.032827  ...  0.385405  0.090662  0.020782   \n",
              "2       0.191186  0.174297  0.032827  ...  0.385405  0.090662  0.020782   \n",
              "3       0.191186  0.174297  0.032827  ...  0.385405  0.090662  0.020782   \n",
              "4       0.191186  0.174297  0.032827  ...  0.385405  0.090662  0.020782   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "134570  0.119314  0.041390  0.022624  ...  0.423801  0.053481  0.055481   \n",
              "134571  0.118551  0.041846  0.021603  ...  0.424760  0.054188  0.056568   \n",
              "134572  0.118551  0.041846  0.021603  ...  0.424760  0.054188  0.056568   \n",
              "134573  0.118551  0.041846  0.021603  ...  0.424760  0.054188  0.056568   \n",
              "134574  0.113636  0.026307  0.019415  ...  0.430399  0.054214  0.061350   \n",
              "\n",
              "             249       250       251       252       253       254       255  \n",
              "0       0.042742 -0.158264  0.030908  0.173386  0.118791  0.025483  0.211854  \n",
              "1       0.042742 -0.158264  0.030908  0.173386  0.118791  0.025483  0.211854  \n",
              "2       0.042742 -0.158264  0.030908  0.173386  0.118791  0.025483  0.211854  \n",
              "3       0.042742 -0.158264  0.030908  0.173386  0.118791  0.025483  0.211854  \n",
              "4       0.042742 -0.158264  0.030908  0.173386  0.118791  0.025483  0.211854  \n",
              "...          ...       ...       ...       ...       ...       ...       ...  \n",
              "134570 -0.037401 -0.031056  0.121892  0.243400  0.231039  0.111731  0.177376  \n",
              "134571 -0.036497 -0.031627  0.124728  0.246042  0.229108  0.112977  0.176967  \n",
              "134572 -0.036497 -0.031627  0.124728  0.246042  0.229108  0.112977  0.176967  \n",
              "134573 -0.036497 -0.031627  0.124728  0.246042  0.229108  0.112977  0.176967  \n",
              "134574 -0.033797 -0.030178  0.129017  0.260804  0.231583  0.115644  0.169147  \n",
              "\n",
              "[134575 rows x 256 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_raw_train = pd.concat([X_train.drop(columns=[\"IPV4_SRC_ADDR\",\"IPV4_DST_ADDR\", \"h\"]), y_train], axis=1)\n",
        "df_raw_test = pd.concat([X_test.drop(columns=[\"IPV4_SRC_ADDR\",\"IPV4_DST_ADDR\", \"h\"]), y_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>TCP_FLAGS</th>\n",
              "      <th>CLIENT_TCP_FLAGS</th>\n",
              "      <th>SERVER_TCP_FLAGS</th>\n",
              "      <th>FLOW_DURATION_MILLISECONDS</th>\n",
              "      <th>...</th>\n",
              "      <th>TCP_WIN_MAX_IN</th>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <th>ICMP_TYPE</th>\n",
              "      <th>ICMP_IPV4_TYPE</th>\n",
              "      <th>DNS_QUERY_ID</th>\n",
              "      <th>DNS_QUERY_TYPE</th>\n",
              "      <th>DNS_TTL_ANSWER</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>Attack</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>287406</th>\n",
              "      <td>4.732152e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.003486</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000317</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>1.505900e-09</td>\n",
              "      <td>1.611550e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.530544e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001493</td>\n",
              "      <td>0.002850</td>\n",
              "      <td>2.127056e-08</td>\n",
              "      <td>2.097309e-08</td>\n",
              "      <td>4.396601e-09</td>\n",
              "      <td>4.397286e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.240589e-09</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610356</th>\n",
              "      <td>6.932495e-10</td>\n",
              "      <td>7.976222e-09</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>9.621527e-10</td>\n",
              "      <td>9.621527e-10</td>\n",
              "      <td>4.168656e-09</td>\n",
              "      <td>4.198509e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.010061e-09</td>\n",
              "      <td>4.009943e-09</td>\n",
              "      <td>1.969528e-08</td>\n",
              "      <td>1.969835e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.899640e-08</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456518</th>\n",
              "      <td>6.381741e-07</td>\n",
              "      <td>2.401223e-07</td>\n",
              "      <td>0.060366</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>0.038930</td>\n",
              "      <td>0.000379</td>\n",
              "      <td>2.030844e-07</td>\n",
              "      <td>2.173323e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.533152e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.183020</td>\n",
              "      <td>0.183020</td>\n",
              "      <td>4.321202e-07</td>\n",
              "      <td>4.840666e-07</td>\n",
              "      <td>5.929219e-07</td>\n",
              "      <td>5.930143e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.718822e-07</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2204716</th>\n",
              "      <td>1.390953e-08</td>\n",
              "      <td>2.334703e-08</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000476</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>4.426392e-09</td>\n",
              "      <td>4.736937e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.101955e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002792</td>\n",
              "      <td>0.003191</td>\n",
              "      <td>4.531849e-09</td>\n",
              "      <td>4.766241e-09</td>\n",
              "      <td>1.292322e-08</td>\n",
              "      <td>1.292524e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.246465e-08</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1090799</th>\n",
              "      <td>4.602189e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001485</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>1.464542e-09</td>\n",
              "      <td>1.567291e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.002648e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001980</td>\n",
              "      <td>0.001320</td>\n",
              "      <td>8.530939e-11</td>\n",
              "      <td>8.530939e-11</td>\n",
              "      <td>4.275853e-09</td>\n",
              "      <td>4.276519e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.124125e-09</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1225204</th>\n",
              "      <td>1.960806e-09</td>\n",
              "      <td>1.118412e-09</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000195</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>2.721379e-09</td>\n",
              "      <td>2.721379e-09</td>\n",
              "      <td>1.179074e-08</td>\n",
              "      <td>1.187518e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.134216e-08</td>\n",
              "      <td>1.134183e-08</td>\n",
              "      <td>4.233212e-08</td>\n",
              "      <td>4.713307e-10</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>5.372992e-08</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1161575</th>\n",
              "      <td>3.553645e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000195</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001865</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>1.130867e-09</td>\n",
              "      <td>1.210206e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.853564e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001936</td>\n",
              "      <td>0.001019</td>\n",
              "      <td>1.647801e-10</td>\n",
              "      <td>1.647801e-10</td>\n",
              "      <td>3.301660e-09</td>\n",
              "      <td>3.302174e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.184501e-09</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1927342</th>\n",
              "      <td>7.894386e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.030020</td>\n",
              "      <td>0.000344</td>\n",
              "      <td>0.067420</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>2.512209e-07</td>\n",
              "      <td>2.688460e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.662692e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.203761</td>\n",
              "      <td>0.203761</td>\n",
              "      <td>6.386150e-08</td>\n",
              "      <td>6.386150e-08</td>\n",
              "      <td>7.334604e-07</td>\n",
              "      <td>7.335747e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.074338e-07</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844639</th>\n",
              "      <td>2.088732e-06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.042651</td>\n",
              "      <td>0.000786</td>\n",
              "      <td>0.060978</td>\n",
              "      <td>0.000869</td>\n",
              "      <td>5.627404e-07</td>\n",
              "      <td>5.628146e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.223766e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.599022</td>\n",
              "      <td>0.539120</td>\n",
              "      <td>1.482757e-07</td>\n",
              "      <td>1.751208e-07</td>\n",
              "      <td>1.940623e-06</td>\n",
              "      <td>1.940925e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.339281e-06</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024253</th>\n",
              "      <td>1.088598e-08</td>\n",
              "      <td>2.780065e-08</td>\n",
              "      <td>0.004095</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.234555</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>3.464216e-09</td>\n",
              "      <td>3.707257e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.191361e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014049</td>\n",
              "      <td>0.001561</td>\n",
              "      <td>3.008442e-09</td>\n",
              "      <td>3.290587e-09</td>\n",
              "      <td>1.011407e-08</td>\n",
              "      <td>1.011564e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.755173e-09</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>157006 rows × 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             PROTOCOL      L7_PROTO  IN_BYTES   IN_PKTS  OUT_BYTES  OUT_PKTS  \\\n",
              "287406   4.732152e-09  0.000000e+00  0.003486  0.000005   0.000317  0.000004   \n",
              "610356   6.932495e-10  7.976222e-09  0.000215  0.000002   0.000128  0.000002   \n",
              "1456518  6.381741e-07  2.401223e-07  0.060366  0.000354   0.038930  0.000379   \n",
              "2204716  1.390953e-08  2.334703e-08  0.000405  0.000006   0.000476  0.000004   \n",
              "1090799  4.602189e-09  0.000000e+00  0.000213  0.000003   0.001485  0.000003   \n",
              "...               ...           ...       ...       ...        ...       ...   \n",
              "1225204  1.960806e-09  1.118412e-09  0.000157  0.000002   0.000195  0.000002   \n",
              "1161575  3.553645e-09  0.000000e+00  0.000195  0.000003   0.001865  0.000003   \n",
              "1927342  7.894386e-07  0.000000e+00  0.030020  0.000344   0.067420  0.000375   \n",
              "844639   2.088732e-06  0.000000e+00  0.042651  0.000786   0.060978  0.000869   \n",
              "2024253  1.088598e-08  2.780065e-08  0.004095  0.000077   0.234555  0.000161   \n",
              "\n",
              "            TCP_FLAGS  CLIENT_TCP_FLAGS  SERVER_TCP_FLAGS  \\\n",
              "287406   1.505900e-09      1.611550e-09      0.000000e+00   \n",
              "610356   9.621527e-10      9.621527e-10      4.168656e-09   \n",
              "1456518  2.030844e-07      2.173323e-07      0.000000e+00   \n",
              "2204716  4.426392e-09      4.736937e-09      0.000000e+00   \n",
              "1090799  1.464542e-09      1.567291e-09      0.000000e+00   \n",
              "...               ...               ...               ...   \n",
              "1225204  2.721379e-09      2.721379e-09      1.179074e-08   \n",
              "1161575  1.130867e-09      1.210206e-09      0.000000e+00   \n",
              "1927342  2.512209e-07      2.688460e-07      0.000000e+00   \n",
              "844639   5.627404e-07      5.628146e-07      0.000000e+00   \n",
              "2024253  3.464216e-09      3.707257e-09      0.000000e+00   \n",
              "\n",
              "         FLOW_DURATION_MILLISECONDS  ...  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
              "287406                 2.530544e-06  ...        0.001493         0.002850   \n",
              "610356                 4.198509e-07  ...        0.000000         0.000000   \n",
              "1456518                7.533152e-03  ...        0.183020         0.183020   \n",
              "2204716                1.101955e-06  ...        0.002792         0.003191   \n",
              "1090799                1.002648e-06  ...        0.001980         0.001320   \n",
              "...                             ...  ...             ...              ...   \n",
              "1225204                1.187518e-06  ...        0.000000         0.000000   \n",
              "1161575                9.853564e-07  ...        0.001936         0.001019   \n",
              "1927342                9.662692e-03  ...        0.203761         0.203761   \n",
              "844639                 4.223766e-02  ...        0.599022         0.539120   \n",
              "2024253                4.191361e-04  ...        0.014049         0.001561   \n",
              "\n",
              "            ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
              "287406   2.127056e-08    2.097309e-08  4.396601e-09    4.397286e-09   \n",
              "610356   4.010061e-09    4.009943e-09  1.969528e-08    1.969835e-08   \n",
              "1456518  4.321202e-07    4.840666e-07  5.929219e-07    5.930143e-07   \n",
              "2204716  4.531849e-09    4.766241e-09  1.292322e-08    1.292524e-08   \n",
              "1090799  8.530939e-11    8.530939e-11  4.275853e-09    4.276519e-09   \n",
              "...               ...             ...           ...             ...   \n",
              "1225204  1.134216e-08    1.134183e-08  4.233212e-08    4.713307e-10   \n",
              "1161575  1.647801e-10    1.647801e-10  3.301660e-09    3.302174e-09   \n",
              "1927342  6.386150e-08    6.386150e-08  7.334604e-07    7.335747e-07   \n",
              "844639   1.482757e-07    1.751208e-07  1.940623e-06    1.940925e-06   \n",
              "2024253  3.008442e-09    3.290587e-09  1.011407e-08    1.011564e-08   \n",
              "\n",
              "         DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  Attack  Label  \n",
              "287406         0.000000          4.240589e-09  Benign      0  \n",
              "610356         0.000000          1.899640e-08  Benign      0  \n",
              "1456518        0.000000          5.718822e-07  Benign      0  \n",
              "2204716        0.000000          1.246465e-08  Benign      0  \n",
              "1090799        0.000000          4.124125e-09  Benign      0  \n",
              "...                 ...                   ...     ...    ...  \n",
              "1225204        0.000071          5.372992e-08  Benign      0  \n",
              "1161575        0.000000          3.184501e-09  Benign      0  \n",
              "1927342        0.000000          7.074338e-07  Benign      0  \n",
              "844639         0.000000          1.339281e-06  Benign      0  \n",
              "2024253        0.000000          9.755173e-09  Benign      0  \n",
              "\n",
              "[157006 rows x 41 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_raw_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_benign_train_samples = df_raw_train[df_raw_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "raw_normal_train_samples = df_raw_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "raw_train_labels = df_raw_train[\"Label\"]\n",
        "raw_test_labels = df_raw_test[\"Label\"]\n",
        "\n",
        "raw_test_samples = df_raw_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "62BUDLtO4mla"
      },
      "outputs": [],
      "source": [
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "2i48uLj74mla",
        "outputId": "a0dd33ee-824d-4328-a960-e656e3aaf0ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [01:13<00:00,  2.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 2, 'con': 0.001}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "n_est = [2,3,5,7,9,10]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "rK-Rng9q4mla",
        "outputId": "1796db22-cfb8-4bf8-9004-6420c08c3399"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [01:12<00:00,  2.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 2, 'con': 0.05}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "tHSOcEhH4mlb"
      },
      "outputs": [],
      "source": [
        "###  CBLOF RAW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "u_l1Vz8S4mlb",
        "outputId": "c1b8d03c-7105-42d9-f49a-bba4ff4905a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 2/36 [00:00<00:06,  5.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 3/36 [00:00<00:06,  5.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 7/36 [00:02<00:09,  3.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 8/36 [00:02<00:07,  3.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 10/36 [00:02<00:06,  4.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 11/36 [00:03<00:05,  4.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 12/36 [00:03<00:05,  4.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [00:14<00:00,  2.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 9, 'con': 0.04}\n",
            "0.7506361347727226\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9871    0.9587    0.9727     64531\n",
            "           1     0.4224    0.7059    0.5286      2758\n",
            "\n",
            "    accuracy                         0.9484     67289\n",
            "   macro avg     0.7047    0.8323    0.7506     67289\n",
            "weighted avg     0.9639    0.9484    0.9545     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "\n",
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_b = CBLOF(n_clusters=n_est, contamination=con)\n",
        "        clf_b.fit(raw_benign_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "   \n",
        "    y_pred = clf_b.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_b\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "H-_InJ1-4mlc",
        "outputId": "e22139e6-d1cf-46e1-adf3-f0dc9b499244"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 2/36 [00:00<00:06,  5.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 4/36 [00:00<00:06,  5.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 7/36 [00:01<00:06,  4.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 9/36 [00:01<00:05,  4.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 11/36 [00:02<00:05,  4.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 12/36 [00:02<00:04,  4.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [00:13<00:00,  2.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 10}\n",
            "0.7452839132779379\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9819    0.9709    0.9764     64531\n",
            "           1     0.4608    0.5816    0.5142      2758\n",
            "\n",
            "    accuracy                         0.9550     67289\n",
            "   macro avg     0.7214    0.7762    0.7453     67289\n",
            "weighted avg     0.9606    0.9550    0.9574     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "        clf_if.fit(raw_normal_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "    \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nd0-H7UT4mlc"
      },
      "outputs": [],
      "source": [
        "# HBOS  Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "sDquxErU4mld"
      },
      "outputs": [],
      "source": [
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "xLBIT-Rc4mld",
        "outputId": "8162929e-4879-40e2-a040-afc57eafe7c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [02:13<00:00,  3.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 15, 'con': 0.001}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.hbos import HBOS\n",
        "\n",
        "n_est = [5,10,15,20,25,30]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "MDcX0mma4mld",
        "outputId": "a2b64cfc-d413-4ba0-9f24-b4935343c315"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [02:18<00:00,  3.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.05}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "wRUOrQqB4mle"
      },
      "outputs": [],
      "source": [
        "##  HBOS  RAw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "9sZfAnER4mle",
        "outputId": "6e9cb145-8540-4aa7-8ed1-fc9aca495b07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [00:13<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 30, 'con': 0.01}\n",
            "0.8525989286730036\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9875    0.9887    0.9881     64531\n",
            "           1     0.7282    0.7063    0.7171      2758\n",
            "\n",
            "    accuracy                         0.9772     67289\n",
            "   macro avg     0.8578    0.8475    0.8526     67289\n",
            "weighted avg     0.9768    0.9772    0.9770     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "\n",
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_b = HBOS(n_bins=n_est, contamination=con)\n",
        "        clf_b.fit(raw_benign_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "   \n",
        "    y_pred = clf_b.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_b\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "z5A-gLN34mle",
        "outputId": "8a6dfd26-a45b-4ce3-8d85-1b61652e7f90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [00:12<00:00,  2.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 5}\n",
            "0.8078362549428174\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9857    0.9811    0.9834     64531\n",
            "           1     0.6012    0.6668    0.6323      2758\n",
            "\n",
            "    accuracy                         0.9682     67289\n",
            "   macro avg     0.7934    0.8239    0.8078     67289\n",
            "weighted avg     0.9699    0.9682    0.9690     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "        clf_if.fit(raw_normal_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "    \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "UbDOqrcy4mle"
      },
      "outputs": [],
      "source": [
        "##  PCA  Emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Nga82Fw_4mle",
        "outputId": "0fe52043-af21-45c1-a404-040ab5845efc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [01:01<00:00,  1.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.001}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.pca import PCA\n",
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "sg6AcAUW4mlf",
        "outputId": "a9949458-96cf-44dc-b4f6-c73458cb2719"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [01:03<00:00,  1.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.05}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "JSoyZpDu4mlf"
      },
      "outputs": [],
      "source": [
        "##  PCA  RAw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "3hKgicW14mlf",
        "outputId": "16c93b66-4eac-4d40-d5ce-96f3b3a5b3bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [00:11<00:00,  3.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.001}\n",
            "0.9079572980994904\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9881    0.9988    0.9934     64531\n",
            "           1     0.9621    0.7183    0.8225      2758\n",
            "\n",
            "    accuracy                         0.9873     67289\n",
            "   macro avg     0.9751    0.8585    0.9080     67289\n",
            "weighted avg     0.9870    0.9873    0.9864     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(raw_benign_train_samples)\n",
        "   \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "nAdfwnlP4mlf",
        "outputId": "ddc9c2b4-a3b6-4ab6-cc74-7ed93ca23d22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [00:10<00:00,  3.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 15}\n",
            "0.7820758463846016\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9823    0.9817    0.9820     64531\n",
            "           1     0.5784    0.5859    0.5821      2758\n",
            "\n",
            "    accuracy                         0.9655     67289\n",
            "   macro avg     0.7803    0.7838    0.7821     67289\n",
            "weighted avg     0.9657    0.9655    0.9656     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(raw_normal_train_samples)\n",
        "\n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "yi8SO3tL4mlg"
      },
      "outputs": [],
      "source": [
        "##  IF  Emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "9D0m4vb04mlg",
        "outputId": "bd5a55e6-ac70-4943-9b28-92474b5fb9e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:43<00:00,  1.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 50, 'con': 0.001}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "NCj-3u4t4mlg",
        "outputId": "5f6b1720-9662-4704-ba96-dd57ee32a900"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:44<00:00,  1.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 20, 'con': 0.05}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "iOIn_Kr44mlg"
      },
      "outputs": [],
      "source": [
        "##  IF  Raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "E_60yAo34mlg",
        "outputId": "354e56cd-ee22-4538-ba6f-43c1d67eb648"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:15<00:00,  1.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 150, 'con': 0.01}\n",
            "0.8767910931391057\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9908    0.9884    0.9896     64531\n",
            "           1     0.7434    0.7857    0.7640      2758\n",
            "\n",
            "    accuracy                         0.9801     67289\n",
            "   macro avg     0.8671    0.8871    0.8768     67289\n",
            "weighted avg     0.9807    0.9801    0.9804     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(raw_benign_train_samples.to_numpy())\n",
        "   \n",
        "    y_pred = clf_if.predict(raw_test_samples.to_numpy())\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "5xNKBA7X4mlh",
        "outputId": "cd0ee1c5-5394-4e2b-efde-1f58bf922282"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:16<00:00,  1.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 100}\n",
            "0.8248948684545866\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9891    0.9787    0.9839     64531\n",
            "           1     0.6001    0.7480    0.6659      2758\n",
            "\n",
            "    accuracy                         0.9692     67289\n",
            "   macro avg     0.7946    0.8633    0.8249     67289\n",
            "weighted avg     0.9732    0.9692    0.9708     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(raw_normal_train_samples.to_numpy())\n",
        "\n",
        "    y_pred = clf_if.predict(raw_test_samples.to_numpy())\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
