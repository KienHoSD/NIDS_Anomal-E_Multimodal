{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hjc3iIihKLn-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn import preprocessing\n",
        "from dgl.data import DGLDataset\n",
        "import dgl\n",
        "import time\n",
        "import networkx as nx\n",
        "import category_encoders as ce\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "import torch\n",
        "import tqdm\n",
        "import math\n",
        "\n",
        "from typing import *\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "import socket\n",
        "import struct\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SvWHb_BpKsLq"
      },
      "outputs": [],
      "source": [
        "file_name = \"NF-UNSW-NB15-v3.parquet\"\n",
        "data = pd.read_parquet(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "fqly1y-LMwYS",
        "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Label\n",
              "0    2151027\n",
              "1      91904\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3t4OREvSM33h"
      },
      "outputs": [],
      "source": [
        "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
        "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
        "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
        "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
        "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bTtHq0XqNXxI"
      },
      "outputs": [],
      "source": [
        "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUNIP-8zNkn9",
        "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Benign', 'Fuzzers', 'Exploits', 'Backdoor', 'Generic', 'DoS',\n",
              "       'Reconnaissance', 'Shellcode', 'Analysis', 'Worms'], dtype=object)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Attack.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AlPa58fVN7gB"
      },
      "outputs": [],
      "source": [
        "data = data.groupby(by='Attack').sample(frac=0.1, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "lcfAP6ViOp-J",
        "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FLOW_START_MILLISECONDS</th>\n",
              "      <th>FLOW_END_MILLISECONDS</th>\n",
              "      <th>IPV4_SRC_ADDR</th>\n",
              "      <th>IPV4_DST_ADDR</th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>...</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>SRC_TO_DST_IAT_MIN</th>\n",
              "      <th>SRC_TO_DST_IAT_MAX</th>\n",
              "      <th>SRC_TO_DST_IAT_AVG</th>\n",
              "      <th>SRC_TO_DST_IAT_STDDEV</th>\n",
              "      <th>DST_TO_SRC_IAT_MIN</th>\n",
              "      <th>DST_TO_SRC_IAT_MAX</th>\n",
              "      <th>DST_TO_SRC_IAT_AVG</th>\n",
              "      <th>DST_TO_SRC_IAT_STDDEV</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Attack</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Analysis</th>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>...</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Backdoor</th>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>...</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Benign</th>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>...</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "      <td>215103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS</th>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>...</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exploits</th>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>...</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "      <td>3882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fuzzers</th>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>...</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "      <td>2559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Generic</th>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>...</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reconnaissance</th>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>...</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "      <td>1129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shellcode</th>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>...</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worms</th>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 52 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                FLOW_START_MILLISECONDS  FLOW_END_MILLISECONDS  IPV4_SRC_ADDR  \\\n",
              "Attack                                                                          \n",
              "Analysis                            123                    123            123   \n",
              "Backdoor                            345                    345            345   \n",
              "Benign                           215103                 215103         215103   \n",
              "DoS                                 505                    505            505   \n",
              "Exploits                           3882                   3882           3882   \n",
              "Fuzzers                            2559                   2559           2559   \n",
              "Generic                             476                    476            476   \n",
              "Reconnaissance                     1129                   1129           1129   \n",
              "Shellcode                           159                    159            159   \n",
              "Worms                                14                     14             14   \n",
              "\n",
              "                IPV4_DST_ADDR  PROTOCOL  L7_PROTO  IN_BYTES  IN_PKTS  \\\n",
              "Attack                                                                 \n",
              "Analysis                  123       123       123       123      123   \n",
              "Backdoor                  345       345       345       345      345   \n",
              "Benign                 215103    215103    215103    215103   215103   \n",
              "DoS                       505       505       505       505      505   \n",
              "Exploits                 3882      3882      3882      3882     3882   \n",
              "Fuzzers                  2559      2559      2559      2559     2559   \n",
              "Generic                   476       476       476       476      476   \n",
              "Reconnaissance           1129      1129      1129      1129     1129   \n",
              "Shellcode                 159       159       159       159      159   \n",
              "Worms                      14        14        14        14       14   \n",
              "\n",
              "                OUT_BYTES  OUT_PKTS  ...  FTP_COMMAND_RET_CODE  \\\n",
              "Attack                               ...                         \n",
              "Analysis              123       123  ...                   123   \n",
              "Backdoor              345       345  ...                   345   \n",
              "Benign             215103    215103  ...                215103   \n",
              "DoS                   505       505  ...                   505   \n",
              "Exploits             3882      3882  ...                  3882   \n",
              "Fuzzers              2559      2559  ...                  2559   \n",
              "Generic               476       476  ...                   476   \n",
              "Reconnaissance       1129      1129  ...                  1129   \n",
              "Shellcode             159       159  ...                   159   \n",
              "Worms                  14        14  ...                    14   \n",
              "\n",
              "                SRC_TO_DST_IAT_MIN  SRC_TO_DST_IAT_MAX  SRC_TO_DST_IAT_AVG  \\\n",
              "Attack                                                                       \n",
              "Analysis                       123                 123                 123   \n",
              "Backdoor                       345                 345                 345   \n",
              "Benign                      215103              215103              215103   \n",
              "DoS                            505                 505                 505   \n",
              "Exploits                      3882                3882                3882   \n",
              "Fuzzers                       2559                2559                2559   \n",
              "Generic                        476                 476                 476   \n",
              "Reconnaissance                1129                1129                1129   \n",
              "Shellcode                      159                 159                 159   \n",
              "Worms                           14                  14                  14   \n",
              "\n",
              "                SRC_TO_DST_IAT_STDDEV  DST_TO_SRC_IAT_MIN  DST_TO_SRC_IAT_MAX  \\\n",
              "Attack                                                                          \n",
              "Analysis                          123                 123                 123   \n",
              "Backdoor                          345                 345                 345   \n",
              "Benign                         215103              215103              215103   \n",
              "DoS                               505                 505                 505   \n",
              "Exploits                         3882                3882                3882   \n",
              "Fuzzers                          2559                2559                2559   \n",
              "Generic                           476                 476                 476   \n",
              "Reconnaissance                   1129                1129                1129   \n",
              "Shellcode                         159                 159                 159   \n",
              "Worms                              14                  14                  14   \n",
              "\n",
              "                DST_TO_SRC_IAT_AVG  DST_TO_SRC_IAT_STDDEV   Label  \n",
              "Attack                                                             \n",
              "Analysis                       123                    123     123  \n",
              "Backdoor                       345                    345     345  \n",
              "Benign                      215103                 215103  215103  \n",
              "DoS                            505                    505     505  \n",
              "Exploits                      3882                   3882    3882  \n",
              "Fuzzers                       2559                   2559    2559  \n",
              "Generic                        476                    476     476  \n",
              "Reconnaissance                1129                   1129    1129  \n",
              "Shellcode                      159                    159     159  \n",
              "Worms                           14                     14      14  \n",
              "\n",
              "[10 rows x 52 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.groupby(by=\"Attack\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FqRx5xCPOuv8"
      },
      "outputs": [],
      "source": [
        "# X = data.drop(columns=[\"Attack\", \"Label\"])\n",
        "# calculate the distance miliseconds betweeen columns 2 and 1, put the new column name FLOW_TIME_DIFF (Modified)\n",
        "# data['FLOW_DIFF_MILISECONDS'] = (data['FLOW_END_MILLISECONDS'] - data['FLOW_START_MILLISECONDS'])\n",
        "X = data.drop(columns=[\"Attack\", \"Label\", \"FLOW_START_MILLISECONDS\", \"FLOW_END_MILLISECONDS\",\n",
        "                       \"SRC_TO_DST_IAT_MIN\", \"SRC_TO_DST_IAT_MAX\", \"SRC_TO_DST_IAT_AVG\",\n",
        "                       \"SRC_TO_DST_IAT_STDDEV\", \"DST_TO_SRC_IAT_MIN\", \"DST_TO_SRC_IAT_MAX\",\n",
        "                       \"DST_TO_SRC_IAT_AVG\", \"DST_TO_SRC_IAT_STDDEV\"])\n",
        "y = data[[\"Attack\", \"Label\"]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=13, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bPfakXplPGGx"
      },
      "outputs": [],
      "source": [
        "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
        "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
        "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
        "                                  'FTP_COMMAND_RET_CODE'])\n",
        "encoder.fit(X_train, y_train.Label)\n",
        "\n",
        "# Transform on training set\n",
        "X_train = encoder.transform(X_train)\n",
        "\n",
        "# Transform on testing set\n",
        "X_test = encoder.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ibyOfV-8PouK"
      },
      "outputs": [],
      "source": [
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "asDnsSIWPee0"
      },
      "outputs": [],
      "source": [
        "scaler = Normalizer()\n",
        "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
        "scaler.fit(X_train[cols_to_norm])\n",
        "\n",
        "# Transform on training set\n",
        "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
        "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
        "\n",
        "# Transform on testing set\n",
        "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
        "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
        "\n",
        "train = pd.concat([X_train, y_train], axis=1)\n",
        "test = pd.concat([X_test, y_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "hErQbsnrPluV",
        "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IPV4_SRC_ADDR</th>\n",
              "      <th>IPV4_DST_ADDR</th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>TCP_FLAGS</th>\n",
              "      <th>CLIENT_TCP_FLAGS</th>\n",
              "      <th>...</th>\n",
              "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
              "      <th>TCP_WIN_MAX_IN</th>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <th>ICMP_TYPE</th>\n",
              "      <th>ICMP_IPV4_TYPE</th>\n",
              "      <th>DNS_QUERY_ID</th>\n",
              "      <th>DNS_QUERY_TYPE</th>\n",
              "      <th>DNS_TTL_ANSWER</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>287406</th>\n",
              "      <td>59.166.0.8</td>\n",
              "      <td>149.171.126.4</td>\n",
              "      <td>4.732152e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.003486</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000317</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>1.505900e-09</td>\n",
              "      <td>1.611550e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>2.249372e-06</td>\n",
              "      <td>0.001493</td>\n",
              "      <td>0.002850</td>\n",
              "      <td>2.127056e-08</td>\n",
              "      <td>2.097309e-08</td>\n",
              "      <td>4.396601e-09</td>\n",
              "      <td>4.397286e-09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.240589e-09</td>\n",
              "      <td>[4.732152333835413e-09, 0.0, 0.003485589444774...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610356</th>\n",
              "      <td>59.166.0.9</td>\n",
              "      <td>149.171.126.6</td>\n",
              "      <td>6.932495e-10</td>\n",
              "      <td>7.976222e-09</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>9.621527e-10</td>\n",
              "      <td>9.621527e-10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.010061e-09</td>\n",
              "      <td>4.009943e-09</td>\n",
              "      <td>1.969528e-08</td>\n",
              "      <td>1.969835e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.899640e-08</td>\n",
              "      <td>[6.932494894241551e-10, 7.976221604219919e-09,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456518</th>\n",
              "      <td>59.166.0.2</td>\n",
              "      <td>149.171.126.2</td>\n",
              "      <td>6.381741e-07</td>\n",
              "      <td>2.401223e-07</td>\n",
              "      <td>0.060366</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>0.038930</td>\n",
              "      <td>0.000379</td>\n",
              "      <td>2.030844e-07</td>\n",
              "      <td>2.173323e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.183020</td>\n",
              "      <td>0.183020</td>\n",
              "      <td>4.321202e-07</td>\n",
              "      <td>4.840666e-07</td>\n",
              "      <td>5.929219e-07</td>\n",
              "      <td>5.930143e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.718822e-07</td>\n",
              "      <td>[6.381740567526722e-07, 2.40122348914616e-07, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2204716</th>\n",
              "      <td>59.166.0.0</td>\n",
              "      <td>149.171.126.0</td>\n",
              "      <td>1.390953e-08</td>\n",
              "      <td>2.334703e-08</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000476</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>4.426392e-09</td>\n",
              "      <td>4.736937e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.002792</td>\n",
              "      <td>0.003191</td>\n",
              "      <td>4.531849e-09</td>\n",
              "      <td>4.766241e-09</td>\n",
              "      <td>1.292322e-08</td>\n",
              "      <td>1.292524e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.246465e-08</td>\n",
              "      <td>[1.3909530687793816e-08, 2.334702611325599e-08...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1090799</th>\n",
              "      <td>59.166.0.1</td>\n",
              "      <td>149.171.126.3</td>\n",
              "      <td>4.602189e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001485</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>1.464542e-09</td>\n",
              "      <td>1.567291e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>9.114981e-07</td>\n",
              "      <td>0.001980</td>\n",
              "      <td>0.001320</td>\n",
              "      <td>8.530939e-11</td>\n",
              "      <td>8.530939e-11</td>\n",
              "      <td>4.275853e-09</td>\n",
              "      <td>4.276519e-09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.124125e-09</td>\n",
              "      <td>[4.602188564242696e-09, 0.0, 0.000212743645752...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 42 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        IPV4_SRC_ADDR  IPV4_DST_ADDR      PROTOCOL      L7_PROTO  IN_BYTES  \\\n",
              "287406     59.166.0.8  149.171.126.4  4.732152e-09  0.000000e+00  0.003486   \n",
              "610356     59.166.0.9  149.171.126.6  6.932495e-10  7.976222e-09  0.000215   \n",
              "1456518    59.166.0.2  149.171.126.2  6.381741e-07  2.401223e-07  0.060366   \n",
              "2204716    59.166.0.0  149.171.126.0  1.390953e-08  2.334703e-08  0.000405   \n",
              "1090799    59.166.0.1  149.171.126.3  4.602189e-09  0.000000e+00  0.000213   \n",
              "\n",
              "          IN_PKTS  OUT_BYTES  OUT_PKTS     TCP_FLAGS  CLIENT_TCP_FLAGS  ...  \\\n",
              "287406   0.000005   0.000317  0.000004  1.505900e-09      1.611550e-09  ...   \n",
              "610356   0.000002   0.000128  0.000002  9.621527e-10      9.621527e-10  ...   \n",
              "1456518  0.000354   0.038930  0.000379  2.030844e-07      2.173323e-07  ...   \n",
              "2204716  0.000006   0.000476  0.000004  4.426392e-09      4.736937e-09  ...   \n",
              "1090799  0.000003   0.001485  0.000003  1.464542e-09      1.567291e-09  ...   \n",
              "\n",
              "         NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
              "287406                  2.249372e-06        0.001493         0.002850   \n",
              "610356                  0.000000e+00        0.000000         0.000000   \n",
              "1456518                 0.000000e+00        0.183020         0.183020   \n",
              "2204716                 0.000000e+00        0.002792         0.003191   \n",
              "1090799                 9.114981e-07        0.001980         0.001320   \n",
              "\n",
              "            ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
              "287406   2.127056e-08    2.097309e-08  4.396601e-09    4.397286e-09   \n",
              "610356   4.010061e-09    4.009943e-09  1.969528e-08    1.969835e-08   \n",
              "1456518  4.321202e-07    4.840666e-07  5.929219e-07    5.930143e-07   \n",
              "2204716  4.531849e-09    4.766241e-09  1.292322e-08    1.292524e-08   \n",
              "1090799  8.530939e-11    8.530939e-11  4.275853e-09    4.276519e-09   \n",
              "\n",
              "         DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \\\n",
              "287406              0.0          4.240589e-09   \n",
              "610356              0.0          1.899640e-08   \n",
              "1456518             0.0          5.718822e-07   \n",
              "2204716             0.0          1.246465e-08   \n",
              "1090799             0.0          4.124125e-09   \n",
              "\n",
              "                                                         h  \n",
              "287406   [4.732152333835413e-09, 0.0, 0.003485589444774...  \n",
              "610356   [6.932494894241551e-10, 7.976221604219919e-09,...  \n",
              "1456518  [6.381740567526722e-07, 2.40122348914616e-07, ...  \n",
              "2204716  [1.3909530687793816e-08, 2.334702611325599e-08...  \n",
              "1090799  [4.602188564242696e-09, 0.0, 0.000212743645752...  \n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "d_tLtK4WPtrF"
      },
      "outputs": [],
      "source": [
        "lab_enc = preprocessing.LabelEncoder()\n",
        "lab_enc.fit(data[\"Attack\"])\n",
        "\n",
        "# Transform on training set\n",
        "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
        "\n",
        "# Transform on testing set\n",
        "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8yaicjecP1fZ"
      },
      "outputs": [],
      "source": [
        "# Training graph\n",
        "\n",
        "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
        "           [\"h\", \"Label\", \"Attack\"], create_using=nx.MultiGraph())\n",
        "train_g = train_g.to_directed()\n",
        "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label'])\n",
        "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
        "train_g.edata['h'].shape[1]])\n",
        "train_g.ndata['h'] = nfeat_weight\n",
        "\n",
        "# Testing graph\n",
        "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
        "            [\"h\", \"Label\", \"Attack\"], create_using=nx.MultiGraph())\n",
        "\n",
        "test_g = test_g.to_directed()\n",
        "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label'])\n",
        "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
        "test_g.edata['h'].shape[1]])\n",
        "test_g.ndata['h'] = nfeat_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PUV6DgJ9QRaP"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "import tqdm\n",
        "import gc\n",
        "\n",
        "class SAGELayer(nn.Module):\n",
        "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
        "      super(SAGELayer, self).__init__()\n",
        "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
        "      self.activation = F.relu\n",
        "      self.W_edge = nn.Linear(128 * 2, 256)\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      gain = nn.init.calculate_gain('relu')\n",
        "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
        "\n",
        "    def message_func(self, edges):\n",
        "      return {'m':  edges.data['h']}\n",
        "\n",
        "    def forward(self, g_dgl, nfeats, efeats):\n",
        "      with g_dgl.local_scope():\n",
        "        g = g_dgl\n",
        "        g.ndata['h'] = nfeats\n",
        "        g.edata['h'] = efeats\n",
        "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
        "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
        "\n",
        "        # Compute edge embeddings\n",
        "        u, v = g.edges()\n",
        "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
        "        return g.ndata['h'], edge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_xo-3K4QRGqc"
      },
      "outputs": [],
      "source": [
        "class SAGE(nn.Module):\n",
        "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
        "      super(SAGE, self).__init__()\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
        "\n",
        "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
        "      if corrupt:\n",
        "        e_perm = torch.randperm(g.number_of_edges())\n",
        "        #n_perm = torch.randperm(g.number_of_nodes())\n",
        "        efeats = efeats[e_perm]\n",
        "        #nfeats = nfeats[n_perm]\n",
        "      for i, layer in enumerate(self.layers):\n",
        "        #nfeats = layer(g, nfeats, efeats)\n",
        "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
        "      #return nfeats.sum(1)\n",
        "      return nfeats.sum(1), e_feats.sum(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6uuxRtLuRJQL"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, n_hidden):\n",
        "      super(Discriminator, self).__init__()\n",
        "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def uniform(self, size, tensor):\n",
        "      bound = 1.0 / math.sqrt(size)\n",
        "      if tensor is not None:\n",
        "        tensor.data.uniform_(-bound, bound)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      size = self.weight.size(0)\n",
        "      self.uniform(size, self.weight)\n",
        "\n",
        "    def forward(self, features, summary):\n",
        "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
        "      return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZPbVjlCyRUco"
      },
      "outputs": [],
      "source": [
        "class DGI(nn.Module):\n",
        "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
        "      super(DGI, self).__init__()\n",
        "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
        "      #self.discriminator = Discriminator(128)\n",
        "      self.discriminator = Discriminator(256)\n",
        "      self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, g, n_features, e_features):\n",
        "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
        "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
        "      self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, g, n_features, e_features):\n",
        "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
        "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
        "\n",
        "      positive = positive[1]\n",
        "      negative = negative[1]\n",
        "\n",
        "      summary = torch.sigmoid(positive.mean(dim=0))\n",
        "\n",
        "      positive = self.discriminator(positive, summary)\n",
        "      negative = self.discriminator(negative, summary)\n",
        "\n",
        "      l1 = self.loss(positive, torch.ones_like(positive))\n",
        "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
        "\n",
        "      return l1 + l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sKnfpWFMR19u"
      },
      "outputs": [],
      "source": [
        "ndim_in = train_g.ndata['h'].shape[1]\n",
        "hidden_features = 128\n",
        "ndim_out = 128\n",
        "num_layers = 1\n",
        "edim = train_g.edata['h'].shape[1]\n",
        "learning_rate = 1e-3\n",
        "epochs = 4000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aSl_9qY8SbA0"
      },
      "outputs": [],
      "source": [
        "dgi = DGI(ndim_in,\n",
        "    ndim_out,\n",
        "    edim,\n",
        "    F.relu)\n",
        "\n",
        "dgi = dgi.to('cuda')\n",
        "\n",
        "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
        "                lr=1e-3,\n",
        "                weight_decay=0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9K6_cOiWSdJA"
      },
      "outputs": [],
      "source": [
        "# Format node and edge features for E-GraphSAGE\n",
        "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
        "                                   (train_g.ndata['h'].shape[0], 1,\n",
        "                                    train_g.ndata['h'].shape[1]))\n",
        "\n",
        "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
        "                                   (train_g.edata['h'].shape[0], 1,\n",
        "                                    train_g.edata['h'].shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "O44auIyWSexg"
      },
      "outputs": [],
      "source": [
        "# Convert to GPU\n",
        "train_g = train_g.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gZtafIdxSheN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00000 | Time(s) nan | Loss 1.9401 | ETputs(KTEPS) nan\n",
            "Epoch 00050 | Time(s) 0.0902 | Loss 1.3919 | ETputs(KTEPS) 3481.73\n",
            "Epoch 00100 | Time(s) 0.0922 | Loss 1.3774 | ETputs(KTEPS) 3407.37\n",
            "Epoch 00150 | Time(s) 0.0922 | Loss 1.3526 | ETputs(KTEPS) 3406.03\n",
            "Epoch 00200 | Time(s) 0.0919 | Loss 1.3576 | ETputs(KTEPS) 3417.49\n",
            "Epoch 00250 | Time(s) 0.0917 | Loss 1.3371 | ETputs(KTEPS) 3422.94\n",
            "Epoch 00300 | Time(s) 0.0915 | Loss 1.2568 | ETputs(KTEPS) 3432.78\n",
            "Epoch 00350 | Time(s) 0.0912 | Loss 1.0818 | ETputs(KTEPS) 3443.23\n",
            "Epoch 00400 | Time(s) 0.0910 | Loss 0.6947 | ETputs(KTEPS) 3451.14\n",
            "Epoch 00450 | Time(s) 0.0909 | Loss 0.2463 | ETputs(KTEPS) 3456.13\n",
            "Epoch 00500 | Time(s) 0.0908 | Loss 0.1004 | ETputs(KTEPS) 3458.52\n",
            "Epoch 00550 | Time(s) 0.0907 | Loss 0.0519 | ETputs(KTEPS) 3461.74\n",
            "Epoch 00600 | Time(s) 0.0906 | Loss 0.0413 | ETputs(KTEPS) 3465.10\n",
            "Epoch 00650 | Time(s) 0.0906 | Loss 0.0243 | ETputs(KTEPS) 3467.75\n",
            "Epoch 00700 | Time(s) 0.0905 | Loss 0.0175 | ETputs(KTEPS) 3469.76\n",
            "Epoch 00750 | Time(s) 0.0904 | Loss 0.0130 | ETputs(KTEPS) 3471.78\n",
            "Epoch 00800 | Time(s) 0.0904 | Loss 0.0138 | ETputs(KTEPS) 3474.41\n",
            "Epoch 00850 | Time(s) 0.0903 | Loss 0.0092 | ETputs(KTEPS) 3476.46\n",
            "Epoch 00900 | Time(s) 0.0903 | Loss 1.4896 | ETputs(KTEPS) 3478.50\n",
            "Epoch 00950 | Time(s) 0.0902 | Loss 1.3857 | ETputs(KTEPS) 3481.32\n",
            "Epoch 01000 | Time(s) 0.0901 | Loss 1.3859 | ETputs(KTEPS) 3484.12\n",
            "Epoch 01050 | Time(s) 0.0901 | Loss 1.3859 | ETputs(KTEPS) 3486.51\n",
            "Epoch 01100 | Time(s) 0.0900 | Loss 1.3859 | ETputs(KTEPS) 3488.60\n",
            "Epoch 01150 | Time(s) 0.0900 | Loss 1.3858 | ETputs(KTEPS) 3490.20\n",
            "Epoch 01200 | Time(s) 0.0899 | Loss 1.3858 | ETputs(KTEPS) 3491.96\n",
            "Epoch 01250 | Time(s) 0.0899 | Loss 1.3858 | ETputs(KTEPS) 3493.66\n",
            "Epoch 01300 | Time(s) 0.0898 | Loss 1.3858 | ETputs(KTEPS) 3495.30\n",
            "Epoch 01350 | Time(s) 0.0898 | Loss 1.3865 | ETputs(KTEPS) 3496.77\n",
            "Epoch 01400 | Time(s) 0.0898 | Loss 1.3858 | ETputs(KTEPS) 3498.11\n",
            "Epoch 01450 | Time(s) 0.0897 | Loss 1.3858 | ETputs(KTEPS) 3499.35\n",
            "Epoch 01500 | Time(s) 0.0897 | Loss 1.3858 | ETputs(KTEPS) 3500.54\n",
            "Epoch 01550 | Time(s) 0.0897 | Loss 1.3858 | ETputs(KTEPS) 3501.53\n",
            "Epoch 01600 | Time(s) 0.0897 | Loss 1.3858 | ETputs(KTEPS) 3502.52\n",
            "Epoch 01650 | Time(s) 0.0896 | Loss 1.3858 | ETputs(KTEPS) 3503.41\n",
            "Epoch 01700 | Time(s) 0.0896 | Loss 1.3858 | ETputs(KTEPS) 3504.30\n",
            "Epoch 01750 | Time(s) 0.0896 | Loss 1.3858 | ETputs(KTEPS) 3505.25\n",
            "Epoch 01800 | Time(s) 0.0896 | Loss 1.3857 | ETputs(KTEPS) 3506.14\n",
            "Epoch 01850 | Time(s) 0.0895 | Loss 1.3857 | ETputs(KTEPS) 3506.95\n",
            "Epoch 01900 | Time(s) 0.0895 | Loss 1.3857 | ETputs(KTEPS) 3507.72\n",
            "Epoch 01950 | Time(s) 0.0895 | Loss 1.3857 | ETputs(KTEPS) 3508.44\n",
            "Epoch 02000 | Time(s) 0.0895 | Loss 1.3857 | ETputs(KTEPS) 3509.16\n",
            "Epoch 02050 | Time(s) 0.0895 | Loss 1.3856 | ETputs(KTEPS) 3509.79\n",
            "Epoch 02100 | Time(s) 0.0895 | Loss 1.3856 | ETputs(KTEPS) 3510.33\n",
            "Epoch 02150 | Time(s) 0.0894 | Loss 1.3856 | ETputs(KTEPS) 3510.94\n",
            "Epoch 02200 | Time(s) 0.0894 | Loss 1.3855 | ETputs(KTEPS) 3511.56\n",
            "Epoch 02250 | Time(s) 0.0894 | Loss 1.3855 | ETputs(KTEPS) 3512.14\n",
            "Epoch 02300 | Time(s) 0.0894 | Loss 1.3854 | ETputs(KTEPS) 3512.53\n",
            "Epoch 02350 | Time(s) 0.0894 | Loss 1.3853 | ETputs(KTEPS) 3512.76\n",
            "Epoch 02400 | Time(s) 0.0894 | Loss 1.3852 | ETputs(KTEPS) 3513.04\n",
            "Epoch 02450 | Time(s) 0.0894 | Loss 1.3851 | ETputs(KTEPS) 3513.30\n",
            "Epoch 02500 | Time(s) 0.0894 | Loss 1.3850 | ETputs(KTEPS) 3513.53\n",
            "Epoch 02550 | Time(s) 0.0894 | Loss 1.3849 | ETputs(KTEPS) 3513.66\n",
            "Epoch 02600 | Time(s) 0.0894 | Loss 1.3847 | ETputs(KTEPS) 3513.55\n",
            "Epoch 02650 | Time(s) 0.0894 | Loss 1.3845 | ETputs(KTEPS) 3512.22\n",
            "Epoch 02700 | Time(s) 0.0894 | Loss 1.3842 | ETputs(KTEPS) 3511.20\n",
            "Epoch 02750 | Time(s) 0.0895 | Loss 1.3839 | ETputs(KTEPS) 3509.80\n",
            "Epoch 02800 | Time(s) 0.0895 | Loss 1.3836 | ETputs(KTEPS) 3509.34\n",
            "Epoch 02850 | Time(s) 0.0895 | Loss 1.3832 | ETputs(KTEPS) 3508.94\n",
            "Epoch 02900 | Time(s) 0.0895 | Loss 1.3827 | ETputs(KTEPS) 3508.67\n",
            "Epoch 02950 | Time(s) 0.0895 | Loss 1.3821 | ETputs(KTEPS) 3508.43\n",
            "Epoch 03000 | Time(s) 0.0895 | Loss 1.3813 | ETputs(KTEPS) 3508.20\n",
            "Epoch 03050 | Time(s) 0.0896 | Loss 1.3805 | ETputs(KTEPS) 3505.92\n",
            "Epoch 03100 | Time(s) 0.0896 | Loss 1.3800 | ETputs(KTEPS) 3505.81\n",
            "Epoch 03150 | Time(s) 0.0896 | Loss 1.3787 | ETputs(KTEPS) 3505.80\n",
            "Epoch 03200 | Time(s) 0.0896 | Loss 1.3788 | ETputs(KTEPS) 3505.76\n",
            "Epoch 03250 | Time(s) 0.0896 | Loss 1.3764 | ETputs(KTEPS) 3504.94\n",
            "Epoch 03300 | Time(s) 0.0896 | Loss 1.3760 | ETputs(KTEPS) 3503.80\n",
            "Epoch 03350 | Time(s) 0.0896 | Loss 1.3733 | ETputs(KTEPS) 3503.21\n",
            "Epoch 03400 | Time(s) 0.0897 | Loss 1.3728 | ETputs(KTEPS) 3501.88\n",
            "Epoch 03450 | Time(s) 0.0897 | Loss 1.3700 | ETputs(KTEPS) 3501.15\n",
            "Epoch 03500 | Time(s) 0.0897 | Loss 1.3717 | ETputs(KTEPS) 3500.82\n",
            "Epoch 03550 | Time(s) 0.0897 | Loss 1.3662 | ETputs(KTEPS) 3500.23\n",
            "Epoch 03600 | Time(s) 0.0897 | Loss 1.3735 | ETputs(KTEPS) 3499.34\n",
            "Epoch 03650 | Time(s) 0.0897 | Loss 1.3618 | ETputs(KTEPS) 3498.84\n",
            "Epoch 03700 | Time(s) 0.0898 | Loss 1.3621 | ETputs(KTEPS) 3498.66\n",
            "Epoch 03750 | Time(s) 0.0898 | Loss 1.2789 | ETputs(KTEPS) 3498.35\n",
            "Epoch 03800 | Time(s) 0.0898 | Loss 1.2129 | ETputs(KTEPS) 3498.10\n",
            "Epoch 03850 | Time(s) 0.0898 | Loss 0.9914 | ETputs(KTEPS) 3497.37\n",
            "Epoch 03900 | Time(s) 0.0898 | Loss 0.8479 | ETputs(KTEPS) 3496.91\n",
            "Epoch 03950 | Time(s) 0.0898 | Loss 0.4838 | ETputs(KTEPS) 3496.65\n"
          ]
        }
      ],
      "source": [
        "cnt_wait = 0\n",
        "best = 1e9\n",
        "best_t = 0\n",
        "dur = []\n",
        "node_features = train_g.ndata['h'] \n",
        "edge_features = train_g.edata['h']\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    dgi.train()\n",
        "    if epoch >= 3:\n",
        "        t0 = time.time()\n",
        "\n",
        "    dgi_optimizer.zero_grad()\n",
        "    loss = dgi(train_g, node_features, edge_features)\n",
        "    loss.backward()\n",
        "    dgi_optimizer.step()\n",
        "\n",
        "    if loss < best:\n",
        "        best = loss\n",
        "        best_t = epoch\n",
        "        cnt_wait = 0\n",
        "        torch.save(dgi.state_dict(), 'best_dgi_UNSW_v3.pkl')\n",
        "    else:\n",
        "        cnt_wait += 1\n",
        "\n",
        "  # if cnt_wait == patience:\n",
        "  #     print('Early stopping!')\n",
        "  #     break\n",
        "\n",
        "    if epoch >= 3:\n",
        "        dur.append(time.time() - t0)\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "\n",
        "        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
        "            \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
        "              loss.item(),\n",
        "              train_g.num_edges() / np.mean(dur) / 1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RZ2HAQDAF-4c",
        "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_71465/1319261381.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  dgi.load_state_dict(torch.load('best_dgi_UNSW_v3.pkl'))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dgi.load_state_dict(torch.load('best_dgi_UNSW_v3.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6Ek16GkRStKP"
      },
      "outputs": [],
      "source": [
        "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
        "training_emb = training_emb.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-FwaBlOdS4ep"
      },
      "outputs": [],
      "source": [
        "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
        "                                   (test_g.ndata['h'].shape[0], 1,\n",
        "                                    test_g.ndata['h'].shape[1]))\n",
        "\n",
        "\n",
        "\n",
        "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
        "                                   (test_g.edata['h'].shape[0], 1,\n",
        "                                    test_g.edata['h'].shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "SBa-rdivS6cQ"
      },
      "outputs": [],
      "source": [
        "# Convert to GPU\n",
        "test_g = test_g.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "W12WLjslS-kx"
      },
      "outputs": [],
      "source": [
        "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
        "testing_emb = testing_emb.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ERsOAMjeS_D8"
      },
      "outputs": [],
      "source": [
        "df_train = pd.DataFrame(training_emb, )\n",
        "df_train[\"Attack\"] = lab_enc.inverse_transform(\n",
        "        train_g.edata['Attack'].detach().cpu().numpy())\n",
        "df_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
        "\n",
        "df_test = pd.DataFrame(testing_emb, )\n",
        "df_test[\"Attack\"] = lab_enc.inverse_transform(\n",
        "        test_g.edata['Attack'].detach().cpu().numpy())\n",
        "df_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "B8p79H9dat5T",
        "outputId": "0d6e82d8-5d02-49eb-a16f-d44e52ea3dff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>Attack</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.086565</td>\n",
              "      <td>-0.078549</td>\n",
              "      <td>0.047042</td>\n",
              "      <td>-0.007064</td>\n",
              "      <td>0.074815</td>\n",
              "      <td>0.074366</td>\n",
              "      <td>0.079844</td>\n",
              "      <td>0.014425</td>\n",
              "      <td>0.006140</td>\n",
              "      <td>0.175500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060640</td>\n",
              "      <td>0.072725</td>\n",
              "      <td>-0.035717</td>\n",
              "      <td>0.003195</td>\n",
              "      <td>-0.009364</td>\n",
              "      <td>-0.047279</td>\n",
              "      <td>-0.045267</td>\n",
              "      <td>0.116082</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.086565</td>\n",
              "      <td>-0.078549</td>\n",
              "      <td>0.047042</td>\n",
              "      <td>-0.007064</td>\n",
              "      <td>0.074815</td>\n",
              "      <td>0.074366</td>\n",
              "      <td>0.079844</td>\n",
              "      <td>0.014425</td>\n",
              "      <td>0.006140</td>\n",
              "      <td>0.175500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060640</td>\n",
              "      <td>0.072725</td>\n",
              "      <td>-0.035717</td>\n",
              "      <td>0.003195</td>\n",
              "      <td>-0.009364</td>\n",
              "      <td>-0.047279</td>\n",
              "      <td>-0.045267</td>\n",
              "      <td>0.116082</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.086565</td>\n",
              "      <td>-0.078549</td>\n",
              "      <td>0.047042</td>\n",
              "      <td>-0.007064</td>\n",
              "      <td>0.074815</td>\n",
              "      <td>0.074366</td>\n",
              "      <td>0.079844</td>\n",
              "      <td>0.014425</td>\n",
              "      <td>0.006140</td>\n",
              "      <td>0.175500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060640</td>\n",
              "      <td>0.072725</td>\n",
              "      <td>-0.035717</td>\n",
              "      <td>0.003195</td>\n",
              "      <td>-0.009364</td>\n",
              "      <td>-0.047279</td>\n",
              "      <td>-0.045267</td>\n",
              "      <td>0.116082</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.086565</td>\n",
              "      <td>-0.078549</td>\n",
              "      <td>0.047042</td>\n",
              "      <td>-0.007064</td>\n",
              "      <td>0.074815</td>\n",
              "      <td>0.074366</td>\n",
              "      <td>0.079844</td>\n",
              "      <td>0.014425</td>\n",
              "      <td>0.006140</td>\n",
              "      <td>0.175500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060640</td>\n",
              "      <td>0.072725</td>\n",
              "      <td>-0.035717</td>\n",
              "      <td>0.003195</td>\n",
              "      <td>-0.009364</td>\n",
              "      <td>-0.047279</td>\n",
              "      <td>-0.045267</td>\n",
              "      <td>0.116082</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.086565</td>\n",
              "      <td>-0.078549</td>\n",
              "      <td>0.047042</td>\n",
              "      <td>-0.007064</td>\n",
              "      <td>0.074815</td>\n",
              "      <td>0.074366</td>\n",
              "      <td>0.079844</td>\n",
              "      <td>0.014425</td>\n",
              "      <td>0.006140</td>\n",
              "      <td>0.175500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060640</td>\n",
              "      <td>0.072725</td>\n",
              "      <td>-0.035717</td>\n",
              "      <td>0.003195</td>\n",
              "      <td>-0.009364</td>\n",
              "      <td>-0.047279</td>\n",
              "      <td>-0.045267</td>\n",
              "      <td>0.116082</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314005</th>\n",
              "      <td>0.074496</td>\n",
              "      <td>-0.016501</td>\n",
              "      <td>0.164899</td>\n",
              "      <td>0.047463</td>\n",
              "      <td>-0.003604</td>\n",
              "      <td>0.042451</td>\n",
              "      <td>0.055327</td>\n",
              "      <td>-0.040595</td>\n",
              "      <td>0.019819</td>\n",
              "      <td>0.295323</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072077</td>\n",
              "      <td>0.107858</td>\n",
              "      <td>-0.025936</td>\n",
              "      <td>0.070601</td>\n",
              "      <td>-0.004867</td>\n",
              "      <td>0.010269</td>\n",
              "      <td>0.003222</td>\n",
              "      <td>0.056055</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314006</th>\n",
              "      <td>0.074496</td>\n",
              "      <td>-0.016501</td>\n",
              "      <td>0.164899</td>\n",
              "      <td>0.047463</td>\n",
              "      <td>-0.003604</td>\n",
              "      <td>0.042451</td>\n",
              "      <td>0.055327</td>\n",
              "      <td>-0.040595</td>\n",
              "      <td>0.019819</td>\n",
              "      <td>0.295323</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072077</td>\n",
              "      <td>0.107858</td>\n",
              "      <td>-0.025936</td>\n",
              "      <td>0.070601</td>\n",
              "      <td>-0.004867</td>\n",
              "      <td>0.010269</td>\n",
              "      <td>0.003222</td>\n",
              "      <td>0.056055</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314007</th>\n",
              "      <td>0.075656</td>\n",
              "      <td>-0.013816</td>\n",
              "      <td>0.163346</td>\n",
              "      <td>0.043606</td>\n",
              "      <td>-0.003214</td>\n",
              "      <td>0.038514</td>\n",
              "      <td>0.052368</td>\n",
              "      <td>-0.043132</td>\n",
              "      <td>0.019450</td>\n",
              "      <td>0.294129</td>\n",
              "      <td>...</td>\n",
              "      <td>0.071256</td>\n",
              "      <td>0.107451</td>\n",
              "      <td>-0.026052</td>\n",
              "      <td>0.070893</td>\n",
              "      <td>-0.005146</td>\n",
              "      <td>0.010128</td>\n",
              "      <td>0.006694</td>\n",
              "      <td>0.058039</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314008</th>\n",
              "      <td>0.075741</td>\n",
              "      <td>-0.012053</td>\n",
              "      <td>0.165243</td>\n",
              "      <td>0.042784</td>\n",
              "      <td>-0.002876</td>\n",
              "      <td>0.033116</td>\n",
              "      <td>0.050093</td>\n",
              "      <td>-0.041187</td>\n",
              "      <td>0.021071</td>\n",
              "      <td>0.292281</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072707</td>\n",
              "      <td>0.107472</td>\n",
              "      <td>-0.027843</td>\n",
              "      <td>0.070031</td>\n",
              "      <td>-0.005759</td>\n",
              "      <td>0.010884</td>\n",
              "      <td>0.010045</td>\n",
              "      <td>0.058938</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314009</th>\n",
              "      <td>0.075741</td>\n",
              "      <td>-0.012053</td>\n",
              "      <td>0.165243</td>\n",
              "      <td>0.042784</td>\n",
              "      <td>-0.002876</td>\n",
              "      <td>0.033116</td>\n",
              "      <td>0.050093</td>\n",
              "      <td>-0.041187</td>\n",
              "      <td>0.021071</td>\n",
              "      <td>0.292281</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072707</td>\n",
              "      <td>0.107472</td>\n",
              "      <td>-0.027843</td>\n",
              "      <td>0.070031</td>\n",
              "      <td>-0.005759</td>\n",
              "      <td>0.010884</td>\n",
              "      <td>0.010045</td>\n",
              "      <td>0.058938</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>314010 rows × 258 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0         1         2         3         4         5         6  \\\n",
              "0       0.086565 -0.078549  0.047042 -0.007064  0.074815  0.074366  0.079844   \n",
              "1       0.086565 -0.078549  0.047042 -0.007064  0.074815  0.074366  0.079844   \n",
              "2       0.086565 -0.078549  0.047042 -0.007064  0.074815  0.074366  0.079844   \n",
              "3       0.086565 -0.078549  0.047042 -0.007064  0.074815  0.074366  0.079844   \n",
              "4       0.086565 -0.078549  0.047042 -0.007064  0.074815  0.074366  0.079844   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "314005  0.074496 -0.016501  0.164899  0.047463 -0.003604  0.042451  0.055327   \n",
              "314006  0.074496 -0.016501  0.164899  0.047463 -0.003604  0.042451  0.055327   \n",
              "314007  0.075656 -0.013816  0.163346  0.043606 -0.003214  0.038514  0.052368   \n",
              "314008  0.075741 -0.012053  0.165243  0.042784 -0.002876  0.033116  0.050093   \n",
              "314009  0.075741 -0.012053  0.165243  0.042784 -0.002876  0.033116  0.050093   \n",
              "\n",
              "               7         8         9  ...       248       249       250  \\\n",
              "0       0.014425  0.006140  0.175500  ...  0.060640  0.072725 -0.035717   \n",
              "1       0.014425  0.006140  0.175500  ...  0.060640  0.072725 -0.035717   \n",
              "2       0.014425  0.006140  0.175500  ...  0.060640  0.072725 -0.035717   \n",
              "3       0.014425  0.006140  0.175500  ...  0.060640  0.072725 -0.035717   \n",
              "4       0.014425  0.006140  0.175500  ...  0.060640  0.072725 -0.035717   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "314005 -0.040595  0.019819  0.295323  ...  0.072077  0.107858 -0.025936   \n",
              "314006 -0.040595  0.019819  0.295323  ...  0.072077  0.107858 -0.025936   \n",
              "314007 -0.043132  0.019450  0.294129  ...  0.071256  0.107451 -0.026052   \n",
              "314008 -0.041187  0.021071  0.292281  ...  0.072707  0.107472 -0.027843   \n",
              "314009 -0.041187  0.021071  0.292281  ...  0.072707  0.107472 -0.027843   \n",
              "\n",
              "             251       252       253       254       255  Attack  Label  \n",
              "0       0.003195 -0.009364 -0.047279 -0.045267  0.116082  Benign      0  \n",
              "1       0.003195 -0.009364 -0.047279 -0.045267  0.116082  Benign      0  \n",
              "2       0.003195 -0.009364 -0.047279 -0.045267  0.116082  Benign      0  \n",
              "3       0.003195 -0.009364 -0.047279 -0.045267  0.116082  Benign      0  \n",
              "4       0.003195 -0.009364 -0.047279 -0.045267  0.116082  Benign      0  \n",
              "...          ...       ...       ...       ...       ...     ...    ...  \n",
              "314005  0.070601 -0.004867  0.010269  0.003222  0.056055  Benign      0  \n",
              "314006  0.070601 -0.004867  0.010269  0.003222  0.056055  Benign      0  \n",
              "314007  0.070893 -0.005146  0.010128  0.006694  0.058039  Benign      0  \n",
              "314008  0.070031 -0.005759  0.010884  0.010045  0.058938  Benign      0  \n",
              "314009  0.070031 -0.005759  0.010884  0.010045  0.058938  Benign      0  \n",
              "\n",
              "[314010 rows x 258 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ScEk1y_TzzX"
      },
      "source": [
        "# Embeddings CBLOF  Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZYABKzdrTGas"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import dgl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import gc\n",
        "\n",
        "from tqdm import tqdm\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "RkFS_-dcTJeK"
      },
      "outputs": [],
      "source": [
        "benign_train_samples = df_train[df_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "normal_train_samples = df_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "train_labels = df_train[\"Label\"]\n",
        "test_labels = df_test[\"Label\"]\n",
        "\n",
        "test_samples = df_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.086665</td>\n",
              "      <td>-0.077150</td>\n",
              "      <td>0.047454</td>\n",
              "      <td>-0.007279</td>\n",
              "      <td>0.074681</td>\n",
              "      <td>0.073748</td>\n",
              "      <td>0.078764</td>\n",
              "      <td>0.015200</td>\n",
              "      <td>0.006211</td>\n",
              "      <td>0.175336</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042621</td>\n",
              "      <td>0.038639</td>\n",
              "      <td>0.060561</td>\n",
              "      <td>0.072690</td>\n",
              "      <td>-0.035716</td>\n",
              "      <td>0.004154</td>\n",
              "      <td>-0.009358</td>\n",
              "      <td>-0.047378</td>\n",
              "      <td>-0.044947</td>\n",
              "      <td>0.116477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.086665</td>\n",
              "      <td>-0.077150</td>\n",
              "      <td>0.047454</td>\n",
              "      <td>-0.007279</td>\n",
              "      <td>0.074681</td>\n",
              "      <td>0.073748</td>\n",
              "      <td>0.078764</td>\n",
              "      <td>0.015200</td>\n",
              "      <td>0.006211</td>\n",
              "      <td>0.175336</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042621</td>\n",
              "      <td>0.038639</td>\n",
              "      <td>0.060561</td>\n",
              "      <td>0.072690</td>\n",
              "      <td>-0.035716</td>\n",
              "      <td>0.004154</td>\n",
              "      <td>-0.009358</td>\n",
              "      <td>-0.047378</td>\n",
              "      <td>-0.044947</td>\n",
              "      <td>0.116477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.086665</td>\n",
              "      <td>-0.077150</td>\n",
              "      <td>0.047454</td>\n",
              "      <td>-0.007279</td>\n",
              "      <td>0.074681</td>\n",
              "      <td>0.073748</td>\n",
              "      <td>0.078764</td>\n",
              "      <td>0.015200</td>\n",
              "      <td>0.006211</td>\n",
              "      <td>0.175336</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042621</td>\n",
              "      <td>0.038639</td>\n",
              "      <td>0.060561</td>\n",
              "      <td>0.072690</td>\n",
              "      <td>-0.035716</td>\n",
              "      <td>0.004154</td>\n",
              "      <td>-0.009358</td>\n",
              "      <td>-0.047378</td>\n",
              "      <td>-0.044947</td>\n",
              "      <td>0.116477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.086665</td>\n",
              "      <td>-0.077150</td>\n",
              "      <td>0.047454</td>\n",
              "      <td>-0.007279</td>\n",
              "      <td>0.074681</td>\n",
              "      <td>0.073748</td>\n",
              "      <td>0.078764</td>\n",
              "      <td>0.015200</td>\n",
              "      <td>0.006211</td>\n",
              "      <td>0.175336</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042621</td>\n",
              "      <td>0.038639</td>\n",
              "      <td>0.060561</td>\n",
              "      <td>0.072690</td>\n",
              "      <td>-0.035716</td>\n",
              "      <td>0.004154</td>\n",
              "      <td>-0.009358</td>\n",
              "      <td>-0.047378</td>\n",
              "      <td>-0.044947</td>\n",
              "      <td>0.116477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.086665</td>\n",
              "      <td>-0.077150</td>\n",
              "      <td>0.047454</td>\n",
              "      <td>-0.007279</td>\n",
              "      <td>0.074681</td>\n",
              "      <td>0.073748</td>\n",
              "      <td>0.078764</td>\n",
              "      <td>0.015200</td>\n",
              "      <td>0.006211</td>\n",
              "      <td>0.175336</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042621</td>\n",
              "      <td>0.038639</td>\n",
              "      <td>0.060561</td>\n",
              "      <td>0.072690</td>\n",
              "      <td>-0.035716</td>\n",
              "      <td>0.004154</td>\n",
              "      <td>-0.009358</td>\n",
              "      <td>-0.047378</td>\n",
              "      <td>-0.044947</td>\n",
              "      <td>0.116477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134570</th>\n",
              "      <td>0.076041</td>\n",
              "      <td>-0.011342</td>\n",
              "      <td>0.164471</td>\n",
              "      <td>0.042110</td>\n",
              "      <td>-0.003041</td>\n",
              "      <td>0.031472</td>\n",
              "      <td>0.049593</td>\n",
              "      <td>-0.040263</td>\n",
              "      <td>0.021010</td>\n",
              "      <td>0.291303</td>\n",
              "      <td>...</td>\n",
              "      <td>0.036148</td>\n",
              "      <td>-0.022990</td>\n",
              "      <td>0.072594</td>\n",
              "      <td>0.106978</td>\n",
              "      <td>-0.027857</td>\n",
              "      <td>0.070675</td>\n",
              "      <td>-0.006553</td>\n",
              "      <td>0.010637</td>\n",
              "      <td>0.010740</td>\n",
              "      <td>0.059727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134571</th>\n",
              "      <td>0.075704</td>\n",
              "      <td>-0.012132</td>\n",
              "      <td>0.165324</td>\n",
              "      <td>0.042877</td>\n",
              "      <td>-0.002877</td>\n",
              "      <td>0.033308</td>\n",
              "      <td>0.050156</td>\n",
              "      <td>-0.041293</td>\n",
              "      <td>0.021071</td>\n",
              "      <td>0.292362</td>\n",
              "      <td>...</td>\n",
              "      <td>0.037042</td>\n",
              "      <td>-0.023410</td>\n",
              "      <td>0.072710</td>\n",
              "      <td>0.107524</td>\n",
              "      <td>-0.027825</td>\n",
              "      <td>0.069943</td>\n",
              "      <td>-0.005669</td>\n",
              "      <td>0.010920</td>\n",
              "      <td>0.009956</td>\n",
              "      <td>0.058846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134572</th>\n",
              "      <td>0.075704</td>\n",
              "      <td>-0.012132</td>\n",
              "      <td>0.165324</td>\n",
              "      <td>0.042877</td>\n",
              "      <td>-0.002877</td>\n",
              "      <td>0.033308</td>\n",
              "      <td>0.050156</td>\n",
              "      <td>-0.041293</td>\n",
              "      <td>0.021071</td>\n",
              "      <td>0.292362</td>\n",
              "      <td>...</td>\n",
              "      <td>0.037042</td>\n",
              "      <td>-0.023410</td>\n",
              "      <td>0.072710</td>\n",
              "      <td>0.107524</td>\n",
              "      <td>-0.027825</td>\n",
              "      <td>0.069943</td>\n",
              "      <td>-0.005669</td>\n",
              "      <td>0.010920</td>\n",
              "      <td>0.009956</td>\n",
              "      <td>0.058846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134573</th>\n",
              "      <td>0.075704</td>\n",
              "      <td>-0.012132</td>\n",
              "      <td>0.165324</td>\n",
              "      <td>0.042877</td>\n",
              "      <td>-0.002877</td>\n",
              "      <td>0.033308</td>\n",
              "      <td>0.050156</td>\n",
              "      <td>-0.041293</td>\n",
              "      <td>0.021071</td>\n",
              "      <td>0.292362</td>\n",
              "      <td>...</td>\n",
              "      <td>0.037042</td>\n",
              "      <td>-0.023410</td>\n",
              "      <td>0.072710</td>\n",
              "      <td>0.107524</td>\n",
              "      <td>-0.027825</td>\n",
              "      <td>0.069943</td>\n",
              "      <td>-0.005669</td>\n",
              "      <td>0.010920</td>\n",
              "      <td>0.009956</td>\n",
              "      <td>0.058846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134574</th>\n",
              "      <td>0.068403</td>\n",
              "      <td>-0.021661</td>\n",
              "      <td>0.171648</td>\n",
              "      <td>0.048546</td>\n",
              "      <td>-0.011978</td>\n",
              "      <td>0.042046</td>\n",
              "      <td>0.059924</td>\n",
              "      <td>-0.035130</td>\n",
              "      <td>0.031238</td>\n",
              "      <td>0.294926</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048374</td>\n",
              "      <td>-0.022125</td>\n",
              "      <td>0.081614</td>\n",
              "      <td>0.110979</td>\n",
              "      <td>-0.023380</td>\n",
              "      <td>0.069417</td>\n",
              "      <td>0.010316</td>\n",
              "      <td>0.015663</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.061551</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>134575 rows × 256 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2         3         4         5         6    \\\n",
              "0       0.086665 -0.077150  0.047454 -0.007279  0.074681  0.073748  0.078764   \n",
              "1       0.086665 -0.077150  0.047454 -0.007279  0.074681  0.073748  0.078764   \n",
              "2       0.086665 -0.077150  0.047454 -0.007279  0.074681  0.073748  0.078764   \n",
              "3       0.086665 -0.077150  0.047454 -0.007279  0.074681  0.073748  0.078764   \n",
              "4       0.086665 -0.077150  0.047454 -0.007279  0.074681  0.073748  0.078764   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "134570  0.076041 -0.011342  0.164471  0.042110 -0.003041  0.031472  0.049593   \n",
              "134571  0.075704 -0.012132  0.165324  0.042877 -0.002877  0.033308  0.050156   \n",
              "134572  0.075704 -0.012132  0.165324  0.042877 -0.002877  0.033308  0.050156   \n",
              "134573  0.075704 -0.012132  0.165324  0.042877 -0.002877  0.033308  0.050156   \n",
              "134574  0.068403 -0.021661  0.171648  0.048546 -0.011978  0.042046  0.059924   \n",
              "\n",
              "             7         8         9    ...       246       247       248  \\\n",
              "0       0.015200  0.006211  0.175336  ...  0.042621  0.038639  0.060561   \n",
              "1       0.015200  0.006211  0.175336  ...  0.042621  0.038639  0.060561   \n",
              "2       0.015200  0.006211  0.175336  ...  0.042621  0.038639  0.060561   \n",
              "3       0.015200  0.006211  0.175336  ...  0.042621  0.038639  0.060561   \n",
              "4       0.015200  0.006211  0.175336  ...  0.042621  0.038639  0.060561   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "134570 -0.040263  0.021010  0.291303  ...  0.036148 -0.022990  0.072594   \n",
              "134571 -0.041293  0.021071  0.292362  ...  0.037042 -0.023410  0.072710   \n",
              "134572 -0.041293  0.021071  0.292362  ...  0.037042 -0.023410  0.072710   \n",
              "134573 -0.041293  0.021071  0.292362  ...  0.037042 -0.023410  0.072710   \n",
              "134574 -0.035130  0.031238  0.294926  ...  0.048374 -0.022125  0.081614   \n",
              "\n",
              "             249       250       251       252       253       254       255  \n",
              "0       0.072690 -0.035716  0.004154 -0.009358 -0.047378 -0.044947  0.116477  \n",
              "1       0.072690 -0.035716  0.004154 -0.009358 -0.047378 -0.044947  0.116477  \n",
              "2       0.072690 -0.035716  0.004154 -0.009358 -0.047378 -0.044947  0.116477  \n",
              "3       0.072690 -0.035716  0.004154 -0.009358 -0.047378 -0.044947  0.116477  \n",
              "4       0.072690 -0.035716  0.004154 -0.009358 -0.047378 -0.044947  0.116477  \n",
              "...          ...       ...       ...       ...       ...       ...       ...  \n",
              "134570  0.106978 -0.027857  0.070675 -0.006553  0.010637  0.010740  0.059727  \n",
              "134571  0.107524 -0.027825  0.069943 -0.005669  0.010920  0.009956  0.058846  \n",
              "134572  0.107524 -0.027825  0.069943 -0.005669  0.010920  0.009956  0.058846  \n",
              "134573  0.107524 -0.027825  0.069943 -0.005669  0.010920  0.009956  0.058846  \n",
              "134574  0.110979 -0.023380  0.069417  0.010316  0.015663  0.000100  0.061551  \n",
              "\n",
              "[134575 rows x 256 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_raw_train = pd.concat([X_train.drop(columns=[\"IPV4_SRC_ADDR\",\"IPV4_DST_ADDR\", \"h\"]), y_train], axis=1)\n",
        "df_raw_test = pd.concat([X_test.drop(columns=[\"IPV4_SRC_ADDR\",\"IPV4_DST_ADDR\", \"h\"]), y_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>TCP_FLAGS</th>\n",
              "      <th>CLIENT_TCP_FLAGS</th>\n",
              "      <th>SERVER_TCP_FLAGS</th>\n",
              "      <th>FLOW_DURATION_MILLISECONDS</th>\n",
              "      <th>...</th>\n",
              "      <th>TCP_WIN_MAX_IN</th>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <th>ICMP_TYPE</th>\n",
              "      <th>ICMP_IPV4_TYPE</th>\n",
              "      <th>DNS_QUERY_ID</th>\n",
              "      <th>DNS_QUERY_TYPE</th>\n",
              "      <th>DNS_TTL_ANSWER</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>Attack</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>287406</th>\n",
              "      <td>4.732152e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.003486</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000317</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>1.505900e-09</td>\n",
              "      <td>1.611550e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.530544e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001493</td>\n",
              "      <td>0.002850</td>\n",
              "      <td>2.127056e-08</td>\n",
              "      <td>2.097309e-08</td>\n",
              "      <td>4.396601e-09</td>\n",
              "      <td>4.397286e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.240589e-09</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610356</th>\n",
              "      <td>6.932495e-10</td>\n",
              "      <td>7.976222e-09</td>\n",
              "      <td>0.000215</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>9.621527e-10</td>\n",
              "      <td>9.621527e-10</td>\n",
              "      <td>4.168656e-09</td>\n",
              "      <td>4.198509e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.010061e-09</td>\n",
              "      <td>4.009943e-09</td>\n",
              "      <td>1.969528e-08</td>\n",
              "      <td>1.969835e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.899640e-08</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456518</th>\n",
              "      <td>6.381741e-07</td>\n",
              "      <td>2.401223e-07</td>\n",
              "      <td>0.060366</td>\n",
              "      <td>0.000354</td>\n",
              "      <td>0.038930</td>\n",
              "      <td>0.000379</td>\n",
              "      <td>2.030844e-07</td>\n",
              "      <td>2.173323e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.533152e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.183020</td>\n",
              "      <td>0.183020</td>\n",
              "      <td>4.321202e-07</td>\n",
              "      <td>4.840666e-07</td>\n",
              "      <td>5.929219e-07</td>\n",
              "      <td>5.930143e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.718822e-07</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2204716</th>\n",
              "      <td>1.390953e-08</td>\n",
              "      <td>2.334703e-08</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000476</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>4.426392e-09</td>\n",
              "      <td>4.736937e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.101955e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002792</td>\n",
              "      <td>0.003191</td>\n",
              "      <td>4.531849e-09</td>\n",
              "      <td>4.766241e-09</td>\n",
              "      <td>1.292322e-08</td>\n",
              "      <td>1.292524e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.246465e-08</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1090799</th>\n",
              "      <td>4.602189e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001485</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>1.464542e-09</td>\n",
              "      <td>1.567291e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.002648e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001980</td>\n",
              "      <td>0.001320</td>\n",
              "      <td>8.530939e-11</td>\n",
              "      <td>8.530939e-11</td>\n",
              "      <td>4.275853e-09</td>\n",
              "      <td>4.276519e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.124125e-09</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1225204</th>\n",
              "      <td>1.960806e-09</td>\n",
              "      <td>1.118412e-09</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000195</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>2.721379e-09</td>\n",
              "      <td>2.721379e-09</td>\n",
              "      <td>1.179074e-08</td>\n",
              "      <td>1.187518e-06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.134216e-08</td>\n",
              "      <td>1.134183e-08</td>\n",
              "      <td>4.233212e-08</td>\n",
              "      <td>4.713307e-10</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>5.372992e-08</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1161575</th>\n",
              "      <td>3.553645e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000195</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001865</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>1.130867e-09</td>\n",
              "      <td>1.210206e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.853564e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001936</td>\n",
              "      <td>0.001019</td>\n",
              "      <td>1.647801e-10</td>\n",
              "      <td>1.647801e-10</td>\n",
              "      <td>3.301660e-09</td>\n",
              "      <td>3.302174e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.184501e-09</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1927342</th>\n",
              "      <td>7.894386e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.030020</td>\n",
              "      <td>0.000344</td>\n",
              "      <td>0.067420</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>2.512209e-07</td>\n",
              "      <td>2.688460e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.662692e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.203761</td>\n",
              "      <td>0.203761</td>\n",
              "      <td>6.386150e-08</td>\n",
              "      <td>6.386150e-08</td>\n",
              "      <td>7.334604e-07</td>\n",
              "      <td>7.335747e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.074338e-07</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844639</th>\n",
              "      <td>2.088732e-06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.042651</td>\n",
              "      <td>0.000786</td>\n",
              "      <td>0.060978</td>\n",
              "      <td>0.000869</td>\n",
              "      <td>5.627404e-07</td>\n",
              "      <td>5.628146e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.223766e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.599022</td>\n",
              "      <td>0.539120</td>\n",
              "      <td>1.482757e-07</td>\n",
              "      <td>1.751208e-07</td>\n",
              "      <td>1.940623e-06</td>\n",
              "      <td>1.940925e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.339281e-06</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024253</th>\n",
              "      <td>1.088598e-08</td>\n",
              "      <td>2.780065e-08</td>\n",
              "      <td>0.004095</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.234555</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>3.464216e-09</td>\n",
              "      <td>3.707257e-09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.191361e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014049</td>\n",
              "      <td>0.001561</td>\n",
              "      <td>3.008442e-09</td>\n",
              "      <td>3.290587e-09</td>\n",
              "      <td>1.011407e-08</td>\n",
              "      <td>1.011564e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.755173e-09</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>157006 rows × 41 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             PROTOCOL      L7_PROTO  IN_BYTES   IN_PKTS  OUT_BYTES  OUT_PKTS  \\\n",
              "287406   4.732152e-09  0.000000e+00  0.003486  0.000005   0.000317  0.000004   \n",
              "610356   6.932495e-10  7.976222e-09  0.000215  0.000002   0.000128  0.000002   \n",
              "1456518  6.381741e-07  2.401223e-07  0.060366  0.000354   0.038930  0.000379   \n",
              "2204716  1.390953e-08  2.334703e-08  0.000405  0.000006   0.000476  0.000004   \n",
              "1090799  4.602189e-09  0.000000e+00  0.000213  0.000003   0.001485  0.000003   \n",
              "...               ...           ...       ...       ...        ...       ...   \n",
              "1225204  1.960806e-09  1.118412e-09  0.000157  0.000002   0.000195  0.000002   \n",
              "1161575  3.553645e-09  0.000000e+00  0.000195  0.000003   0.001865  0.000003   \n",
              "1927342  7.894386e-07  0.000000e+00  0.030020  0.000344   0.067420  0.000375   \n",
              "844639   2.088732e-06  0.000000e+00  0.042651  0.000786   0.060978  0.000869   \n",
              "2024253  1.088598e-08  2.780065e-08  0.004095  0.000077   0.234555  0.000161   \n",
              "\n",
              "            TCP_FLAGS  CLIENT_TCP_FLAGS  SERVER_TCP_FLAGS  \\\n",
              "287406   1.505900e-09      1.611550e-09      0.000000e+00   \n",
              "610356   9.621527e-10      9.621527e-10      4.168656e-09   \n",
              "1456518  2.030844e-07      2.173323e-07      0.000000e+00   \n",
              "2204716  4.426392e-09      4.736937e-09      0.000000e+00   \n",
              "1090799  1.464542e-09      1.567291e-09      0.000000e+00   \n",
              "...               ...               ...               ...   \n",
              "1225204  2.721379e-09      2.721379e-09      1.179074e-08   \n",
              "1161575  1.130867e-09      1.210206e-09      0.000000e+00   \n",
              "1927342  2.512209e-07      2.688460e-07      0.000000e+00   \n",
              "844639   5.627404e-07      5.628146e-07      0.000000e+00   \n",
              "2024253  3.464216e-09      3.707257e-09      0.000000e+00   \n",
              "\n",
              "         FLOW_DURATION_MILLISECONDS  ...  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
              "287406                 2.530544e-06  ...        0.001493         0.002850   \n",
              "610356                 4.198509e-07  ...        0.000000         0.000000   \n",
              "1456518                7.533152e-03  ...        0.183020         0.183020   \n",
              "2204716                1.101955e-06  ...        0.002792         0.003191   \n",
              "1090799                1.002648e-06  ...        0.001980         0.001320   \n",
              "...                             ...  ...             ...              ...   \n",
              "1225204                1.187518e-06  ...        0.000000         0.000000   \n",
              "1161575                9.853564e-07  ...        0.001936         0.001019   \n",
              "1927342                9.662692e-03  ...        0.203761         0.203761   \n",
              "844639                 4.223766e-02  ...        0.599022         0.539120   \n",
              "2024253                4.191361e-04  ...        0.014049         0.001561   \n",
              "\n",
              "            ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
              "287406   2.127056e-08    2.097309e-08  4.396601e-09    4.397286e-09   \n",
              "610356   4.010061e-09    4.009943e-09  1.969528e-08    1.969835e-08   \n",
              "1456518  4.321202e-07    4.840666e-07  5.929219e-07    5.930143e-07   \n",
              "2204716  4.531849e-09    4.766241e-09  1.292322e-08    1.292524e-08   \n",
              "1090799  8.530939e-11    8.530939e-11  4.275853e-09    4.276519e-09   \n",
              "...               ...             ...           ...             ...   \n",
              "1225204  1.134216e-08    1.134183e-08  4.233212e-08    4.713307e-10   \n",
              "1161575  1.647801e-10    1.647801e-10  3.301660e-09    3.302174e-09   \n",
              "1927342  6.386150e-08    6.386150e-08  7.334604e-07    7.335747e-07   \n",
              "844639   1.482757e-07    1.751208e-07  1.940623e-06    1.940925e-06   \n",
              "2024253  3.008442e-09    3.290587e-09  1.011407e-08    1.011564e-08   \n",
              "\n",
              "         DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  Attack  Label  \n",
              "287406         0.000000          4.240589e-09  Benign      0  \n",
              "610356         0.000000          1.899640e-08  Benign      0  \n",
              "1456518        0.000000          5.718822e-07  Benign      0  \n",
              "2204716        0.000000          1.246465e-08  Benign      0  \n",
              "1090799        0.000000          4.124125e-09  Benign      0  \n",
              "...                 ...                   ...     ...    ...  \n",
              "1225204        0.000071          5.372992e-08  Benign      0  \n",
              "1161575        0.000000          3.184501e-09  Benign      0  \n",
              "1927342        0.000000          7.074338e-07  Benign      0  \n",
              "844639         0.000000          1.339281e-06  Benign      0  \n",
              "2024253        0.000000          9.755173e-09  Benign      0  \n",
              "\n",
              "[157006 rows x 41 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_raw_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_benign_train_samples = df_raw_train[df_raw_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "raw_normal_train_samples = df_raw_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "raw_train_labels = df_raw_train[\"Label\"]\n",
        "raw_test_labels = df_raw_test[\"Label\"]\n",
        "\n",
        "raw_test_samples = df_raw_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "62BUDLtO4mla"
      },
      "outputs": [],
      "source": [
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "2i48uLj74mla",
        "outputId": "a0dd33ee-824d-4328-a960-e656e3aaf0ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [01:48<00:00,  3.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 2, 'con': 0.001}\n",
            "0.9373418473269503\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9884    0.9942    129059\n",
            "           1     0.7865    1.0000    0.8805      5516\n",
            "\n",
            "    accuracy                         0.9889    134575\n",
            "   macro avg     0.8933    0.9942    0.9373    134575\n",
            "weighted avg     0.9913    0.9889    0.9895    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "n_est = [2,3,5,7,9,10]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "rK-Rng9q4mla",
        "outputId": "1796db22-cfb8-4bf8-9004-6420c08c3399"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [01:28<00:00,  2.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 2, 'con': 0.04}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "tHSOcEhH4mlb"
      },
      "outputs": [],
      "source": [
        "###  CBLOF RAW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "u_l1Vz8S4mlb",
        "outputId": "c1b8d03c-7105-42d9-f49a-bba4ff4905a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 1/36 [00:00<00:06,  5.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 4/36 [00:01<00:09,  3.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 6/36 [00:01<00:07,  4.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 8/36 [00:02<00:05,  4.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 10/36 [00:02<00:04,  5.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 12/36 [00:02<00:04,  5.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [00:13<00:00,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 9, 'con': 0.04}\n",
            "0.7471535377464055\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9866    0.9585    0.9724     64531\n",
            "           1     0.4175    0.6962    0.5220      2758\n",
            "\n",
            "    accuracy                         0.9477     67289\n",
            "   macro avg     0.7021    0.8273    0.7472     67289\n",
            "weighted avg     0.9633    0.9477    0.9539     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "\n",
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_b = CBLOF(n_clusters=n_est, contamination=con)\n",
        "        clf_b.fit(raw_benign_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "   \n",
        "    y_pred = clf_b.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_b\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "H-_InJ1-4mlc",
        "outputId": "e22139e6-d1cf-46e1-adf3-f0dc9b499244"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 2/36 [00:00<00:06,  5.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 4/36 [00:00<00:05,  5.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 6/36 [00:01<00:05,  5.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 8/36 [00:01<00:05,  5.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 9/36 [00:01<00:05,  5.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 11/36 [00:02<00:04,  5.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 12/36 [00:02<00:04,  5.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [00:12<00:00,  2.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 10}\n",
            "0.7467783775952068\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9820    0.9711    0.9765     64531\n",
            "           1     0.4637    0.5841    0.5170      2758\n",
            "\n",
            "    accuracy                         0.9553     67289\n",
            "   macro avg     0.7229    0.7776    0.7468     67289\n",
            "weighted avg     0.9608    0.9553    0.9577     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "        clf_if.fit(raw_normal_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "    \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nd0-H7UT4mlc"
      },
      "outputs": [],
      "source": [
        "# HBOS  Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "sDquxErU4mld"
      },
      "outputs": [],
      "source": [
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "xLBIT-Rc4mld",
        "outputId": "8162929e-4879-40e2-a040-afc57eafe7c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [02:50<00:00,  4.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.001}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.hbos import HBOS\n",
        "\n",
        "n_est = [5,10,15,20,25,30]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "MDcX0mma4mld",
        "outputId": "a2b64cfc-d413-4ba0-9f24-b4935343c315"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [03:11<00:00,  5.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 15, 'con': 0.04}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "wRUOrQqB4mle"
      },
      "outputs": [],
      "source": [
        "##  HBOS  RAw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "9sZfAnER4mle",
        "outputId": "6e9cb145-8540-4aa7-8ed1-fc9aca495b07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [00:14<00:00,  2.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 30, 'con': 0.01}\n",
            "0.8525989286730036\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9875    0.9887    0.9881     64531\n",
            "           1     0.7282    0.7063    0.7171      2758\n",
            "\n",
            "    accuracy                         0.9772     67289\n",
            "   macro avg     0.8578    0.8475    0.8526     67289\n",
            "weighted avg     0.9768    0.9772    0.9770     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "\n",
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_b = HBOS(n_bins=n_est, contamination=con)\n",
        "        clf_b.fit(raw_benign_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "   \n",
        "    y_pred = clf_b.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_b\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "z5A-gLN34mle",
        "outputId": "8a6dfd26-a45b-4ce3-8d85-1b61652e7f90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [00:14<00:00,  2.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 5}\n",
            "0.8078362549428174\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9857    0.9811    0.9834     64531\n",
            "           1     0.6012    0.6668    0.6323      2758\n",
            "\n",
            "    accuracy                         0.9682     67289\n",
            "   macro avg     0.7934    0.8239    0.8078     67289\n",
            "weighted avg     0.9699    0.9682    0.9690     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "        clf_if.fit(raw_normal_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "    \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "UbDOqrcy4mle"
      },
      "outputs": [],
      "source": [
        "##  PCA  Emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Nga82Fw_4mle",
        "outputId": "0fe52043-af21-45c1-a404-040ab5845efc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [01:11<00:00,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.001}\n",
            "0.9373418473269503\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9884    0.9942    129059\n",
            "           1     0.7865    1.0000    0.8805      5516\n",
            "\n",
            "    accuracy                         0.9889    134575\n",
            "   macro avg     0.8933    0.9942    0.9373    134575\n",
            "weighted avg     0.9913    0.9889    0.9895    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.pca import PCA\n",
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "sg6AcAUW4mlf",
        "outputId": "a9949458-96cf-44dc-b4f6-c73458cb2719"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [01:29<00:00,  2.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.04}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "JSoyZpDu4mlf"
      },
      "outputs": [],
      "source": [
        "##  PCA  RAw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "3hKgicW14mlf",
        "outputId": "16c93b66-4eac-4d40-d5ce-96f3b3a5b3bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [00:12<00:00,  2.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.001}\n",
            "0.9079572980994904\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9881    0.9988    0.9934     64531\n",
            "           1     0.9621    0.7183    0.8225      2758\n",
            "\n",
            "    accuracy                         0.9873     67289\n",
            "   macro avg     0.9751    0.8585    0.9080     67289\n",
            "weighted avg     0.9870    0.9873    0.9864     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(raw_benign_train_samples)\n",
        "   \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "nAdfwnlP4mlf",
        "outputId": "ddc9c2b4-a3b6-4ab6-cc74-7ed93ca23d22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [00:12<00:00,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 15}\n",
            "0.7820758463846016\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9823    0.9817    0.9820     64531\n",
            "           1     0.5784    0.5859    0.5821      2758\n",
            "\n",
            "    accuracy                         0.9655     67289\n",
            "   macro avg     0.7803    0.7838    0.7821     67289\n",
            "weighted avg     0.9657    0.9655    0.9656     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(raw_normal_train_samples)\n",
        "\n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "yi8SO3tL4mlg"
      },
      "outputs": [],
      "source": [
        "##  IF  Emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "9D0m4vb04mlg",
        "outputId": "bd5a55e6-ac70-4943-9b28-92474b5fb9e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/24 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:53<00:00,  2.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 150, 'con': 0.001}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "NCj-3u4t4mlg",
        "outputId": "5f6b1720-9662-4704-ba96-dd57ee32a900"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:55<00:00,  2.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 150, 'con': 0.04}\n",
            "0.9937861202229019\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9990    0.9995    129059\n",
            "           1     0.9765    1.0000    0.9881      5516\n",
            "\n",
            "    accuracy                         0.9990    134575\n",
            "   macro avg     0.9882    0.9995    0.9938    134575\n",
            "weighted avg     0.9990    0.9990    0.9990    134575\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "iOIn_Kr44mlg"
      },
      "outputs": [],
      "source": [
        "##  IF  Raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "E_60yAo34mlg",
        "outputId": "354e56cd-ee22-4538-ba6f-43c1d67eb648"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/24 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:16<00:00,  1.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 150, 'con': 0.01}\n",
            "0.879820091825837\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9910    0.9888    0.9899     64531\n",
            "           1     0.7508    0.7897    0.7697      2758\n",
            "\n",
            "    accuracy                         0.9806     67289\n",
            "   macro avg     0.8709    0.8892    0.8798     67289\n",
            "weighted avg     0.9811    0.9806    0.9809     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(raw_benign_train_samples.to_numpy())\n",
        "   \n",
        "    y_pred = clf_if.predict(raw_test_samples.to_numpy())\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "5xNKBA7X4mlh",
        "outputId": "cd0ee1c5-5394-4e2b-efde-1f58bf922282"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:16<00:00,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 50}\n",
            "0.8354279839346712\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9900    0.9798    0.9849     64531\n",
            "           1     0.6193    0.7687    0.6860      2758\n",
            "\n",
            "    accuracy                         0.9712     67289\n",
            "   macro avg     0.8047    0.8742    0.8354     67289\n",
            "weighted avg     0.9748    0.9712    0.9726     67289\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(raw_normal_train_samples.to_numpy())\n",
        "\n",
        "    y_pred = clf_if.predict(raw_test_samples.to_numpy())\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
