{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hjc3iIihKLn-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kienho/miniforge3/envs/py3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn import preprocessing\n",
        "from dgl.data import DGLDataset\n",
        "import dgl\n",
        "import time\n",
        "import networkx as nx\n",
        "import category_encoders as ce\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "import torch\n",
        "import tqdm\n",
        "import math\n",
        "\n",
        "from typing import *\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "import socket\n",
        "import struct\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SvWHb_BpKsLq"
      },
      "outputs": [],
      "source": [
        "# file_name = \"NF-CSE-CIC-IDS2018-v2.csv\"\n",
        "file_name = \"NF-UNSW-NB15-v2.csv\"\n",
        "data = pd.read_csv(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "fqly1y-LMwYS",
        "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Label\n",
              "0    2295222\n",
              "1      95053\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3t4OREvSM33h"
      },
      "outputs": [],
      "source": [
        "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
        "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
        "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
        "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
        "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bTtHq0XqNXxI"
      },
      "outputs": [],
      "source": [
        "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUNIP-8zNkn9",
        "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Benign', 'Exploits', 'Generic', 'Fuzzers', 'Backdoor', 'DoS',\n",
              "       'Reconnaissance', 'Shellcode', 'Worms', 'Analysis'], dtype=object)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Attack.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AlPa58fVN7gB"
      },
      "outputs": [],
      "source": [
        "data = data.groupby(by='Attack').sample(frac=0.1, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "lcfAP6ViOp-J",
        "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IPV4_SRC_ADDR</th>\n",
              "      <th>IPV4_DST_ADDR</th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>TCP_FLAGS</th>\n",
              "      <th>CLIENT_TCP_FLAGS</th>\n",
              "      <th>...</th>\n",
              "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
              "      <th>TCP_WIN_MAX_IN</th>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <th>ICMP_TYPE</th>\n",
              "      <th>ICMP_IPV4_TYPE</th>\n",
              "      <th>DNS_QUERY_ID</th>\n",
              "      <th>DNS_QUERY_TYPE</th>\n",
              "      <th>DNS_TTL_ANSWER</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Attack</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Analysis</th>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>...</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Backdoor</th>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>...</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Benign</th>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>...</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS</th>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>...</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exploits</th>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>...</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fuzzers</th>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>...</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Generic</th>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>...</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reconnaissance</th>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>...</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shellcode</th>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>...</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worms</th>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 42 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                IPV4_SRC_ADDR  IPV4_DST_ADDR  PROTOCOL  L7_PROTO  IN_BYTES  \\\n",
              "Attack                                                                       \n",
              "Analysis                  230            230       230       230       230   \n",
              "Backdoor                  217            217       217       217       217   \n",
              "Benign                 229522         229522    229522    229522    229522   \n",
              "DoS                       579            579       579       579       579   \n",
              "Exploits                 3155           3155      3155      3155      3155   \n",
              "Fuzzers                  2231           2231      2231      2231      2231   \n",
              "Generic                  1656           1656      1656      1656      1656   \n",
              "Reconnaissance           1278           1278      1278      1278      1278   \n",
              "Shellcode                 143            143       143       143       143   \n",
              "Worms                      16             16        16        16        16   \n",
              "\n",
              "                IN_PKTS  OUT_BYTES  OUT_PKTS  TCP_FLAGS  CLIENT_TCP_FLAGS  \\\n",
              "Attack                                                                      \n",
              "Analysis            230        230       230        230               230   \n",
              "Backdoor            217        217       217        217               217   \n",
              "Benign           229522     229522    229522     229522            229522   \n",
              "DoS                 579        579       579        579               579   \n",
              "Exploits           3155       3155      3155       3155              3155   \n",
              "Fuzzers            2231       2231      2231       2231              2231   \n",
              "Generic            1656       1656      1656       1656              1656   \n",
              "Reconnaissance     1278       1278      1278       1278              1278   \n",
              "Shellcode           143        143       143        143               143   \n",
              "Worms                16         16        16         16                16   \n",
              "\n",
              "                ...  NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  \\\n",
              "Attack          ...                                                \n",
              "Analysis        ...                          230             230   \n",
              "Backdoor        ...                          217             217   \n",
              "Benign          ...                       229522          229522   \n",
              "DoS             ...                          579             579   \n",
              "Exploits        ...                         3155            3155   \n",
              "Fuzzers         ...                         2231            2231   \n",
              "Generic         ...                         1656            1656   \n",
              "Reconnaissance  ...                         1278            1278   \n",
              "Shellcode       ...                          143             143   \n",
              "Worms           ...                           16              16   \n",
              "\n",
              "                TCP_WIN_MAX_OUT  ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  \\\n",
              "Attack                                                                     \n",
              "Analysis                    230        230             230           230   \n",
              "Backdoor                    217        217             217           217   \n",
              "Benign                   229522     229522          229522        229522   \n",
              "DoS                         579        579             579           579   \n",
              "Exploits                   3155       3155            3155          3155   \n",
              "Fuzzers                    2231       2231            2231          2231   \n",
              "Generic                    1656       1656            1656          1656   \n",
              "Reconnaissance             1278       1278            1278          1278   \n",
              "Shellcode                   143        143             143           143   \n",
              "Worms                        16         16              16            16   \n",
              "\n",
              "                DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE   Label  \n",
              "Attack                                                                        \n",
              "Analysis                   230             230                   230     230  \n",
              "Backdoor                   217             217                   217     217  \n",
              "Benign                  229522          229522                229522  229522  \n",
              "DoS                        579             579                   579     579  \n",
              "Exploits                  3155            3155                  3155    3155  \n",
              "Fuzzers                   2231            2231                  2231    2231  \n",
              "Generic                   1656            1656                  1656    1656  \n",
              "Reconnaissance            1278            1278                  1278    1278  \n",
              "Shellcode                  143             143                   143     143  \n",
              "Worms                       16              16                    16      16  \n",
              "\n",
              "[10 rows x 42 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.groupby(by=\"Attack\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FqRx5xCPOuv8"
      },
      "outputs": [],
      "source": [
        "X = data.drop(columns=[\"Attack\", \"Label\"])\n",
        "y = data[[\"Attack\", \"Label\"]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=13, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bPfakXplPGGx"
      },
      "outputs": [],
      "source": [
        "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
        "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
        "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
        "                                  'FTP_COMMAND_RET_CODE'])\n",
        "encoder.fit(X_train, y_train.Label)\n",
        "\n",
        "# Transform on training set\n",
        "X_train = encoder.transform(X_train)\n",
        "\n",
        "# Transform on testing set\n",
        "X_test = encoder.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ibyOfV-8PouK"
      },
      "outputs": [],
      "source": [
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "asDnsSIWPee0"
      },
      "outputs": [],
      "source": [
        "scaler = Normalizer()\n",
        "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
        "scaler.fit(X_train[cols_to_norm])\n",
        "\n",
        "# Transform on training set\n",
        "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
        "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
        "\n",
        "# Transform on testing set\n",
        "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
        "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
        "\n",
        "train = pd.concat([X_train, y_train], axis=1)\n",
        "test = pd.concat([X_test, y_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "hErQbsnrPluV",
        "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IPV4_SRC_ADDR</th>\n",
              "      <th>IPV4_DST_ADDR</th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>TCP_FLAGS</th>\n",
              "      <th>CLIENT_TCP_FLAGS</th>\n",
              "      <th>...</th>\n",
              "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
              "      <th>TCP_WIN_MAX_IN</th>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <th>ICMP_TYPE</th>\n",
              "      <th>ICMP_IPV4_TYPE</th>\n",
              "      <th>DNS_QUERY_ID</th>\n",
              "      <th>DNS_QUERY_TYPE</th>\n",
              "      <th>DNS_TTL_ANSWER</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>220614</th>\n",
              "      <td>59.166.0.4</td>\n",
              "      <td>149.171.126.1</td>\n",
              "      <td>4.802078e-09</td>\n",
              "      <td>3.048648e-09</td>\n",
              "      <td>3.994566e-05</td>\n",
              "      <td>7.652425e-07</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>1.071339e-06</td>\n",
              "      <td>1.980229e-09</td>\n",
              "      <td>1.980360e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.329685e-03</td>\n",
              "      <td>1.329685e-03</td>\n",
              "      <td>4.043553e-10</td>\n",
              "      <td>4.043553e-10</td>\n",
              "      <td>6.314168e-09</td>\n",
              "      <td>6.314212e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.618463e-09</td>\n",
              "      <td>[4.802078220820267e-09, 3.0486475517277593e-09...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329844</th>\n",
              "      <td>59.166.0.1</td>\n",
              "      <td>149.171.126.8</td>\n",
              "      <td>9.025364e-09</td>\n",
              "      <td>8.052833e-09</td>\n",
              "      <td>1.079121e-04</td>\n",
              "      <td>8.300931e-07</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>8.300931e-07</td>\n",
              "      <td>1.397062e-08</td>\n",
              "      <td>1.396955e-08</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.181795e-08</td>\n",
              "      <td>1.182599e-08</td>\n",
              "      <td>8.561578e-09</td>\n",
              "      <td>8.561639e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.271523e-09</td>\n",
              "      <td>[9.025363504432674e-09, 8.052833119952719e-09,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1093665</th>\n",
              "      <td>59.166.0.3</td>\n",
              "      <td>149.171.126.8</td>\n",
              "      <td>3.068685e-13</td>\n",
              "      <td>8.437668e-13</td>\n",
              "      <td>1.638983e-07</td>\n",
              "      <td>3.061234e-09</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>7.129838e-09</td>\n",
              "      <td>1.188386e-13</td>\n",
              "      <td>1.274923e-13</td>\n",
              "      <td>...</td>\n",
              "      <td>6.875550e-09</td>\n",
              "      <td>6.372843e-07</td>\n",
              "      <td>7.080936e-08</td>\n",
              "      <td>4.545956e-14</td>\n",
              "      <td>5.191930e-14</td>\n",
              "      <td>4.034959e-13</td>\n",
              "      <td>4.034988e-13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.369547e-13</td>\n",
              "      <td>[3.068684887633906e-13, 8.437667728858196e-13,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1764268</th>\n",
              "      <td>59.166.0.4</td>\n",
              "      <td>149.171.126.0</td>\n",
              "      <td>2.361402e-08</td>\n",
              "      <td>2.106949e-08</td>\n",
              "      <td>7.927293e-05</td>\n",
              "      <td>1.085931e-06</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>1.085931e-06</td>\n",
              "      <td>3.655283e-08</td>\n",
              "      <td>3.655002e-08</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.092057e-08</td>\n",
              "      <td>3.094159e-08</td>\n",
              "      <td>1.878071e-08</td>\n",
              "      <td>3.577436e-10</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>2.425808e-08</td>\n",
              "      <td>[2.3614022984160315e-08, 2.1069487814953574e-0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1525176</th>\n",
              "      <td>59.166.0.9</td>\n",
              "      <td>149.171.126.5</td>\n",
              "      <td>2.309362e-10</td>\n",
              "      <td>2.856102e-10</td>\n",
              "      <td>1.717880e-05</td>\n",
              "      <td>2.649686e-07</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>2.796890e-07</td>\n",
              "      <td>8.943290e-11</td>\n",
              "      <td>9.594530e-11</td>\n",
              "      <td>...</td>\n",
              "      <td>7.360238e-08</td>\n",
              "      <td>1.598644e-04</td>\n",
              "      <td>1.065762e-04</td>\n",
              "      <td>5.174884e-12</td>\n",
              "      <td>5.174884e-12</td>\n",
              "      <td>3.036539e-10</td>\n",
              "      <td>3.036561e-10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.288336e-10</td>\n",
              "      <td>[2.3093620396957016e-10, 2.8561023679188587e-1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 42 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        IPV4_SRC_ADDR  IPV4_DST_ADDR      PROTOCOL      L7_PROTO  \\\n",
              "220614     59.166.0.4  149.171.126.1  4.802078e-09  3.048648e-09   \n",
              "329844     59.166.0.1  149.171.126.8  9.025364e-09  8.052833e-09   \n",
              "1093665    59.166.0.3  149.171.126.8  3.068685e-13  8.437668e-13   \n",
              "1764268    59.166.0.4  149.171.126.0  2.361402e-08  2.106949e-08   \n",
              "1525176    59.166.0.9  149.171.126.5  2.309362e-10  2.856102e-10   \n",
              "\n",
              "             IN_BYTES       IN_PKTS  OUT_BYTES      OUT_PKTS     TCP_FLAGS  \\\n",
              "220614   3.994566e-05  7.652425e-07   0.000072  1.071339e-06  1.980229e-09   \n",
              "329844   1.079121e-04  8.300931e-07   0.000063  8.300931e-07  1.397062e-08   \n",
              "1093665  1.638983e-07  3.061234e-09   0.000010  7.129838e-09  1.188386e-13   \n",
              "1764268  7.927293e-05  1.085931e-06   0.000097  1.085931e-06  3.655283e-08   \n",
              "1525176  1.717880e-05  2.649686e-07   0.000124  2.796890e-07  8.943290e-11   \n",
              "\n",
              "         CLIENT_TCP_FLAGS  ...  NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  \\\n",
              "220614       1.980360e-09  ...                 0.000000e+00    1.329685e-03   \n",
              "329844       1.396955e-08  ...                 0.000000e+00    0.000000e+00   \n",
              "1093665      1.274923e-13  ...                 6.875550e-09    6.372843e-07   \n",
              "1764268      3.655002e-08  ...                 0.000000e+00    0.000000e+00   \n",
              "1525176      9.594530e-11  ...                 7.360238e-08    1.598644e-04   \n",
              "\n",
              "         TCP_WIN_MAX_OUT     ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  \\\n",
              "220614      1.329685e-03  4.043553e-10    4.043553e-10  6.314168e-09   \n",
              "329844      0.000000e+00  1.181795e-08    1.182599e-08  8.561578e-09   \n",
              "1093665     7.080936e-08  4.545956e-14    5.191930e-14  4.034959e-13   \n",
              "1764268     0.000000e+00  3.092057e-08    3.094159e-08  1.878071e-08   \n",
              "1525176     1.065762e-04  5.174884e-12    5.174884e-12  3.036539e-10   \n",
              "\n",
              "         DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \\\n",
              "220614     6.314212e-09        0.000000          3.618463e-09   \n",
              "329844     8.561639e-09        0.000000          9.271523e-09   \n",
              "1093665    4.034988e-13        0.000000          4.369547e-13   \n",
              "1764268    3.577436e-10        0.000033          2.425808e-08   \n",
              "1525176    3.036561e-10        0.000000          3.288336e-10   \n",
              "\n",
              "                                                         h  \n",
              "220614   [4.802078220820267e-09, 3.0486475517277593e-09...  \n",
              "329844   [9.025363504432674e-09, 8.052833119952719e-09,...  \n",
              "1093665  [3.068684887633906e-13, 8.437667728858196e-13,...  \n",
              "1764268  [2.3614022984160315e-08, 2.1069487814953574e-0...  \n",
              "1525176  [2.3093620396957016e-10, 2.8561023679188587e-1...  \n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "d_tLtK4WPtrF"
      },
      "outputs": [],
      "source": [
        "lab_enc = preprocessing.LabelEncoder()\n",
        "lab_enc.fit(data[\"Attack\"])\n",
        "\n",
        "# Transform on training set\n",
        "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
        "\n",
        "# Transform on testing set\n",
        "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8yaicjecP1fZ"
      },
      "outputs": [],
      "source": [
        "# Training graph\n",
        "\n",
        "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
        "            [\"h\", \"Label\", \"Attack\"], create_using=nx.MultiGraph())\n",
        "\n",
        "train_g = train_g.to_directed()\n",
        "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label'])\n",
        "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
        "train_g.edata['h'].shape[1]])\n",
        "train_g.ndata['h'] = nfeat_weight\n",
        "\n",
        "# Testing graph\n",
        "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
        "            [\"h\", \"Label\", \"Attack\"], create_using=nx.MultiGraph())\n",
        "\n",
        "test_g = test_g.to_directed()\n",
        "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label'])\n",
        "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
        "test_g.edata['h'].shape[1]])\n",
        "test_g.ndata['h'] = nfeat_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PUV6DgJ9QRaP"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "import tqdm\n",
        "import gc\n",
        "\n",
        "class SAGELayer(nn.Module):\n",
        "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
        "      super(SAGELayer, self).__init__()\n",
        "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
        "      self.activation = F.relu\n",
        "      # self.W_edge = nn.Linear(128 * 2, 256)\n",
        "      self.W_edge = nn.Linear(256 * 2, 512)\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      gain = nn.init.calculate_gain('relu')\n",
        "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
        "\n",
        "    def message_func(self, edges):\n",
        "      return {'m':  edges.data['h']}\n",
        "\n",
        "    def forward(self, g_dgl, nfeats, efeats):\n",
        "      with g_dgl.local_scope():\n",
        "        g = g_dgl\n",
        "        g.ndata['h'] = nfeats\n",
        "        g.edata['h'] = efeats\n",
        "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
        "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
        "\n",
        "        # Compute edge embeddings\n",
        "        u, v = g.edges()\n",
        "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
        "        return g.ndata['h'], edge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_xo-3K4QRGqc"
      },
      "outputs": [],
      "source": [
        "class SAGE(nn.Module):\n",
        "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
        "      super(SAGE, self).__init__()\n",
        "      self.layers = nn.ModuleList()\n",
        "      # self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
        "      self.layers.append(SAGELayer(ndim_in, edim, 256, F.relu))\n",
        "\n",
        "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
        "      if corrupt:\n",
        "        e_perm = torch.randperm(g.number_of_edges())\n",
        "        #n_perm = torch.randperm(g.number_of_nodes())\n",
        "        efeats = efeats[e_perm]\n",
        "        #nfeats = nfeats[n_perm]\n",
        "      for i, layer in enumerate(self.layers):\n",
        "        #nfeats = layer(g, nfeats, efeats)\n",
        "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
        "      #return nfeats.sum(1)\n",
        "      return nfeats.sum(1), e_feats.sum(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6uuxRtLuRJQL"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, n_hidden):\n",
        "      super(Discriminator, self).__init__()\n",
        "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def uniform(self, size, tensor):\n",
        "      bound = 1.0 / math.sqrt(size)\n",
        "      if tensor is not None:\n",
        "        tensor.data.uniform_(-bound, bound)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      size = self.weight.size(0)\n",
        "      self.uniform(size, self.weight)\n",
        "\n",
        "    def forward(self, features, summary):\n",
        "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
        "      return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZPbVjlCyRUco"
      },
      "outputs": [],
      "source": [
        "class DGI(nn.Module):\n",
        "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
        "      super(DGI, self).__init__()\n",
        "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
        "      #self.discriminator = Discriminator(128)\n",
        "      # self.discriminator = Discriminator(256)\n",
        "      self.discriminator = Discriminator(512)\n",
        "      self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, g, n_features, e_features):\n",
        "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
        "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
        "      self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, g, n_features, e_features):\n",
        "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
        "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
        "\n",
        "      positive = positive[1]\n",
        "      negative = negative[1]\n",
        "\n",
        "      summary = torch.sigmoid(positive.mean(dim=0))\n",
        "\n",
        "      positive = self.discriminator(positive, summary)\n",
        "      negative = self.discriminator(negative, summary)\n",
        "\n",
        "      l1 = self.loss(positive, torch.ones_like(positive))\n",
        "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
        "\n",
        "      return l1 + l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sKnfpWFMR19u"
      },
      "outputs": [],
      "source": [
        "ndim_in = train_g.ndata['h'].shape[1]\n",
        "# hidden_features = 128\n",
        "hidden_features = 256\n",
        "# ndim_out = 128\n",
        "ndim_out = 256\n",
        "num_layers = 1\n",
        "edim = train_g.edata['h'].shape[1]\n",
        "learning_rate = 1e-3\n",
        "epochs = 4000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aSl_9qY8SbA0"
      },
      "outputs": [],
      "source": [
        "dgi = DGI(ndim_in,\n",
        "    ndim_out,\n",
        "    edim,\n",
        "    F.relu)\n",
        "\n",
        "dgi = dgi.to('cuda')\n",
        "\n",
        "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
        "                lr=1e-3,\n",
        "                weight_decay=0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9K6_cOiWSdJA"
      },
      "outputs": [],
      "source": [
        "# Format node and edge features for E-GraphSAGE\n",
        "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
        "                                   (train_g.ndata['h'].shape[0], 1,\n",
        "                                    train_g.ndata['h'].shape[1]))\n",
        "\n",
        "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
        "                                   (train_g.edata['h'].shape[0], 1,\n",
        "                                    train_g.edata['h'].shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "O44auIyWSexg"
      },
      "outputs": [],
      "source": [
        "# Convert to GPU\n",
        "train_g = train_g.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gZtafIdxSheN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kienho/miniforge3/envs/py3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/home/kienho/miniforge3/envs/py3.9/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00000 | Time(s) nan | Loss 1.4037 | ETputs(KTEPS) nan\n",
            "Epoch 00050 | Time(s) 0.2958 | Loss 1.4227 | ETputs(KTEPS) 1131.43\n",
            "Epoch 00100 | Time(s) 0.2978 | Loss 1.3843 | ETputs(KTEPS) 1123.62\n",
            "Epoch 00150 | Time(s) 0.3007 | Loss 1.3810 | ETputs(KTEPS) 1112.69\n",
            "Epoch 00200 | Time(s) 0.3015 | Loss 1.3791 | ETputs(KTEPS) 1109.99\n",
            "Epoch 00250 | Time(s) 0.3012 | Loss 1.3783 | ETputs(KTEPS) 1110.91\n",
            "Epoch 00300 | Time(s) 0.3012 | Loss 1.3784 | ETputs(KTEPS) 1111.19\n",
            "Epoch 00350 | Time(s) 0.3014 | Loss 1.3742 | ETputs(KTEPS) 1110.41\n",
            "Epoch 00400 | Time(s) 0.3018 | Loss 1.3629 | ETputs(KTEPS) 1108.94\n",
            "Epoch 00450 | Time(s) 0.3020 | Loss 1.3464 | ETputs(KTEPS) 1107.91\n",
            "Epoch 00500 | Time(s) 0.3023 | Loss 1.3272 | ETputs(KTEPS) 1106.89\n",
            "Epoch 00550 | Time(s) 0.3027 | Loss 1.2723 | ETputs(KTEPS) 1105.44\n",
            "Epoch 00600 | Time(s) 0.3030 | Loss 1.1922 | ETputs(KTEPS) 1104.38\n",
            "Epoch 00650 | Time(s) 0.3033 | Loss 1.0458 | ETputs(KTEPS) 1103.30\n",
            "Epoch 00700 | Time(s) 0.3035 | Loss 0.8353 | ETputs(KTEPS) 1102.49\n",
            "Epoch 00750 | Time(s) 0.3036 | Loss 0.7961 | ETputs(KTEPS) 1102.34\n",
            "Epoch 00800 | Time(s) 0.3036 | Loss 0.4733 | ETputs(KTEPS) 1102.14\n",
            "Epoch 00850 | Time(s) 0.3035 | Loss 0.5925 | ETputs(KTEPS) 1102.42\n",
            "Epoch 00900 | Time(s) 0.3035 | Loss 0.1842 | ETputs(KTEPS) 1102.48\n",
            "Epoch 00950 | Time(s) 0.3036 | Loss 0.1158 | ETputs(KTEPS) 1102.09\n",
            "Epoch 01000 | Time(s) 0.3037 | Loss 0.0798 | ETputs(KTEPS) 1101.70\n",
            "Epoch 01050 | Time(s) 0.3038 | Loss 0.0652 | ETputs(KTEPS) 1101.47\n",
            "Epoch 01100 | Time(s) 0.3038 | Loss 0.0574 | ETputs(KTEPS) 1101.46\n",
            "Epoch 01150 | Time(s) 0.3038 | Loss 0.0541 | ETputs(KTEPS) 1101.51\n",
            "Epoch 01200 | Time(s) 0.3038 | Loss 0.0398 | ETputs(KTEPS) 1101.59\n",
            "Epoch 01250 | Time(s) 0.3038 | Loss 0.0363 | ETputs(KTEPS) 1101.37\n",
            "Epoch 01300 | Time(s) 0.3039 | Loss 0.0245 | ETputs(KTEPS) 1101.31\n",
            "Epoch 01350 | Time(s) 0.3038 | Loss 0.0268 | ETputs(KTEPS) 1101.40\n",
            "Epoch 01400 | Time(s) 0.3038 | Loss 0.0204 | ETputs(KTEPS) 1101.51\n",
            "Epoch 01450 | Time(s) 0.3037 | Loss 2.0560 | ETputs(KTEPS) 1101.93\n",
            "Epoch 01500 | Time(s) 0.3035 | Loss 1.3862 | ETputs(KTEPS) 1102.76\n",
            "Epoch 01550 | Time(s) 0.3033 | Loss 1.3861 | ETputs(KTEPS) 1103.40\n",
            "Epoch 01600 | Time(s) 0.3031 | Loss 1.3864 | ETputs(KTEPS) 1104.07\n",
            "Epoch 01650 | Time(s) 0.3031 | Loss 1.3861 | ETputs(KTEPS) 1104.13\n",
            "Epoch 01700 | Time(s) 0.3031 | Loss 1.3861 | ETputs(KTEPS) 1104.16\n",
            "Epoch 01750 | Time(s) 0.3031 | Loss 1.3860 | ETputs(KTEPS) 1104.21\n",
            "Epoch 01800 | Time(s) 0.3031 | Loss 1.3861 | ETputs(KTEPS) 1104.18\n",
            "Epoch 01850 | Time(s) 0.3031 | Loss 1.3862 | ETputs(KTEPS) 1104.19\n",
            "Epoch 01900 | Time(s) 0.3031 | Loss 1.3861 | ETputs(KTEPS) 1104.19\n",
            "Epoch 01950 | Time(s) 0.3031 | Loss 1.3861 | ETputs(KTEPS) 1104.19\n",
            "Epoch 02000 | Time(s) 0.3030 | Loss 1.3860 | ETputs(KTEPS) 1104.26\n",
            "Epoch 02050 | Time(s) 0.3030 | Loss 1.3853 | ETputs(KTEPS) 1104.37\n",
            "Epoch 02100 | Time(s) 0.3029 | Loss 1.3861 | ETputs(KTEPS) 1104.95\n",
            "Epoch 02150 | Time(s) 0.3027 | Loss 1.3861 | ETputs(KTEPS) 1105.53\n",
            "Epoch 02200 | Time(s) 0.3025 | Loss 1.3861 | ETputs(KTEPS) 1106.10\n",
            "Epoch 02250 | Time(s) 0.3024 | Loss 1.3861 | ETputs(KTEPS) 1106.66\n",
            "Epoch 02300 | Time(s) 0.3022 | Loss 1.3861 | ETputs(KTEPS) 1107.20\n",
            "Epoch 02350 | Time(s) 0.3021 | Loss 1.3859 | ETputs(KTEPS) 1107.77\n",
            "Epoch 02400 | Time(s) 0.3020 | Loss 1.3862 | ETputs(KTEPS) 1107.93\n",
            "Epoch 02450 | Time(s) 0.3020 | Loss 1.3861 | ETputs(KTEPS) 1108.07\n",
            "Epoch 02500 | Time(s) 0.3020 | Loss 1.3861 | ETputs(KTEPS) 1108.20\n",
            "Epoch 02550 | Time(s) 0.3019 | Loss 1.3861 | ETputs(KTEPS) 1108.35\n",
            "Epoch 02600 | Time(s) 0.3019 | Loss 1.3861 | ETputs(KTEPS) 1108.48\n",
            "Epoch 02650 | Time(s) 0.3018 | Loss 1.3861 | ETputs(KTEPS) 1108.62\n",
            "Epoch 02700 | Time(s) 0.3018 | Loss 1.3861 | ETputs(KTEPS) 1108.76\n",
            "Epoch 02750 | Time(s) 0.3018 | Loss 1.3861 | ETputs(KTEPS) 1108.89\n",
            "Epoch 02800 | Time(s) 0.3017 | Loss 1.3861 | ETputs(KTEPS) 1109.02\n",
            "Epoch 02850 | Time(s) 0.3017 | Loss 1.3861 | ETputs(KTEPS) 1109.14\n",
            "Epoch 02900 | Time(s) 0.3017 | Loss 1.3861 | ETputs(KTEPS) 1109.27\n",
            "Epoch 02950 | Time(s) 0.3016 | Loss 1.3861 | ETputs(KTEPS) 1109.38\n",
            "Epoch 03000 | Time(s) 0.3016 | Loss 1.3861 | ETputs(KTEPS) 1109.45\n",
            "Epoch 03050 | Time(s) 0.3016 | Loss 1.3861 | ETputs(KTEPS) 1109.50\n",
            "Epoch 03100 | Time(s) 0.3016 | Loss 1.3861 | ETputs(KTEPS) 1109.59\n",
            "Epoch 03150 | Time(s) 0.3016 | Loss 1.3861 | ETputs(KTEPS) 1109.70\n",
            "Epoch 03200 | Time(s) 0.3015 | Loss 1.3861 | ETputs(KTEPS) 1109.75\n",
            "Epoch 03250 | Time(s) 0.3015 | Loss 1.3860 | ETputs(KTEPS) 1109.82\n",
            "Epoch 03300 | Time(s) 0.3015 | Loss 1.3860 | ETputs(KTEPS) 1109.88\n",
            "Epoch 03350 | Time(s) 0.3015 | Loss 1.3860 | ETputs(KTEPS) 1109.97\n",
            "Epoch 03400 | Time(s) 0.3015 | Loss 1.3859 | ETputs(KTEPS) 1110.06\n",
            "Epoch 03450 | Time(s) 0.3014 | Loss 1.3861 | ETputs(KTEPS) 1110.15\n",
            "Epoch 03500 | Time(s) 0.3014 | Loss 1.3859 | ETputs(KTEPS) 1110.18\n",
            "Epoch 03550 | Time(s) 0.3014 | Loss 1.4007 | ETputs(KTEPS) 1110.22\n",
            "Epoch 03600 | Time(s) 0.3013 | Loss 1.3861 | ETputs(KTEPS) 1110.50\n",
            "Epoch 03650 | Time(s) 0.3013 | Loss 1.3861 | ETputs(KTEPS) 1110.77\n",
            "Epoch 03700 | Time(s) 0.3012 | Loss 1.3861 | ETputs(KTEPS) 1111.03\n",
            "Epoch 03750 | Time(s) 0.3011 | Loss 1.3861 | ETputs(KTEPS) 1111.29\n",
            "Epoch 03800 | Time(s) 0.3011 | Loss 1.3861 | ETputs(KTEPS) 1111.54\n",
            "Epoch 03850 | Time(s) 0.3010 | Loss 1.3861 | ETputs(KTEPS) 1111.79\n",
            "Epoch 03900 | Time(s) 0.3009 | Loss 1.3861 | ETputs(KTEPS) 1112.03\n",
            "Epoch 03950 | Time(s) 0.3009 | Loss 1.3861 | ETputs(KTEPS) 1112.26\n"
          ]
        }
      ],
      "source": [
        "cnt_wait = 0\n",
        "best = 1e9\n",
        "best_t = 0\n",
        "dur = []\n",
        "node_features = train_g.ndata['h'] \n",
        "edge_features = train_g.edata['h']\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    dgi.train()\n",
        "    if epoch >= 3:\n",
        "        t0 = time.time()\n",
        "\n",
        "    dgi_optimizer.zero_grad()\n",
        "    loss = dgi(train_g, node_features, edge_features)\n",
        "    loss.backward()\n",
        "    dgi_optimizer.step()\n",
        "\n",
        "    if loss < best:\n",
        "        best = loss\n",
        "        best_t = epoch\n",
        "        cnt_wait = 0\n",
        "        torch.save(dgi.state_dict(), 'best_dgi_UNSW_256.pkl')\n",
        "    else:\n",
        "        cnt_wait += 1\n",
        "\n",
        "  # if cnt_wait == patience:\n",
        "  #     print('Early stopping!')\n",
        "  #     break\n",
        "\n",
        "    if epoch >= 3:\n",
        "        dur.append(time.time() - t0)\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "\n",
        "        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
        "            \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
        "              loss.item(),\n",
        "              train_g.num_edges() / np.mean(dur) / 1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "RZ2HAQDAF-4c",
        "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dgi.load_state_dict(torch.load('best_dgi_UNSW_256.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6Ek16GkRStKP"
      },
      "outputs": [],
      "source": [
        "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
        "training_emb = training_emb.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-FwaBlOdS4ep"
      },
      "outputs": [],
      "source": [
        "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
        "                                   (test_g.ndata['h'].shape[0], 1,\n",
        "                                    test_g.ndata['h'].shape[1]))\n",
        "\n",
        "\n",
        "\n",
        "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
        "                                   (test_g.edata['h'].shape[0], 1,\n",
        "                                    test_g.edata['h'].shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SBa-rdivS6cQ"
      },
      "outputs": [],
      "source": [
        "# Convert to GPU\n",
        "test_g = test_g.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "W12WLjslS-kx"
      },
      "outputs": [],
      "source": [
        "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
        "testing_emb = testing_emb.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ERsOAMjeS_D8"
      },
      "outputs": [],
      "source": [
        "df_train = pd.DataFrame(training_emb, )\n",
        "df_train[\"Attack\"] = lab_enc.inverse_transform(\n",
        "        train_g.edata['Attack'].detach().cpu().numpy())\n",
        "df_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
        "\n",
        "df_test = pd.DataFrame(testing_emb, )\n",
        "df_test[\"Attack\"] = lab_enc.inverse_transform(\n",
        "        test_g.edata['Attack'].detach().cpu().numpy())\n",
        "df_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "B8p79H9dat5T",
        "outputId": "0d6e82d8-5d02-49eb-a16f-d44e52ea3dff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>Attack</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.005961</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>0.019134</td>\n",
              "      <td>0.009085</td>\n",
              "      <td>-0.001186</td>\n",
              "      <td>-0.163274</td>\n",
              "      <td>-0.039003</td>\n",
              "      <td>-0.079817</td>\n",
              "      <td>-0.004475</td>\n",
              "      <td>-0.060485</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017648</td>\n",
              "      <td>0.002822</td>\n",
              "      <td>-0.058855</td>\n",
              "      <td>0.006481</td>\n",
              "      <td>0.006078</td>\n",
              "      <td>0.055153</td>\n",
              "      <td>-0.033665</td>\n",
              "      <td>0.042774</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.005961</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>0.019134</td>\n",
              "      <td>0.009085</td>\n",
              "      <td>-0.001186</td>\n",
              "      <td>-0.163274</td>\n",
              "      <td>-0.039003</td>\n",
              "      <td>-0.079817</td>\n",
              "      <td>-0.004475</td>\n",
              "      <td>-0.060485</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017648</td>\n",
              "      <td>0.002822</td>\n",
              "      <td>-0.058855</td>\n",
              "      <td>0.006481</td>\n",
              "      <td>0.006078</td>\n",
              "      <td>0.055153</td>\n",
              "      <td>-0.033665</td>\n",
              "      <td>0.042774</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.005961</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>0.019134</td>\n",
              "      <td>0.009085</td>\n",
              "      <td>-0.001186</td>\n",
              "      <td>-0.163274</td>\n",
              "      <td>-0.039003</td>\n",
              "      <td>-0.079817</td>\n",
              "      <td>-0.004475</td>\n",
              "      <td>-0.060485</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017648</td>\n",
              "      <td>0.002822</td>\n",
              "      <td>-0.058855</td>\n",
              "      <td>0.006481</td>\n",
              "      <td>0.006078</td>\n",
              "      <td>0.055153</td>\n",
              "      <td>-0.033665</td>\n",
              "      <td>0.042774</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.005961</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>0.019134</td>\n",
              "      <td>0.009085</td>\n",
              "      <td>-0.001186</td>\n",
              "      <td>-0.163274</td>\n",
              "      <td>-0.039003</td>\n",
              "      <td>-0.079817</td>\n",
              "      <td>-0.004475</td>\n",
              "      <td>-0.060485</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017648</td>\n",
              "      <td>0.002822</td>\n",
              "      <td>-0.058855</td>\n",
              "      <td>0.006481</td>\n",
              "      <td>0.006078</td>\n",
              "      <td>0.055153</td>\n",
              "      <td>-0.033665</td>\n",
              "      <td>0.042774</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.005961</td>\n",
              "      <td>0.002289</td>\n",
              "      <td>0.019134</td>\n",
              "      <td>0.009085</td>\n",
              "      <td>-0.001186</td>\n",
              "      <td>-0.163274</td>\n",
              "      <td>-0.039003</td>\n",
              "      <td>-0.079817</td>\n",
              "      <td>-0.004475</td>\n",
              "      <td>-0.060485</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017648</td>\n",
              "      <td>0.002822</td>\n",
              "      <td>-0.058855</td>\n",
              "      <td>0.006481</td>\n",
              "      <td>0.006078</td>\n",
              "      <td>0.055153</td>\n",
              "      <td>-0.033665</td>\n",
              "      <td>0.042774</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334631</th>\n",
              "      <td>-0.007362</td>\n",
              "      <td>0.033753</td>\n",
              "      <td>0.032109</td>\n",
              "      <td>0.025822</td>\n",
              "      <td>0.041144</td>\n",
              "      <td>-0.154995</td>\n",
              "      <td>-0.050813</td>\n",
              "      <td>-0.065310</td>\n",
              "      <td>0.018276</td>\n",
              "      <td>-0.076151</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031140</td>\n",
              "      <td>-0.017732</td>\n",
              "      <td>-0.040883</td>\n",
              "      <td>0.011116</td>\n",
              "      <td>0.004925</td>\n",
              "      <td>0.015312</td>\n",
              "      <td>-0.018667</td>\n",
              "      <td>-0.021402</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334632</th>\n",
              "      <td>-0.007362</td>\n",
              "      <td>0.033753</td>\n",
              "      <td>0.032109</td>\n",
              "      <td>0.025822</td>\n",
              "      <td>0.041144</td>\n",
              "      <td>-0.154995</td>\n",
              "      <td>-0.050813</td>\n",
              "      <td>-0.065310</td>\n",
              "      <td>0.018276</td>\n",
              "      <td>-0.076151</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031140</td>\n",
              "      <td>-0.017732</td>\n",
              "      <td>-0.040883</td>\n",
              "      <td>0.011116</td>\n",
              "      <td>0.004925</td>\n",
              "      <td>0.015312</td>\n",
              "      <td>-0.018667</td>\n",
              "      <td>-0.021402</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334633</th>\n",
              "      <td>-0.007362</td>\n",
              "      <td>0.033753</td>\n",
              "      <td>0.032109</td>\n",
              "      <td>0.025822</td>\n",
              "      <td>0.041144</td>\n",
              "      <td>-0.154995</td>\n",
              "      <td>-0.050813</td>\n",
              "      <td>-0.065310</td>\n",
              "      <td>0.018276</td>\n",
              "      <td>-0.076151</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031140</td>\n",
              "      <td>-0.017732</td>\n",
              "      <td>-0.040883</td>\n",
              "      <td>0.011116</td>\n",
              "      <td>0.004925</td>\n",
              "      <td>0.015312</td>\n",
              "      <td>-0.018667</td>\n",
              "      <td>-0.021402</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334634</th>\n",
              "      <td>-0.007362</td>\n",
              "      <td>0.033753</td>\n",
              "      <td>0.032109</td>\n",
              "      <td>0.025822</td>\n",
              "      <td>0.041144</td>\n",
              "      <td>-0.154995</td>\n",
              "      <td>-0.050813</td>\n",
              "      <td>-0.065310</td>\n",
              "      <td>0.018276</td>\n",
              "      <td>-0.076151</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031140</td>\n",
              "      <td>-0.017732</td>\n",
              "      <td>-0.040883</td>\n",
              "      <td>0.011116</td>\n",
              "      <td>0.004925</td>\n",
              "      <td>0.015312</td>\n",
              "      <td>-0.018667</td>\n",
              "      <td>-0.021402</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334635</th>\n",
              "      <td>-0.007362</td>\n",
              "      <td>0.033753</td>\n",
              "      <td>0.032109</td>\n",
              "      <td>0.025822</td>\n",
              "      <td>0.041144</td>\n",
              "      <td>-0.154995</td>\n",
              "      <td>-0.050813</td>\n",
              "      <td>-0.065310</td>\n",
              "      <td>0.018276</td>\n",
              "      <td>-0.076151</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031140</td>\n",
              "      <td>-0.017732</td>\n",
              "      <td>-0.040883</td>\n",
              "      <td>0.011116</td>\n",
              "      <td>0.004925</td>\n",
              "      <td>0.015312</td>\n",
              "      <td>-0.018667</td>\n",
              "      <td>-0.021402</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>334636 rows × 514 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0         1         2         3         4         5         6  \\\n",
              "0      -0.005961  0.002289  0.019134  0.009085 -0.001186 -0.163274 -0.039003   \n",
              "1      -0.005961  0.002289  0.019134  0.009085 -0.001186 -0.163274 -0.039003   \n",
              "2      -0.005961  0.002289  0.019134  0.009085 -0.001186 -0.163274 -0.039003   \n",
              "3      -0.005961  0.002289  0.019134  0.009085 -0.001186 -0.163274 -0.039003   \n",
              "4      -0.005961  0.002289  0.019134  0.009085 -0.001186 -0.163274 -0.039003   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "334631 -0.007362  0.033753  0.032109  0.025822  0.041144 -0.154995 -0.050813   \n",
              "334632 -0.007362  0.033753  0.032109  0.025822  0.041144 -0.154995 -0.050813   \n",
              "334633 -0.007362  0.033753  0.032109  0.025822  0.041144 -0.154995 -0.050813   \n",
              "334634 -0.007362  0.033753  0.032109  0.025822  0.041144 -0.154995 -0.050813   \n",
              "334635 -0.007362  0.033753  0.032109  0.025822  0.041144 -0.154995 -0.050813   \n",
              "\n",
              "               7         8         9  ...       504       505       506  \\\n",
              "0      -0.079817 -0.004475 -0.060485  ...  0.017648  0.002822 -0.058855   \n",
              "1      -0.079817 -0.004475 -0.060485  ...  0.017648  0.002822 -0.058855   \n",
              "2      -0.079817 -0.004475 -0.060485  ...  0.017648  0.002822 -0.058855   \n",
              "3      -0.079817 -0.004475 -0.060485  ...  0.017648  0.002822 -0.058855   \n",
              "4      -0.079817 -0.004475 -0.060485  ...  0.017648  0.002822 -0.058855   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "334631 -0.065310  0.018276 -0.076151  ...  0.031140 -0.017732 -0.040883   \n",
              "334632 -0.065310  0.018276 -0.076151  ...  0.031140 -0.017732 -0.040883   \n",
              "334633 -0.065310  0.018276 -0.076151  ...  0.031140 -0.017732 -0.040883   \n",
              "334634 -0.065310  0.018276 -0.076151  ...  0.031140 -0.017732 -0.040883   \n",
              "334635 -0.065310  0.018276 -0.076151  ...  0.031140 -0.017732 -0.040883   \n",
              "\n",
              "             507       508       509       510       511  Attack  Label  \n",
              "0       0.006481  0.006078  0.055153 -0.033665  0.042774  Benign      0  \n",
              "1       0.006481  0.006078  0.055153 -0.033665  0.042774  Benign      0  \n",
              "2       0.006481  0.006078  0.055153 -0.033665  0.042774  Benign      0  \n",
              "3       0.006481  0.006078  0.055153 -0.033665  0.042774  Benign      0  \n",
              "4       0.006481  0.006078  0.055153 -0.033665  0.042774  Benign      0  \n",
              "...          ...       ...       ...       ...       ...     ...    ...  \n",
              "334631  0.011116  0.004925  0.015312 -0.018667 -0.021402  Benign      0  \n",
              "334632  0.011116  0.004925  0.015312 -0.018667 -0.021402  Benign      0  \n",
              "334633  0.011116  0.004925  0.015312 -0.018667 -0.021402  Benign      0  \n",
              "334634  0.011116  0.004925  0.015312 -0.018667 -0.021402  Benign      0  \n",
              "334635  0.011116  0.004925  0.015312 -0.018667 -0.021402  Benign      0  \n",
              "\n",
              "[334636 rows x 514 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ScEk1y_TzzX"
      },
      "source": [
        "# Embeddings CBLOF  Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ZYABKzdrTGas"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import dgl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import gc\n",
        "\n",
        "from tqdm import tqdm\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "RkFS_-dcTJeK"
      },
      "outputs": [],
      "source": [
        "benign_train_samples = df_train[df_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "normal_train_samples = df_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "train_labels = df_train[\"Label\"]\n",
        "test_labels = df_test[\"Label\"]\n",
        "\n",
        "test_samples = df_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "62BUDLtO4mla"
      },
      "outputs": [],
      "source": [
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2i48uLj74mla",
        "outputId": "a0dd33ee-824d-4328-a960-e656e3aaf0ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [05:36<00:00,  9.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 2, 'con': 0.01}\n",
            "0.8341442196105132\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9851    0.9902    0.9876    137714\n",
            "           1     0.7301    0.6374    0.6806      5704\n",
            "\n",
            "    accuracy                         0.9762    143418\n",
            "   macro avg     0.8576    0.8138    0.8341    143418\n",
            "weighted avg     0.9749    0.9762    0.9754    143418\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "n_est = [2,3,5,7,9,10]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rK-Rng9q4mla",
        "outputId": "1796db22-cfb8-4bf8-9004-6420c08c3399"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [08:36<00:00, 14.34s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 2, 'con': 0.05}\n",
            "0.9170230759540074\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9982    0.9868    0.9925    137714\n",
            "           1     0.7508    0.9572    0.8416      5704\n",
            "\n",
            "    accuracy                         0.9857    143418\n",
            "   macro avg     0.8745    0.9720    0.9170    143418\n",
            "weighted avg     0.9884    0.9857    0.9865    143418\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "nd0-H7UT4mlc"
      },
      "outputs": [],
      "source": [
        "# HBOS  Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "a34ZbzAX4mld"
      },
      "outputs": [],
      "source": [
        "benign_train_samples = df_train[df_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "normal_train_samples = df_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "train_labels = df_train[\"Label\"]\n",
        "test_labels = df_test[\"Label\"]\n",
        "\n",
        "test_samples = df_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "sDquxErU4mld"
      },
      "outputs": [],
      "source": [
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xLBIT-Rc4mld",
        "outputId": "8162929e-4879-40e2-a040-afc57eafe7c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [10:06<00:00, 16.85s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 15, 'con': 0.01}\n",
            "0.8971048198477583\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9936    0.9892    0.9914    137714\n",
            "           1     0.7642    0.8455    0.8028      5704\n",
            "\n",
            "    accuracy                         0.9835    143418\n",
            "   macro avg     0.8789    0.9174    0.8971    143418\n",
            "weighted avg     0.9845    0.9835    0.9839    143418\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.hbos import HBOS\n",
        "\n",
        "n_est = [5,10,15,20,25,30]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "MDcX0mma4mld",
        "outputId": "a2b64cfc-d413-4ba0-9f24-b4935343c315"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [10:12<00:00, 17.00s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.05}\n",
            "0.9264385476143018\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9865    0.9932    137714\n",
            "           1     0.7539    1.0000    0.8597      5704\n",
            "\n",
            "    accuracy                         0.9870    143418\n",
            "   macro avg     0.8769    0.9932    0.9264    143418\n",
            "weighted avg     0.9902    0.9870    0.9879    143418\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "UbDOqrcy4mle"
      },
      "outputs": [],
      "source": [
        "##  PCA  Emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Nga82Fw_4mle",
        "outputId": "0fe52043-af21-45c1-a404-040ab5845efc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [03:35<00:00,  5.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.01}\n",
            "0.8298160211518412\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9842    0.9911    0.9876    137714\n",
            "           1     0.7402    0.6154    0.6720      5704\n",
            "\n",
            "    accuracy                         0.9761    143418\n",
            "   macro avg     0.8622    0.8032    0.8298    143418\n",
            "weighted avg     0.9745    0.9761    0.9751    143418\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.pca import PCA\n",
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "sg6AcAUW4mlf",
        "outputId": "a9949458-96cf-44dc-b4f6-c73458cb2719"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [03:04<00:00,  5.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.05}\n",
            "0.9102031301543931\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9969    0.9871    0.9920    137714\n",
            "           1     0.7489    0.9267    0.8284      5704\n",
            "\n",
            "    accuracy                         0.9847    143418\n",
            "   macro avg     0.8729    0.9569    0.9102    143418\n",
            "weighted avg     0.9871    0.9847    0.9855    143418\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "yi8SO3tL4mlg"
      },
      "outputs": [],
      "source": [
        "##  IF  Emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "9D0m4vb04mlg",
        "outputId": "bd5a55e6-ac70-4943-9b28-92474b5fb9e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [01:08<00:00,  2.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 50, 'con': 0.01}\n",
            "0.8898530832675655\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9927    0.9890    0.9908    137714\n",
            "           1     0.7557    0.8250    0.7889      5704\n",
            "\n",
            "    accuracy                         0.9824    143418\n",
            "   macro avg     0.8742    0.9070    0.8899    143418\n",
            "weighted avg     0.9833    0.9824    0.9828    143418\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "NCj-3u4t4mlg",
        "outputId": "5f6b1720-9662-4704-ba96-dd57ee32a900"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [01:16<00:00,  3.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 50, 'con': 0.05}\n",
            "0.9241258299753028\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9996    0.9865    0.9930    137714\n",
            "           1     0.7527    0.9902    0.8552      5704\n",
            "\n",
            "    accuracy                         0.9867    143418\n",
            "   macro avg     0.8761    0.9884    0.9241    143418\n",
            "weighted avg     0.9898    0.9867    0.9875    143418\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
