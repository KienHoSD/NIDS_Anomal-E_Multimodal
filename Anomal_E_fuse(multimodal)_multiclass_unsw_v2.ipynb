{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Hjc3iIihKLn-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from dgl.data import DGLDataset\n",
    "import dgl\n",
    "import time\n",
    "import networkx as nx\n",
    "import category_encoders as ce\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "from typing import *\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SvWHb_BpKsLq"
   },
   "outputs": [],
   "source": [
    "file_name = \"NF-UNSW-NB15-v2.parquet\"\n",
    "data = pd.read_parquet(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "fqly1y-LMwYS",
    "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    2295222\n",
       "1      95053\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3t4OREvSM33h"
   },
   "outputs": [],
   "source": [
    "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
    "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
    "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
    "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bTtHq0XqNXxI"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUNIP-8zNkn9",
    "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Exploits', 'Generic', 'Fuzzers', 'Backdoor', 'DoS',\n",
       "       'Reconnaissance', 'Shellcode', 'Worms', 'Analysis'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Attack.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    95053\n",
       "0    45904\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the dataset based on your needs (machine capacity) ideally ~500k rows\n",
    "data_attack = data[data['Label'] == 1]\n",
    "data_benign = data[data['Label'] == 0].sample(frac=0.02, random_state=13)\n",
    "data = pd.concat([data_attack, data_benign], axis=0)\n",
    "data = data.sample(frac=1, random_state=13).reset_index(drop=True)\n",
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "lcfAP6ViOp-J",
    "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Analysis</th>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>...</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Backdoor</th>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>...</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>...</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS</th>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>...</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exploits</th>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>...</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuzzers</th>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>...</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generic</th>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>...</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reconnaissance</th>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>...</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shellcode</th>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>...</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Worms</th>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                IPV4_SRC_ADDR  IPV4_DST_ADDR  PROTOCOL  L7_PROTO  IN_BYTES  \\\n",
       "Attack                                                                       \n",
       "Analysis                 2299           2299      2299      2299      2299   \n",
       "Backdoor                 2169           2169      2169      2169      2169   \n",
       "Benign                  45904          45904     45904     45904     45904   \n",
       "DoS                      5794           5794      5794      5794      5794   \n",
       "Exploits                31551          31551     31551     31551     31551   \n",
       "Fuzzers                 22310          22310     22310     22310     22310   \n",
       "Generic                 16560          16560     16560     16560     16560   \n",
       "Reconnaissance          12779          12779     12779     12779     12779   \n",
       "Shellcode                1427           1427      1427      1427      1427   \n",
       "Worms                     164            164       164       164       164   \n",
       "\n",
       "                IN_PKTS  OUT_BYTES  OUT_PKTS  TCP_FLAGS  CLIENT_TCP_FLAGS  \\\n",
       "Attack                                                                      \n",
       "Analysis           2299       2299      2299       2299              2299   \n",
       "Backdoor           2169       2169      2169       2169              2169   \n",
       "Benign            45904      45904     45904      45904             45904   \n",
       "DoS                5794       5794      5794       5794              5794   \n",
       "Exploits          31551      31551     31551      31551             31551   \n",
       "Fuzzers           22310      22310     22310      22310             22310   \n",
       "Generic           16560      16560     16560      16560             16560   \n",
       "Reconnaissance    12779      12779     12779      12779             12779   \n",
       "Shellcode          1427       1427      1427       1427              1427   \n",
       "Worms               164        164       164        164               164   \n",
       "\n",
       "                ...  NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  \\\n",
       "Attack          ...                                                \n",
       "Analysis        ...                         2299            2299   \n",
       "Backdoor        ...                         2169            2169   \n",
       "Benign          ...                        45904           45904   \n",
       "DoS             ...                         5794            5794   \n",
       "Exploits        ...                        31551           31551   \n",
       "Fuzzers         ...                        22310           22310   \n",
       "Generic         ...                        16560           16560   \n",
       "Reconnaissance  ...                        12779           12779   \n",
       "Shellcode       ...                         1427            1427   \n",
       "Worms           ...                          164             164   \n",
       "\n",
       "                TCP_WIN_MAX_OUT  ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  \\\n",
       "Attack                                                                     \n",
       "Analysis                   2299       2299            2299          2299   \n",
       "Backdoor                   2169       2169            2169          2169   \n",
       "Benign                    45904      45904           45904         45904   \n",
       "DoS                        5794       5794            5794          5794   \n",
       "Exploits                  31551      31551           31551         31551   \n",
       "Fuzzers                   22310      22310           22310         22310   \n",
       "Generic                   16560      16560           16560         16560   \n",
       "Reconnaissance            12779      12779           12779         12779   \n",
       "Shellcode                  1427       1427            1427          1427   \n",
       "Worms                       164        164             164           164   \n",
       "\n",
       "                DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  Label  \n",
       "Attack                                                                       \n",
       "Analysis                  2299            2299                  2299   2299  \n",
       "Backdoor                  2169            2169                  2169   2169  \n",
       "Benign                   45904           45904                 45904  45904  \n",
       "DoS                       5794            5794                  5794   5794  \n",
       "Exploits                 31551           31551                 31551  31551  \n",
       "Fuzzers                  22310           22310                 22310  22310  \n",
       "Generic                  16560           16560                 16560  16560  \n",
       "Reconnaissance           12779           12779                 12779  12779  \n",
       "Shellcode                 1427            1427                  1427   1427  \n",
       "Worms                      164             164                   164    164  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=\"Attack\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FqRx5xCPOuv8"
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Attack\", \"Label\"])\n",
    "y = data[[\"Attack\", \"Label\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=13, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bPfakXplPGGx"
   },
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
    "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
    "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
    "                                  'FTP_COMMAND_RET_CODE'])\n",
    "encoder.fit(X_train, y_train.Label)\n",
    "\n",
    "# Transform on training set\n",
    "X_train = encoder.transform(X_train)\n",
    "\n",
    "# Transform on testing set\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ibyOfV-8PouK"
   },
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "asDnsSIWPee0"
   },
   "outputs": [],
   "source": [
    "# (Modified)\n",
    "scaler = Normalizer()\n",
    "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
    "scaler.fit(X_train[cols_to_norm])\n",
    "\n",
    "# Transform on training set\n",
    "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
    "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
    "X_train['id'] = X_train.index\n",
    "\n",
    "# Transform on testing set\n",
    "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
    "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
    "X_test['id'] = X_test.index\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "hErQbsnrPluV",
    "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>h</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54790</th>\n",
       "      <td>59.166.0.7</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>3.814536e-08</td>\n",
       "      <td>4.108020e-08</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>3.681363e-07</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>4.908484e-07</td>\n",
       "      <td>2.369303e-08</td>\n",
       "      <td>5.817156e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>4.588295e-08</td>\n",
       "      <td>4.588380e-08</td>\n",
       "      <td>4.191008e-08</td>\n",
       "      <td>4.191625e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.300362e-08</td>\n",
       "      <td>[3.814535708763979e-08, 4.108020165677007e-08,...</td>\n",
       "      <td>54790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62828</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>149.171.126.10</td>\n",
       "      <td>8.270785e-07</td>\n",
       "      <td>8.047329e-07</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>2.403846e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.359471e-07</td>\n",
       "      <td>9.359471e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.988155e-07</td>\n",
       "      <td>8.988322e-07</td>\n",
       "      <td>8.209898e-07</td>\n",
       "      <td>8.211105e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.424114e-07</td>\n",
       "      <td>[8.270784791926004e-07, 8.047329196686106e-07,...</td>\n",
       "      <td>62828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41042</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>149.171.126.2</td>\n",
       "      <td>2.390521e-09</td>\n",
       "      <td>2.574444e-09</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.845651e-07</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>1.922553e-07</td>\n",
       "      <td>1.484812e-09</td>\n",
       "      <td>1.547512e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.120062e-10</td>\n",
       "      <td>1.183919e-10</td>\n",
       "      <td>2.626452e-09</td>\n",
       "      <td>2.626838e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.694982e-09</td>\n",
       "      <td>[2.3905211630149368e-09, 2.574444150982946e-09...</td>\n",
       "      <td>41042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80853</th>\n",
       "      <td>175.45.176.1</td>\n",
       "      <td>149.171.126.10</td>\n",
       "      <td>5.985176e-07</td>\n",
       "      <td>4.184611e-07</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>1.250000e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.866925e-07</td>\n",
       "      <td>4.866925e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.673841e-07</td>\n",
       "      <td>4.673928e-07</td>\n",
       "      <td>4.269147e-07</td>\n",
       "      <td>4.269775e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.380540e-07</td>\n",
       "      <td>[5.985176447375138e-07, 4.1846114668570904e-07...</td>\n",
       "      <td>80853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25170</th>\n",
       "      <td>175.45.176.2</td>\n",
       "      <td>149.171.126.10</td>\n",
       "      <td>4.521337e-09</td>\n",
       "      <td>3.598448e-09</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>9.454226e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.636241e-08</td>\n",
       "      <td>7.242284e-09</td>\n",
       "      <td>7.237300e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>6.992736e-09</td>\n",
       "      <td>7.003109e-09</td>\n",
       "      <td>4.967567e-09</td>\n",
       "      <td>4.968298e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.810103e-09</td>\n",
       "      <td>[4.521336912811051e-09, 3.5984476719847035e-09...</td>\n",
       "      <td>25170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPV4_SRC_ADDR   IPV4_DST_ADDR      PROTOCOL      L7_PROTO  IN_BYTES  \\\n",
       "54790    59.166.0.7   149.171.126.7  3.814536e-08  4.108020e-08  0.000020   \n",
       "62828  175.45.176.0  149.171.126.10  8.270785e-07  8.047329e-07  0.000125   \n",
       "41042    59.166.0.5   149.171.126.2  2.390521e-09  2.574444e-09  0.000011   \n",
       "80853  175.45.176.1  149.171.126.10  5.985176e-07  4.184611e-07  0.000125   \n",
       "25170  175.45.176.2  149.171.126.10  4.521337e-09  3.598448e-09  0.000102   \n",
       "\n",
       "            IN_PKTS  OUT_BYTES      OUT_PKTS     TCP_FLAGS  CLIENT_TCP_FLAGS  \\\n",
       "54790  3.681363e-07   0.000123  4.908484e-07  2.369303e-08      5.817156e-08   \n",
       "62828  2.403846e-06   0.000000  0.000000e+00  9.359471e-07      9.359471e-07   \n",
       "41042  1.845651e-07   0.000124  1.922553e-07  1.484812e-09      1.547512e-09   \n",
       "80853  1.250000e-06   0.000000  0.000000e+00  4.866925e-07      4.866925e-07   \n",
       "25170  9.454226e-08   0.000002  3.636241e-08  7.242284e-09      7.237300e-09   \n",
       "\n",
       "       ...  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT     ICMP_TYPE  ICMP_IPV4_TYPE  \\\n",
       "54790  ...        0.000444         0.000355  4.588295e-08    4.588380e-08   \n",
       "62828  ...        0.000000         0.000000  8.988155e-07    8.988322e-07   \n",
       "41042  ...        0.000117         0.000056  1.120062e-10    1.183919e-10   \n",
       "80853  ...        0.000000         0.000000  4.673841e-07    4.673928e-07   \n",
       "25170  ...        0.000119         0.000119  6.992736e-09    7.003109e-09   \n",
       "\n",
       "       DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \\\n",
       "54790  4.191008e-08    4.191625e-08             0.0          4.300362e-08   \n",
       "62828  8.209898e-07    8.211105e-07             0.0          8.424114e-07   \n",
       "41042  2.626452e-09    2.626838e-09             0.0          2.694982e-09   \n",
       "80853  4.269147e-07    4.269775e-07             0.0          4.380540e-07   \n",
       "25170  4.967567e-09    4.968298e-09             0.0          3.810103e-09   \n",
       "\n",
       "                                                       h     id  \n",
       "54790  [3.814535708763979e-08, 4.108020165677007e-08,...  54790  \n",
       "62828  [8.270784791926004e-07, 8.047329196686106e-07,...  62828  \n",
       "41042  [2.3905211630149368e-09, 2.574444150982946e-09...  41042  \n",
       "80853  [5.985176447375138e-07, 4.1846114668570904e-07...  80853  \n",
       "25170  [4.521336912811051e-09, 3.5984476719847035e-09...  25170  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d_tLtK4WPtrF"
   },
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "lab_enc.fit(data[\"Attack\"])\n",
    "\n",
    "# Transform on training set\n",
    "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
    "\n",
    "# Transform on testing set\n",
    "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8yaicjecP1fZ"
   },
   "outputs": [],
   "source": [
    "# Training graph (Modified)\n",
    "\n",
    "train['id'] = train.index\n",
    "\n",
    "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "           [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "train_g = train_g.to_directed()\n",
    "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
    "train_g.edata['h'].shape[1]])\n",
    "train_g.ndata['h'] = nfeat_weight\n",
    "\n",
    "test['id'] = test.index\n",
    "\n",
    "# Testing graph\n",
    "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "            [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "# print(test_g)\n",
    "test_g = test_g.to_directed()\n",
    "# print(test_g)\n",
    "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
    "test_g.edata['h'].shape[1]])\n",
    "test_g.ndata['h'] = nfeat_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PUV6DgJ9QRaP"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import tqdm\n",
    "import gc\n",
    "\n",
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "      super(SAGELayer, self).__init__()\n",
    "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
    "      self.activation = F.relu\n",
    "      self.W_edge = nn.Linear(128 * 2, 256)\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      gain = nn.init.calculate_gain('relu')\n",
    "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "      return {'m':  edges.data['h']}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "      with g_dgl.local_scope():\n",
    "        g = g_dgl\n",
    "        g.ndata['h'] = nfeats\n",
    "        g.edata['h'] = efeats\n",
    "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "\n",
    "        # Compute edge embeddings\n",
    "        u, v = g.edges()\n",
    "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
    "        return g.ndata['h'], edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_xo-3K4QRGqc"
   },
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
    "      super(SAGE, self).__init__()\n",
    "      self.layers = nn.ModuleList()\n",
    "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
    "\n",
    "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
    "      if corrupt:\n",
    "        e_perm = torch.randperm(g.number_of_edges())\n",
    "        #n_perm = torch.randperm(g.number_of_nodes())\n",
    "        efeats = efeats[e_perm]\n",
    "        #nfeats = nfeats[n_perm]\n",
    "      for i, layer in enumerate(self.layers):\n",
    "        #nfeats = layer(g, nfeats, efeats)\n",
    "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
    "      #return nfeats.sum(1)\n",
    "      return nfeats.sum(1), e_feats.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6uuxRtLuRJQL"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "      super(Discriminator, self).__init__()\n",
    "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def uniform(self, size, tensor):\n",
    "      bound = 1.0 / math.sqrt(size)\n",
    "      if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      size = self.weight.size(0)\n",
    "      self.uniform(size, self.weight)\n",
    "\n",
    "    def forward(self, features, summary):\n",
    "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
    "      return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZPbVjlCyRUco"
   },
   "outputs": [],
   "source": [
    "class DGI(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
    "      super(DGI, self).__init__()\n",
    "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
    "      #self.discriminator = Discriminator(128)\n",
    "      self.discriminator = Discriminator(256)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "\n",
    "      positive = positive[1]\n",
    "      negative = negative[1]\n",
    "\n",
    "      summary = torch.sigmoid(positive.mean(dim=0))\n",
    "\n",
    "      positive = self.discriminator(positive, summary)\n",
    "      negative = self.discriminator(negative, summary)\n",
    "\n",
    "      l1 = self.loss(positive, torch.ones_like(positive))\n",
    "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
    "\n",
    "      return l1 + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sKnfpWFMR19u"
   },
   "outputs": [],
   "source": [
    "ndim_in = train_g.ndata['h'].shape[1]\n",
    "hidden_features = 128\n",
    "ndim_out = 128\n",
    "num_layers = 1\n",
    "edim = train_g.edata['h'].shape[1]\n",
    "learning_rate = 1e-3\n",
    "epochs = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "aSl_9qY8SbA0"
   },
   "outputs": [],
   "source": [
    "dgi = DGI(ndim_in,\n",
    "    ndim_out,\n",
    "    edim,\n",
    "    F.relu)\n",
    "\n",
    "dgi = dgi.to('cuda')\n",
    "\n",
    "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
    "                lr=1e-3,\n",
    "                weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9K6_cOiWSdJA"
   },
   "outputs": [],
   "source": [
    "# Format node and edge features for E-GraphSAGE\n",
    "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
    "                                   (train_g.ndata['h'].shape[0], 1,\n",
    "                                    train_g.ndata['h'].shape[1]))\n",
    "\n",
    "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
    "                                   (train_g.edata['h'].shape[0], 1,\n",
    "                                    train_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "O44auIyWSexg"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "train_g = train_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gZtafIdxSheN"
   },
   "outputs": [],
   "source": [
    "# cnt_wait = 0\n",
    "# best = 1e9\n",
    "# best_t = 0\n",
    "# dur = []\n",
    "# node_features = train_g.ndata['h'] \n",
    "# edge_features = train_g.edata['h']\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     dgi.train()\n",
    "#     if epoch >= 3:\n",
    "#         t0 = time.time()\n",
    "\n",
    "#     dgi_optimizer.zero_grad()\n",
    "#     loss = dgi(train_g, node_features, edge_features)\n",
    "#     loss.backward()\n",
    "#     dgi_optimizer.step()\n",
    "\n",
    "#     if loss < best:\n",
    "#         best = loss\n",
    "#         best_t = epoch\n",
    "#         cnt_wait = 0\n",
    "#         torch.save(dgi.state_dict(), 'best_dgi_UNSW_multiclass_v2.pkl')\n",
    "#     else:\n",
    "#         cnt_wait += 1\n",
    "\n",
    "#   # if cnt_wait == patience:\n",
    "#   #     print('Early stopping!')\n",
    "#   #     break\n",
    "\n",
    "#     if epoch >= 3:\n",
    "#         dur.append(time.time() - t0)\n",
    "\n",
    "#     if epoch % 50 == 0:\n",
    "\n",
    "#         print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "#             \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
    "#               loss.item(),\n",
    "#               train_g.num_edges() / np.mean(dur) / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RZ2HAQDAF-4c",
    "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124692/1257123129.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dgi.load_state_dict(torch.load('best_dgi_UNSW_multiclass_v2.pkl'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgi.load_state_dict(torch.load('best_dgi_UNSW_multiclass_v2.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6Ek16GkRStKP"
   },
   "outputs": [],
   "source": [
    "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
    "training_emb = training_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-FwaBlOdS4ep"
   },
   "outputs": [],
   "source": [
    "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
    "                                   (test_g.ndata['h'].shape[0], 1,\n",
    "                                    test_g.ndata['h'].shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
    "                                   (test_g.edata['h'].shape[0], 1,\n",
    "                                    test_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SBa-rdivS6cQ"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "test_g = test_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "W12WLjslS-kx"
   },
   "outputs": [],
   "source": [
    "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
    "testing_emb = testing_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal (Fusion) Learning\n",
    "\n",
    "df_train = pd.DataFrame(training_emb,)\n",
    "# map the id to the original data\n",
    "df_train['id'] = train_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "df_raw_train = pd.DataFrame(X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_fuse_train = pd.merge(df_train, df_raw_train, on='id', how='left')\n",
    "df_fuse_train = df_fuse_train.drop(columns=[\"id\"])\n",
    "df_fuse_train[\"Attacks\"] = train_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
    "\n",
    "df_test = pd.DataFrame(testing_emb,)\n",
    "# map the id to the original data\n",
    "df_test['id'] = test_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "df_raw_test = pd.DataFrame(X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_raw_test = pd.merge(df_test, df_raw_test, on='id', how='left')\n",
    "df_fuse_test = df_raw_test.drop(columns=[\"id\"])\n",
    "df_fuse_test[\"Attacks\"] = test_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ZYABKzdrTGas"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pyod.models.cblof import CBLOF\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_fuse_train_samples = df_fuse_train[df_fuse_train.Label == 0].drop(columns=[\"Label\", \"Attacks\"])\n",
    "normal_fuse_train_samples = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"])\n",
    "\n",
    "fuse_train_labels = df_fuse_train[\"Label\"]\n",
    "fuse_test_labels = df_fuse_test[\"Label\"]\n",
    "\n",
    "fuse_test_samples = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_512_TO_1024_BYTES</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027564</td>\n",
       "      <td>0.061195</td>\n",
       "      <td>0.106339</td>\n",
       "      <td>0.123702</td>\n",
       "      <td>0.088148</td>\n",
       "      <td>0.194936</td>\n",
       "      <td>0.051847</td>\n",
       "      <td>-0.021169</td>\n",
       "      <td>0.073368</td>\n",
       "      <td>0.141140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>1.167008e-08</td>\n",
       "      <td>1.192984e-08</td>\n",
       "      <td>9.322658e-08</td>\n",
       "      <td>9.324029e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.565909e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027564</td>\n",
       "      <td>0.061195</td>\n",
       "      <td>0.106339</td>\n",
       "      <td>0.123702</td>\n",
       "      <td>0.088148</td>\n",
       "      <td>0.194936</td>\n",
       "      <td>0.051847</td>\n",
       "      <td>-0.021169</td>\n",
       "      <td>0.073368</td>\n",
       "      <td>0.141140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>9.275525e-08</td>\n",
       "      <td>9.296284e-08</td>\n",
       "      <td>7.805673e-08</td>\n",
       "      <td>7.806821e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.009342e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027564</td>\n",
       "      <td>0.061195</td>\n",
       "      <td>0.106339</td>\n",
       "      <td>0.123702</td>\n",
       "      <td>0.088148</td>\n",
       "      <td>0.194936</td>\n",
       "      <td>0.051847</td>\n",
       "      <td>-0.021169</td>\n",
       "      <td>0.073368</td>\n",
       "      <td>0.141140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.564097e-07</td>\n",
       "      <td>5.564200e-07</td>\n",
       "      <td>5.082318e-07</td>\n",
       "      <td>5.083065e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.214928e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027564</td>\n",
       "      <td>0.061195</td>\n",
       "      <td>0.106339</td>\n",
       "      <td>0.123702</td>\n",
       "      <td>0.088148</td>\n",
       "      <td>0.194936</td>\n",
       "      <td>0.051847</td>\n",
       "      <td>-0.021169</td>\n",
       "      <td>0.073368</td>\n",
       "      <td>0.141140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>1.430868e-07</td>\n",
       "      <td>1.456895e-07</td>\n",
       "      <td>1.243948e-07</td>\n",
       "      <td>1.244131e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.276406e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027564</td>\n",
       "      <td>0.061195</td>\n",
       "      <td>0.106339</td>\n",
       "      <td>0.123702</td>\n",
       "      <td>0.088148</td>\n",
       "      <td>0.194936</td>\n",
       "      <td>0.051847</td>\n",
       "      <td>-0.021169</td>\n",
       "      <td>0.073368</td>\n",
       "      <td>0.141140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>1.915947e-07</td>\n",
       "      <td>1.915958e-07</td>\n",
       "      <td>1.321255e-07</td>\n",
       "      <td>1.321449e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.355729e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84571</th>\n",
       "      <td>-0.022834</td>\n",
       "      <td>0.279163</td>\n",
       "      <td>-0.048518</td>\n",
       "      <td>0.017740</td>\n",
       "      <td>0.133633</td>\n",
       "      <td>0.538629</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>-0.180243</td>\n",
       "      <td>-0.024673</td>\n",
       "      <td>0.098406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.741292e-07</td>\n",
       "      <td>1.741324e-07</td>\n",
       "      <td>1.590519e-07</td>\n",
       "      <td>1.590752e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.632019e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84572</th>\n",
       "      <td>-0.012005</td>\n",
       "      <td>0.273036</td>\n",
       "      <td>-0.080949</td>\n",
       "      <td>0.021493</td>\n",
       "      <td>0.135640</td>\n",
       "      <td>0.547582</td>\n",
       "      <td>0.081690</td>\n",
       "      <td>-0.215371</td>\n",
       "      <td>-0.036512</td>\n",
       "      <td>0.086712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.589433e-07</td>\n",
       "      <td>1.589462e-07</td>\n",
       "      <td>1.451809e-07</td>\n",
       "      <td>1.452022e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489690e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84573</th>\n",
       "      <td>-0.012005</td>\n",
       "      <td>0.273036</td>\n",
       "      <td>-0.080949</td>\n",
       "      <td>0.021493</td>\n",
       "      <td>0.135640</td>\n",
       "      <td>0.547582</td>\n",
       "      <td>0.081690</td>\n",
       "      <td>-0.215371</td>\n",
       "      <td>-0.036512</td>\n",
       "      <td>0.086712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.668599e-07</td>\n",
       "      <td>1.668630e-07</td>\n",
       "      <td>1.524120e-07</td>\n",
       "      <td>1.524344e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.563888e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84574</th>\n",
       "      <td>-0.016502</td>\n",
       "      <td>0.280284</td>\n",
       "      <td>-0.064395</td>\n",
       "      <td>0.018897</td>\n",
       "      <td>0.143809</td>\n",
       "      <td>0.553309</td>\n",
       "      <td>0.075904</td>\n",
       "      <td>-0.210710</td>\n",
       "      <td>-0.031080</td>\n",
       "      <td>0.090374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.589433e-07</td>\n",
       "      <td>1.589462e-07</td>\n",
       "      <td>1.451809e-07</td>\n",
       "      <td>1.452022e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489690e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84575</th>\n",
       "      <td>-0.016502</td>\n",
       "      <td>0.280284</td>\n",
       "      <td>-0.064395</td>\n",
       "      <td>0.018897</td>\n",
       "      <td>0.143809</td>\n",
       "      <td>0.553309</td>\n",
       "      <td>0.075904</td>\n",
       "      <td>-0.210710</td>\n",
       "      <td>-0.031080</td>\n",
       "      <td>0.090374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.668599e-07</td>\n",
       "      <td>1.668630e-07</td>\n",
       "      <td>1.524120e-07</td>\n",
       "      <td>1.524344e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.563888e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84576 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.027564  0.061195  0.106339  0.123702  0.088148  0.194936  0.051847   \n",
       "1      0.027564  0.061195  0.106339  0.123702  0.088148  0.194936  0.051847   \n",
       "2      0.027564  0.061195  0.106339  0.123702  0.088148  0.194936  0.051847   \n",
       "3      0.027564  0.061195  0.106339  0.123702  0.088148  0.194936  0.051847   \n",
       "4      0.027564  0.061195  0.106339  0.123702  0.088148  0.194936  0.051847   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "84571 -0.022834  0.279163 -0.048518  0.017740  0.133633  0.538629  0.069336   \n",
       "84572 -0.012005  0.273036 -0.080949  0.021493  0.135640  0.547582  0.081690   \n",
       "84573 -0.012005  0.273036 -0.080949  0.021493  0.135640  0.547582  0.081690   \n",
       "84574 -0.016502  0.280284 -0.064395  0.018897  0.143809  0.553309  0.075904   \n",
       "84575 -0.016502  0.280284 -0.064395  0.018897  0.143809  0.553309  0.075904   \n",
       "\n",
       "              7         8         9  ...  NUM_PKTS_512_TO_1024_BYTES  \\\n",
       "0     -0.021169  0.073368  0.141140  ...                    0.000000   \n",
       "1     -0.021169  0.073368  0.141140  ...                    0.000000   \n",
       "2     -0.021169  0.073368  0.141140  ...                    0.000000   \n",
       "3     -0.021169  0.073368  0.141140  ...                    0.000002   \n",
       "4     -0.021169  0.073368  0.141140  ...                    0.000000   \n",
       "...         ...       ...       ...  ...                         ...   \n",
       "84571 -0.180243 -0.024673  0.098406  ...                    0.000000   \n",
       "84572 -0.215371 -0.036512  0.086712  ...                    0.000000   \n",
       "84573 -0.215371 -0.036512  0.086712  ...                    0.000000   \n",
       "84574 -0.210710 -0.031080  0.090374  ...                    0.000000   \n",
       "84575 -0.210710 -0.031080  0.090374  ...                    0.000000   \n",
       "\n",
       "       NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
       "0                              0.0        0.002236         0.002236   \n",
       "1                              0.0        0.001872         0.001872   \n",
       "2                              0.0        0.000000         0.000000   \n",
       "3                              0.0        0.002984         0.002984   \n",
       "4                              0.0        0.003169         0.003169   \n",
       "...                            ...             ...              ...   \n",
       "84571                          0.0        0.000000         0.000000   \n",
       "84572                          0.0        0.000000         0.000000   \n",
       "84573                          0.0        0.000000         0.000000   \n",
       "84574                          0.0        0.000000         0.000000   \n",
       "84575                          0.0        0.000000         0.000000   \n",
       "\n",
       "          ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "0      1.167008e-08    1.192984e-08  9.322658e-08    9.324029e-08   \n",
       "1      9.275525e-08    9.296284e-08  7.805673e-08    7.806821e-08   \n",
       "2      5.564097e-07    5.564200e-07  5.082318e-07    5.083065e-07   \n",
       "3      1.430868e-07    1.456895e-07  1.243948e-07    1.244131e-07   \n",
       "4      1.915947e-07    1.915958e-07  1.321255e-07    1.321449e-07   \n",
       "...             ...             ...           ...             ...   \n",
       "84571  1.741292e-07    1.741324e-07  1.590519e-07    1.590752e-07   \n",
       "84572  1.589433e-07    1.589462e-07  1.451809e-07    1.452022e-07   \n",
       "84573  1.668599e-07    1.668630e-07  1.524120e-07    1.524344e-07   \n",
       "84574  1.589433e-07    1.589462e-07  1.451809e-07    1.452022e-07   \n",
       "84575  1.668599e-07    1.668630e-07  1.524120e-07    1.524344e-07   \n",
       "\n",
       "       DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \n",
       "0                 0.0          9.565909e-08  \n",
       "1                 0.0          8.009342e-08  \n",
       "2                 0.0          5.214928e-07  \n",
       "3                 0.0          1.276406e-07  \n",
       "4                 0.0          1.355729e-07  \n",
       "...               ...                   ...  \n",
       "84571             0.0          1.632019e-07  \n",
       "84572             0.0          1.489690e-07  \n",
       "84573             0.0          1.563888e-07  \n",
       "84574             0.0          1.489690e-07  \n",
       "84575             0.0          1.563888e-07  \n",
       "\n",
       "[84576 rows x 295 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuse_test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised attack classification (Fusion)\n",
    "\n",
    "We now train a supervised classifier on the fused features to predict multi-class attack labels:\n",
    "- Features: embeddings + raw numeric features from `df_fuse_train`/`df_fuse_test` (without `Label`, `Attacks`).\n",
    "- Target: `Attacks` (encoded integer classes from earlier `LabelEncoder`).\n",
    "- Model: HistGradientBoostingClassifier (fast, strong on tabular data). Class imbalance handled via per-sample weights.\n",
    "- Metrics: macro F1, per-class report, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare supervised train/test for attack classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.utils import class_weight\n",
    "import pickle\n",
    "\n",
    "# Build train features/targets from already prepared fused DataFrames\n",
    "X_sup_train = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_sup_test = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights to mitigate class imbalance on training set\n",
    "classes = np.unique(y_sup_train)\n",
    "class_w = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes, y=y_sup_train\n",
    ")\n",
    "class_to_w = {c: w for c, w in zip(classes, class_w)}\n",
    "sample_weight = y_sup_train.map(class_to_w).values\n",
    "\n",
    "# Feature names to all str\n",
    "X_sup_train.columns = X_sup_train.columns.map(str)\n",
    "X_sup_test.columns = X_sup_test.columns.map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Methods (Fused Features)\n",
    "\n",
    "Now we'll compare multiple classification algorithms on the fused features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:19<00:00,  8.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 20}\n",
      "Best Macro F1: 0.5146\n",
      "Model saved to: best_rf_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2754    0.0333    0.0595      1380\n",
      "           1     0.1488    0.4309    0.2213      1302\n",
      "           2     0.9997    0.9935    0.9966     27542\n",
      "           3     0.3421    0.1384    0.1971      3476\n",
      "           4     0.7865    0.8049    0.7956     18932\n",
      "           5     0.8272    0.7469    0.7850     13386\n",
      "           6     0.9526    0.4849    0.6427      9936\n",
      "           7     0.8347    0.7993    0.8166      7668\n",
      "           8     0.0692    0.6379    0.1248       856\n",
      "           9     0.4860    0.5306    0.5073        98\n",
      "\n",
      "    accuracy                         0.7713     84576\n",
      "   macro avg     0.5722    0.5601    0.5146     84576\n",
      "weighted avg     0.8422    0.7713    0.7907     84576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with Grid Search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            rf_clf = RandomForestClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            rf_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_rf = rf_clf.predict(X_sup_test)\n",
    "            rf_f1 = f1_score(y_sup_test, y_pred_rf, average='macro')\n",
    "            \n",
    "            if rf_f1 > score:\n",
    "                score = rf_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = rf_clf\n",
    "                # Save best model\n",
    "                with open('best_rf_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(rf_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_rf_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Random Forest: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [11:02:00] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "100%|██████████| 27/27 [12:10<00:00, 27.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.6633\n",
      "Model saved to: best_xgb_classifier_fused.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1625    0.1572    0.1599      1380\n",
      "           1     0.1589    0.7104    0.2597      1302\n",
      "           2     0.9838    0.9944    0.9891     27542\n",
      "           3     0.3767    0.3720    0.3743      3476\n",
      "           4     0.8991    0.8126    0.8537     18932\n",
      "           5     0.9405    0.8357    0.8850     13386\n",
      "           6     0.9634    0.8446    0.9001      9936\n",
      "           7     0.8785    0.7996    0.8372      7668\n",
      "           8     0.5498    0.8645    0.6721       856\n",
      "           9     0.6636    0.7449    0.7019        98\n",
      "\n",
      "    accuracy                         0.8481     84576\n",
      "   macro avg     0.6577    0.7136    0.6633     84576\n",
      "weighted avg     0.8902    0.8481    0.8645     84576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with Grid Search\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    import pickle\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST CLASSIFIER (Fused Features)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            xgb_clf = XGBClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                learning_rate=lr,\n",
    "                random_state=13,\n",
    "                tree_method='hist', \n",
    "                device=\"cuda\"\n",
    "            )\n",
    "            \n",
    "            xgb_clf.fit(X_sup_train, y_sup_train, sample_weight=sample_weight)\n",
    "            y_pred_xgb = xgb_clf.predict(X_sup_test)\n",
    "            xgb_f1 = f1_score(y_sup_test, y_pred_xgb, average='macro')\n",
    "            \n",
    "            if xgb_f1 > score:\n",
    "                score = xgb_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = xgb_clf\n",
    "                # Save best model\n",
    "                xgb_clf.save_model('best_xgb_classifier_fused.json')\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_xgb_classifier_fused.json\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed. XGBoost might not support your GPU.\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CatBoost Grid Search (Expanded)...\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [08:37<00:00, 19.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BEST CATBOOST HYPERPARAMETERS (Fused Features):\n",
      "{'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.5986\n",
      "============================================================\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_fused.cbm\n",
      "\n",
      "============================================================\n",
      "FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1537    0.1587    0.1561      1380\n",
      "           1     0.1558    0.5069    0.2384      1302\n",
      "           2     0.9999    0.9940    0.9970     27542\n",
      "           3     0.2581    0.4517    0.3285      3476\n",
      "           4     0.9028    0.7326    0.8088     18932\n",
      "           5     0.8971    0.7757    0.8320     13386\n",
      "           6     0.9425    0.7952    0.8626      9936\n",
      "           7     0.8427    0.8183    0.8304      7668\n",
      "           8     0.3318    0.9404    0.4906       856\n",
      "           9     0.3038    0.8061    0.4413        98\n",
      "\n",
      "    accuracy                         0.8175     84576\n",
      "   macro avg     0.5788    0.6980    0.5986     84576\n",
      "weighted avg     0.8760    0.8175    0.8392     84576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost with Grid Search (Expanded, no l2_leaf_reg/border_count, fixed best score logic)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"Starting CatBoost Grid Search (Expanded)...\")\n",
    "    \n",
    "    # Expanded hyperparameter grid\n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'  # Use 'CPU' if GPU not available\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_cat = cat_clf.predict(X_sup_test)\n",
    "            cat_f1 = f1_score(y_sup_test, y_pred_cat, average='macro')\n",
    "            \n",
    "            if cat_f1 > best_score:\n",
    "                best_score = cat_f1\n",
    "                best_params = {\n",
    "                    'iterations': iterations,\n",
    "                    'depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for fused features\n",
    "                best_model_path = \"best_catboost_classifier_fused.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEST CATBOOST HYPERPARAMETERS (Fused Features):\")\n",
    "    print(best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    if best_model_path:\n",
    "        print(f\"\\nBest CatBoost model saved to: {best_model_path}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    y_pred_best = best_model.predict(X_sup_test)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_sup_test, y_pred_best, digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed. Install with: pip install catboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:51<00:00,  5.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 30}\n",
      "Best Macro F1: 0.4730\n",
      "Model saved to: best_et_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1368    0.1130    0.1238      1380\n",
      "           1     0.1399    0.1743    0.1552      1302\n",
      "           2     0.9989    0.9919    0.9954     27542\n",
      "           3     0.3034    0.1001    0.1506      3476\n",
      "           4     0.7108    0.8354    0.7680     18932\n",
      "           5     0.8136    0.7088    0.7576     13386\n",
      "           6     0.9115    0.5119    0.6556      9936\n",
      "           7     0.8468    0.7703    0.8067      7668\n",
      "           8     0.0562    0.4463    0.0998       856\n",
      "           9     0.3265    0.1633    0.2177        98\n",
      "\n",
      "    accuracy                         0.7655     84576\n",
      "   macro avg     0.5244    0.4815    0.4730     84576\n",
      "weighted avg     0.8148    0.7655    0.7780     84576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            et_clf = ExtraTreesClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            et_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_et = et_clf.predict(X_sup_test)\n",
    "            et_f1 = f1_score(y_sup_test, y_pred_et, average='macro')\n",
    "            \n",
    "            if et_f1 > score:\n",
    "                score = et_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = et_clf\n",
    "                # Save best model\n",
    "                with open('best_et_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(et_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_et_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Extra Trees: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Features Classification (Comparison Baseline)\n",
    "\n",
    "Now we'll train classifiers on **raw features only** (without graph embeddings) to compare the benefit of multimodal fusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw feature shape - Train: (98669, 39), Test: (42288, 39)\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Prepare raw features (without embeddings)\n",
    "# Use only the original numeric features from X_train/X_test\n",
    "\n",
    "X_raw_train = X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_train = y_train[\"Attack\"].copy()\n",
    "\n",
    "X_raw_test = X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_test = y_test[\"Attack\"].copy()\n",
    "\n",
    "# Encode labels\n",
    "y_raw_train_encoded = lab_enc.transform(y_train[\"Attack\"])\n",
    "y_raw_test_encoded = lab_enc.transform(y_test[\"Attack\"])\n",
    "\n",
    "# Compute sample weights\n",
    "classes_raw = np.unique(y_raw_train_encoded)\n",
    "class_w_raw = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_raw, y=y_raw_train_encoded\n",
    ")\n",
    "class_to_w_raw = {c: w for c, w in zip(classes_raw, class_w_raw)}\n",
    "sample_weight_raw = pd.Series(y_raw_train_encoded).map(class_to_w_raw).values\n",
    "\n",
    "# Feature names to str\n",
    "X_raw_train.columns = X_raw_train.columns.map(str)\n",
    "X_raw_test.columns = X_raw_test.columns.map(str)\n",
    "\n",
    "print(f\"Raw feature shape - Train: {X_raw_train.shape}, Test: {X_raw_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_raw_train_encoded))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Raw Features Only)\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:22<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 20}\n",
      "Best Macro F1: 0.6009\n",
      "Model saved to: best_rf_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1573    0.8565    0.2658       690\n",
      "           1     0.1874    0.1966    0.1919       651\n",
      "           2     0.9993    0.9926    0.9959     13771\n",
      "           3     0.5340    0.2980    0.3826      1738\n",
      "           4     0.9012    0.7799    0.8362      9466\n",
      "           5     0.9233    0.7895    0.8512      6693\n",
      "           6     0.9620    0.8198    0.8852      4968\n",
      "           7     0.8169    0.8135    0.8152      3834\n",
      "           8     0.3498    0.8294    0.4920       428\n",
      "           9     0.1797    0.7959    0.2932        49\n",
      "\n",
      "    accuracy                         0.8314     42288\n",
      "   macro avg     0.6011    0.7172    0.6009     42288\n",
      "weighted avg     0.8915    0.8314    0.8525     42288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Raw Features Only)\")\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = rf_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Raw Features Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [03:15<00:00,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.6703\n",
      "Model saved to: best_xgb_classifier_raw.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1457    0.6275    0.2365       690\n",
      "           1     0.1419    0.3041    0.1935       651\n",
      "           2     0.9996    0.9939    0.9968     13771\n",
      "           3     0.4929    0.3602    0.4162      1738\n",
      "           4     0.9249    0.7881    0.8510      9466\n",
      "           5     0.9447    0.8575    0.8990      6693\n",
      "           6     0.9684    0.8504    0.9056      4968\n",
      "           7     0.8538    0.8135    0.8332      3834\n",
      "           8     0.5557    0.9439    0.6996       428\n",
      "           9     0.5526    0.8571    0.6720        49\n",
      "\n",
      "    accuracy                         0.8497     42288\n",
      "   macro avg     0.6580    0.7396    0.6703     42288\n",
      "weighted avg     0.9043    0.8497    0.8711     42288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Raw Features Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='cuda'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_raw_train, y_raw_train_encoded, sample_weight=sample_weight_raw)\n",
    "        y_pred = xgb_clf.predict(X_raw_test)\n",
    "        f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_raw.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_raw.json\\n\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Raw Features Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [02:31<00:00,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.6163\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_raw.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1538    0.7362    0.2544       690\n",
      "           1     0.1481    0.2934    0.1968       651\n",
      "           2     0.9999    0.9922    0.9960     13771\n",
      "           3     0.3975    0.3516    0.3731      1738\n",
      "           4     0.9229    0.7191    0.8083      9466\n",
      "           5     0.9152    0.8050    0.8566      6693\n",
      "           6     0.9472    0.8126    0.8748      4968\n",
      "           7     0.8479    0.8200    0.8337      3834\n",
      "           8     0.3823    0.9603    0.5469       428\n",
      "           9     0.2678    1.0000    0.4224        49\n",
      "\n",
      "    accuracy                         0.8232     42288\n",
      "   macro avg     0.5982    0.7490    0.6163     42288\n",
      "weighted avg     0.8905    0.8232    0.8478     42288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Raw Features Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "            y_pred = cat_clf.predict(X_raw_test)\n",
    "            f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for raw features\n",
    "                best_model_path = \"best_catboost_classifier_raw.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Raw Features Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 30}\n",
      "Best Macro F1: 0.6463\n",
      "Model saved to: best_et_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1548    0.8174    0.2603       690\n",
      "           1     0.1652    0.1997    0.1808       651\n",
      "           2     0.9984    0.9937    0.9960     13771\n",
      "           3     0.5221    0.3199    0.3967      1738\n",
      "           4     0.9063    0.7966    0.8479      9466\n",
      "           5     0.9311    0.8253    0.8750      6693\n",
      "           6     0.9623    0.8430    0.8987      4968\n",
      "           7     0.8621    0.7890    0.8239      3834\n",
      "           8     0.4538    0.9299    0.6100       428\n",
      "           9     0.4362    0.8367    0.5734        49\n",
      "\n",
      "    accuracy                         0.8431     42288\n",
      "   macro avg     0.6392    0.7351    0.6463     42288\n",
      "weighted avg     0.8982    0.8431    0.8631     42288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Raw Features Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = et_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Only Classification (Graph Features)\n",
    "\n",
    "Now we'll train classifiers on **embeddings only** (graph features without raw features) to isolate the value of graph-based learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape - Train: (197338, 256), Test: (84576, 256)\n",
      "Number of classes: 10\n",
      "Using only graph embeddings (no raw features)\n"
     ]
    }
   ],
   "source": [
    "# Prepare embeddings-only features (graph features without raw data)\n",
    "# Extract only the embedding columns (first 256 dimensions from graph encoder)\n",
    "\n",
    "# From the fused dataframes, extract only embedding columns\n",
    "# df_fuse_train has: [0-255] = embeddings, [256+] = raw features\n",
    "num_embedding_dims = 256  # Based on the DGI encoder output dimension\n",
    "\n",
    "X_emb_train = df_fuse_train.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_emb_test = df_fuse_test.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights\n",
    "classes_emb = np.unique(y_emb_train)\n",
    "class_w_emb = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_emb, y=y_emb_train\n",
    ")\n",
    "class_to_w_emb = {c: w for c, w in zip(classes_emb, class_w_emb)}\n",
    "sample_weight_emb = y_emb_train.map(class_to_w_emb).values\n",
    "\n",
    "# Feature names to str\n",
    "X_emb_train.columns = X_emb_train.columns.map(str)\n",
    "X_emb_test.columns = X_emb_test.columns.map(str)\n",
    "\n",
    "print(f\"Embeddings shape - Train: {X_emb_train.shape}, Test: {X_emb_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_emb_train))}\")\n",
    "print(f\"Using only graph embeddings (no raw features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:34<00:00,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 20}\n",
      "Best Macro F1: 0.1896\n",
      "Model saved to: best_rf_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1380\n",
      "           1     0.0558    0.5330    0.1010      1302\n",
      "           2     1.0000    0.9869    0.9934     27542\n",
      "           3     0.0000    0.0000    0.0000      3476\n",
      "           4     0.3831    0.0791    0.1312     18932\n",
      "           5     0.2696    0.1962    0.2272     13386\n",
      "           6     0.3296    0.4860    0.3928      9936\n",
      "           7     0.1592    0.0121    0.0225      7668\n",
      "           8     0.0126    0.1086    0.0226       856\n",
      "           9     0.0029    0.2551    0.0057        98\n",
      "\n",
      "    accuracy                         0.4379     84576\n",
      "   macro avg     0.2213    0.2657    0.1896     84576\n",
      "weighted avg     0.5082    0.4379    0.4388     84576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = rf_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [08:22<00:00, 18.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "Best Macro F1: 0.1948\n",
      "Model saved to: best_xgb_classifier_embeddings.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0072    0.0145    0.0096      1380\n",
      "           1     0.0531    0.2043    0.0843      1302\n",
      "           2     0.9816    0.9869    0.9842     27542\n",
      "           3     0.0662    0.0400    0.0499      3476\n",
      "           4     0.4051    0.0691    0.1180     18932\n",
      "           5     0.2545    0.1987    0.2232     13386\n",
      "           6     0.2947    0.4607    0.3595      9936\n",
      "           7     0.1325    0.0627    0.0851      7668\n",
      "           8     0.0187    0.0736    0.0298       856\n",
      "           9     0.0023    0.2551    0.0046        98\n",
      "\n",
      "    accuracy                         0.4342     84576\n",
      "   macro avg     0.2216    0.2366    0.1948     84576\n",
      "weighted avg     0.5011    0.4342    0.4360     84576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Embeddings Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='gpu'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_emb_train, y_emb_train, sample_weight=sample_weight_emb)\n",
    "        y_pred = xgb_clf.predict(X_emb_test)\n",
    "        f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_embeddings.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_embeddings.json\\n\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Embeddings Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [06:31<00:00, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 200, 'depth': 8, 'learning_rate': 0.05}\n",
      "Best Macro F1: 0.2001\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_embeddings.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1380\n",
      "           1     0.0555    0.4662    0.0992      1302\n",
      "           2     1.0000    0.9869    0.9934     27542\n",
      "           3     0.0743    0.0768    0.0755      3476\n",
      "           4     0.3804    0.1486    0.2137     18932\n",
      "           5     0.2734    0.1271    0.1736     13386\n",
      "           6     0.4720    0.2361    0.3148      9936\n",
      "           7     0.1302    0.0788    0.0982      7668\n",
      "           8     0.0149    0.2325    0.0280       856\n",
      "           9     0.0022    0.1429    0.0044        98\n",
      "\n",
      "    accuracy                         0.4225     84576\n",
      "   macro avg     0.2403    0.2496    0.2001     84576\n",
      "weighted avg     0.5254    0.4225    0.4496     84576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Embeddings Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_emb_train, y_emb_train)\n",
    "            y_pred = cat_clf.predict(X_emb_test)\n",
    "            f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for embeddings\n",
    "                best_model_path = \"best_catboost_classifier_embeddings.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:23<00:00,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 10}\n",
      "Best Macro F1: 0.1839\n",
      "Model saved to: best_et_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1380\n",
      "           1     0.0526    0.4793    0.0948      1302\n",
      "           2     1.0000    0.9869    0.9934     27542\n",
      "           3     0.0000    0.0000    0.0000      3476\n",
      "           4     0.3745    0.0678    0.1148     18932\n",
      "           5     0.2713    0.1780    0.2150     13386\n",
      "           6     0.2975    0.5061    0.3748      9936\n",
      "           7     0.1663    0.0104    0.0196      7668\n",
      "           8     0.0118    0.0689    0.0201       856\n",
      "           9     0.0030    0.3367    0.0060        98\n",
      "\n",
      "    accuracy                         0.4336     84576\n",
      "   macro avg     0.2177    0.2634    0.1839     84576\n",
      "weighted avg     0.5034    0.4336    0.4307     84576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = et_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Comparison Table\n",
    "\n",
    "Create a comparison table of all methods (Fused vs Raw features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\n",
      "===============================================================================================\n",
      "\n",
      "Instructions:\n",
      "1. Run all cells above to get F1 scores for each method\n",
      "2. Record the best Macro F1 score for each method\n",
      "3. Compare three approaches:\n",
      "   - Fused Features: Embeddings + Raw (Multimodal)\n",
      "   - Embeddings Only: Graph features only\n",
      "   - Raw Features: Traditional features only\n",
      "\n",
      "Expected format:\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Method               Fused (Emb+Raw)           Embeddings Only           Raw Only                 \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Random Forest        [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "XGBoost              [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "CatBoost             [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "Extra Trees          [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysis:\n",
      "- Fused features should show best performance (multimodal learning)\n",
      "- Embeddings capture structural/graph patterns\n",
      "- Raw features provide traditional statistical information\n",
      "- Compare to understand the contribution of each modality\n"
     ]
    }
   ],
   "source": [
    "# Create a summary comparison table\n",
    "# NOTE: After running all cells above, manually collect the F1 scores and create a comparison\n",
    "\n",
    "print(\"=\"*95)\n",
    "print(\"PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\")\n",
    "print(\"=\"*95)\n",
    "print(\"\\nInstructions:\")\n",
    "print(\"1. Run all cells above to get F1 scores for each method\")\n",
    "print(\"2. Record the best Macro F1 score for each method\")\n",
    "print(\"3. Compare three approaches:\")\n",
    "print(\"   - Fused Features: Embeddings + Raw (Multimodal)\")\n",
    "print(\"   - Embeddings Only: Graph features only\")\n",
    "print(\"   - Raw Features: Traditional features only\")\n",
    "print(\"\\nExpected format:\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Method':<20} {'Fused (Emb+Raw)':<25} {'Embeddings Only':<25} {'Raw Only':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Random Forest':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'XGBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'CatBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'Extra Trees':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"- Fused features should show best performance (multimodal learning)\")\n",
    "print(\"- Embeddings capture structural/graph patterns\")\n",
    "print(\"- Raw features provide traditional statistical information\")\n",
    "print(\"- Compare to understand the contribution of each modality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights & Interpretation\n",
    "\n",
    "After running all experiments, analyze the results to answer:\n",
    "\n",
    "1. **Which approach performs best overall?**\n",
    "   - Fused features (multimodal) should ideally outperform single modalities\n",
    "   - Compare the magnitude of improvements\n",
    "\n",
    "2. **What is the value of graph embeddings?**\n",
    "   - Compare Embeddings-only vs Raw-only to see if graph structure helps\n",
    "   - If embeddings alone beat raw features, graph learning is beneficial\n",
    "\n",
    "3. **Is multimodal fusion effective?**\n",
    "   - Compare Fused vs (Embeddings + Raw separately)\n",
    "   - Synergy should provide additional gains beyond individual modalities\n",
    "\n",
    "4. **Which classifier is most suitable?**\n",
    "   - Identify the best performing algorithm for each feature type\n",
    "   - Consider computational cost vs accuracy trade-offs\n",
    "\n",
    "5. **Feature contribution analysis:**\n",
    "   - If Fused ≈ Embeddings > Raw: Graph structure dominates\n",
    "   - If Fused ≈ Raw > Embeddings: Traditional features dominate\n",
    "   - If Fused > Both: True synergy from multimodal learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
