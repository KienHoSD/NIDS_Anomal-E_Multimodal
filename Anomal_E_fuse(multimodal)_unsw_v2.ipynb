{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "Hjc3iIihKLn-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from dgl.data import DGLDataset\n",
    "import dgl\n",
    "import time\n",
    "import networkx as nx\n",
    "import category_encoders as ce\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "from typing import *\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "SvWHb_BpKsLq"
   },
   "outputs": [],
   "source": [
    "file_name = \"NF-UNSW-NB15-v2.parquet\"\n",
    "data = pd.read_parquet(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "fqly1y-LMwYS",
    "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    2295222\n",
       "1      95053\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "3t4OREvSM33h"
   },
   "outputs": [],
   "source": [
    "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
    "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
    "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
    "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "bTtHq0XqNXxI"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUNIP-8zNkn9",
    "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Exploits', 'Generic', 'Fuzzers', 'Backdoor', 'DoS',\n",
       "       'Reconnaissance', 'Shellcode', 'Worms', 'Analysis'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Attack.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    95053\n",
       "0    45904\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = data.groupby(by='Attack').sample(frac=0.1, random_state=13)\n",
    "# scale attack flows to 0.4\n",
    "data_attack = data[data['Label'] == 1]\n",
    "data_benign = data[data['Label'] == 0].sample(frac=0.02, random_state=13)\n",
    "data = pd.concat([data_attack, data_benign], axis=0)\n",
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "lcfAP6ViOp-J",
    "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Analysis</th>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>...</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "      <td>2299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Backdoor</th>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>...</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "      <td>2169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>...</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "      <td>45904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS</th>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>...</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "      <td>5794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exploits</th>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>...</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "      <td>31551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuzzers</th>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>...</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "      <td>22310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generic</th>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>...</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "      <td>16560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reconnaissance</th>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>...</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "      <td>12779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shellcode</th>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>...</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Worms</th>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                IPV4_SRC_ADDR  IPV4_DST_ADDR  PROTOCOL  L7_PROTO  IN_BYTES  \\\n",
       "Attack                                                                       \n",
       "Analysis                 2299           2299      2299      2299      2299   \n",
       "Backdoor                 2169           2169      2169      2169      2169   \n",
       "Benign                  45904          45904     45904     45904     45904   \n",
       "DoS                      5794           5794      5794      5794      5794   \n",
       "Exploits                31551          31551     31551     31551     31551   \n",
       "Fuzzers                 22310          22310     22310     22310     22310   \n",
       "Generic                 16560          16560     16560     16560     16560   \n",
       "Reconnaissance          12779          12779     12779     12779     12779   \n",
       "Shellcode                1427           1427      1427      1427      1427   \n",
       "Worms                     164            164       164       164       164   \n",
       "\n",
       "                IN_PKTS  OUT_BYTES  OUT_PKTS  TCP_FLAGS  CLIENT_TCP_FLAGS  \\\n",
       "Attack                                                                      \n",
       "Analysis           2299       2299      2299       2299              2299   \n",
       "Backdoor           2169       2169      2169       2169              2169   \n",
       "Benign            45904      45904     45904      45904             45904   \n",
       "DoS                5794       5794      5794       5794              5794   \n",
       "Exploits          31551      31551     31551      31551             31551   \n",
       "Fuzzers           22310      22310     22310      22310             22310   \n",
       "Generic           16560      16560     16560      16560             16560   \n",
       "Reconnaissance    12779      12779     12779      12779             12779   \n",
       "Shellcode          1427       1427      1427       1427              1427   \n",
       "Worms               164        164       164        164               164   \n",
       "\n",
       "                ...  NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  \\\n",
       "Attack          ...                                                \n",
       "Analysis        ...                         2299            2299   \n",
       "Backdoor        ...                         2169            2169   \n",
       "Benign          ...                        45904           45904   \n",
       "DoS             ...                         5794            5794   \n",
       "Exploits        ...                        31551           31551   \n",
       "Fuzzers         ...                        22310           22310   \n",
       "Generic         ...                        16560           16560   \n",
       "Reconnaissance  ...                        12779           12779   \n",
       "Shellcode       ...                         1427            1427   \n",
       "Worms           ...                          164             164   \n",
       "\n",
       "                TCP_WIN_MAX_OUT  ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  \\\n",
       "Attack                                                                     \n",
       "Analysis                   2299       2299            2299          2299   \n",
       "Backdoor                   2169       2169            2169          2169   \n",
       "Benign                    45904      45904           45904         45904   \n",
       "DoS                        5794       5794            5794          5794   \n",
       "Exploits                  31551      31551           31551         31551   \n",
       "Fuzzers                   22310      22310           22310         22310   \n",
       "Generic                   16560      16560           16560         16560   \n",
       "Reconnaissance            12779      12779           12779         12779   \n",
       "Shellcode                  1427       1427            1427          1427   \n",
       "Worms                       164        164             164           164   \n",
       "\n",
       "                DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  Label  \n",
       "Attack                                                                       \n",
       "Analysis                  2299            2299                  2299   2299  \n",
       "Backdoor                  2169            2169                  2169   2169  \n",
       "Benign                   45904           45904                 45904  45904  \n",
       "DoS                       5794            5794                  5794   5794  \n",
       "Exploits                 31551           31551                 31551  31551  \n",
       "Fuzzers                  22310           22310                 22310  22310  \n",
       "Generic                  16560           16560                 16560  16560  \n",
       "Reconnaissance           12779           12779                 12779  12779  \n",
       "Shellcode                 1427            1427                  1427   1427  \n",
       "Worms                      164             164                   164    164  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=\"Attack\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "FqRx5xCPOuv8"
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Attack\", \"Label\"])\n",
    "y = data[[\"Attack\", \"Label\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=13, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "bPfakXplPGGx"
   },
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
    "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
    "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
    "                                  'FTP_COMMAND_RET_CODE'])\n",
    "encoder.fit(X_train, y_train.Label)\n",
    "\n",
    "# Transform on training set\n",
    "X_train = encoder.transform(X_train)\n",
    "\n",
    "# Transform on testing set\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "ibyOfV-8PouK"
   },
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "asDnsSIWPee0"
   },
   "outputs": [],
   "source": [
    "# (Modified)\n",
    "scaler = Normalizer()\n",
    "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
    "scaler.fit(X_train[cols_to_norm])\n",
    "\n",
    "# Transform on training set\n",
    "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
    "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
    "X_train['id'] = X_train.index\n",
    "\n",
    "# Transform on testing set\n",
    "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
    "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
    "X_test['id'] = X_test.index\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "hErQbsnrPluV",
    "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>h</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2303512</th>\n",
       "      <td>59.166.0.1</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>3.195953e-09</td>\n",
       "      <td>3.450790e-09</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.265974e-07</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>2.368973e-07</td>\n",
       "      <td>1.990142e-09</td>\n",
       "      <td>2.075070e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>2.815574e-10</td>\n",
       "      <td>2.839759e-10</td>\n",
       "      <td>3.516510e-09</td>\n",
       "      <td>3.516932e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.613093e-09</td>\n",
       "      <td>[3.1959528356221716e-09, 3.450790320527692e-09...</td>\n",
       "      <td>2303512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621997</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>149.171.126.10</td>\n",
       "      <td>5.996599e-08</td>\n",
       "      <td>6.474753e-08</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>1.159547e-06</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>7.730311e-07</td>\n",
       "      <td>9.627892e-08</td>\n",
       "      <td>9.149574e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>9.418255e-08</td>\n",
       "      <td>9.430046e-08</td>\n",
       "      <td>6.598064e-08</td>\n",
       "      <td>6.598856e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.779282e-08</td>\n",
       "      <td>[5.996599021772413e-08, 6.474753203418179e-08,...</td>\n",
       "      <td>1621997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353664</th>\n",
       "      <td>59.166.0.8</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>3.117918e-08</td>\n",
       "      <td>3.366533e-08</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>6.029037e-07</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>6.029037e-07</td>\n",
       "      <td>1.941549e-08</td>\n",
       "      <td>2.024404e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>9.562671e-09</td>\n",
       "      <td>1.052265e-08</td>\n",
       "      <td>3.430648e-08</td>\n",
       "      <td>3.431060e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.524873e-08</td>\n",
       "      <td>[3.117918247798922e-08, 3.366533444980148e-08,...</td>\n",
       "      <td>1353664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853118</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>149.171.126.19</td>\n",
       "      <td>5.141805e-07</td>\n",
       "      <td>4.985595e-07</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>1.488095e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.812618e-07</td>\n",
       "      <td>5.812618e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.571449e-07</td>\n",
       "      <td>5.571500e-07</td>\n",
       "      <td>5.080544e-07</td>\n",
       "      <td>5.081154e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.220084e-07</td>\n",
       "      <td>[5.141805153463133e-07, 4.985594668314381e-07,...</td>\n",
       "      <td>1853118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223489</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>149.171.126.19</td>\n",
       "      <td>1.331376e-07</td>\n",
       "      <td>2.111734e-07</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>2.145372e-06</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>1.716298e-06</td>\n",
       "      <td>2.137602e-07</td>\n",
       "      <td>2.031405e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>2.123919e-07</td>\n",
       "      <td>2.124644e-07</td>\n",
       "      <td>1.464914e-07</td>\n",
       "      <td>1.465090e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.505149e-07</td>\n",
       "      <td>[1.3313759613512936e-07, 2.1117340154866449e-0...</td>\n",
       "      <td>1223489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        IPV4_SRC_ADDR   IPV4_DST_ADDR      PROTOCOL      L7_PROTO  IN_BYTES  \\\n",
       "2303512    59.166.0.1   149.171.126.4  3.195953e-09  3.450790e-09  0.000014   \n",
       "1621997  175.45.176.0  149.171.126.10  5.996599e-08  6.474753e-08  0.000102   \n",
       "1353664    59.166.0.8   149.171.126.7  3.117918e-08  3.366533e-08  0.000052   \n",
       "1853118  175.45.176.0  149.171.126.19  5.141805e-07  4.985595e-07  0.000125   \n",
       "1223489  175.45.176.0  149.171.126.19  1.331376e-07  2.111734e-07  0.000102   \n",
       "\n",
       "              IN_PKTS  OUT_BYTES      OUT_PKTS     TCP_FLAGS  \\\n",
       "2303512  2.265974e-07   0.000124  2.368973e-07  1.990142e-09   \n",
       "1621997  1.159547e-06   0.000072  7.730311e-07  9.627892e-08   \n",
       "1353664  6.029037e-07   0.000114  6.029037e-07  1.941549e-08   \n",
       "1853118  1.488095e-06   0.000000  0.000000e+00  5.812618e-07   \n",
       "1223489  2.145372e-06   0.000072  1.716298e-06  2.137602e-07   \n",
       "\n",
       "         CLIENT_TCP_FLAGS  ...  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT     ICMP_TYPE  \\\n",
       "2303512      2.075070e-09  ...        0.000142         0.000075  2.815574e-10   \n",
       "1621997      9.149574e-08  ...        0.001583         0.001583  9.418255e-08   \n",
       "1353664      2.024404e-08  ...        0.000509         0.000509  9.562671e-09   \n",
       "1853118      5.812618e-07  ...        0.000000         0.000000  5.571449e-07   \n",
       "1223489      2.031405e-07  ...        0.003515         0.003515  2.123919e-07   \n",
       "\n",
       "         ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  \\\n",
       "2303512    2.839759e-10  3.516510e-09    3.516932e-09             0.0   \n",
       "1621997    9.430046e-08  6.598064e-08    6.598856e-08             0.0   \n",
       "1353664    1.052265e-08  3.430648e-08    3.431060e-08             0.0   \n",
       "1853118    5.571500e-07  5.080544e-07    5.081154e-07             0.0   \n",
       "1223489    2.124644e-07  1.464914e-07    1.465090e-07             0.0   \n",
       "\n",
       "         FTP_COMMAND_RET_CODE  \\\n",
       "2303512          3.613093e-09   \n",
       "1621997          6.779282e-08   \n",
       "1353664          3.524873e-08   \n",
       "1853118          5.220084e-07   \n",
       "1223489          1.505149e-07   \n",
       "\n",
       "                                                         h       id  \n",
       "2303512  [3.1959528356221716e-09, 3.450790320527692e-09...  2303512  \n",
       "1621997  [5.996599021772413e-08, 6.474753203418179e-08,...  1621997  \n",
       "1353664  [3.117918247798922e-08, 3.366533444980148e-08,...  1353664  \n",
       "1853118  [5.141805153463133e-07, 4.985594668314381e-07,...  1853118  \n",
       "1223489  [1.3313759613512936e-07, 2.1117340154866449e-0...  1223489  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "d_tLtK4WPtrF"
   },
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "lab_enc.fit(data[\"Attack\"])\n",
    "\n",
    "# Transform on training set\n",
    "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
    "\n",
    "# Transform on testing set\n",
    "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "8yaicjecP1fZ"
   },
   "outputs": [],
   "source": [
    "# Training graph (Modified)\n",
    "\n",
    "train['id'] = train.index\n",
    "\n",
    "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "           [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "train_g = train_g.to_directed()\n",
    "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
    "train_g.edata['h'].shape[1]])\n",
    "train_g.ndata['h'] = nfeat_weight\n",
    "\n",
    "test['id'] = test.index\n",
    "\n",
    "# Testing graph\n",
    "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "            [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "# print(test_g)\n",
    "test_g = test_g.to_directed()\n",
    "# print(test_g)\n",
    "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
    "test_g.edata['h'].shape[1]])\n",
    "test_g.ndata['h'] = nfeat_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "PUV6DgJ9QRaP"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import tqdm\n",
    "import gc\n",
    "\n",
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "      super(SAGELayer, self).__init__()\n",
    "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
    "      self.activation = F.relu\n",
    "      self.W_edge = nn.Linear(128 * 2, 256)\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      gain = nn.init.calculate_gain('relu')\n",
    "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "      return {'m':  edges.data['h']}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "      with g_dgl.local_scope():\n",
    "        g = g_dgl\n",
    "        g.ndata['h'] = nfeats\n",
    "        g.edata['h'] = efeats\n",
    "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "\n",
    "        # Compute edge embeddings\n",
    "        u, v = g.edges()\n",
    "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
    "        return g.ndata['h'], edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "_xo-3K4QRGqc"
   },
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
    "      super(SAGE, self).__init__()\n",
    "      self.layers = nn.ModuleList()\n",
    "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
    "\n",
    "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
    "      if corrupt:\n",
    "        e_perm = torch.randperm(g.number_of_edges())\n",
    "        #n_perm = torch.randperm(g.number_of_nodes())\n",
    "        efeats = efeats[e_perm]\n",
    "        #nfeats = nfeats[n_perm]\n",
    "      for i, layer in enumerate(self.layers):\n",
    "        #nfeats = layer(g, nfeats, efeats)\n",
    "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
    "      #return nfeats.sum(1)\n",
    "      return nfeats.sum(1), e_feats.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "6uuxRtLuRJQL"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "      super(Discriminator, self).__init__()\n",
    "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def uniform(self, size, tensor):\n",
    "      bound = 1.0 / math.sqrt(size)\n",
    "      if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      size = self.weight.size(0)\n",
    "      self.uniform(size, self.weight)\n",
    "\n",
    "    def forward(self, features, summary):\n",
    "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
    "      return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "ZPbVjlCyRUco"
   },
   "outputs": [],
   "source": [
    "class DGI(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
    "      super(DGI, self).__init__()\n",
    "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
    "      #self.discriminator = Discriminator(128)\n",
    "      self.discriminator = Discriminator(256)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "\n",
    "      positive = positive[1]\n",
    "      negative = negative[1]\n",
    "\n",
    "      summary = torch.sigmoid(positive.mean(dim=0))\n",
    "\n",
    "      positive = self.discriminator(positive, summary)\n",
    "      negative = self.discriminator(negative, summary)\n",
    "\n",
    "      l1 = self.loss(positive, torch.ones_like(positive))\n",
    "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
    "\n",
    "      return l1 + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "sKnfpWFMR19u"
   },
   "outputs": [],
   "source": [
    "ndim_in = train_g.ndata['h'].shape[1]\n",
    "hidden_features = 128\n",
    "ndim_out = 128\n",
    "num_layers = 1\n",
    "edim = train_g.edata['h'].shape[1]\n",
    "learning_rate = 1e-3\n",
    "epochs = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "aSl_9qY8SbA0"
   },
   "outputs": [],
   "source": [
    "dgi = DGI(ndim_in,\n",
    "    ndim_out,\n",
    "    edim,\n",
    "    F.relu)\n",
    "\n",
    "dgi = dgi.to('cuda')\n",
    "\n",
    "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
    "                lr=1e-3,\n",
    "                weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "9K6_cOiWSdJA"
   },
   "outputs": [],
   "source": [
    "# Format node and edge features for E-GraphSAGE\n",
    "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
    "                                   (train_g.ndata['h'].shape[0], 1,\n",
    "                                    train_g.ndata['h'].shape[1]))\n",
    "\n",
    "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
    "                                   (train_g.edata['h'].shape[0], 1,\n",
    "                                    train_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "O44auIyWSexg"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "train_g = train_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "gZtafIdxSheN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Time(s) nan | Loss 1.4068 | ETputs(KTEPS) nan\n",
      "Epoch 00050 | Time(s) 0.0984 | Loss 1.3912 | ETputs(KTEPS) 2005.47\n",
      "Epoch 00100 | Time(s) 0.0996 | Loss 1.3270 | ETputs(KTEPS) 1980.80\n",
      "Epoch 00150 | Time(s) 0.1001 | Loss 1.0624 | ETputs(KTEPS) 1971.90\n",
      "Epoch 00200 | Time(s) 0.1001 | Loss 0.2465 | ETputs(KTEPS) 1970.89\n",
      "Epoch 00250 | Time(s) 0.1002 | Loss 0.0595 | ETputs(KTEPS) 1968.54\n",
      "Epoch 00300 | Time(s) 0.1003 | Loss 0.0322 | ETputs(KTEPS) 1967.59\n",
      "Epoch 00350 | Time(s) 0.1002 | Loss 0.0219 | ETputs(KTEPS) 1968.73\n",
      "Epoch 00400 | Time(s) 0.1002 | Loss 0.0153 | ETputs(KTEPS) 1969.60\n",
      "Epoch 00450 | Time(s) 0.1002 | Loss 0.0112 | ETputs(KTEPS) 1970.01\n",
      "Epoch 00500 | Time(s) 0.1002 | Loss 0.0091 | ETputs(KTEPS) 1969.92\n",
      "Epoch 00550 | Time(s) 0.1001 | Loss 0.0078 | ETputs(KTEPS) 1970.50\n",
      "Epoch 00600 | Time(s) 0.1001 | Loss 0.0056 | ETputs(KTEPS) 1970.79\n",
      "Epoch 00650 | Time(s) 0.1001 | Loss 0.0061 | ETputs(KTEPS) 1971.26\n",
      "Epoch 00700 | Time(s) 0.1001 | Loss 0.0041 | ETputs(KTEPS) 1971.41\n",
      "Epoch 00750 | Time(s) 0.1001 | Loss 0.0051 | ETputs(KTEPS) 1971.75\n",
      "Epoch 00800 | Time(s) 0.1001 | Loss 0.0034 | ETputs(KTEPS) 1972.03\n",
      "Epoch 00850 | Time(s) 0.1001 | Loss 0.0035 | ETputs(KTEPS) 1972.27\n",
      "Epoch 00900 | Time(s) 0.1000 | Loss 0.0026 | ETputs(KTEPS) 1972.44\n",
      "Epoch 00950 | Time(s) 0.1000 | Loss 0.0025 | ETputs(KTEPS) 1972.61\n",
      "Epoch 01000 | Time(s) 0.1000 | Loss 0.0029 | ETputs(KTEPS) 1972.65\n",
      "Epoch 01050 | Time(s) 0.1000 | Loss 0.0025 | ETputs(KTEPS) 1972.78\n",
      "Epoch 01100 | Time(s) 0.1000 | Loss 0.0029 | ETputs(KTEPS) 1972.88\n",
      "Epoch 01150 | Time(s) 0.1000 | Loss 0.0037 | ETputs(KTEPS) 1972.96\n",
      "Epoch 01200 | Time(s) 0.1000 | Loss 0.0017 | ETputs(KTEPS) 1973.14\n",
      "Epoch 01250 | Time(s) 0.1000 | Loss 0.0024 | ETputs(KTEPS) 1973.18\n",
      "Epoch 01300 | Time(s) 0.1000 | Loss 0.0019 | ETputs(KTEPS) 1973.25\n",
      "Epoch 01350 | Time(s) 0.1000 | Loss 0.0022 | ETputs(KTEPS) 1973.38\n",
      "Epoch 01400 | Time(s) 0.1000 | Loss 0.0021 | ETputs(KTEPS) 1973.43\n",
      "Epoch 01450 | Time(s) 0.1000 | Loss 0.0018 | ETputs(KTEPS) 1973.51\n",
      "Epoch 01500 | Time(s) 0.1000 | Loss 0.0012 | ETputs(KTEPS) 1973.58\n",
      "Epoch 01550 | Time(s) 0.1000 | Loss 0.0023 | ETputs(KTEPS) 1973.64\n",
      "Epoch 01600 | Time(s) 0.1000 | Loss 0.0013 | ETputs(KTEPS) 1973.70\n",
      "Epoch 01650 | Time(s) 0.1000 | Loss 0.0017 | ETputs(KTEPS) 1973.76\n",
      "Epoch 01700 | Time(s) 0.1000 | Loss 0.0008 | ETputs(KTEPS) 1973.82\n",
      "Epoch 01750 | Time(s) 0.1000 | Loss 0.0009 | ETputs(KTEPS) 1973.87\n",
      "Epoch 01800 | Time(s) 0.1000 | Loss 0.0014 | ETputs(KTEPS) 1973.92\n",
      "Epoch 01850 | Time(s) 0.1000 | Loss 0.0033 | ETputs(KTEPS) 1973.87\n",
      "Epoch 01900 | Time(s) 0.1000 | Loss 0.0022 | ETputs(KTEPS) 1973.81\n",
      "Epoch 01950 | Time(s) 0.1000 | Loss 0.0008 | ETputs(KTEPS) 1973.85\n",
      "Epoch 02000 | Time(s) 0.1000 | Loss 0.0027 | ETputs(KTEPS) 1973.90\n",
      "Epoch 02050 | Time(s) 0.1000 | Loss 0.0037 | ETputs(KTEPS) 1973.93\n",
      "Epoch 02100 | Time(s) 0.1000 | Loss 0.0019 | ETputs(KTEPS) 1973.98\n",
      "Epoch 02150 | Time(s) 0.1000 | Loss 0.0017 | ETputs(KTEPS) 1974.02\n",
      "Epoch 02200 | Time(s) 0.1000 | Loss 0.0015 | ETputs(KTEPS) 1974.05\n",
      "Epoch 02250 | Time(s) 0.1000 | Loss 0.0012 | ETputs(KTEPS) 1974.08\n",
      "Epoch 02300 | Time(s) 0.1000 | Loss 0.0019 | ETputs(KTEPS) 1974.13\n",
      "Epoch 02350 | Time(s) 0.1000 | Loss 0.0022 | ETputs(KTEPS) 1974.15\n",
      "Epoch 02400 | Time(s) 0.1000 | Loss 0.0010 | ETputs(KTEPS) 1974.18\n",
      "Epoch 02450 | Time(s) 0.1000 | Loss 0.0004 | ETputs(KTEPS) 1974.21\n",
      "Epoch 02500 | Time(s) 0.1000 | Loss 0.0018 | ETputs(KTEPS) 1974.24\n",
      "Epoch 02550 | Time(s) 0.1000 | Loss 0.0012 | ETputs(KTEPS) 1974.26\n",
      "Epoch 02600 | Time(s) 0.1000 | Loss 0.0021 | ETputs(KTEPS) 1974.29\n",
      "Epoch 02650 | Time(s) 0.1000 | Loss 0.0031 | ETputs(KTEPS) 1974.31\n",
      "Epoch 02700 | Time(s) 0.1000 | Loss 0.0026 | ETputs(KTEPS) 1974.34\n",
      "Epoch 02750 | Time(s) 0.1000 | Loss 0.0022 | ETputs(KTEPS) 1974.35\n",
      "Epoch 02800 | Time(s) 0.0999 | Loss 0.0015 | ETputs(KTEPS) 1974.38\n",
      "Epoch 02850 | Time(s) 0.0999 | Loss 0.0017 | ETputs(KTEPS) 1974.40\n",
      "Epoch 02900 | Time(s) 0.0999 | Loss 0.0007 | ETputs(KTEPS) 1974.43\n",
      "Epoch 02950 | Time(s) 0.0999 | Loss 0.0014 | ETputs(KTEPS) 1974.45\n",
      "Epoch 03000 | Time(s) 0.0999 | Loss 0.0036 | ETputs(KTEPS) 1974.46\n",
      "Epoch 03050 | Time(s) 0.0999 | Loss 0.0013 | ETputs(KTEPS) 1974.42\n",
      "Epoch 03100 | Time(s) 0.0999 | Loss 0.0006 | ETputs(KTEPS) 1974.43\n",
      "Epoch 03150 | Time(s) 0.0999 | Loss 0.0010 | ETputs(KTEPS) 1974.45\n",
      "Epoch 03200 | Time(s) 0.0999 | Loss 0.0016 | ETputs(KTEPS) 1974.47\n",
      "Epoch 03250 | Time(s) 0.0999 | Loss 0.0017 | ETputs(KTEPS) 1974.48\n",
      "Epoch 03300 | Time(s) 0.0999 | Loss 0.0021 | ETputs(KTEPS) 1974.50\n",
      "Epoch 03350 | Time(s) 0.0999 | Loss 0.0008 | ETputs(KTEPS) 1974.51\n",
      "Epoch 03400 | Time(s) 0.0999 | Loss 0.0003 | ETputs(KTEPS) 1974.53\n",
      "Epoch 03450 | Time(s) 0.0999 | Loss 0.0014 | ETputs(KTEPS) 1974.54\n",
      "Epoch 03500 | Time(s) 0.0999 | Loss 0.0003 | ETputs(KTEPS) 1974.56\n",
      "Epoch 03550 | Time(s) 0.0999 | Loss 0.0026 | ETputs(KTEPS) 1974.57\n",
      "Epoch 03600 | Time(s) 0.0999 | Loss 0.0003 | ETputs(KTEPS) 1974.59\n",
      "Epoch 03650 | Time(s) 0.0999 | Loss 0.0014 | ETputs(KTEPS) 1974.59\n",
      "Epoch 03700 | Time(s) 0.0999 | Loss 0.0017 | ETputs(KTEPS) 1974.61\n",
      "Epoch 03750 | Time(s) 0.0999 | Loss 0.0017 | ETputs(KTEPS) 1974.62\n",
      "Epoch 03800 | Time(s) 0.0999 | Loss 0.0012 | ETputs(KTEPS) 1974.63\n",
      "Epoch 03850 | Time(s) 0.0999 | Loss 0.0004 | ETputs(KTEPS) 1974.64\n",
      "Epoch 03900 | Time(s) 0.0999 | Loss 0.0020 | ETputs(KTEPS) 1974.66\n",
      "Epoch 03950 | Time(s) 0.0999 | Loss 0.0017 | ETputs(KTEPS) 1974.66\n"
     ]
    }
   ],
   "source": [
    "cnt_wait = 0\n",
    "best = 1e9\n",
    "best_t = 0\n",
    "dur = []\n",
    "node_features = train_g.ndata['h'] \n",
    "edge_features = train_g.edata['h']\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    dgi.train()\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    dgi_optimizer.zero_grad()\n",
    "    loss = dgi(train_g, node_features, edge_features)\n",
    "    loss.backward()\n",
    "    dgi_optimizer.step()\n",
    "\n",
    "    if loss < best:\n",
    "        best = loss\n",
    "        best_t = epoch\n",
    "        cnt_wait = 0\n",
    "        torch.save(dgi.state_dict(), 'best_dgi_UNSW_v2.pkl')\n",
    "    else:\n",
    "        cnt_wait += 1\n",
    "\n",
    "  # if cnt_wait == patience:\n",
    "  #     print('Early stopping!')\n",
    "  #     break\n",
    "\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "\n",
    "        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "            \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
    "              loss.item(),\n",
    "              train_g.num_edges() / np.mean(dur) / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "RZ2HAQDAF-4c",
    "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgi.load_state_dict(torch.load('best_dgi_UNSW_v2.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "6Ek16GkRStKP"
   },
   "outputs": [],
   "source": [
    "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
    "training_emb = training_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "-FwaBlOdS4ep"
   },
   "outputs": [],
   "source": [
    "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
    "                                   (test_g.ndata['h'].shape[0], 1,\n",
    "                                    test_g.ndata['h'].shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
    "                                   (test_g.edata['h'].shape[0], 1,\n",
    "                                    test_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "SBa-rdivS6cQ"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "test_g = test_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "W12WLjslS-kx"
   },
   "outputs": [],
   "source": [
    "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
    "testing_emb = testing_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal (Fusion) Learning\n",
    "\n",
    "df_train = pd.DataFrame(training_emb,)\n",
    "# map the id to the original data\n",
    "df_train['id'] = train_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "df_raw_train = pd.DataFrame(X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_fuse_train = pd.merge(df_train, df_raw_train, on='id', how='left')\n",
    "df_fuse_train = df_fuse_train.drop(columns=[\"id\"])\n",
    "df_fuse_train[\"Attacks\"] = train_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
    "\n",
    "df_test = pd.DataFrame(testing_emb,)\n",
    "# map the id to the original data\n",
    "df_test['id'] = test_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "df_raw_test = pd.DataFrame(X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_raw_test = pd.merge(df_test, df_raw_test, on='id', how='left')\n",
    "df_fuse_test = df_raw_test.drop(columns=[\"id\"])\n",
    "df_fuse_test[\"Attacks\"] = test_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ScEk1y_TzzX"
   },
   "source": [
    "# Embeddings CBLOF  Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "ZYABKzdrTGas"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pyod.models.cblof import CBLOF\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_fuse_train_samples = df_fuse_train[df_fuse_train.Label == 0].drop(columns=[\"Label\", \"Attacks\"])\n",
    "normal_fuse_train_samples = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"])\n",
    "\n",
    "fuse_train_labels = df_fuse_train[\"Label\"]\n",
    "fuse_test_labels = df_fuse_test[\"Label\"]\n",
    "\n",
    "fuse_test_samples = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_512_TO_1024_BYTES</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.011583</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>-0.010781</td>\n",
       "      <td>-0.001299</td>\n",
       "      <td>-0.100072</td>\n",
       "      <td>0.026116</td>\n",
       "      <td>-0.018159</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>-0.029538</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.370473e-08</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>2.356220e-12</td>\n",
       "      <td>2.356220e-12</td>\n",
       "      <td>1.233329e-10</td>\n",
       "      <td>1.233338e-10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.335599e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.011583</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>-0.010781</td>\n",
       "      <td>-0.001299</td>\n",
       "      <td>-0.100072</td>\n",
       "      <td>0.026116</td>\n",
       "      <td>-0.018159</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>-0.029538</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.092057e-08</td>\n",
       "      <td>3.094159e-08</td>\n",
       "      <td>2.158972e-08</td>\n",
       "      <td>3.577436e-10</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>2.425808e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.011583</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>-0.010781</td>\n",
       "      <td>-0.001299</td>\n",
       "      <td>-0.100072</td>\n",
       "      <td>0.026116</td>\n",
       "      <td>-0.018159</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>-0.029538</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.155203e-08</td>\n",
       "      <td>1.155988e-08</td>\n",
       "      <td>8.368929e-09</td>\n",
       "      <td>8.368988e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.062899e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.011583</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>-0.010781</td>\n",
       "      <td>-0.001299</td>\n",
       "      <td>-0.100072</td>\n",
       "      <td>0.026116</td>\n",
       "      <td>-0.018159</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>-0.029538</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.381315e-08</td>\n",
       "      <td>3.383613e-08</td>\n",
       "      <td>2.360940e-08</td>\n",
       "      <td>3.912099e-10</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>2.652738e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.011583</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>-0.010781</td>\n",
       "      <td>-0.001299</td>\n",
       "      <td>-0.100072</td>\n",
       "      <td>0.026116</td>\n",
       "      <td>-0.018159</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>-0.029538</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>...</td>\n",
       "      <td>9.504689e-09</td>\n",
       "      <td>8.554220e-08</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>2.206288e-12</td>\n",
       "      <td>2.206288e-12</td>\n",
       "      <td>6.535423e-11</td>\n",
       "      <td>6.535469e-11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.077354e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143413</th>\n",
       "      <td>0.016703</td>\n",
       "      <td>0.058107</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>-0.003440</td>\n",
       "      <td>-0.063689</td>\n",
       "      <td>0.158615</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.061308</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.006514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.326019e-08</td>\n",
       "      <td>1.326921e-08</td>\n",
       "      <td>9.606417e-09</td>\n",
       "      <td>9.606485e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.040300e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143414</th>\n",
       "      <td>0.016703</td>\n",
       "      <td>0.058107</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>-0.003440</td>\n",
       "      <td>-0.063689</td>\n",
       "      <td>0.158615</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.061308</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.006514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.308516e-08</td>\n",
       "      <td>1.309405e-08</td>\n",
       "      <td>9.479610e-09</td>\n",
       "      <td>9.479677e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.026568e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143415</th>\n",
       "      <td>0.016703</td>\n",
       "      <td>0.058107</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>-0.003440</td>\n",
       "      <td>-0.063689</td>\n",
       "      <td>0.158615</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.061308</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.006514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.326024e-08</td>\n",
       "      <td>1.326926e-08</td>\n",
       "      <td>9.606453e-09</td>\n",
       "      <td>9.606521e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.040304e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143416</th>\n",
       "      <td>0.016703</td>\n",
       "      <td>0.058107</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>-0.003440</td>\n",
       "      <td>-0.063689</td>\n",
       "      <td>0.158615</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.061308</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.006514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.326020e-08</td>\n",
       "      <td>1.326921e-08</td>\n",
       "      <td>9.606419e-09</td>\n",
       "      <td>9.606487e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.040300e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143417</th>\n",
       "      <td>0.022807</td>\n",
       "      <td>0.049973</td>\n",
       "      <td>-0.004680</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>-0.069899</td>\n",
       "      <td>0.141014</td>\n",
       "      <td>-0.006232</td>\n",
       "      <td>0.074734</td>\n",
       "      <td>0.026013</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.319987e-08</td>\n",
       "      <td>1.320884e-08</td>\n",
       "      <td>9.562716e-09</td>\n",
       "      <td>9.562784e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.035568e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143418 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.011583  0.019045 -0.010781 -0.001299 -0.100072  0.026116 -0.018159   \n",
       "1      -0.011583  0.019045 -0.010781 -0.001299 -0.100072  0.026116 -0.018159   \n",
       "2      -0.011583  0.019045 -0.010781 -0.001299 -0.100072  0.026116 -0.018159   \n",
       "3      -0.011583  0.019045 -0.010781 -0.001299 -0.100072  0.026116 -0.018159   \n",
       "4      -0.011583  0.019045 -0.010781 -0.001299 -0.100072  0.026116 -0.018159   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "143413  0.016703  0.058107  0.000909 -0.003440 -0.063689  0.158615  0.000451   \n",
       "143414  0.016703  0.058107  0.000909 -0.003440 -0.063689  0.158615  0.000451   \n",
       "143415  0.016703  0.058107  0.000909 -0.003440 -0.063689  0.158615  0.000451   \n",
       "143416  0.016703  0.058107  0.000909 -0.003440 -0.063689  0.158615  0.000451   \n",
       "143417  0.022807  0.049973 -0.004680  0.002263 -0.069899  0.141014 -0.006232   \n",
       "\n",
       "               7         8         9  ...  NUM_PKTS_512_TO_1024_BYTES  \\\n",
       "0       0.024632 -0.029538  0.013363  ...                0.000000e+00   \n",
       "1       0.024632 -0.029538  0.013363  ...                0.000000e+00   \n",
       "2       0.024632 -0.029538  0.013363  ...                0.000000e+00   \n",
       "3       0.024632 -0.029538  0.013363  ...                0.000000e+00   \n",
       "4       0.024632 -0.029538  0.013363  ...                9.504689e-09   \n",
       "...          ...       ...       ...  ...                         ...   \n",
       "143413  0.061308 -0.000357 -0.006514  ...                0.000000e+00   \n",
       "143414  0.061308 -0.000357 -0.006514  ...                0.000000e+00   \n",
       "143415  0.061308 -0.000357 -0.006514  ...                0.000000e+00   \n",
       "143416  0.061308 -0.000357 -0.006514  ...                0.000000e+00   \n",
       "143417  0.074734  0.026013 -0.000335  ...                0.000000e+00   \n",
       "\n",
       "        NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
       "0                      8.370473e-08        0.000108         0.000043   \n",
       "1                      0.000000e+00        0.000000         0.000000   \n",
       "2                      0.000000e+00        0.000000         0.000000   \n",
       "3                      0.000000e+00        0.000000         0.000000   \n",
       "4                      8.554220e-08        0.000089         0.000023   \n",
       "...                             ...             ...              ...   \n",
       "143413                 0.000000e+00        0.000000         0.000000   \n",
       "143414                 0.000000e+00        0.000000         0.000000   \n",
       "143415                 0.000000e+00        0.000000         0.000000   \n",
       "143416                 0.000000e+00        0.000000         0.000000   \n",
       "143417                 0.000000e+00        0.001354         0.000000   \n",
       "\n",
       "           ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "0       2.356220e-12    2.356220e-12  1.233329e-10    1.233338e-10   \n",
       "1       3.092057e-08    3.094159e-08  2.158972e-08    3.577436e-10   \n",
       "2       1.155203e-08    1.155988e-08  8.368929e-09    8.368988e-09   \n",
       "3       3.381315e-08    3.383613e-08  2.360940e-08    3.912099e-10   \n",
       "4       2.206288e-12    2.206288e-12  6.535423e-11    6.535469e-11   \n",
       "...              ...             ...           ...             ...   \n",
       "143413  1.326019e-08    1.326921e-08  9.606417e-09    9.606485e-09   \n",
       "143414  1.308516e-08    1.309405e-08  9.479610e-09    9.479677e-09   \n",
       "143415  1.326024e-08    1.326926e-08  9.606453e-09    9.606521e-09   \n",
       "143416  1.326020e-08    1.326921e-08  9.606419e-09    9.606487e-09   \n",
       "143417  1.319987e-08    1.320884e-08  9.562716e-09    9.562784e-09   \n",
       "\n",
       "        DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \n",
       "0             0.000000          1.335599e-10  \n",
       "1             0.000033          2.425808e-08  \n",
       "2             0.000000          9.062899e-09  \n",
       "3             0.000036          2.652738e-08  \n",
       "4             0.000000          7.077354e-11  \n",
       "...                ...                   ...  \n",
       "143413        0.000000          1.040300e-08  \n",
       "143414        0.000000          1.026568e-08  \n",
       "143415        0.000000          1.040304e-08  \n",
       "143416        0.000000          1.040300e-08  \n",
       "143417        0.000000          1.035568e-08  \n",
       "\n",
       "[143418 rows x 295 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuse_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "62BUDLtO4mla"
   },
   "outputs": [],
   "source": [
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2i48uLj74mla",
    "outputId": "a0dd33ee-824d-4328-a960-e656e3aaf0ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [02:41<02:37,  9.86s/it]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fa0da177850>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kienho/.local/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      " 53%|█████▎    | 16/30 [03:03<02:26, 10.45s/it]"
     ]
    }
   ],
   "source": [
    "n_est = [5,6,7,9,10] # cant be lower than 5 or 4\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    try:\n",
    "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
    "        clf_if.fit(benign_fuse_train_samples)\n",
    "    except Exception as e:\n",
    "        print(n_est)\n",
    "        continue\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rK-Rng9q4mla",
    "outputId": "1796db22-cfb8-4bf8-9004-6420c08c3399"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:13<00:00, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'con': 0.2}\n",
      "0.7246850923456903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9713    0.8682    0.9168    374702\n",
      "           1     0.4050    0.7773    0.5325     43236\n",
      "\n",
      "    accuracy                         0.8588    417938\n",
      "   macro avg     0.6881    0.8228    0.7247    417938\n",
      "weighted avg     0.9127    0.8588    0.8771    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,6,7,9,10]\n",
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    try:\n",
    "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
    "        clf_if.fit(normal_fuse_train_samples)\n",
    "    except Exception as e:\n",
    "        print(n_est)\n",
    "        continue\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nd0-H7UT4mlc"
   },
   "outputs": [],
   "source": [
    "# HBOS  Embeddings+Raw (Multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDquxErU4mld"
   },
   "outputs": [],
   "source": [
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLBIT-Rc4mld",
    "outputId": "8162929e-4879-40e2-a040-afc57eafe7c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [05:45<00:00,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'con': 0.05}\n",
      "0.8471039149382792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9177    0.9571    374702\n",
      "           1     0.5837    1.0000    0.7371     43236\n",
      "\n",
      "    accuracy                         0.9262    417938\n",
      "   macro avg     0.7918    0.9588    0.8471    417938\n",
      "weighted avg     0.9569    0.9262    0.9343    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "n_est = [5,10,15,20,25,30]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    \n",
    "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDcX0mma4mld",
    "outputId": "a2b64cfc-d413-4ba0-9f24-b4935343c315"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [06:05<00:00, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'con': 0.1}\n",
      "0.8471039149382792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9177    0.9571    374702\n",
      "           1     0.5837    1.0000    0.7371     43236\n",
      "\n",
      "    accuracy                         0.9262    417938\n",
      "   macro avg     0.7918    0.9588    0.8471    417938\n",
      "weighted avg     0.9569    0.9262    0.9343    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,10,15,20,25,30]\n",
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    \n",
    "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbDOqrcy4mle"
   },
   "outputs": [],
   "source": [
    "##  PCA  Emb+Raw (Multimodal/Fusion) Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nga82Fw_4mle",
    "outputId": "0fe52043-af21-45c1-a404-040ab5845efc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [05:07<00:00,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'con': 0.1}\n",
      "0.8207887532486517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8987    0.9466    374702\n",
      "           1     0.5325    1.0000    0.6949     43236\n",
      "\n",
      "    accuracy                         0.9092    417938\n",
      "   macro avg     0.7662    0.9493    0.8208    417938\n",
      "weighted avg     0.9516    0.9092    0.9206    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.pca import PCA\n",
    "n_est = [5,10,15,20,25,30]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = PCA(n_components=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sg6AcAUW4mlf",
    "outputId": "a9949458-96cf-44dc-b4f6-c73458cb2719"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [05:49<00:00,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 15, 'con': 0.2}\n",
      "0.8085873162698853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8893    0.9414    374702\n",
      "           1     0.5103    1.0000    0.6758     43236\n",
      "\n",
      "    accuracy                         0.9007    417938\n",
      "   macro avg     0.7552    0.9446    0.8086    417938\n",
      "weighted avg     0.9493    0.9007    0.9139    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,10,15,20,25,30]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = PCA(n_components=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yi8SO3tL4mlg"
   },
   "outputs": [],
   "source": [
    "##  IF  Emb+Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(benign_fuse_train_samples.columns)):\n",
    "    benign_fuse_train_samples.rename(columns={benign_fuse_train_samples.columns[i]: f\"feature {i}\"}, inplace=True)\n",
    "\n",
    "for i in range(len(normal_fuse_train_samples.columns)):\n",
    "    normal_fuse_train_samples.rename(columns={normal_fuse_train_samples.columns[i]: f\"feature {i}\"}, inplace=True)\n",
    "\n",
    "for i in range(len(fuse_test_samples.columns)):\n",
    "    fuse_test_samples.rename(columns={fuse_test_samples.columns[i]: f\"feature {i}\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9D0m4vb04mlg",
    "outputId": "bd5a55e6-ac70-4943-9b28-92474b5fb9e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "  4%|▍         | 1/24 [00:02<00:54,  2.36s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "  8%|▊         | 2/24 [00:04<00:51,  2.34s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 12%|█▎        | 3/24 [00:07<00:48,  2.33s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 17%|█▋        | 4/24 [00:09<00:46,  2.31s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 21%|██        | 5/24 [00:11<00:44,  2.32s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 25%|██▌       | 6/24 [00:13<00:40,  2.27s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 29%|██▉       | 7/24 [00:16<00:43,  2.56s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 33%|███▎      | 8/24 [00:20<00:44,  2.77s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 38%|███▊      | 9/24 [00:23<00:43,  2.90s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 42%|████▏     | 10/24 [00:26<00:41,  2.99s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 46%|████▌     | 11/24 [00:29<00:39,  3.06s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 50%|█████     | 12/24 [00:32<00:37,  3.11s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 54%|█████▍    | 13/24 [00:38<00:41,  3.78s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 58%|█████▊    | 14/24 [00:43<00:42,  4.22s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 62%|██████▎   | 15/24 [00:48<00:40,  4.50s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 67%|██████▋   | 16/24 [00:53<00:36,  4.58s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 71%|███████   | 17/24 [00:58<00:33,  4.81s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 75%|███████▌  | 18/24 [01:03<00:29,  4.91s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 79%|███████▉  | 19/24 [01:10<00:27,  5.50s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 83%|████████▎ | 20/24 [01:17<00:23,  5.85s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 21/24 [01:24<00:18,  6.10s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 22/24 [01:30<00:12,  6.29s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 23/24 [01:37<00:06,  6.42s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "100%|██████████| 24/24 [01:44<00:00,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50, 'con': 0.1}\n",
      "0.820368662501618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8984    0.9465    374702\n",
      "           1     0.5317    1.0000    0.6943     43236\n",
      "\n",
      "    accuracy                         0.9089    417938\n",
      "   macro avg     0.7659    0.9492    0.8204    417938\n",
      "weighted avg     0.9516    0.9089    0.9204    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "n_est = [20, 50, 100, 150]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples.to_numpy())\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCj-3u4t4mlg",
    "outputId": "5f6b1720-9662-4704-ba96-dd57ee32a900"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:52<00:00,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 150, 'con': 0.2}\n",
      "0.802806141381684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9991    0.8861    0.9392    374702\n",
      "           1     0.5015    0.9928    0.6664     43236\n",
      "\n",
      "    accuracy                         0.8972    417938\n",
      "   macro avg     0.7503    0.9395    0.8028    417938\n",
      "weighted avg     0.9476    0.8972    0.9110    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "n_est = [20, 50, 100, 150]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised attack classification (Fusion)\n",
    "\n",
    "We now train a supervised classifier on the fused features to predict multi-class attack labels:\n",
    "- Features: embeddings + raw numeric features from `df_fuse_train`/`df_fuse_test` (without `Label`, `Attacks`).\n",
    "- Target: `Attacks` (encoded integer classes from earlier `LabelEncoder`).\n",
    "- Model: HistGradientBoostingClassifier (fast, strong on tabular data). Class imbalance handled via per-sample weights.\n",
    "- Metrics: macro F1, per-class report, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare supervised train/test for attack classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.utils import class_weight\n",
    "import pickle\n",
    "\n",
    "# Build train features/targets from already prepared fused DataFrames\n",
    "X_sup_train = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_sup_test = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights to mitigate class imbalance on training set\n",
    "classes = np.unique(y_sup_train)\n",
    "class_w = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes, y=y_sup_train\n",
    ")\n",
    "class_to_w = {c: w for c, w in zip(classes, class_w)}\n",
    "sample_weight = y_sup_train.map(class_to_w).values\n",
    "\n",
    "# Feature names to all str\n",
    "X_sup_train.columns = X_sup_train.columns.map(str)\n",
    "X_sup_test.columns = X_sup_test.columns.map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Methods (Fused Features)\n",
    "\n",
    "Now we'll compare multiple classification algorithms on the fused features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:25<00:00, 16.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 20}\n",
      "Best Macro F1: 0.5047\n",
      "Model saved to: best_rf_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3207    0.0551    0.0940      1380\n",
      "           1     0.1572    0.1966    0.1747      1302\n",
      "           2     0.9999    0.9919    0.9959     27542\n",
      "           3     0.3168    0.1343    0.1887      3476\n",
      "           4     0.8013    0.8095    0.8054     18932\n",
      "           5     0.8225    0.7663    0.7934     13386\n",
      "           6     0.9524    0.5997    0.7360      9936\n",
      "           7     0.7150    0.7930    0.7520      7668\n",
      "           8     0.0656    0.5724    0.1176       856\n",
      "           9     0.4268    0.3571    0.3889        98\n",
      "\n",
      "    accuracy                         0.7835     84576\n",
      "   macro avg     0.5578    0.5276    0.5047     84576\n",
      "weighted avg     0.8337    0.7835    0.7984     84576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with Grid Search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            rf_clf = RandomForestClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            rf_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_rf = rf_clf.predict(X_sup_test)\n",
    "            rf_f1 = f1_score(y_sup_test, y_pred_rf, average='macro')\n",
    "            \n",
    "            if rf_f1 > score:\n",
    "                score = rf_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = rf_clf\n",
    "                # Save best model\n",
    "                with open('best_rf_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(rf_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_rf_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Random Forest: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:58:50] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "100%|██████████| 27/27 [25:12<00:00, 56.02s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.6648\n",
      "Model saved to: best_xgb_classifier_fused.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1573    0.3072    0.2081      1380\n",
      "           1     0.1482    0.5753    0.2356      1302\n",
      "           2     0.9869    0.9950    0.9909     27542\n",
      "           3     0.4138    0.3452    0.3764      3476\n",
      "           4     0.9039    0.8070    0.8527     18932\n",
      "           5     0.9400    0.8501    0.8928     13386\n",
      "           6     0.9639    0.8427    0.8992      9936\n",
      "           7     0.8679    0.7969    0.8309      7668\n",
      "           8     0.5650    0.8680    0.6845       856\n",
      "           9     0.6509    0.7041    0.6765        98\n",
      "\n",
      "    accuracy                         0.8481     84576\n",
      "   macro avg     0.6598    0.7092    0.6648     84576\n",
      "weighted avg     0.8927    0.8481    0.8661     84576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with Grid Search\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    import pickle\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST CLASSIFIER (Fused Features)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            xgb_clf = XGBClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                learning_rate=lr,\n",
    "                random_state=13,\n",
    "                tree_method='hist', \n",
    "                device=\"cuda\"\n",
    "            )\n",
    "            \n",
    "            xgb_clf.fit(X_sup_train, y_sup_train, sample_weight=sample_weight)\n",
    "            y_pred_xgb = xgb_clf.predict(X_sup_test)\n",
    "            xgb_f1 = f1_score(y_sup_test, y_pred_xgb, average='macro')\n",
    "            \n",
    "            if xgb_f1 > score:\n",
    "                score = xgb_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = xgb_clf\n",
    "                # Save best model\n",
    "                xgb_clf.save_model('best_xgb_classifier_fused.json')\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_xgb_classifier_fused.json\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed. XGBoost might not support your GPU.\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CatBoost Grid Search (Expanded)...\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 3069.25 Total: 5806.3125\n",
      "  4%|▎         | 1/27 [00:04<01:47,  4.15s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      "  7%|▋         | 2/27 [00:08<01:40,  4.02s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 11%|█         | 3/27 [00:11<01:34,  3.96s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 15%|█▍        | 4/27 [00:24<02:53,  7.52s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 19%|█▊        | 5/27 [00:38<03:31,  9.60s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 22%|██▏       | 6/27 [00:51<03:48, 10.89s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 26%|██▌       | 7/27 [01:24<06:03, 18.19s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 30%|██▉       | 8/27 [01:59<07:26, 23.50s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 33%|███▎      | 9/27 [02:34<08:08, 27.17s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 37%|███▋      | 10/27 [02:40<05:49, 20.57s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 41%|████      | 11/27 [02:46<04:15, 16.00s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 44%|████▍     | 12/27 [02:51<03:12, 12.83s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 48%|████▊     | 13/27 [03:11<03:27, 14.79s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 52%|█████▏    | 14/27 [03:30<03:31, 16.25s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 56%|█████▌    | 15/27 [03:50<03:27, 17.28s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 59%|█████▉    | 16/27 [04:40<04:58, 27.15s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 63%|██████▎   | 17/27 [05:33<05:47, 34.79s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 67%|██████▋   | 18/27 [06:25<06:00, 40.07s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 70%|███████   | 19/27 [06:34<04:06, 30.84s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 74%|███████▍  | 20/27 [06:43<02:50, 24.30s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 78%|███████▊  | 21/27 [06:52<01:58, 19.68s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 81%|████████▏ | 22/27 [07:24<01:56, 23.33s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 85%|████████▌ | 23/27 [07:57<01:44, 26.06s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 89%|████████▉ | 24/27 [08:29<01:23, 27.92s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 93%|█████████▎| 25/27 [09:53<01:29, 44.69s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      " 96%|█████████▋| 26/27 [11:20<00:57, 57.45s/it]Warning: less than 75% GPU memory available for training. Free: 3067.25 Total: 5806.3125\n",
      "100%|██████████| 27/27 [12:46<00:00, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BEST CATBOOST HYPERPARAMETERS (Fused Features):\n",
      "{'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.6008\n",
      "============================================================\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_fused.cbm\n",
      "\n",
      "============================================================\n",
      "FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1760    0.3899    0.2426      1380\n",
      "           1     0.1521    0.5661    0.2398      1302\n",
      "           2     0.9999    0.9945    0.9972     27542\n",
      "           3     0.3115    0.3501    0.3297      3476\n",
      "           4     0.9102    0.7263    0.8079     18932\n",
      "           5     0.9003    0.7905    0.8418     13386\n",
      "           6     0.9386    0.7966    0.8618      9936\n",
      "           7     0.8405    0.8129    0.8264      7668\n",
      "           8     0.3444    0.9428    0.5045       856\n",
      "           9     0.2322    0.7653    0.3563        98\n",
      "\n",
      "    accuracy                         0.8187     84576\n",
      "   macro avg     0.5806    0.7135    0.6008     84576\n",
      "weighted avg     0.8801    0.8187    0.8417     84576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost with Grid Search (Expanded, no l2_leaf_reg/border_count, fixed best score logic)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"Starting CatBoost Grid Search (Expanded)...\")\n",
    "    \n",
    "    # Expanded hyperparameter grid\n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'  # Use 'CPU' if GPU not available\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_cat = cat_clf.predict(X_sup_test)\n",
    "            cat_f1 = f1_score(y_sup_test, y_pred_cat, average='macro')\n",
    "            \n",
    "            if cat_f1 > best_score:\n",
    "                best_score = cat_f1\n",
    "                best_params = {\n",
    "                    'iterations': iterations,\n",
    "                    'depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for fused features\n",
    "                best_model_path = \"best_catboost_classifier_fused.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEST CATBOOST HYPERPARAMETERS (Fused Features):\")\n",
    "    print(best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    if best_model_path:\n",
    "        print(f\"\\nBest CatBoost model saved to: {best_model_path}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    y_pred_best = best_model.predict(X_sup_test)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_sup_test, y_pred_best, digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed. Install with: pip install catboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:38<00:00, 10.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 30}\n",
      "Best Macro F1: 0.4646\n",
      "Model saved to: best_et_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2551    0.0457    0.0774      1380\n",
      "           1     0.1271    0.1382    0.1325      1302\n",
      "           2     0.9909    0.9902    0.9906     27542\n",
      "           3     0.2846    0.0964    0.1440      3476\n",
      "           4     0.7625    0.8391    0.7989     18932\n",
      "           5     0.8322    0.7370    0.7817     13386\n",
      "           6     0.9069    0.4902    0.6364      9936\n",
      "           7     0.7298    0.7578    0.7436      7668\n",
      "           8     0.0480    0.4544    0.0868       856\n",
      "           9     0.2771    0.2347    0.2541        98\n",
      "\n",
      "    accuracy                         0.7649     84576\n",
      "   macro avg     0.5214    0.4784    0.4646     84576\n",
      "weighted avg     0.8164    0.7649    0.7777     84576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            et_clf = ExtraTreesClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            et_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_et = et_clf.predict(X_sup_test)\n",
    "            et_f1 = f1_score(y_sup_test, y_pred_et, average='macro')\n",
    "            \n",
    "            if et_f1 > score:\n",
    "                score = et_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = et_clf\n",
    "                # Save best model\n",
    "                with open('best_et_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(et_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_et_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Extra Trees: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Features Classification (Comparison Baseline)\n",
    "\n",
    "Now we'll train classifiers on **raw features only** (without graph embeddings) to compare the benefit of multimodal fusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw feature shape - Train: (98669, 39), Test: (42288, 39)\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Prepare raw features (without embeddings)\n",
    "# Use only the original numeric features from X_train/X_test\n",
    "\n",
    "X_raw_train = X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_train = y_train[\"Attack\"].copy()\n",
    "\n",
    "X_raw_test = X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_test = y_test[\"Attack\"].copy()\n",
    "\n",
    "# Encode labels\n",
    "y_raw_train_encoded = lab_enc.transform(y_train[\"Attack\"])\n",
    "y_raw_test_encoded = lab_enc.transform(y_test[\"Attack\"])\n",
    "\n",
    "# Compute sample weights\n",
    "classes_raw = np.unique(y_raw_train_encoded)\n",
    "class_w_raw = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_raw, y=y_raw_train_encoded\n",
    ")\n",
    "class_to_w_raw = {c: w for c, w in zip(classes_raw, class_w_raw)}\n",
    "sample_weight_raw = pd.Series(y_raw_train_encoded).map(class_to_w_raw).values\n",
    "\n",
    "# Feature names to str\n",
    "X_raw_train.columns = X_raw_train.columns.map(str)\n",
    "X_raw_test.columns = X_raw_test.columns.map(str)\n",
    "\n",
    "print(f\"Raw feature shape - Train: {X_raw_train.shape}, Test: {X_raw_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_raw_train_encoded))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Raw Features Only)\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:46<00:00,  5.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 30}\n",
      "Best Macro F1: 0.6044\n",
      "Model saved to: best_rf_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1585    0.8420    0.2668       690\n",
      "           1     0.1820    0.1828    0.1824       651\n",
      "           2     0.9985    0.9932    0.9959     13771\n",
      "           3     0.5497    0.2768    0.3682      1738\n",
      "           4     0.9020    0.7907    0.8427      9466\n",
      "           5     0.9219    0.7950    0.8538      6693\n",
      "           6     0.9584    0.8247    0.8865      4968\n",
      "           7     0.8106    0.8125    0.8115      3834\n",
      "           8     0.3601    0.8388    0.5039       428\n",
      "           9     0.2048    0.8776    0.3320        49\n",
      "\n",
      "    accuracy                         0.8343     42288\n",
      "   macro avg     0.6046    0.7234    0.6044     42288\n",
      "weighted avg     0.8909    0.8343    0.8536     42288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Raw Features Only)\")\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = rf_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Raw Features Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [04:43<00:00, 10.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.6716\n",
      "Model saved to: best_xgb_classifier_raw.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1538    0.6797    0.2509       690\n",
      "           1     0.1434    0.2780    0.1892       651\n",
      "           2     0.9993    0.9946    0.9969     13771\n",
      "           3     0.4683    0.3487    0.3997      1738\n",
      "           4     0.9211    0.7907    0.8510      9466\n",
      "           5     0.9456    0.8624    0.9021      6693\n",
      "           6     0.9707    0.8476    0.9050      4968\n",
      "           7     0.8546    0.8112    0.8323      3834\n",
      "           8     0.5704    0.9276    0.7064       428\n",
      "           9     0.5676    0.8571    0.6829        49\n",
      "\n",
      "    accuracy                         0.8506     42288\n",
      "   macro avg     0.6595    0.7398    0.6716     42288\n",
      "weighted avg     0.9032    0.8506    0.8711     42288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Raw Features Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='cuda'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_raw_train, y_raw_train_encoded, sample_weight=sample_weight_raw)\n",
    "        y_pred = xgb_clf.predict(X_raw_test)\n",
    "        f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_raw.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_raw.json\\n\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Raw Features Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 3063.25 Total: 5806.3125\n",
      "  4%|▎         | 1/27 [00:03<01:23,  3.23s/it]Warning: less than 75% GPU memory available for training. Free: 3063.25 Total: 5806.3125\n",
      "  7%|▋         | 2/27 [00:07<01:34,  3.79s/it]Warning: less than 75% GPU memory available for training. Free: 3063.25 Total: 5806.3125\n",
      " 11%|█         | 3/27 [00:11<01:33,  3.89s/it]Warning: less than 75% GPU memory available for training. Free: 3063.25 Total: 5806.3125\n",
      " 15%|█▍        | 4/27 [00:20<02:12,  5.76s/it]Warning: less than 75% GPU memory available for training. Free: 3063.25 Total: 5806.3125\n",
      " 19%|█▊        | 5/27 [00:24<01:53,  5.16s/it]Warning: less than 75% GPU memory available for training. Free: 2795.25 Total: 5806.3125\n",
      " 22%|██▏       | 6/27 [00:38<02:54,  8.32s/it]Warning: less than 75% GPU memory available for training. Free: 2795.25 Total: 5806.3125\n",
      " 26%|██▌       | 7/27 [00:57<03:55, 11.78s/it]Warning: less than 75% GPU memory available for training. Free: 2791.25 Total: 5806.3125\n",
      " 30%|██▉       | 8/27 [01:16<04:28, 14.15s/it]Warning: less than 75% GPU memory available for training. Free: 2791.25 Total: 5806.3125\n",
      " 33%|███▎      | 9/27 [01:35<04:42, 15.72s/it]Warning: less than 75% GPU memory available for training. Free: 2661.25 Total: 5806.3125\n",
      " 37%|███▋      | 10/27 [01:40<03:28, 12.29s/it]Warning: less than 75% GPU memory available for training. Free: 3055.25 Total: 5806.3125\n",
      " 41%|████      | 11/27 [01:42<02:23,  8.98s/it]Warning: less than 75% GPU memory available for training. Free: 3055.25 Total: 5806.3125\n",
      " 44%|████▍     | 12/27 [01:43<01:40,  6.70s/it]Warning: less than 75% GPU memory available for training. Free: 3055.25 Total: 5806.3125\n",
      " 48%|████▊     | 13/27 [01:48<01:24,  6.07s/it]Warning: less than 75% GPU memory available for training. Free: 3055.25 Total: 5806.3125\n",
      " 52%|█████▏    | 14/27 [01:52<01:13,  5.65s/it]Warning: less than 75% GPU memory available for training. Free: 3055.25 Total: 5806.3125\n",
      " 56%|█████▌    | 15/27 [01:57<01:03,  5.32s/it]Warning: less than 75% GPU memory available for training. Free: 3055.25 Total: 5806.3125\n",
      " 59%|█████▉    | 16/27 [02:08<01:19,  7.19s/it]Warning: less than 75% GPU memory available for training. Free: 3055.25 Total: 5806.3125\n",
      " 63%|██████▎   | 17/27 [02:20<01:24,  8.48s/it]Warning: less than 75% GPU memory available for training. Free: 3059.25 Total: 5806.3125\n",
      " 67%|██████▋   | 18/27 [02:31<01:23,  9.29s/it]Warning: less than 75% GPU memory available for training. Free: 3059.25 Total: 5806.3125\n",
      " 70%|███████   | 19/27 [02:33<00:57,  7.16s/it]Warning: less than 75% GPU memory available for training. Free: 3059.25 Total: 5806.3125\n",
      " 74%|███████▍  | 20/27 [02:35<00:39,  5.64s/it]Warning: less than 75% GPU memory available for training. Free: 3059.25 Total: 5806.3125\n",
      " 78%|███████▊  | 21/27 [02:37<00:27,  4.59s/it]Warning: less than 75% GPU memory available for training. Free: 3059.25 Total: 5806.3125\n",
      " 81%|████████▏ | 22/27 [02:45<00:26,  5.36s/it]Warning: less than 75% GPU memory available for training. Free: 3059.25 Total: 5806.3125\n",
      " 85%|████████▌ | 23/27 [02:52<00:23,  5.88s/it]Warning: less than 75% GPU memory available for training. Free: 3059.25 Total: 5806.3125\n",
      " 89%|████████▉ | 24/27 [02:59<00:18,  6.23s/it]Warning: less than 75% GPU memory available for training. Free: 3059.25 Total: 5806.3125\n",
      "100%|██████████| 27/27 [03:53<00:00,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.6138\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_raw.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1578    0.7884    0.2629       690\n",
      "           1     0.1566    0.2704    0.1983       651\n",
      "           2     0.9998    0.9935    0.9966     13771\n",
      "           3     0.3842    0.3435    0.3627      1738\n",
      "           4     0.9193    0.7242    0.8101      9466\n",
      "           5     0.9206    0.8061    0.8596      6693\n",
      "           6     0.9548    0.8082    0.8754      4968\n",
      "           7     0.8465    0.8159    0.8309      3834\n",
      "           8     0.3760    0.9533    0.5393       428\n",
      "           9     0.2571    0.9184    0.4018        49\n",
      "\n",
      "    accuracy                         0.8240     42288\n",
      "   macro avg     0.5973    0.7422    0.6138     42288\n",
      "weighted avg     0.8909    0.8240    0.8483     42288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Raw Features Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "            y_pred = cat_clf.predict(X_raw_test)\n",
    "            f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for raw features\n",
    "                best_model_path = \"best_catboost_classifier_raw.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Raw Features Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:28<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 30}\n",
      "Best Macro F1: 0.6525\n",
      "Model saved to: best_et_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1584    0.8420    0.2666       690\n",
      "           1     0.1747    0.1951    0.1843       651\n",
      "           2     0.9983    0.9946    0.9964     13771\n",
      "           3     0.5066    0.3084    0.3834      1738\n",
      "           4     0.9130    0.8008    0.8532      9466\n",
      "           5     0.9304    0.8345    0.8798      6693\n",
      "           6     0.9568    0.8428    0.8962      4968\n",
      "           7     0.8541    0.7833    0.8171      3834\n",
      "           8     0.4659    0.9089    0.6160       428\n",
      "           9     0.5000    0.8571    0.6316        49\n",
      "\n",
      "    accuracy                         0.8448     42288\n",
      "   macro avg     0.6458    0.7367    0.6525     42288\n",
      "weighted avg     0.8980    0.8448    0.8640     42288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Raw Features Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = et_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Only Classification (Graph Features)\n",
    "\n",
    "Now we'll train classifiers on **embeddings only** (graph features without raw features) to isolate the value of graph-based learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape - Train: (197338, 256), Test: (84576, 256)\n",
      "Number of classes: 10\n",
      "Using only graph embeddings (no raw features)\n"
     ]
    }
   ],
   "source": [
    "# Prepare embeddings-only features (graph features without raw data)\n",
    "# Extract only the embedding columns (first 256 dimensions from graph encoder)\n",
    "\n",
    "# From the fused dataframes, extract only embedding columns\n",
    "# df_fuse_train has: [0-255] = embeddings, [256+] = raw features\n",
    "num_embedding_dims = 256  # Based on the DGI encoder output dimension\n",
    "\n",
    "X_emb_train = df_fuse_train.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_emb_test = df_fuse_test.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights\n",
    "classes_emb = np.unique(y_emb_train)\n",
    "class_w_emb = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_emb, y=y_emb_train\n",
    ")\n",
    "class_to_w_emb = {c: w for c, w in zip(classes_emb, class_w_emb)}\n",
    "sample_weight_emb = y_emb_train.map(class_to_w_emb).values\n",
    "\n",
    "# Feature names to str\n",
    "X_emb_train.columns = X_emb_train.columns.map(str)\n",
    "X_emb_test.columns = X_emb_test.columns.map(str)\n",
    "\n",
    "print(f\"Embeddings shape - Train: {X_emb_train.shape}, Test: {X_emb_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_emb_train))}\")\n",
    "print(f\"Using only graph embeddings (no raw features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:03<00:00,  7.08s/it]\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 20}\n",
      "Best Macro F1: 0.1944\n",
      "Model saved to: best_rf_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1380\n",
      "           1     0.0663    0.4539    0.1157      1302\n",
      "           2     1.0000    0.9858    0.9929     27542\n",
      "           3     0.0532    0.0178    0.0267      3476\n",
      "           4     0.4365    0.0383    0.0704     18932\n",
      "           5     0.2781    0.3266    0.3004     13386\n",
      "           6     0.3324    0.4207    0.3714      9936\n",
      "           7     0.1557    0.0198    0.0352      7668\n",
      "           8     0.0154    0.1016    0.0267       856\n",
      "           9     0.0021    0.2347    0.0042        98\n",
      "\n",
      "    accuracy                         0.4415     84576\n",
      "   macro avg     0.2340    0.2599    0.1944     84576\n",
      "weighted avg     0.5239    0.4415    0.4366     84576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = rf_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [13:05<00:00, 29.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "Best Macro F1: 0.2050\n",
      "Model saved to: best_xgb_classifier_embeddings.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1380\n",
      "           1     0.0715    0.1866    0.1034      1302\n",
      "           2     0.9660    0.9859    0.9758     27542\n",
      "           3     0.0967    0.1536    0.1187      3476\n",
      "           4     0.3745    0.1354    0.1989     18932\n",
      "           5     0.2825    0.2542    0.2676     13386\n",
      "           6     0.2818    0.3091    0.2948      9936\n",
      "           7     0.1721    0.0346    0.0576      7668\n",
      "           8     0.0168    0.1589    0.0303       856\n",
      "           9     0.0014    0.1020    0.0029        98\n",
      "\n",
      "    accuracy                         0.4420     84576\n",
      "   macro avg     0.2263    0.2320    0.2050     84576\n",
      "weighted avg     0.4971    0.4420    0.4513     84576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Embeddings Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='gpu'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_emb_train, y_emb_train, sample_weight=sample_weight_emb)\n",
    "        y_pred = xgb_clf.predict(X_emb_test)\n",
    "        f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_embeddings.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_embeddings.json\\n\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Embeddings Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [09:30<00:00, 21.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 500, 'depth': 8, 'learning_rate': 0.05}\n",
      "Best Macro F1: 0.1950\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_embeddings.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1380\n",
      "           1     0.0711    0.2473    0.1105      1302\n",
      "           2     1.0000    0.9858    0.9929     27542\n",
      "           3     0.0881    0.1657    0.1151      3476\n",
      "           4     0.3932    0.0632    0.1089     18932\n",
      "           5     0.3046    0.0728    0.1176     13386\n",
      "           6     0.3672    0.4114    0.3881      9936\n",
      "           7     0.1487    0.0561    0.0814      7668\n",
      "           8     0.0156    0.3166    0.0296       856\n",
      "           9     0.0029    0.2551    0.0057        98\n",
      "\n",
      "    accuracy                         0.4142     84576\n",
      "   macro avg     0.2391    0.2574    0.1950     84576\n",
      "weighted avg     0.5234    0.4142    0.4260     84576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Embeddings Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_emb_train, y_emb_train)\n",
    "            y_pred = cat_clf.predict(X_emb_test)\n",
    "            f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for embeddings\n",
    "                best_model_path = \"best_catboost_classifier_embeddings.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:40<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 20}\n",
      "Best Macro F1: 0.1906\n",
      "Model saved to: best_et_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      1380\n",
      "           1     0.0521    0.2281    0.0848      1302\n",
      "           2     1.0000    0.9858    0.9929     27542\n",
      "           3     0.0532    0.0089    0.0153      3476\n",
      "           4     0.3719    0.1086    0.1681     18932\n",
      "           5     0.2681    0.2784    0.2731     13386\n",
      "           6     0.2842    0.3867    0.3276      9936\n",
      "           7     0.1557    0.0099    0.0186      7668\n",
      "           8     0.0136    0.0421    0.0205       856\n",
      "           9     0.0027    0.4082    0.0053        98\n",
      "\n",
      "    accuracy                         0.4405     84576\n",
      "   macro avg     0.2201    0.2457    0.1906     84576\n",
      "weighted avg     0.5020    0.4405    0.4465     84576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = et_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Comparison Table\n",
    "\n",
    "Create a comparison table of all methods (Fused vs Raw features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\n",
      "===============================================================================================\n",
      "\n",
      "Instructions:\n",
      "1. Run all cells above to get F1 scores for each method\n",
      "2. Record the best Macro F1 score for each method\n",
      "3. Compare three approaches:\n",
      "   - Fused Features: Embeddings + Raw (Multimodal)\n",
      "   - Embeddings Only: Graph features only\n",
      "   - Raw Features: Traditional features only\n",
      "\n",
      "Expected format:\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Method               Fused (Emb+Raw)           Embeddings Only           Raw Only                 \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Random Forest        [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "XGBoost              [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "CatBoost             [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "Extra Trees          [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysis:\n",
      "- Fused features should show best performance (multimodal learning)\n",
      "- Embeddings capture structural/graph patterns\n",
      "- Raw features provide traditional statistical information\n",
      "- Compare to understand the contribution of each modality\n"
     ]
    }
   ],
   "source": [
    "# Create a summary comparison table\n",
    "# NOTE: After running all cells above, manually collect the F1 scores and create a comparison\n",
    "\n",
    "print(\"=\"*95)\n",
    "print(\"PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\")\n",
    "print(\"=\"*95)\n",
    "print(\"\\nInstructions:\")\n",
    "print(\"1. Run all cells above to get F1 scores for each method\")\n",
    "print(\"2. Record the best Macro F1 score for each method\")\n",
    "print(\"3. Compare three approaches:\")\n",
    "print(\"   - Fused Features: Embeddings + Raw (Multimodal)\")\n",
    "print(\"   - Embeddings Only: Graph features only\")\n",
    "print(\"   - Raw Features: Traditional features only\")\n",
    "print(\"\\nExpected format:\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Method':<20} {'Fused (Emb+Raw)':<25} {'Embeddings Only':<25} {'Raw Only':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Random Forest':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'XGBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'CatBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'Extra Trees':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"- Fused features should show best performance (multimodal learning)\")\n",
    "print(\"- Embeddings capture structural/graph patterns\")\n",
    "print(\"- Raw features provide traditional statistical information\")\n",
    "print(\"- Compare to understand the contribution of each modality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights & Interpretation\n",
    "\n",
    "After running all experiments, analyze the results to answer:\n",
    "\n",
    "1. **Which approach performs best overall?**\n",
    "   - Fused features (multimodal) should ideally outperform single modalities\n",
    "   - Compare the magnitude of improvements\n",
    "\n",
    "2. **What is the value of graph embeddings?**\n",
    "   - Compare Embeddings-only vs Raw-only to see if graph structure helps\n",
    "   - If embeddings alone beat raw features, graph learning is beneficial\n",
    "\n",
    "3. **Is multimodal fusion effective?**\n",
    "   - Compare Fused vs (Embeddings + Raw separately)\n",
    "   - Synergy should provide additional gains beyond individual modalities\n",
    "\n",
    "4. **Which classifier is most suitable?**\n",
    "   - Identify the best performing algorithm for each feature type\n",
    "   - Consider computational cost vs accuracy trade-offs\n",
    "\n",
    "5. **Feature contribution analysis:**\n",
    "   - If Fused ≈ Embeddings > Raw: Graph structure dominates\n",
    "   - If Fused ≈ Raw > Embeddings: Traditional features dominate\n",
    "   - If Fused > Both: True synergy from multimodal learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
