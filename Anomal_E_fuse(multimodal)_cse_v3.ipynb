{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Hjc3iIihKLn-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from dgl.data import DGLDataset\n",
    "import dgl\n",
    "import time\n",
    "import networkx as nx\n",
    "import category_encoders as ce\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "from typing import *\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SvWHb_BpKsLq"
   },
   "outputs": [],
   "source": [
    "file_name = \"NF-CICIDS2018-v3.parquet\"\n",
    "# file_name = \"final.csv\"\n",
    "data = pd.read_parquet(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "fqly1y-LMwYS",
    "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    17514626\n",
       "1     2600903\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3t4OREvSM33h"
   },
   "outputs": [],
   "source": [
    "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
    "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
    "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
    "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bTtHq0XqNXxI"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUNIP-8zNkn9",
    "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'FTP-BruteForce', 'SSH-Bruteforce',\n",
       "       'DoS_attacks-GoldenEye', 'DoS_attacks-Slowloris',\n",
       "       'DoS_attacks-SlowHTTPTest', 'DoS_attacks-Hulk',\n",
       "       'DDoS_attacks-LOIC-HTTP', 'DDOS_attack-LOIC-UDP',\n",
       "       'DDOS_attack-HOIC', 'Brute_Force_-Web', 'Brute_Force_-XSS',\n",
       "       'SQL_Injection', 'Infilteration', 'Bot'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Attack.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    259694\n",
       "0    175543\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = data.groupby(by='Attack').sample(frac=0.1, random_state=13)\n",
    "# scale attack flows to 0.4\n",
    "data_attack = data[data['Label'] == 1]\n",
    "data_benign = data[data['Label'] == 0].sample(frac=0.1, random_state=13)\n",
    "data = pd.concat([data_attack, data_benign], axis=0)\n",
    "data = data.sample(frac=0.1, random_state=13).reset_index(drop=True)\n",
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "lcfAP6ViOp-J",
    "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLOW_START_MILLISECONDS</th>\n",
       "      <th>FLOW_END_MILLISECONDS</th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>...</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>SRC_TO_DST_IAT_MIN</th>\n",
       "      <th>SRC_TO_DST_IAT_MAX</th>\n",
       "      <th>SRC_TO_DST_IAT_AVG</th>\n",
       "      <th>SRC_TO_DST_IAT_STDDEV</th>\n",
       "      <th>DST_TO_SRC_IAT_MIN</th>\n",
       "      <th>DST_TO_SRC_IAT_MAX</th>\n",
       "      <th>DST_TO_SRC_IAT_AVG</th>\n",
       "      <th>DST_TO_SRC_IAT_STDDEV</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>...</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bot</th>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>...</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute_Force_-Web</th>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>...</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute_Force_-XSS</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDOS_attack-HOIC</th>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>...</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDOS_attack-LOIC-UDP</th>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDoS_attacks-LOIC-HTTP</th>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>...</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS_attacks-GoldenEye</th>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>...</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS_attacks-Hulk</th>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>...</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS_attacks-SlowHTTPTest</th>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>...</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS_attacks-Slowloris</th>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>...</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTP-BruteForce</th>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>...</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infilteration</th>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>...</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQL_Injection</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSH-Bruteforce</th>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>...</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          FLOW_START_MILLISECONDS  FLOW_END_MILLISECONDS  \\\n",
       "Attack                                                                     \n",
       "Benign                                     175543                 175543   \n",
       "Bot                                         20730                  20730   \n",
       "Brute_Force_-Web                              169                    169   \n",
       "Brute_Force_-XSS                               56                     56   \n",
       "DDOS_attack-HOIC                           102984                 102984   \n",
       "DDOS_attack-LOIC-UDP                          313                    313   \n",
       "DDoS_attacks-LOIC-HTTP                      28935                  28935   \n",
       "DoS_attacks-GoldenEye                        6053                   6053   \n",
       "DoS_attacks-Hulk                             9818                   9818   \n",
       "DoS_attacks-SlowHTTPTest                    10535                  10535   \n",
       "DoS_attacks-Slowloris                        3607                   3607   \n",
       "FTP-BruteForce                              38735                  38735   \n",
       "Infilteration                               18857                  18857   \n",
       "SQL_Injection                                  52                     52   \n",
       "SSH-Bruteforce                              18850                  18850   \n",
       "\n",
       "                          IPV4_SRC_ADDR  IPV4_DST_ADDR  PROTOCOL  L7_PROTO  \\\n",
       "Attack                                                                       \n",
       "Benign                           175543         175543    175543    175543   \n",
       "Bot                               20730          20730     20730     20730   \n",
       "Brute_Force_-Web                    169            169       169       169   \n",
       "Brute_Force_-XSS                     56             56        56        56   \n",
       "DDOS_attack-HOIC                 102984         102984    102984    102984   \n",
       "DDOS_attack-LOIC-UDP                313            313       313       313   \n",
       "DDoS_attacks-LOIC-HTTP            28935          28935     28935     28935   \n",
       "DoS_attacks-GoldenEye              6053           6053      6053      6053   \n",
       "DoS_attacks-Hulk                   9818           9818      9818      9818   \n",
       "DoS_attacks-SlowHTTPTest          10535          10535     10535     10535   \n",
       "DoS_attacks-Slowloris              3607           3607      3607      3607   \n",
       "FTP-BruteForce                    38735          38735     38735     38735   \n",
       "Infilteration                     18857          18857     18857     18857   \n",
       "SQL_Injection                        52             52        52        52   \n",
       "SSH-Bruteforce                    18850          18850     18850     18850   \n",
       "\n",
       "                          IN_BYTES  IN_PKTS  OUT_BYTES  OUT_PKTS  ...  \\\n",
       "Attack                                                            ...   \n",
       "Benign                      175543   175543     175543    175543  ...   \n",
       "Bot                          20730    20730      20730     20730  ...   \n",
       "Brute_Force_-Web               169      169        169       169  ...   \n",
       "Brute_Force_-XSS                56       56         56        56  ...   \n",
       "DDOS_attack-HOIC            102984   102984     102984    102984  ...   \n",
       "DDOS_attack-LOIC-UDP           313      313        313       313  ...   \n",
       "DDoS_attacks-LOIC-HTTP       28935    28935      28935     28935  ...   \n",
       "DoS_attacks-GoldenEye         6053     6053       6053      6053  ...   \n",
       "DoS_attacks-Hulk              9818     9818       9818      9818  ...   \n",
       "DoS_attacks-SlowHTTPTest     10535    10535      10535     10535  ...   \n",
       "DoS_attacks-Slowloris         3607     3607       3607      3607  ...   \n",
       "FTP-BruteForce               38735    38735      38735     38735  ...   \n",
       "Infilteration                18857    18857      18857     18857  ...   \n",
       "SQL_Injection                   52       52         52        52  ...   \n",
       "SSH-Bruteforce               18850    18850      18850     18850  ...   \n",
       "\n",
       "                          FTP_COMMAND_RET_CODE  SRC_TO_DST_IAT_MIN  \\\n",
       "Attack                                                               \n",
       "Benign                                  175543              175543   \n",
       "Bot                                      20730               20730   \n",
       "Brute_Force_-Web                           169                 169   \n",
       "Brute_Force_-XSS                            56                  56   \n",
       "DDOS_attack-HOIC                        102984              102984   \n",
       "DDOS_attack-LOIC-UDP                       313                 313   \n",
       "DDoS_attacks-LOIC-HTTP                   28935               28935   \n",
       "DoS_attacks-GoldenEye                     6053                6053   \n",
       "DoS_attacks-Hulk                          9818                9818   \n",
       "DoS_attacks-SlowHTTPTest                 10535               10535   \n",
       "DoS_attacks-Slowloris                     3607                3607   \n",
       "FTP-BruteForce                           38735               38735   \n",
       "Infilteration                            18857               18857   \n",
       "SQL_Injection                               52                  52   \n",
       "SSH-Bruteforce                           18850               18850   \n",
       "\n",
       "                          SRC_TO_DST_IAT_MAX  SRC_TO_DST_IAT_AVG  \\\n",
       "Attack                                                             \n",
       "Benign                                175543              175543   \n",
       "Bot                                    20730               20730   \n",
       "Brute_Force_-Web                         169                 169   \n",
       "Brute_Force_-XSS                          56                  56   \n",
       "DDOS_attack-HOIC                      102984              102984   \n",
       "DDOS_attack-LOIC-UDP                     313                 313   \n",
       "DDoS_attacks-LOIC-HTTP                 28935               28935   \n",
       "DoS_attacks-GoldenEye                   6053                6053   \n",
       "DoS_attacks-Hulk                        9818                9818   \n",
       "DoS_attacks-SlowHTTPTest               10535               10535   \n",
       "DoS_attacks-Slowloris                   3607                3607   \n",
       "FTP-BruteForce                         38735               38735   \n",
       "Infilteration                          18857               18857   \n",
       "SQL_Injection                             52                  52   \n",
       "SSH-Bruteforce                         18850               18850   \n",
       "\n",
       "                          SRC_TO_DST_IAT_STDDEV  DST_TO_SRC_IAT_MIN  \\\n",
       "Attack                                                                \n",
       "Benign                                   175543              175543   \n",
       "Bot                                       20730               20730   \n",
       "Brute_Force_-Web                            169                 169   \n",
       "Brute_Force_-XSS                             56                  56   \n",
       "DDOS_attack-HOIC                         102984              102984   \n",
       "DDOS_attack-LOIC-UDP                        313                 313   \n",
       "DDoS_attacks-LOIC-HTTP                    28935               28935   \n",
       "DoS_attacks-GoldenEye                      6053                6053   \n",
       "DoS_attacks-Hulk                           9818                9818   \n",
       "DoS_attacks-SlowHTTPTest                  10535               10535   \n",
       "DoS_attacks-Slowloris                      3607                3607   \n",
       "FTP-BruteForce                            38735               38735   \n",
       "Infilteration                             18857               18857   \n",
       "SQL_Injection                                52                  52   \n",
       "SSH-Bruteforce                            18850               18850   \n",
       "\n",
       "                          DST_TO_SRC_IAT_MAX  DST_TO_SRC_IAT_AVG  \\\n",
       "Attack                                                             \n",
       "Benign                                175543              175543   \n",
       "Bot                                    20730               20730   \n",
       "Brute_Force_-Web                         169                 169   \n",
       "Brute_Force_-XSS                          56                  56   \n",
       "DDOS_attack-HOIC                      102984              102984   \n",
       "DDOS_attack-LOIC-UDP                     313                 313   \n",
       "DDoS_attacks-LOIC-HTTP                 28935               28935   \n",
       "DoS_attacks-GoldenEye                   6053                6053   \n",
       "DoS_attacks-Hulk                        9818                9818   \n",
       "DoS_attacks-SlowHTTPTest               10535               10535   \n",
       "DoS_attacks-Slowloris                   3607                3607   \n",
       "FTP-BruteForce                         38735               38735   \n",
       "Infilteration                          18857               18857   \n",
       "SQL_Injection                             52                  52   \n",
       "SSH-Bruteforce                         18850               18850   \n",
       "\n",
       "                          DST_TO_SRC_IAT_STDDEV   Label  \n",
       "Attack                                                   \n",
       "Benign                                   175543  175543  \n",
       "Bot                                       20730   20730  \n",
       "Brute_Force_-Web                            169     169  \n",
       "Brute_Force_-XSS                             56      56  \n",
       "DDOS_attack-HOIC                         102984  102984  \n",
       "DDOS_attack-LOIC-UDP                        313     313  \n",
       "DDoS_attacks-LOIC-HTTP                    28935   28935  \n",
       "DoS_attacks-GoldenEye                      6053    6053  \n",
       "DoS_attacks-Hulk                           9818    9818  \n",
       "DoS_attacks-SlowHTTPTest                  10535   10535  \n",
       "DoS_attacks-Slowloris                      3607    3607  \n",
       "FTP-BruteForce                            38735   38735  \n",
       "Infilteration                             18857   18857  \n",
       "SQL_Injection                                52      52  \n",
       "SSH-Bruteforce                            18850   18850  \n",
       "\n",
       "[15 rows x 52 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=\"Attack\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FqRx5xCPOuv8"
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Attack\", \"Label\", \"FLOW_START_MILLISECONDS\", \"FLOW_END_MILLISECONDS\",\n",
    "                       \"SRC_TO_DST_IAT_MIN\", \"SRC_TO_DST_IAT_MAX\", \"SRC_TO_DST_IAT_AVG\",\n",
    "                       \"SRC_TO_DST_IAT_STDDEV\", \"DST_TO_SRC_IAT_MIN\", \"DST_TO_SRC_IAT_MAX\",\n",
    "                       \"DST_TO_SRC_IAT_AVG\", \"DST_TO_SRC_IAT_STDDEV\"])\n",
    "y = data[[\"Attack\", \"Label\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=13, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bPfakXplPGGx"
   },
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
    "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
    "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
    "                                  'FTP_COMMAND_RET_CODE'])\n",
    "encoder.fit(X_train, y_train.Label)\n",
    "\n",
    "# Transform on training set\n",
    "X_train = encoder.transform(X_train)\n",
    "\n",
    "# Transform on testing set\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ibyOfV-8PouK"
   },
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "asDnsSIWPee0"
   },
   "outputs": [],
   "source": [
    "# (Modified)\n",
    "scaler = Normalizer()\n",
    "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
    "scaler.fit(X_train[cols_to_norm])\n",
    "\n",
    "# Transform on training set\n",
    "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
    "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
    "X_train['id'] = X_train.index\n",
    "\n",
    "# Transform on testing set\n",
    "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
    "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
    "X_test['id'] = X_test.index\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "hErQbsnrPluV",
    "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>h</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237065</th>\n",
       "      <td>172.31.66.5</td>\n",
       "      <td>172.31.0.2</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.709650e-06</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>[3.7774454035072754e-06, 3.7096502411483668e-0...</td>\n",
       "      <td>237065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15205</th>\n",
       "      <td>172.31.66.40</td>\n",
       "      <td>172.31.0.2</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.517947e-05</td>\n",
       "      <td>0.008051</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.015380</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.007209</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>[1.5456884273229756e-05, 1.5179474048347743e-0...</td>\n",
       "      <td>15205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312483</th>\n",
       "      <td>18.221.219.4</td>\n",
       "      <td>172.31.69.25</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.730706e-06</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>[1.2394324546138451e-06, 1.7307060387105932e-0...</td>\n",
       "      <td>312483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277386</th>\n",
       "      <td>82.212.17.186</td>\n",
       "      <td>172.31.64.68</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5.376285e-07</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125240</td>\n",
       "      <td>0.978439</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>[1.094307220318909e-05, 5.3762845853957e-07, 0...</td>\n",
       "      <td>277386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19084</th>\n",
       "      <td>172.31.69.13</td>\n",
       "      <td>172.31.69.7</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.448487e-07</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>[1.5046602182805569e-06, 9.448487146716061e-07...</td>\n",
       "      <td>19084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        IPV4_SRC_ADDR IPV4_DST_ADDR  PROTOCOL      L7_PROTO  IN_BYTES  \\\n",
       "237065    172.31.66.5    172.31.0.2  0.000004  3.709650e-06  0.001821   \n",
       "15205    172.31.66.40    172.31.0.2  0.000015  1.517947e-05  0.008051   \n",
       "312483   18.221.219.4  172.31.69.25  0.000001  1.730706e-06  0.000104   \n",
       "277386  82.212.17.186  172.31.64.68  0.000011  5.376285e-07  0.002645   \n",
       "19084    172.31.69.13   172.31.69.7  0.000002  9.448487e-07  0.000092   \n",
       "\n",
       "         IN_PKTS  OUT_BYTES  OUT_PKTS  TCP_FLAGS  CLIENT_TCP_FLAGS  ...  \\\n",
       "237065  0.000029   0.004522  0.000029   0.000004          0.000004  ...   \n",
       "15205   0.000120   0.015380  0.000120   0.000015          0.000015  ...   \n",
       "312483  0.000002   0.000069  0.000002   0.000002          0.000002  ...   \n",
       "277386  0.000046   0.001407  0.000031   0.000002          0.000003  ...   \n",
       "19084   0.000002   0.000084  0.000002   0.000002          0.000002  ...   \n",
       "\n",
       "        TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  ICMP_TYPE  ICMP_IPV4_TYPE  \\\n",
       "237065        0.000000         0.000000   0.000018        0.000018   \n",
       "15205         0.000000         0.000000   0.000073        0.000073   \n",
       "312483        0.046550         0.000000   0.000001        0.000001   \n",
       "277386        0.125240         0.978439   0.000009        0.000009   \n",
       "19084         0.002153         0.000000   0.000001        0.000001   \n",
       "\n",
       "        DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \\\n",
       "237065      0.000015        0.000004        0.000558              0.000018   \n",
       "15205       0.000062        0.000015        0.007209              0.000072   \n",
       "312483      0.000001        0.000001        0.000000              0.000001   \n",
       "277386      0.000011        0.000011        0.000000              0.000009   \n",
       "19084       0.000001        0.000001        0.000000              0.000001   \n",
       "\n",
       "                                                        h      id  \n",
       "237065  [3.7774454035072754e-06, 3.7096502411483668e-0...  237065  \n",
       "15205   [1.5456884273229756e-05, 1.5179474048347743e-0...   15205  \n",
       "312483  [1.2394324546138451e-06, 1.7307060387105932e-0...  312483  \n",
       "277386  [1.094307220318909e-05, 5.3762845853957e-07, 0...  277386  \n",
       "19084   [1.5046602182805569e-06, 9.448487146716061e-07...   19084  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d_tLtK4WPtrF"
   },
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "lab_enc.fit(data[\"Attack\"])\n",
    "\n",
    "# Transform on training set\n",
    "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
    "\n",
    "# Transform on testing set\n",
    "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8yaicjecP1fZ"
   },
   "outputs": [],
   "source": [
    "# Training graph (Modified)\n",
    "\n",
    "train['id'] = train.index\n",
    "\n",
    "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "           [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "train_g = train_g.to_directed()\n",
    "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
    "train_g.edata['h'].shape[1]])\n",
    "train_g.ndata['h'] = nfeat_weight\n",
    "\n",
    "test['id'] = test.index\n",
    "\n",
    "# Testing graph\n",
    "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "            [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "# print(test_g)\n",
    "test_g = test_g.to_directed()\n",
    "# print(test_g)\n",
    "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
    "test_g.edata['h'].shape[1]])\n",
    "test_g.ndata['h'] = nfeat_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PUV6DgJ9QRaP"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import tqdm\n",
    "import gc\n",
    "\n",
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "      super(SAGELayer, self).__init__()\n",
    "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
    "      self.activation = F.relu\n",
    "      self.W_edge = nn.Linear(128 * 2, 256)\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      gain = nn.init.calculate_gain('relu')\n",
    "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "      return {'m':  edges.data['h']}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "      with g_dgl.local_scope():\n",
    "        g = g_dgl\n",
    "        g.ndata['h'] = nfeats\n",
    "        g.edata['h'] = efeats\n",
    "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "\n",
    "        # Compute edge embeddings\n",
    "        u, v = g.edges()\n",
    "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
    "        return g.ndata['h'], edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_xo-3K4QRGqc"
   },
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
    "      super(SAGE, self).__init__()\n",
    "      self.layers = nn.ModuleList()\n",
    "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
    "\n",
    "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
    "      if corrupt:\n",
    "        e_perm = torch.randperm(g.number_of_edges())\n",
    "        #n_perm = torch.randperm(g.number_of_nodes())\n",
    "        efeats = efeats[e_perm]\n",
    "        #nfeats = nfeats[n_perm]\n",
    "      for i, layer in enumerate(self.layers):\n",
    "        #nfeats = layer(g, nfeats, efeats)\n",
    "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
    "      #return nfeats.sum(1)\n",
    "      return nfeats.sum(1), e_feats.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6uuxRtLuRJQL"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "      super(Discriminator, self).__init__()\n",
    "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def uniform(self, size, tensor):\n",
    "      bound = 1.0 / math.sqrt(size)\n",
    "      if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      size = self.weight.size(0)\n",
    "      self.uniform(size, self.weight)\n",
    "\n",
    "    def forward(self, features, summary):\n",
    "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
    "      return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZPbVjlCyRUco"
   },
   "outputs": [],
   "source": [
    "class DGI(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
    "      super(DGI, self).__init__()\n",
    "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
    "      #self.discriminator = Discriminator(128)\n",
    "      self.discriminator = Discriminator(256)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "\n",
    "      positive = positive[1]\n",
    "      negative = negative[1]\n",
    "\n",
    "      summary = torch.sigmoid(positive.mean(dim=0))\n",
    "\n",
    "      positive = self.discriminator(positive, summary)\n",
    "      negative = self.discriminator(negative, summary)\n",
    "\n",
    "      l1 = self.loss(positive, torch.ones_like(positive))\n",
    "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
    "\n",
    "      return l1 + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sKnfpWFMR19u"
   },
   "outputs": [],
   "source": [
    "ndim_in = train_g.ndata['h'].shape[1]\n",
    "hidden_features = 128\n",
    "ndim_out = 128\n",
    "num_layers = 1\n",
    "edim = train_g.edata['h'].shape[1]\n",
    "learning_rate = 1e-3\n",
    "epochs = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "aSl_9qY8SbA0"
   },
   "outputs": [],
   "source": [
    "dgi = DGI(ndim_in,\n",
    "    ndim_out,\n",
    "    edim,\n",
    "    F.relu)\n",
    "\n",
    "dgi = dgi.to('cuda')\n",
    "\n",
    "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
    "                lr=1e-3,\n",
    "                weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9K6_cOiWSdJA"
   },
   "outputs": [],
   "source": [
    "# Format node and edge features for E-GraphSAGE\n",
    "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
    "                                   (train_g.ndata['h'].shape[0], 1,\n",
    "                                    train_g.ndata['h'].shape[1]))\n",
    "\n",
    "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
    "                                   (train_g.edata['h'].shape[0], 1,\n",
    "                                    train_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "O44auIyWSexg"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "train_g = train_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gZtafIdxSheN"
   },
   "outputs": [],
   "source": [
    "# cnt_wait = 0\n",
    "# best = 1e9\n",
    "# best_t = 0\n",
    "# dur = []\n",
    "# node_features = train_g.ndata['h'] \n",
    "# edge_features = train_g.edata['h']\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     dgi.train()\n",
    "#     if epoch >= 3:\n",
    "#         t0 = time.time()\n",
    "\n",
    "#     dgi_optimizer.zero_grad()\n",
    "#     loss = dgi(train_g, node_features, edge_features)\n",
    "#     loss.backward()\n",
    "#     dgi_optimizer.step()\n",
    "\n",
    "#     if loss < best:\n",
    "#         best = loss\n",
    "#         best_t = epoch\n",
    "#         cnt_wait = 0\n",
    "#         torch.save(dgi.state_dict(), 'best_dgi_CSE_v3.pkl')\n",
    "#     else:\n",
    "#         cnt_wait += 1\n",
    "\n",
    "#   # if cnt_wait == patience:\n",
    "#   #     print('Early stopping!')\n",
    "#   #     break\n",
    "\n",
    "#     if epoch >= 3:\n",
    "#         dur.append(time.time() - t0)\n",
    "\n",
    "#     if epoch % 50 == 0:\n",
    "\n",
    "#         print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "#             \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
    "#               loss.item(),\n",
    "#               train_g.num_edges() / np.mean(dur) / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RZ2HAQDAF-4c",
    "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgi.load_state_dict(torch.load('best_dgi_CSE_v3.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6Ek16GkRStKP"
   },
   "outputs": [],
   "source": [
    "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
    "training_emb = training_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-FwaBlOdS4ep"
   },
   "outputs": [],
   "source": [
    "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
    "                                   (test_g.ndata['h'].shape[0], 1,\n",
    "                                    test_g.ndata['h'].shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
    "                                   (test_g.edata['h'].shape[0], 1,\n",
    "                                    test_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SBa-rdivS6cQ"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "test_g = test_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "W12WLjslS-kx"
   },
   "outputs": [],
   "source": [
    "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
    "testing_emb = testing_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal (Fusion) Learning\n",
    "\n",
    "df_train = pd.DataFrame(training_emb,)\n",
    "# map the id to the original data\n",
    "df_train['id'] = train_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "df_raw_train = pd.DataFrame(X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_fuse_train = pd.merge(df_train, df_raw_train, on='id', how='left')\n",
    "df_fuse_train = df_fuse_train.drop(columns=[\"id\"])\n",
    "df_fuse_train[\"Attacks\"] = train_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
    "\n",
    "df_test = pd.DataFrame(testing_emb,)\n",
    "# map the id to the original data\n",
    "df_test['id'] = test_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "df_raw_test = pd.DataFrame(X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_raw_test = pd.merge(df_test, df_raw_test, on='id', how='left')\n",
    "df_fuse_test = df_raw_test.drop(columns=[\"id\"])\n",
    "df_fuse_test[\"Attacks\"] = test_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ScEk1y_TzzX"
   },
   "source": [
    "# Embeddings CBLOF  Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ZYABKzdrTGas"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pyod.models.cblof import CBLOF\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_fuse_train_samples = df_fuse_train[df_fuse_train.Label == 0].drop(columns=[\"Label\", \"Attacks\"])\n",
    "normal_fuse_train_samples = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"])\n",
    "\n",
    "fuse_train_labels = df_fuse_train[\"Label\"]\n",
    "fuse_test_labels = df_fuse_test[\"Label\"]\n",
    "\n",
    "fuse_test_samples = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_512_TO_1024_BYTES</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.092887</td>\n",
       "      <td>0.101508</td>\n",
       "      <td>0.040677</td>\n",
       "      <td>0.071878</td>\n",
       "      <td>0.051259</td>\n",
       "      <td>-0.047023</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>-0.013434</td>\n",
       "      <td>0.097486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.092887</td>\n",
       "      <td>0.101508</td>\n",
       "      <td>0.040677</td>\n",
       "      <td>0.071878</td>\n",
       "      <td>0.051259</td>\n",
       "      <td>-0.047023</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>-0.013434</td>\n",
       "      <td>0.097486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.092887</td>\n",
       "      <td>0.101508</td>\n",
       "      <td>0.040677</td>\n",
       "      <td>0.071878</td>\n",
       "      <td>0.051259</td>\n",
       "      <td>-0.047023</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>-0.013434</td>\n",
       "      <td>0.097486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.092887</td>\n",
       "      <td>0.101508</td>\n",
       "      <td>0.040677</td>\n",
       "      <td>0.071878</td>\n",
       "      <td>0.051259</td>\n",
       "      <td>-0.047023</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>-0.013434</td>\n",
       "      <td>0.097486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.092887</td>\n",
       "      <td>0.101508</td>\n",
       "      <td>0.040677</td>\n",
       "      <td>0.071878</td>\n",
       "      <td>0.051259</td>\n",
       "      <td>-0.047023</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>-0.013434</td>\n",
       "      <td>0.097486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260810</th>\n",
       "      <td>-0.067142</td>\n",
       "      <td>-0.019837</td>\n",
       "      <td>0.013006</td>\n",
       "      <td>0.021026</td>\n",
       "      <td>0.006870</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.016654</td>\n",
       "      <td>0.015265</td>\n",
       "      <td>-0.034830</td>\n",
       "      <td>0.093828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631349</td>\n",
       "      <td>0.631349</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260811</th>\n",
       "      <td>-0.047532</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.045636</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.008810</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>-0.021919</td>\n",
       "      <td>0.104940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769311</td>\n",
       "      <td>0.383695</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260812</th>\n",
       "      <td>-0.081734</td>\n",
       "      <td>-0.007846</td>\n",
       "      <td>0.022180</td>\n",
       "      <td>0.038925</td>\n",
       "      <td>0.012128</td>\n",
       "      <td>-0.011006</td>\n",
       "      <td>0.028191</td>\n",
       "      <td>0.019945</td>\n",
       "      <td>-0.028569</td>\n",
       "      <td>0.089264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243872</td>\n",
       "      <td>0.869272</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260813</th>\n",
       "      <td>-0.048916</td>\n",
       "      <td>-0.006230</td>\n",
       "      <td>0.038012</td>\n",
       "      <td>0.018271</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>-0.009537</td>\n",
       "      <td>0.029467</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>-0.003603</td>\n",
       "      <td>0.097674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.859847</td>\n",
       "      <td>0.421561</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260814</th>\n",
       "      <td>-0.039720</td>\n",
       "      <td>-0.004852</td>\n",
       "      <td>0.021869</td>\n",
       "      <td>-0.005706</td>\n",
       "      <td>0.043847</td>\n",
       "      <td>0.013941</td>\n",
       "      <td>0.009544</td>\n",
       "      <td>0.033969</td>\n",
       "      <td>-0.024683</td>\n",
       "      <td>0.076641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.508286</td>\n",
       "      <td>0.332198</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260815 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0       0.002297  0.092887  0.101508  0.040677  0.071878  0.051259 -0.047023   \n",
       "1       0.002297  0.092887  0.101508  0.040677  0.071878  0.051259 -0.047023   \n",
       "2       0.002297  0.092887  0.101508  0.040677  0.071878  0.051259 -0.047023   \n",
       "3       0.002297  0.092887  0.101508  0.040677  0.071878  0.051259 -0.047023   \n",
       "4       0.002297  0.092887  0.101508  0.040677  0.071878  0.051259 -0.047023   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "260810 -0.067142 -0.019837  0.013006  0.021026  0.006870  0.004845  0.016654   \n",
       "260811 -0.047532  0.010358  0.045636  0.005799  0.008810  0.001899  0.020482   \n",
       "260812 -0.081734 -0.007846  0.022180  0.038925  0.012128 -0.011006  0.028191   \n",
       "260813 -0.048916 -0.006230  0.038012  0.018271  0.009925 -0.009537  0.029467   \n",
       "260814 -0.039720 -0.004852  0.021869 -0.005706  0.043847  0.013941  0.009544   \n",
       "\n",
       "               7         8         9  ...  NUM_PKTS_512_TO_1024_BYTES  \\\n",
       "0      -0.032768 -0.013434  0.097486  ...                    0.000000   \n",
       "1      -0.032768 -0.013434  0.097486  ...                    0.000000   \n",
       "2      -0.032768 -0.013434  0.097486  ...                    0.000000   \n",
       "3      -0.032768 -0.013434  0.097486  ...                    0.000000   \n",
       "4      -0.032768 -0.013434  0.097486  ...                    0.000000   \n",
       "...          ...       ...       ...  ...                         ...   \n",
       "260810  0.015265 -0.034830  0.093828  ...                    0.000000   \n",
       "260811  0.011307 -0.021919  0.104940  ...                    0.000000   \n",
       "260812  0.019945 -0.028569  0.089264  ...                    0.000030   \n",
       "260813  0.017500 -0.003603  0.097674  ...                    0.000000   \n",
       "260814  0.033969 -0.024683  0.076641  ...                    0.000062   \n",
       "\n",
       "        NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
       "0                          0.000000        0.046550         0.000000   \n",
       "1                          0.000000        0.046550         0.000000   \n",
       "2                          0.000000        0.046550         0.000000   \n",
       "3                          0.000000        0.046550         0.000000   \n",
       "4                          0.000000        0.046550         0.000000   \n",
       "...                             ...             ...              ...   \n",
       "260810                     0.000000        0.631349         0.631349   \n",
       "260811                     0.000000        0.769311         0.383695   \n",
       "260812                     0.000000        0.243872         0.869272   \n",
       "260813                     0.000000        0.859847         0.421561   \n",
       "260814                     0.000124        0.508286         0.332198   \n",
       "\n",
       "        ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "0        0.000001        0.000001      0.000001        0.000001   \n",
       "1        0.000001        0.000001      0.000001        0.000001   \n",
       "2        0.000001        0.000001      0.000001        0.000001   \n",
       "3        0.000001        0.000001      0.000001        0.000001   \n",
       "4        0.000001        0.000001      0.000001        0.000001   \n",
       "...           ...             ...           ...             ...   \n",
       "260810   0.000047        0.000047      0.000055        0.000055   \n",
       "260811   0.000028        0.000028      0.000033        0.000033   \n",
       "260812   0.000018        0.000018      0.000021        0.000021   \n",
       "260813   0.000031        0.000031      0.000037        0.000037   \n",
       "260814   0.000038        0.000038      0.000044        0.000044   \n",
       "\n",
       "        DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \n",
       "0                  0.0              0.000001  \n",
       "1                  0.0              0.000001  \n",
       "2                  0.0              0.000001  \n",
       "3                  0.0              0.000001  \n",
       "4                  0.0              0.000001  \n",
       "...                ...                   ...  \n",
       "260810             0.0              0.000046  \n",
       "260811             0.0              0.000028  \n",
       "260812             0.0              0.000018  \n",
       "260813             0.0              0.000031  \n",
       "260814             0.0              0.000037  \n",
       "\n",
       "[260815 rows x 295 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuse_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "62BUDLtO4mla"
   },
   "outputs": [],
   "source": [
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "2i48uLj74mla",
    "outputId": "a0dd33ee-824d-4328-a960-e656e3aaf0ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:19<01:04,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:45<00:00,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 7, 'con': 0.2}\n",
      "0.6936377703621189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5906    0.7880    0.6752    104997\n",
      "           1     0.8156    0.6319    0.7121    155818\n",
      "\n",
      "    accuracy                         0.6948    260815\n",
      "   macro avg     0.7031    0.7100    0.6936    260815\n",
      "weighted avg     0.7250    0.6948    0.6972    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,6,7,9,10] # cant be lower than 5 or 4\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    try:\n",
    "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
    "        clf_if.fit(benign_fuse_train_samples)\n",
    "    except Exception as e:\n",
    "        print(n_est)\n",
    "        continue\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "rK-Rng9q4mla",
    "outputId": "1796db22-cfb8-4bf8-9004-6420c08c3399"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:11<02:30,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:21<02:02,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:29<01:43,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:14<00:00,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 9, 'con': 0.1}\n",
      "0.37825055031847954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4095    0.9144    0.5657    104997\n",
      "           1     0.6592    0.1116    0.1908    155818\n",
      "\n",
      "    accuracy                         0.4348    260815\n",
      "   macro avg     0.5343    0.5130    0.3783    260815\n",
      "weighted avg     0.5587    0.4348    0.3417    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,6,7,9,10]\n",
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    try:\n",
    "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
    "        clf_if.fit(normal_fuse_train_samples)\n",
    "    except Exception as e:\n",
    "        print(n_est)\n",
    "        continue\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nd0-H7UT4mlc"
   },
   "outputs": [],
   "source": [
    "# HBOS  Embeddings+Raw (Multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDquxErU4mld"
   },
   "outputs": [],
   "source": [
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLBIT-Rc4mld",
    "outputId": "8162929e-4879-40e2-a040-afc57eafe7c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [05:45<00:00,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'con': 0.05}\n",
      "0.8471039149382792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9177    0.9571    374702\n",
      "           1     0.5837    1.0000    0.7371     43236\n",
      "\n",
      "    accuracy                         0.9262    417938\n",
      "   macro avg     0.7918    0.9588    0.8471    417938\n",
      "weighted avg     0.9569    0.9262    0.9343    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "n_est = [5,10,15,20,25,30]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    \n",
    "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDcX0mma4mld",
    "outputId": "a2b64cfc-d413-4ba0-9f24-b4935343c315"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [06:05<00:00, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'con': 0.1}\n",
      "0.8471039149382792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9177    0.9571    374702\n",
      "           1     0.5837    1.0000    0.7371     43236\n",
      "\n",
      "    accuracy                         0.9262    417938\n",
      "   macro avg     0.7918    0.9588    0.8471    417938\n",
      "weighted avg     0.9569    0.9262    0.9343    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,10,15,20,25,30]\n",
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    \n",
    "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbDOqrcy4mle"
   },
   "outputs": [],
   "source": [
    "##  PCA  Emb+Raw (Multimodal/Fusion) Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nga82Fw_4mle",
    "outputId": "0fe52043-af21-45c1-a404-040ab5845efc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [05:07<00:00,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'con': 0.1}\n",
      "0.8207887532486517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8987    0.9466    374702\n",
      "           1     0.5325    1.0000    0.6949     43236\n",
      "\n",
      "    accuracy                         0.9092    417938\n",
      "   macro avg     0.7662    0.9493    0.8208    417938\n",
      "weighted avg     0.9516    0.9092    0.9206    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.pca import PCA\n",
    "n_est = [5,10,15,20,25,30]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = PCA(n_components=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sg6AcAUW4mlf",
    "outputId": "a9949458-96cf-44dc-b4f6-c73458cb2719"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [05:49<00:00,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 15, 'con': 0.2}\n",
      "0.8085873162698853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8893    0.9414    374702\n",
      "           1     0.5103    1.0000    0.6758     43236\n",
      "\n",
      "    accuracy                         0.9007    417938\n",
      "   macro avg     0.7552    0.9446    0.8086    417938\n",
      "weighted avg     0.9493    0.9007    0.9139    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,10,15,20,25,30]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = PCA(n_components=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yi8SO3tL4mlg"
   },
   "outputs": [],
   "source": [
    "##  IF  Emb+Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(benign_fuse_train_samples.columns)):\n",
    "    benign_fuse_train_samples.rename(columns={benign_fuse_train_samples.columns[i]: f\"feature {i}\"}, inplace=True)\n",
    "\n",
    "for i in range(len(normal_fuse_train_samples.columns)):\n",
    "    normal_fuse_train_samples.rename(columns={normal_fuse_train_samples.columns[i]: f\"feature {i}\"}, inplace=True)\n",
    "\n",
    "for i in range(len(fuse_test_samples.columns)):\n",
    "    fuse_test_samples.rename(columns={fuse_test_samples.columns[i]: f\"feature {i}\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9D0m4vb04mlg",
    "outputId": "bd5a55e6-ac70-4943-9b28-92474b5fb9e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "  4%|▍         | 1/24 [00:02<00:54,  2.36s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "  8%|▊         | 2/24 [00:04<00:51,  2.34s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 12%|█▎        | 3/24 [00:07<00:48,  2.33s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 17%|█▋        | 4/24 [00:09<00:46,  2.31s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 21%|██        | 5/24 [00:11<00:44,  2.32s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 25%|██▌       | 6/24 [00:13<00:40,  2.27s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 29%|██▉       | 7/24 [00:16<00:43,  2.56s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 33%|███▎      | 8/24 [00:20<00:44,  2.77s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 38%|███▊      | 9/24 [00:23<00:43,  2.90s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 42%|████▏     | 10/24 [00:26<00:41,  2.99s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 46%|████▌     | 11/24 [00:29<00:39,  3.06s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 50%|█████     | 12/24 [00:32<00:37,  3.11s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 54%|█████▍    | 13/24 [00:38<00:41,  3.78s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 58%|█████▊    | 14/24 [00:43<00:42,  4.22s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 62%|██████▎   | 15/24 [00:48<00:40,  4.50s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 67%|██████▋   | 16/24 [00:53<00:36,  4.58s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 71%|███████   | 17/24 [00:58<00:33,  4.81s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 75%|███████▌  | 18/24 [01:03<00:29,  4.91s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 79%|███████▉  | 19/24 [01:10<00:27,  5.50s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 83%|████████▎ | 20/24 [01:17<00:23,  5.85s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 21/24 [01:24<00:18,  6.10s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 22/24 [01:30<00:12,  6.29s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 23/24 [01:37<00:06,  6.42s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "100%|██████████| 24/24 [01:44<00:00,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50, 'con': 0.1}\n",
      "0.820368662501618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8984    0.9465    374702\n",
      "           1     0.5317    1.0000    0.6943     43236\n",
      "\n",
      "    accuracy                         0.9089    417938\n",
      "   macro avg     0.7659    0.9492    0.8204    417938\n",
      "weighted avg     0.9516    0.9089    0.9204    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "n_est = [20, 50, 100, 150]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples.to_numpy())\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCj-3u4t4mlg",
    "outputId": "5f6b1720-9662-4704-ba96-dd57ee32a900"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:52<00:00,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 150, 'con': 0.2}\n",
      "0.802806141381684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9991    0.8861    0.9392    374702\n",
      "           1     0.5015    0.9928    0.6664     43236\n",
      "\n",
      "    accuracy                         0.8972    417938\n",
      "   macro avg     0.7503    0.9395    0.8028    417938\n",
      "weighted avg     0.9476    0.8972    0.9110    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "n_est = [20, 50, 100, 150]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised attack classification (Fusion)\n",
    "\n",
    "We now train a supervised classifier on the fused features to predict multi-class attack labels:\n",
    "- Features: embeddings + raw numeric features from `df_fuse_train`/`df_fuse_test` (without `Label`, `Attacks`).\n",
    "- Target: `Attacks` (encoded integer classes from earlier `LabelEncoder`).\n",
    "- Model: HistGradientBoostingClassifier (fast, strong on tabular data). Class imbalance handled via per-sample weights.\n",
    "- Metrics: macro F1, per-class report, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare supervised train/test for attack classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.utils import class_weight\n",
    "import pickle\n",
    "\n",
    "# Build train features/targets from already prepared fused DataFrames\n",
    "X_sup_train = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_sup_test = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights to mitigate class imbalance on training set\n",
    "classes = np.unique(y_sup_train)\n",
    "class_w = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes, y=y_sup_train\n",
    ")\n",
    "class_to_w = {c: w for c, w in zip(classes, class_w)}\n",
    "sample_weight = y_sup_train.map(class_to_w).values\n",
    "\n",
    "# Feature names to all str\n",
    "X_sup_train.columns = X_sup_train.columns.map(str)\n",
    "X_sup_test.columns = X_sup_test.columns.map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Methods (Fused Features)\n",
    "\n",
    "Now we'll compare multiple classification algorithms on the fused features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [11:46<00:00, 78.50s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 20}\n",
      "Best Macro F1: 0.7515\n",
      "Model saved to: best_rf_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8545    0.9701    0.9086     62919\n",
      "           1     1.0000    1.0000    1.0000     12304\n",
      "           2     0.8161    0.7396    0.7760        96\n",
      "           3     0.3889    0.8750    0.5385        32\n",
      "           4     1.0000    0.9529    0.9759     62294\n",
      "           5     1.0000    1.0000    1.0000       200\n",
      "           6     1.0000    0.8917    0.9427     17396\n",
      "           7     1.0000    0.5000    0.6667      3620\n",
      "           8     1.0000    0.5000    0.6667      5930\n",
      "           9     0.2144    0.5000    0.3001      6334\n",
      "          10     1.0000    1.0000    1.0000      2116\n",
      "          11     0.7856    0.5000    0.6111     23204\n",
      "          12     0.8483    0.9291    0.8869     11248\n",
      "          13     0.0000    0.0000    0.0000        24\n",
      "          14     1.0000    1.0000    1.0000     11236\n",
      "\n",
      "    accuracy                         0.8763    218953\n",
      "   macro avg     0.7939    0.7572    0.7515    218953\n",
      "weighted avg     0.9047    0.8763    0.8802    218953\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with Grid Search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            rf_clf = RandomForestClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            rf_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_rf = rf_clf.predict(X_sup_test)\n",
    "            rf_f1 = f1_score(y_sup_test, y_pred_rf, average='macro')\n",
    "            \n",
    "            if rf_f1 > score:\n",
    "                score = rf_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = rf_clf\n",
    "                # Save best model\n",
    "                with open('best_rf_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(rf_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_rf_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Random Forest: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [09:34:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "100%|██████████| 27/27 [29:03<00:00, 64.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7945\n",
      "Model saved to: best_xgb_classifier_fused.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9368    0.9688    0.9525     62919\n",
      "           1     1.0000    1.0000    1.0000     12304\n",
      "           2     0.8706    0.7708    0.8177        96\n",
      "           3     0.3830    0.5625    0.4557        32\n",
      "           4     1.0000    1.0000    1.0000     62294\n",
      "           5     1.0000    1.0000    1.0000       200\n",
      "           6     1.0000    0.9443    0.9714     17396\n",
      "           7     1.0000    0.5000    0.6667      3620\n",
      "           8     1.0000    0.9998    0.9999      5930\n",
      "           9     0.2144    0.5000    0.3001      6334\n",
      "          10     1.0000    0.9830    0.9914      2116\n",
      "          11     0.7856    0.5000    0.6111     23204\n",
      "          12     0.8363    0.8847    0.8598     11248\n",
      "          13     0.2581    0.3333    0.2909        24\n",
      "          14     1.0000    1.0000    1.0000     11236\n",
      "\n",
      "    accuracy                         0.9046    218953\n",
      "   macro avg     0.8190    0.7965    0.7945    218953\n",
      "weighted avg     0.9277    0.9046    0.9096    218953\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# XGBoost with Grid Search\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    import pickle\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST CLASSIFIER (Fused Features)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            xgb_clf = XGBClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                learning_rate=lr,\n",
    "                random_state=13,\n",
    "                tree_method='hist', \n",
    "                device=\"cuda\"\n",
    "            )\n",
    "            \n",
    "            xgb_clf.fit(X_sup_train, y_sup_train, sample_weight=sample_weight)\n",
    "            y_pred_xgb = xgb_clf.predict(X_sup_test)\n",
    "            xgb_f1 = f1_score(y_sup_test, y_pred_xgb, average='macro')\n",
    "            \n",
    "            if xgb_f1 > score:\n",
    "                score = xgb_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = xgb_clf\n",
    "                # Save best model\n",
    "                xgb_clf.save_model('best_xgb_classifier_fused.json')\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_xgb_classifier_fused.json\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed. XGBoost might not support your GPU.\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CatBoost Grid Search (Expanded)...\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 2081.3125 Total: 5806.3125\n",
      "  4%|▎         | 1/27 [00:11<05:06, 11.78s/it]Warning: less than 75% GPU memory available for training. Free: 2079.3125 Total: 5806.3125\n",
      "  7%|▋         | 2/27 [00:23<04:46, 11.48s/it]Warning: less than 75% GPU memory available for training. Free: 2079.3125 Total: 5806.3125\n",
      " 11%|█         | 3/27 [00:34<04:32, 11.35s/it]Warning: less than 75% GPU memory available for training. Free: 2079.3125 Total: 5806.3125\n",
      " 15%|█▍        | 4/27 [01:05<07:19, 19.10s/it]Warning: less than 75% GPU memory available for training. Free: 2079.3125 Total: 5806.3125\n",
      " 19%|█▊        | 5/27 [01:33<08:12, 22.37s/it]Warning: less than 75% GPU memory available for training. Free: 2079.3125 Total: 5806.3125\n",
      " 22%|██▏       | 6/27 [02:00<08:27, 24.15s/it]Warning: less than 75% GPU memory available for training. Free: 2079.3125 Total: 5806.3125\n"
     ]
    }
   ],
   "source": [
    "# CatBoost with Grid Search (Expanded, no l2_leaf_reg/border_count, fixed best score logic)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"Starting CatBoost Grid Search (Expanded)...\")\n",
    "    \n",
    "    # Expanded hyperparameter grid\n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'  # Use 'CPU' if GPU not available\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_cat = cat_clf.predict(X_sup_test)\n",
    "            cat_f1 = f1_score(y_sup_test, y_pred_cat, average='macro')\n",
    "            \n",
    "            if cat_f1 > best_score:\n",
    "                best_score = cat_f1\n",
    "                best_params = {\n",
    "                    'iterations': iterations,\n",
    "                    'depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for fused features\n",
    "                best_model_path = \"best_catboost_classifier_fused.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEST CATBOOST HYPERPARAMETERS (Fused Features):\")\n",
    "    print(best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    if best_model_path:\n",
    "        print(f\"\\nBest CatBoost model saved to: {best_model_path}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    y_pred_best = best_model.predict(X_sup_test)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_sup_test, y_pred_best, digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed. Install with: pip install catboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [06:13<00:00, 41.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10}\n",
      "Best Macro F1: 0.8262\n",
      "Model saved to: best_et_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9986    0.9531    0.9753    104997\n",
      "           1     0.9981    0.9992    0.9986     12438\n",
      "           2     0.8636    0.7451    0.8000       102\n",
      "           3     0.6000    0.3529    0.4444        34\n",
      "           4     1.0000    1.0000    1.0000     61790\n",
      "           5     1.0000    0.9894    0.9947       188\n",
      "           6     1.0000    1.0000    1.0000     17362\n",
      "           7     1.0000    1.0000    1.0000      3632\n",
      "           8     1.0000    1.0000    1.0000      5890\n",
      "           9     0.0000    0.0000    0.0000      6320\n",
      "          10     1.0000    1.0000    1.0000      2164\n",
      "          11     0.7862    1.0000    0.8803     23242\n",
      "          12     0.6957    0.9868    0.8161     11314\n",
      "          13     0.3261    0.9375    0.4839        32\n",
      "          14     1.0000    1.0000    1.0000     11310\n",
      "\n",
      "    accuracy                         0.9561    260815\n",
      "   macro avg     0.8179    0.8643    0.8262    260815\n",
      "weighted avg     0.9427    0.9561    0.9469    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            et_clf = ExtraTreesClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            et_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_et = et_clf.predict(X_sup_test)\n",
    "            et_f1 = f1_score(y_sup_test, y_pred_et, average='macro')\n",
    "            \n",
    "            if et_f1 > score:\n",
    "                score = et_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = et_clf\n",
    "                # Save best model\n",
    "                with open('best_et_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(et_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_et_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Extra Trees: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Features Classification (Comparison Baseline)\n",
    "\n",
    "Now we'll train classifiers on **raw features only** (without graph embeddings) to compare the benefit of multimodal fusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw feature shape - Train: (304665, 39), Test: (130572, 39)\n",
      "Number of classes: 15\n"
     ]
    }
   ],
   "source": [
    "# Prepare raw features (without embeddings)\n",
    "# Use only the original numeric features from X_train/X_test\n",
    "\n",
    "X_raw_train = X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_train = y_train[\"Attack\"].copy()\n",
    "\n",
    "X_raw_test = X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_test = y_test[\"Attack\"].copy()\n",
    "\n",
    "# Encode labels\n",
    "y_raw_train_encoded = lab_enc.transform(y_train[\"Attack\"])\n",
    "y_raw_test_encoded = lab_enc.transform(y_test[\"Attack\"])\n",
    "\n",
    "# Compute sample weights\n",
    "classes_raw = np.unique(y_raw_train_encoded)\n",
    "class_w_raw = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_raw, y=y_raw_train_encoded\n",
    ")\n",
    "class_to_w_raw = {c: w for c, w in zip(classes_raw, class_w_raw)}\n",
    "sample_weight_raw = pd.Series(y_raw_train_encoded).map(class_to_w_raw).values\n",
    "\n",
    "# Feature names to str\n",
    "X_raw_train.columns = X_raw_train.columns.map(str)\n",
    "X_raw_test.columns = X_raw_test.columns.map(str)\n",
    "\n",
    "print(f\"Raw feature shape - Train: {X_raw_train.shape}, Test: {X_raw_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_raw_train_encoded))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Raw Features Only)\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [04:12<00:00, 28.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 30}\n",
      "Best Macro F1: 0.6979\n",
      "Model saved to: best_rf_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9544    0.7950    0.8675     52663\n",
      "           1     1.0000    0.9997    0.9998      6219\n",
      "           2     0.1386    0.4510    0.2120        51\n",
      "           3     0.3846    0.8824    0.5357        17\n",
      "           4     0.9999    1.0000    1.0000     30895\n",
      "           5     0.8440    0.9787    0.9064        94\n",
      "           6     0.9988    0.9980    0.9984      8681\n",
      "           7     0.9994    1.0000    0.9997      1816\n",
      "           8     1.0000    0.9997    0.9998      2945\n",
      "           9     0.2138    1.0000    0.3523      3160\n",
      "          10     1.0000    0.9982    0.9991      1082\n",
      "          11     0.0000    0.0000    0.0000     11621\n",
      "          12     0.2557    0.6470    0.3665      5657\n",
      "          13     0.3000    0.1875    0.2308        16\n",
      "          14     1.0000    1.0000    1.0000      5655\n",
      "\n",
      "    accuracy                         0.8125    130572\n",
      "   macro avg     0.6726    0.7958    0.6979    130572\n",
      "weighted avg     0.8406    0.8125    0.8138    130572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Raw Features Only)\")\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = rf_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Raw Features Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:19:42] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "100%|██████████| 27/27 [05:20<00:00, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7387\n",
      "Model saved to: best_xgb_classifier_raw.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9551    0.7654    0.8498     52663\n",
      "           1     0.9994    1.0000    0.9997      6219\n",
      "           2     0.2500    0.5882    0.3509        51\n",
      "           3     0.3611    0.7647    0.4906        17\n",
      "           4     0.9998    1.0000    0.9999     30895\n",
      "           5     0.8426    0.9681    0.9010        94\n",
      "           6     0.9988    0.9978    0.9983      8681\n",
      "           7     0.9989    1.0000    0.9994      1816\n",
      "           8     1.0000    1.0000    1.0000      2945\n",
      "           9     0.0000    0.0000    0.0000      3160\n",
      "          10     0.9972    0.9991    0.9982      1082\n",
      "          11     0.7862    1.0000    0.8803     11621\n",
      "          12     0.2341    0.6627    0.3460      5657\n",
      "          13     0.2857    0.2500    0.2667        16\n",
      "          14     1.0000    1.0000    1.0000      5655\n",
      "\n",
      "    accuracy                         0.8661    130572\n",
      "   macro avg     0.7139    0.7997    0.7387    130572\n",
      "weighted avg     0.9047    0.8661    0.8756    130572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Raw Features Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='cuda'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_raw_train, y_raw_train_encoded, sample_weight=sample_weight_raw)\n",
    "        y_pred = xgb_clf.predict(X_raw_test)\n",
    "        f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_raw.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_raw.json\\n\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Raw Features Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 3089.3125 Total: 5806.3125\n",
      "  4%|▎         | 1/27 [00:02<01:10,  2.72s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      "  7%|▋         | 2/27 [00:05<01:05,  2.60s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 11%|█         | 3/27 [00:07<01:01,  2.56s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 15%|█▍        | 4/27 [00:13<01:31,  3.99s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 19%|█▊        | 5/27 [00:19<01:42,  4.68s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 22%|██▏       | 6/27 [00:25<01:46,  5.06s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 26%|██▌       | 7/27 [00:38<02:32,  7.63s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 30%|██▉       | 8/27 [00:51<02:55,  9.22s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 33%|███▎      | 9/27 [01:03<03:03, 10.20s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 37%|███▋      | 10/27 [01:07<02:19,  8.23s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 41%|████      | 11/27 [01:10<01:49,  6.82s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 44%|████▍     | 12/27 [01:14<01:27,  5.86s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 48%|████▊     | 13/27 [01:23<01:35,  6.85s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 52%|█████▏    | 14/27 [01:32<01:35,  7.38s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 56%|█████▌    | 15/27 [01:40<01:32,  7.75s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 59%|█████▉    | 16/27 [02:00<02:04, 11.33s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 63%|██████▎   | 17/27 [02:19<02:15, 13.60s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 67%|██████▋   | 18/27 [02:38<02:16, 15.18s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 70%|███████   | 19/27 [02:44<01:39, 12.49s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 74%|███████▍  | 20/27 [02:50<01:13, 10.50s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 78%|███████▊  | 21/27 [02:56<00:54,  9.10s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 81%|████████▏ | 22/27 [03:10<00:53, 10.78s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 85%|████████▌ | 23/27 [03:24<00:46, 11.71s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 89%|████████▉ | 24/27 [03:38<00:37, 12.34s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 93%|█████████▎| 25/27 [04:10<00:36, 18.22s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 96%|█████████▋| 26/27 [04:41<00:21, 21.98s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      "100%|██████████| 27/27 [05:12<00:00, 11.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7170\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_raw.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9556    0.7538    0.8428     52663\n",
      "           1     0.9974    1.0000    0.9987      6219\n",
      "           2     0.1571    0.6471    0.2529        51\n",
      "           3     0.2456    0.8235    0.3784        17\n",
      "           4     0.9997    1.0000    0.9999     30895\n",
      "           5     0.8174    1.0000    0.8995        94\n",
      "           6     0.9982    0.9976    0.9979      8681\n",
      "           7     0.9983    0.9989    0.9986      1816\n",
      "           8     0.9990    0.9980    0.9985      2945\n",
      "           9     0.0000    0.0000    0.0000      3160\n",
      "          10     0.9854    1.0000    0.9927      1082\n",
      "          11     0.7862    1.0000    0.8803     11621\n",
      "          12     0.2289    0.6689    0.3410      5657\n",
      "          13     0.2857    0.1250    0.1739        16\n",
      "          14     1.0000    1.0000    1.0000      5655\n",
      "\n",
      "    accuracy                         0.8617    130572\n",
      "   macro avg     0.6970    0.8008    0.7170    130572\n",
      "weighted avg     0.9043    0.8617    0.8723    130572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Raw Features Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "            y_pred = cat_clf.predict(X_raw_test)\n",
    "            f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for raw features\n",
    "                best_model_path = \"best_catboost_classifier_raw.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Raw Features Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:50<00:00, 18.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 30}\n",
      "Best Macro F1: 0.7311\n",
      "Model saved to: best_et_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9492    0.8420    0.8924     52663\n",
      "           1     0.9997    0.9998    0.9998      6219\n",
      "           2     0.1557    0.3725    0.2197        51\n",
      "           3     0.3684    0.8235    0.5091        17\n",
      "           4     1.0000    1.0000    1.0000     30895\n",
      "           5     0.8542    0.8723    0.8632        94\n",
      "           6     0.9977    0.9984    0.9980      8681\n",
      "           7     1.0000    1.0000    1.0000      1816\n",
      "           8     1.0000    1.0000    1.0000      2945\n",
      "           9     0.0000    0.0000    0.0000      3160\n",
      "          10     0.9991    0.9991    0.9991      1082\n",
      "          11     0.7862    1.0000    0.8803     11621\n",
      "          12     0.2858    0.5816    0.3833      5657\n",
      "          13     0.2727    0.1875    0.2222        16\n",
      "          14     1.0000    1.0000    1.0000      5655\n",
      "\n",
      "    accuracy                         0.8934    130572\n",
      "   macro avg     0.7112    0.7785    0.7311    130572\n",
      "weighted avg     0.9046    0.8934    0.8943    130572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Raw Features Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = et_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Only Classification (Graph Features)\n",
    "\n",
    "Now we'll train classifiers on **embeddings only** (graph features without raw features) to isolate the value of graph-based learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape - Train: (608554, 256), Test: (260815, 256)\n",
      "Number of classes: 15\n",
      "Using only graph embeddings (no raw features)\n"
     ]
    }
   ],
   "source": [
    "# Prepare embeddings-only features (graph features without raw data)\n",
    "# Extract only the embedding columns (first 256 dimensions from graph encoder)\n",
    "\n",
    "# From the fused dataframes, extract only embedding columns\n",
    "# df_fuse_train has: [0-255] = embeddings, [256+] = raw features\n",
    "num_embedding_dims = 256  # Based on the DGI encoder output dimension\n",
    "\n",
    "X_emb_train = df_fuse_train.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_emb_test = df_fuse_test.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights\n",
    "classes_emb = np.unique(y_emb_train)\n",
    "class_w_emb = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_emb, y=y_emb_train\n",
    ")\n",
    "class_to_w_emb = {c: w for c, w in zip(classes_emb, class_w_emb)}\n",
    "sample_weight_emb = y_emb_train.map(class_to_w_emb).values\n",
    "\n",
    "# Feature names to str\n",
    "X_emb_train.columns = X_emb_train.columns.map(str)\n",
    "X_emb_test.columns = X_emb_test.columns.map(str)\n",
    "\n",
    "print(f\"Embeddings shape - Train: {X_emb_train.shape}, Test: {X_emb_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_emb_train))}\")\n",
    "print(f\"Using only graph embeddings (no raw features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [15:00<00:00, 100.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 10}\n",
      "Best Macro F1: 0.4367\n",
      "Model saved to: best_rf_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7489    0.9592    0.8411    104997\n",
      "           1     0.9998    0.9522    0.9755     12438\n",
      "           2     0.8043    0.7255    0.7629       102\n",
      "           3     0.8000    0.1176    0.2051        34\n",
      "           4     0.9970    0.5491    0.7082     61790\n",
      "           5     0.0035    0.4096    0.0070       188\n",
      "           6     1.0000    0.9542    0.9765     17362\n",
      "           7     0.0000    0.0000    0.0000      3632\n",
      "           8     0.0000    0.0000    0.0000      5890\n",
      "           9     0.0000    0.0000    0.0000      6320\n",
      "          10     0.0000    0.0000    0.0000      2164\n",
      "          11     0.7862    0.5000    0.6113     23242\n",
      "          12     0.6843    0.9245    0.7865     11314\n",
      "          13     0.0051    1.0000    0.0101        32\n",
      "          14     1.0000    0.5000    0.6667     11310\n",
      "\n",
      "    accuracy                         0.7322    260815\n",
      "   macro avg     0.5219    0.5061    0.4367    260815\n",
      "weighted avg     0.7955    0.7322    0.7357    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = rf_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [30:41<00:00, 68.21s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "Best Macro F1: 0.5536\n",
      "Model saved to: best_xgb_classifier_embeddings.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8305    0.9623    0.8916    104997\n",
      "           1     0.9999    0.8780    0.9350     12438\n",
      "           2     0.0272    0.8627    0.0528       102\n",
      "           3     0.8000    0.1176    0.2051        34\n",
      "           4     0.9969    0.2991    0.4602     61790\n",
      "           5     0.0032    0.6436    0.0065       188\n",
      "           6     1.0000    1.0000    1.0000     17362\n",
      "           7     1.0000    1.0000    1.0000      3632\n",
      "           8     1.0000    0.5000    0.6667      5890\n",
      "           9     0.0000    0.0000    0.0000      6320\n",
      "          10     1.0000    0.5000    0.6667      2164\n",
      "          11     0.7862    0.5000    0.6113     23242\n",
      "          12     0.6982    0.9220    0.7947     11314\n",
      "          13     0.0066    0.6562    0.0131        32\n",
      "          14     1.0000    1.0000    1.0000     11310\n",
      "\n",
      "    accuracy                         0.7249    260815\n",
      "   macro avg     0.6766    0.6561    0.5536    260815\n",
      "weighted avg     0.8734    0.7249    0.7460    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Embeddings Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='gpu'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_emb_train, y_emb_train, sample_weight=sample_weight_emb)\n",
    "        y_pred = xgb_clf.predict(X_emb_test)\n",
    "        f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_embeddings.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_embeddings.json\\n\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Embeddings Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 3071.3125 Total: 5806.3125\n",
      "  4%|▎         | 1/27 [00:12<05:20, 12.32s/it]Warning: less than 75% GPU memory available for training. Free: 3071.3125 Total: 5806.3125\n",
      "  7%|▋         | 2/27 [00:23<04:58, 11.93s/it]Warning: less than 75% GPU memory available for training. Free: 3071.3125 Total: 5806.3125\n",
      " 11%|█         | 3/27 [00:35<04:41, 11.75s/it]Warning: less than 75% GPU memory available for training. Free: 3071.3125 Total: 5806.3125\n",
      " 15%|█▍        | 4/27 [01:05<07:15, 18.94s/it]Warning: less than 75% GPU memory available for training. Free: 3071.3125 Total: 5806.3125\n",
      " 19%|█▊        | 5/27 [01:32<08:01, 21.87s/it]Warning: less than 75% GPU memory available for training. Free: 3071.3125 Total: 5806.3125\n",
      " 22%|██▏       | 6/27 [01:58<08:09, 23.31s/it]Warning: less than 75% GPU memory available for training. Free: 3071.3125 Total: 5806.3125\n",
      " 22%|██▏       | 6/27 [02:50<09:55, 28.37s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 34\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     cat_clf \u001b[38;5;241m=\u001b[39m CatBoostClassifier(\n\u001b[1;32m     25\u001b[0m         iterations\u001b[38;5;241m=\u001b[39miterations,\n\u001b[1;32m     26\u001b[0m         depth\u001b[38;5;241m=\u001b[39mdepth,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m         task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     32\u001b[0m     )\n\u001b[0;32m---> 34\u001b[0m     \u001b[43mcat_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_emb_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_emb_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m cat_clf\u001b[38;5;241m.\u001b[39mpredict(X_emb_test)\n\u001b[1;32m     36\u001b[0m     f1 \u001b[38;5;241m=\u001b[39m f1_score(y_emb_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/catboost/core.py:5245\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5243\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5245\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5246\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5247\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/catboost/core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2410\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/catboost/core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:5023\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:5072\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Embeddings Only - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Embeddings Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_emb_train, y_emb_train)\n",
    "            y_pred = cat_clf.predict(X_emb_test)\n",
    "            f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for embeddings\n",
    "                best_model_path = \"best_catboost_classifier_embeddings.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [05:23<00:00, 35.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 10}\n",
      "Best Macro F1: 0.6906\n",
      "Model saved to: best_et_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9987    0.9543    0.9760    104997\n",
      "           1     0.9982    0.9761    0.9870     12438\n",
      "           2     0.8636    0.7451    0.8000       102\n",
      "           3     0.8000    0.2353    0.3636        34\n",
      "           4     0.9969    0.5996    0.7488     61790\n",
      "           5     0.0033    0.4415    0.0066       188\n",
      "           6     1.0000    1.0000    1.0000     17362\n",
      "           7     1.0000    1.0000    1.0000      3632\n",
      "           8     1.0000    1.0000    1.0000      5890\n",
      "           9     0.2138    1.0000    0.3523      6320\n",
      "          10     1.0000    1.0000    1.0000      2164\n",
      "          11     0.0000    0.0000    0.0000     23242\n",
      "          12     0.6897    0.9881    0.8123     11314\n",
      "          13     0.2083    0.6250    0.3125        32\n",
      "          14     1.0000    1.0000    1.0000     11310\n",
      "\n",
      "    accuracy                         0.7953    260815\n",
      "   macro avg     0.7182    0.7710    0.6906    260815\n",
      "weighted avg     0.8761    0.7953    0.8163    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = et_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Comparison Table\n",
    "\n",
    "Create a comparison table of all methods (Fused vs Raw features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\n",
      "===============================================================================================\n",
      "\n",
      "Instructions:\n",
      "1. Run all cells above to get F1 scores for each method\n",
      "2. Record the best Macro F1 score for each method\n",
      "3. Compare three approaches:\n",
      "   - Fused Features: Embeddings + Raw (Multimodal)\n",
      "   - Embeddings Only: Graph features only\n",
      "   - Raw Features: Traditional features only\n",
      "\n",
      "Expected format:\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Method               Fused (Emb+Raw)           Embeddings Only           Raw Only                 \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Random Forest        [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "XGBoost              [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "CatBoost             [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "Extra Trees          [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysis:\n",
      "- Fused features should show best performance (multimodal learning)\n",
      "- Embeddings capture structural/graph patterns\n",
      "- Raw features provide traditional statistical information\n",
      "- Compare to understand the contribution of each modality\n"
     ]
    }
   ],
   "source": [
    "# Create a summary comparison table\n",
    "# NOTE: After running all cells above, manually collect the F1 scores and create a comparison\n",
    "\n",
    "print(\"=\"*95)\n",
    "print(\"PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\")\n",
    "print(\"=\"*95)\n",
    "print(\"\\nInstructions:\")\n",
    "print(\"1. Run all cells above to get F1 scores for each method\")\n",
    "print(\"2. Record the best Macro F1 score for each method\")\n",
    "print(\"3. Compare three approaches:\")\n",
    "print(\"   - Fused Features: Embeddings + Raw (Multimodal)\")\n",
    "print(\"   - Embeddings Only: Graph features only\")\n",
    "print(\"   - Raw Features: Traditional features only\")\n",
    "print(\"\\nExpected format:\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Method':<20} {'Fused (Emb+Raw)':<25} {'Embeddings Only':<25} {'Raw Only':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Random Forest':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'XGBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'CatBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'Extra Trees':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"- Fused features should show best performance (multimodal learning)\")\n",
    "print(\"- Embeddings capture structural/graph patterns\")\n",
    "print(\"- Raw features provide traditional statistical information\")\n",
    "print(\"- Compare to understand the contribution of each modality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights & Interpretation\n",
    "\n",
    "After running all experiments, analyze the results to answer:\n",
    "\n",
    "1. **Which approach performs best overall?**\n",
    "   - Fused features (multimodal) should ideally outperform single modalities\n",
    "   - Compare the magnitude of improvements\n",
    "\n",
    "2. **What is the value of graph embeddings?**\n",
    "   - Compare Embeddings-only vs Raw-only to see if graph structure helps\n",
    "   - If embeddings alone beat raw features, graph learning is beneficial\n",
    "\n",
    "3. **Is multimodal fusion effective?**\n",
    "   - Compare Fused vs (Embeddings + Raw separately)\n",
    "   - Synergy should provide additional gains beyond individual modalities\n",
    "\n",
    "4. **Which classifier is most suitable?**\n",
    "   - Identify the best performing algorithm for each feature type\n",
    "   - Consider computational cost vs accuracy trade-offs\n",
    "\n",
    "5. **Feature contribution analysis:**\n",
    "   - If Fused ≈ Embeddings > Raw: Graph structure dominates\n",
    "   - If Fused ≈ Raw > Embeddings: Traditional features dominate\n",
    "   - If Fused > Both: True synergy from multimodal learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
