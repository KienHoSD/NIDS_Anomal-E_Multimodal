{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Hjc3iIihKLn-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from dgl.data import DGLDataset\n",
    "import dgl\n",
    "import time\n",
    "import networkx as nx\n",
    "import category_encoders as ce\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "from typing import *\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SvWHb_BpKsLq"
   },
   "outputs": [],
   "source": [
    "file_name = \"NF-UNSW-NB15-v3.parquet\"\n",
    "data = pd.read_parquet(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "fqly1y-LMwYS",
    "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    2151027\n",
       "1      91904\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3t4OREvSM33h"
   },
   "outputs": [],
   "source": [
    "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
    "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
    "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
    "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bTtHq0XqNXxI"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUNIP-8zNkn9",
    "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Fuzzers', 'Exploits', 'Backdoor', 'Generic', 'DoS',\n",
       "       'Reconnaissance', 'Shellcode', 'Analysis', 'Worms'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Attack.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    91904\n",
       "0    43021\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the dataset based on your needs (machine capacity) ideally ~500k rows\n",
    "data_attack = data[data['Label'] == 1]\n",
    "data_benign = data[data['Label'] == 0].sample(frac=0.02, random_state=13)\n",
    "data = pd.concat([data_attack, data_benign], axis=0)\n",
    "data = data.sample(frac=1, random_state=13).reset_index(drop=True)\n",
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "lcfAP6ViOp-J",
    "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLOW_START_MILLISECONDS</th>\n",
       "      <th>FLOW_END_MILLISECONDS</th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>...</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>SRC_TO_DST_IAT_MIN</th>\n",
       "      <th>SRC_TO_DST_IAT_MAX</th>\n",
       "      <th>SRC_TO_DST_IAT_AVG</th>\n",
       "      <th>SRC_TO_DST_IAT_STDDEV</th>\n",
       "      <th>DST_TO_SRC_IAT_MIN</th>\n",
       "      <th>DST_TO_SRC_IAT_MAX</th>\n",
       "      <th>DST_TO_SRC_IAT_AVG</th>\n",
       "      <th>DST_TO_SRC_IAT_STDDEV</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Analysis</th>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>...</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Backdoor</th>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>...</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "      <td>3451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>...</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "      <td>43021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS</th>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>...</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "      <td>5050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exploits</th>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>...</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "      <td>38816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuzzers</th>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>...</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "      <td>25588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generic</th>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>...</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "      <td>4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reconnaissance</th>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>...</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "      <td>11291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shellcode</th>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>...</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "      <td>1586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Worms</th>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                FLOW_START_MILLISECONDS  FLOW_END_MILLISECONDS  IPV4_SRC_ADDR  \\\n",
       "Attack                                                                          \n",
       "Analysis                           1226                   1226           1226   \n",
       "Backdoor                           3451                   3451           3451   \n",
       "Benign                            43021                  43021          43021   \n",
       "DoS                                5050                   5050           5050   \n",
       "Exploits                          38816                  38816          38816   \n",
       "Fuzzers                           25588                  25588          25588   \n",
       "Generic                            4760                   4760           4760   \n",
       "Reconnaissance                    11291                  11291          11291   \n",
       "Shellcode                          1586                   1586           1586   \n",
       "Worms                               136                    136            136   \n",
       "\n",
       "                IPV4_DST_ADDR  PROTOCOL  L7_PROTO  IN_BYTES  IN_PKTS  \\\n",
       "Attack                                                                 \n",
       "Analysis                 1226      1226      1226      1226     1226   \n",
       "Backdoor                 3451      3451      3451      3451     3451   \n",
       "Benign                  43021     43021     43021     43021    43021   \n",
       "DoS                      5050      5050      5050      5050     5050   \n",
       "Exploits                38816     38816     38816     38816    38816   \n",
       "Fuzzers                 25588     25588     25588     25588    25588   \n",
       "Generic                  4760      4760      4760      4760     4760   \n",
       "Reconnaissance          11291     11291     11291     11291    11291   \n",
       "Shellcode                1586      1586      1586      1586     1586   \n",
       "Worms                     136       136       136       136      136   \n",
       "\n",
       "                OUT_BYTES  OUT_PKTS  ...  FTP_COMMAND_RET_CODE  \\\n",
       "Attack                               ...                         \n",
       "Analysis             1226      1226  ...                  1226   \n",
       "Backdoor             3451      3451  ...                  3451   \n",
       "Benign              43021     43021  ...                 43021   \n",
       "DoS                  5050      5050  ...                  5050   \n",
       "Exploits            38816     38816  ...                 38816   \n",
       "Fuzzers             25588     25588  ...                 25588   \n",
       "Generic              4760      4760  ...                  4760   \n",
       "Reconnaissance      11291     11291  ...                 11291   \n",
       "Shellcode            1586      1586  ...                  1586   \n",
       "Worms                 136       136  ...                   136   \n",
       "\n",
       "                SRC_TO_DST_IAT_MIN  SRC_TO_DST_IAT_MAX  SRC_TO_DST_IAT_AVG  \\\n",
       "Attack                                                                       \n",
       "Analysis                      1226                1226                1226   \n",
       "Backdoor                      3451                3451                3451   \n",
       "Benign                       43021               43021               43021   \n",
       "DoS                           5050                5050                5050   \n",
       "Exploits                     38816               38816               38816   \n",
       "Fuzzers                      25588               25588               25588   \n",
       "Generic                       4760                4760                4760   \n",
       "Reconnaissance               11291               11291               11291   \n",
       "Shellcode                     1586                1586                1586   \n",
       "Worms                          136                 136                 136   \n",
       "\n",
       "                SRC_TO_DST_IAT_STDDEV  DST_TO_SRC_IAT_MIN  DST_TO_SRC_IAT_MAX  \\\n",
       "Attack                                                                          \n",
       "Analysis                         1226                1226                1226   \n",
       "Backdoor                         3451                3451                3451   \n",
       "Benign                          43021               43021               43021   \n",
       "DoS                              5050                5050                5050   \n",
       "Exploits                        38816               38816               38816   \n",
       "Fuzzers                         25588               25588               25588   \n",
       "Generic                          4760                4760                4760   \n",
       "Reconnaissance                  11291               11291               11291   \n",
       "Shellcode                        1586                1586                1586   \n",
       "Worms                             136                 136                 136   \n",
       "\n",
       "                DST_TO_SRC_IAT_AVG  DST_TO_SRC_IAT_STDDEV  Label  \n",
       "Attack                                                            \n",
       "Analysis                      1226                   1226   1226  \n",
       "Backdoor                      3451                   3451   3451  \n",
       "Benign                       43021                  43021  43021  \n",
       "DoS                           5050                   5050   5050  \n",
       "Exploits                     38816                  38816  38816  \n",
       "Fuzzers                      25588                  25588  25588  \n",
       "Generic                       4760                   4760   4760  \n",
       "Reconnaissance               11291                  11291  11291  \n",
       "Shellcode                     1586                   1586   1586  \n",
       "Worms                          136                    136    136  \n",
       "\n",
       "[10 rows x 52 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=\"Attack\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FqRx5xCPOuv8"
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Attack\", \"Label\", \"FLOW_START_MILLISECONDS\", \"FLOW_END_MILLISECONDS\",\n",
    "                       \"SRC_TO_DST_IAT_MIN\", \"SRC_TO_DST_IAT_MAX\", \"SRC_TO_DST_IAT_AVG\",\n",
    "                       \"SRC_TO_DST_IAT_STDDEV\", \"DST_TO_SRC_IAT_MIN\", \"DST_TO_SRC_IAT_MAX\",\n",
    "                       \"DST_TO_SRC_IAT_AVG\", \"DST_TO_SRC_IAT_STDDEV\"])\n",
    "y = data[[\"Attack\", \"Label\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=13, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bPfakXplPGGx"
   },
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
    "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
    "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
    "                                  'FTP_COMMAND_RET_CODE'])\n",
    "encoder.fit(X_train, y_train.Label)\n",
    "\n",
    "# Transform on training set\n",
    "X_train = encoder.transform(X_train)\n",
    "\n",
    "# Transform on testing set\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ibyOfV-8PouK"
   },
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "asDnsSIWPee0"
   },
   "outputs": [],
   "source": [
    "# (Modified)\n",
    "scaler = Normalizer()\n",
    "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
    "scaler.fit(X_train[cols_to_norm])\n",
    "\n",
    "# Transform on training set\n",
    "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
    "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
    "X_train['id'] = X_train.index\n",
    "\n",
    "# Transform on testing set\n",
    "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
    "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
    "X_test['id'] = X_test.index\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "hErQbsnrPluV",
    "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>h</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43890</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>149.171.126.10</td>\n",
       "      <td>2.561330e-05</td>\n",
       "      <td>3.285036e-05</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>1.823049e-05</td>\n",
       "      <td>1.823140e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577486</td>\n",
       "      <td>0.577486</td>\n",
       "      <td>3.524913e-05</td>\n",
       "      <td>3.524913e-05</td>\n",
       "      <td>2.503044e-05</td>\n",
       "      <td>2.503214e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.476545e-05</td>\n",
       "      <td>[2.5613301511952934e-05, 3.2850364394362367e-0...</td>\n",
       "      <td>43890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31028</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>1.114560e-06</td>\n",
       "      <td>1.348046e-06</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1.533861e-06</td>\n",
       "      <td>1.487611e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025129</td>\n",
       "      <td>0.025129</td>\n",
       "      <td>1.529601e-06</td>\n",
       "      <td>1.529647e-06</td>\n",
       "      <td>1.089196e-06</td>\n",
       "      <td>1.089270e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.077666e-06</td>\n",
       "      <td>[1.1145595762408208e-06, 1.3480458653506997e-0...</td>\n",
       "      <td>31028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54825</th>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>149.171.126.16</td>\n",
       "      <td>3.061250e-05</td>\n",
       "      <td>4.212904e-05</td>\n",
       "      <td>0.024266</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.010785</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>4.212904e-05</td>\n",
       "      <td>4.085873e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>3.968311e-05</td>\n",
       "      <td>3.968311e-05</td>\n",
       "      <td>2.991588e-05</td>\n",
       "      <td>2.991790e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.959917e-05</td>\n",
       "      <td>[3.061249825146896e-05, 4.212904313820345e-05,...</td>\n",
       "      <td>54825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73843</th>\n",
       "      <td>59.166.0.7</td>\n",
       "      <td>149.171.126.8</td>\n",
       "      <td>6.287196e-07</td>\n",
       "      <td>1.762213e-10</td>\n",
       "      <td>0.011011</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.474342</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>3.851313e-07</td>\n",
       "      <td>3.997307e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056379</td>\n",
       "      <td>0.030069</td>\n",
       "      <td>1.614266e-07</td>\n",
       "      <td>1.666401e-07</td>\n",
       "      <td>6.144124e-07</td>\n",
       "      <td>6.144540e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.079079e-07</td>\n",
       "      <td>[6.287196210805589e-07, 1.7622127690838925e-10...</td>\n",
       "      <td>73843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85099</th>\n",
       "      <td>175.45.176.2</td>\n",
       "      <td>149.171.126.10</td>\n",
       "      <td>3.039643e-05</td>\n",
       "      <td>3.452972e-05</td>\n",
       "      <td>0.022422</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.018824</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>4.183168e-05</td>\n",
       "      <td>4.057034e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685328</td>\n",
       "      <td>0.685328</td>\n",
       "      <td>3.828346e-05</td>\n",
       "      <td>3.829923e-05</td>\n",
       "      <td>2.970472e-05</td>\n",
       "      <td>2.970673e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.939025e-05</td>\n",
       "      <td>[3.039642517468984e-05, 3.452971558464651e-05,...</td>\n",
       "      <td>85099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPV4_SRC_ADDR   IPV4_DST_ADDR      PROTOCOL      L7_PROTO  IN_BYTES  \\\n",
       "43890  175.45.176.0  149.171.126.10  2.561330e-05  3.285036e-05  0.013782   \n",
       "31028  175.45.176.0  149.171.126.18  1.114560e-06  1.348046e-06  0.104582   \n",
       "54825  175.45.176.3  149.171.126.16  3.061250e-05  4.212904e-05  0.024266   \n",
       "73843    59.166.0.7   149.171.126.8  6.287196e-07  1.762213e-10  0.011011   \n",
       "85099  175.45.176.2  149.171.126.10  3.039643e-05  3.452972e-05  0.022422   \n",
       "\n",
       "        IN_PKTS  OUT_BYTES  OUT_PKTS     TCP_FLAGS  CLIENT_TCP_FLAGS  ...  \\\n",
       "43890  0.000317   0.022207  0.000352  1.823049e-05      1.823140e-05  ...   \n",
       "31028  0.000092   0.000884  0.000021  1.533861e-06      1.487611e-06  ...   \n",
       "54825  0.000421   0.010785  0.000253  4.212904e-05      4.085873e-05  ...   \n",
       "73843  0.000190   0.474342  0.000379  3.851313e-07      3.997307e-07  ...   \n",
       "85099  0.000418   0.018824  0.000418  4.183168e-05      4.057034e-05  ...   \n",
       "\n",
       "       TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT     ICMP_TYPE  ICMP_IPV4_TYPE  \\\n",
       "43890        0.577486         0.577486  3.524913e-05    3.524913e-05   \n",
       "31028        0.025129         0.025129  1.529601e-06    1.529647e-06   \n",
       "54825        0.690200         0.690200  3.968311e-05    3.968311e-05   \n",
       "73843        0.056379         0.030069  1.614266e-07    1.666401e-07   \n",
       "85099        0.685328         0.685328  3.828346e-05    3.829923e-05   \n",
       "\n",
       "       DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \\\n",
       "43890  2.503044e-05    2.503214e-05             0.0          2.476545e-05   \n",
       "31028  1.089196e-06    1.089270e-06             0.0          1.077666e-06   \n",
       "54825  2.991588e-05    2.991790e-05             0.0          2.959917e-05   \n",
       "73843  6.144124e-07    6.144540e-07             0.0          6.079079e-07   \n",
       "85099  2.970472e-05    2.970673e-05             0.0          2.939025e-05   \n",
       "\n",
       "                                                       h     id  \n",
       "43890  [2.5613301511952934e-05, 3.2850364394362367e-0...  43890  \n",
       "31028  [1.1145595762408208e-06, 1.3480458653506997e-0...  31028  \n",
       "54825  [3.061249825146896e-05, 4.212904313820345e-05,...  54825  \n",
       "73843  [6.287196210805589e-07, 1.7622127690838925e-10...  73843  \n",
       "85099  [3.039642517468984e-05, 3.452971558464651e-05,...  85099  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d_tLtK4WPtrF"
   },
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "lab_enc.fit(data[\"Attack\"])\n",
    "\n",
    "# Transform on training set\n",
    "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
    "\n",
    "# Transform on testing set\n",
    "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8yaicjecP1fZ"
   },
   "outputs": [],
   "source": [
    "# Training graph (Modified)\n",
    "\n",
    "train['id'] = train.index\n",
    "\n",
    "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "           [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "train_g = train_g.to_directed()\n",
    "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
    "train_g.edata['h'].shape[1]])\n",
    "train_g.ndata['h'] = nfeat_weight\n",
    "\n",
    "test['id'] = test.index\n",
    "\n",
    "# Testing graph\n",
    "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "            [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "# print(test_g)\n",
    "test_g = test_g.to_directed()\n",
    "# print(test_g)\n",
    "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
    "test_g.edata['h'].shape[1]])\n",
    "test_g.ndata['h'] = nfeat_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PUV6DgJ9QRaP"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import tqdm\n",
    "import gc\n",
    "\n",
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "      super(SAGELayer, self).__init__()\n",
    "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
    "      self.activation = F.relu\n",
    "      self.W_edge = nn.Linear(128 * 2, 256)\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      gain = nn.init.calculate_gain('relu')\n",
    "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "      return {'m':  edges.data['h']}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "      with g_dgl.local_scope():\n",
    "        g = g_dgl\n",
    "        g.ndata['h'] = nfeats\n",
    "        g.edata['h'] = efeats\n",
    "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "\n",
    "        # Compute edge embeddings\n",
    "        u, v = g.edges()\n",
    "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
    "        return g.ndata['h'], edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_xo-3K4QRGqc"
   },
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
    "      super(SAGE, self).__init__()\n",
    "      self.layers = nn.ModuleList()\n",
    "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
    "\n",
    "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
    "      if corrupt:\n",
    "        e_perm = torch.randperm(g.number_of_edges())\n",
    "        #n_perm = torch.randperm(g.number_of_nodes())\n",
    "        efeats = efeats[e_perm]\n",
    "        #nfeats = nfeats[n_perm]\n",
    "      for i, layer in enumerate(self.layers):\n",
    "        #nfeats = layer(g, nfeats, efeats)\n",
    "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
    "      #return nfeats.sum(1)\n",
    "      return nfeats.sum(1), e_feats.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6uuxRtLuRJQL"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "      super(Discriminator, self).__init__()\n",
    "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def uniform(self, size, tensor):\n",
    "      bound = 1.0 / math.sqrt(size)\n",
    "      if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      size = self.weight.size(0)\n",
    "      self.uniform(size, self.weight)\n",
    "\n",
    "    def forward(self, features, summary):\n",
    "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
    "      return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZPbVjlCyRUco"
   },
   "outputs": [],
   "source": [
    "class DGI(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
    "      super(DGI, self).__init__()\n",
    "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
    "      #self.discriminator = Discriminator(128)\n",
    "      self.discriminator = Discriminator(256)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "\n",
    "      positive = positive[1]\n",
    "      negative = negative[1]\n",
    "\n",
    "      summary = torch.sigmoid(positive.mean(dim=0))\n",
    "\n",
    "      positive = self.discriminator(positive, summary)\n",
    "      negative = self.discriminator(negative, summary)\n",
    "\n",
    "      l1 = self.loss(positive, torch.ones_like(positive))\n",
    "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
    "\n",
    "      return l1 + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sKnfpWFMR19u"
   },
   "outputs": [],
   "source": [
    "ndim_in = train_g.ndata['h'].shape[1]\n",
    "hidden_features = 128\n",
    "ndim_out = 128\n",
    "num_layers = 1\n",
    "edim = train_g.edata['h'].shape[1]\n",
    "learning_rate = 1e-3\n",
    "epochs = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "aSl_9qY8SbA0"
   },
   "outputs": [],
   "source": [
    "dgi = DGI(ndim_in,\n",
    "    ndim_out,\n",
    "    edim,\n",
    "    F.relu)\n",
    "\n",
    "dgi = dgi.to('cuda')\n",
    "\n",
    "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
    "                lr=1e-3,\n",
    "                weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9K6_cOiWSdJA"
   },
   "outputs": [],
   "source": [
    "# Format node and edge features for E-GraphSAGE\n",
    "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
    "                                   (train_g.ndata['h'].shape[0], 1,\n",
    "                                    train_g.ndata['h'].shape[1]))\n",
    "\n",
    "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
    "                                   (train_g.edata['h'].shape[0], 1,\n",
    "                                    train_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "O44auIyWSexg"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "train_g = train_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gZtafIdxSheN"
   },
   "outputs": [],
   "source": [
    "# cnt_wait = 0\n",
    "# best = 1e9\n",
    "# best_t = 0\n",
    "# dur = []\n",
    "# node_features = train_g.ndata['h'] \n",
    "# edge_features = train_g.edata['h']\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     dgi.train()\n",
    "#     if epoch >= 3:\n",
    "#         t0 = time.time()\n",
    "\n",
    "#     dgi_optimizer.zero_grad()\n",
    "#     loss = dgi(train_g, node_features, edge_features)\n",
    "#     loss.backward()\n",
    "#     dgi_optimizer.step()\n",
    "\n",
    "#     if loss < best:\n",
    "#         best = loss\n",
    "#         best_t = epoch\n",
    "#         cnt_wait = 0\n",
    "#         torch.save(dgi.state_dict(), 'best_dgi_UNSW_multiclass_v3.pkl')\n",
    "#     else:\n",
    "#         cnt_wait += 1\n",
    "\n",
    "#   # if cnt_wait == patience:\n",
    "#   #     print('Early stopping!')\n",
    "#   #     break\n",
    "\n",
    "#     if epoch >= 3:\n",
    "#         dur.append(time.time() - t0)\n",
    "\n",
    "#     if epoch % 50 == 0:\n",
    "\n",
    "#         print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "#             \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
    "#               loss.item(),\n",
    "#               train_g.num_edges() / np.mean(dur) / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RZ2HAQDAF-4c",
    "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_108373/2929626544.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dgi.load_state_dict(torch.load('best_dgi_UNSW_multiclass_v3.pkl'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgi.load_state_dict(torch.load('best_dgi_UNSW_multiclass_v3.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6Ek16GkRStKP"
   },
   "outputs": [],
   "source": [
    "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
    "training_emb = training_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-FwaBlOdS4ep"
   },
   "outputs": [],
   "source": [
    "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
    "                                   (test_g.ndata['h'].shape[0], 1,\n",
    "                                    test_g.ndata['h'].shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
    "                                   (test_g.edata['h'].shape[0], 1,\n",
    "                                    test_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SBa-rdivS6cQ"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "test_g = test_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "W12WLjslS-kx"
   },
   "outputs": [],
   "source": [
    "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
    "testing_emb = testing_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal (Fusion) Learning\n",
    "\n",
    "df_train = pd.DataFrame(training_emb,)\n",
    "# map the id to the original data\n",
    "df_train['id'] = train_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "df_raw_train = pd.DataFrame(X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_fuse_train = pd.merge(df_train, df_raw_train, on='id', how='left')\n",
    "df_fuse_train = df_fuse_train.drop(columns=[\"id\"])\n",
    "df_fuse_train[\"Attacks\"] = train_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
    "\n",
    "df_test = pd.DataFrame(testing_emb,)\n",
    "# map the id to the original data\n",
    "df_test['id'] = test_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "df_raw_test = pd.DataFrame(X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_raw_test = pd.merge(df_test, df_raw_test, on='id', how='left')\n",
    "df_fuse_test = df_raw_test.drop(columns=[\"id\"])\n",
    "df_fuse_test[\"Attacks\"] = test_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ZYABKzdrTGas"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pyod.models.cblof import CBLOF\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_fuse_train_samples = df_fuse_train[df_fuse_train.Label == 0].drop(columns=[\"Label\", \"Attacks\"])\n",
    "normal_fuse_train_samples = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"])\n",
    "\n",
    "fuse_train_labels = df_fuse_train[\"Label\"]\n",
    "fuse_test_labels = df_fuse_test[\"Label\"]\n",
    "\n",
    "fuse_test_samples = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_512_TO_1024_BYTES</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.228646</td>\n",
       "      <td>0.008042</td>\n",
       "      <td>-0.046584</td>\n",
       "      <td>0.106649</td>\n",
       "      <td>0.236607</td>\n",
       "      <td>-0.053865</td>\n",
       "      <td>0.093044</td>\n",
       "      <td>0.199002</td>\n",
       "      <td>-0.141841</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680750</td>\n",
       "      <td>0.680750</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.228646</td>\n",
       "      <td>0.008042</td>\n",
       "      <td>-0.046584</td>\n",
       "      <td>0.106649</td>\n",
       "      <td>0.236607</td>\n",
       "      <td>-0.053865</td>\n",
       "      <td>0.093044</td>\n",
       "      <td>0.199002</td>\n",
       "      <td>-0.141841</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.228646</td>\n",
       "      <td>0.008042</td>\n",
       "      <td>-0.046584</td>\n",
       "      <td>0.106649</td>\n",
       "      <td>0.236607</td>\n",
       "      <td>-0.053865</td>\n",
       "      <td>0.093044</td>\n",
       "      <td>0.199002</td>\n",
       "      <td>-0.141841</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605306</td>\n",
       "      <td>0.605306</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.228646</td>\n",
       "      <td>0.008042</td>\n",
       "      <td>-0.046584</td>\n",
       "      <td>0.106649</td>\n",
       "      <td>0.236607</td>\n",
       "      <td>-0.053865</td>\n",
       "      <td>0.093044</td>\n",
       "      <td>0.199002</td>\n",
       "      <td>-0.141841</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.074341</td>\n",
       "      <td>0.074341</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.228646</td>\n",
       "      <td>0.008042</td>\n",
       "      <td>-0.046584</td>\n",
       "      <td>0.106649</td>\n",
       "      <td>0.236607</td>\n",
       "      <td>-0.053865</td>\n",
       "      <td>0.093044</td>\n",
       "      <td>0.199002</td>\n",
       "      <td>-0.141841</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.028140</td>\n",
       "      <td>0.028140</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80951</th>\n",
       "      <td>0.228198</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.156387</td>\n",
       "      <td>0.114963</td>\n",
       "      <td>0.112120</td>\n",
       "      <td>0.081342</td>\n",
       "      <td>0.108953</td>\n",
       "      <td>0.304428</td>\n",
       "      <td>-0.158716</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80952</th>\n",
       "      <td>0.228198</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.156387</td>\n",
       "      <td>0.114963</td>\n",
       "      <td>0.112120</td>\n",
       "      <td>0.081342</td>\n",
       "      <td>0.108953</td>\n",
       "      <td>0.304428</td>\n",
       "      <td>-0.158716</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80953</th>\n",
       "      <td>0.228198</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.156387</td>\n",
       "      <td>0.114963</td>\n",
       "      <td>0.112120</td>\n",
       "      <td>0.081342</td>\n",
       "      <td>0.108953</td>\n",
       "      <td>0.304428</td>\n",
       "      <td>-0.158716</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80954</th>\n",
       "      <td>0.228198</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.156387</td>\n",
       "      <td>0.114963</td>\n",
       "      <td>0.112120</td>\n",
       "      <td>0.081342</td>\n",
       "      <td>0.108953</td>\n",
       "      <td>0.304428</td>\n",
       "      <td>-0.158716</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80955</th>\n",
       "      <td>0.228198</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.156387</td>\n",
       "      <td>0.114963</td>\n",
       "      <td>0.112120</td>\n",
       "      <td>0.081342</td>\n",
       "      <td>0.108953</td>\n",
       "      <td>0.304428</td>\n",
       "      <td>-0.158716</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80956 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.228646  0.008042 -0.046584  0.106649  0.236607 -0.053865  0.093044   \n",
       "1      0.228646  0.008042 -0.046584  0.106649  0.236607 -0.053865  0.093044   \n",
       "2      0.228646  0.008042 -0.046584  0.106649  0.236607 -0.053865  0.093044   \n",
       "3      0.228646  0.008042 -0.046584  0.106649  0.236607 -0.053865  0.093044   \n",
       "4      0.228646  0.008042 -0.046584  0.106649  0.236607 -0.053865  0.093044   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "80951  0.228198 -0.000198 -0.156387  0.114963  0.112120  0.081342  0.108953   \n",
       "80952  0.228198 -0.000198 -0.156387  0.114963  0.112120  0.081342  0.108953   \n",
       "80953  0.228198 -0.000198 -0.156387  0.114963  0.112120  0.081342  0.108953   \n",
       "80954  0.228198 -0.000198 -0.156387  0.114963  0.112120  0.081342  0.108953   \n",
       "80955  0.228198 -0.000198 -0.156387  0.114963  0.112120  0.081342  0.108953   \n",
       "\n",
       "              7         8         9  ...  NUM_PKTS_512_TO_1024_BYTES  \\\n",
       "0      0.199002 -0.141841  0.008991  ...                    0.000000   \n",
       "1      0.199002 -0.141841  0.008991  ...                    0.000007   \n",
       "2      0.199002 -0.141841  0.008991  ...                    0.000074   \n",
       "3      0.199002 -0.141841  0.008991  ...                    0.000009   \n",
       "4      0.199002 -0.141841  0.008991  ...                    0.000003   \n",
       "...         ...       ...       ...  ...                         ...   \n",
       "80951  0.304428 -0.158716 -0.001274  ...                    0.000000   \n",
       "80952  0.304428 -0.158716 -0.001274  ...                    0.000000   \n",
       "80953  0.304428 -0.158716 -0.001274  ...                    0.000000   \n",
       "80954  0.304428 -0.158716 -0.001274  ...                    0.000000   \n",
       "80955  0.304428 -0.158716 -0.001274  ...                    0.000000   \n",
       "\n",
       "       NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
       "0                         0.000000        0.680750         0.680750   \n",
       "1                         0.000122        0.055655         0.055655   \n",
       "2                         0.000000        0.605306         0.605306   \n",
       "3                         0.000073        0.074341         0.074341   \n",
       "4                         0.000072        0.028140         0.028140   \n",
       "...                            ...             ...              ...   \n",
       "80951                     0.000000        0.000000         0.000000   \n",
       "80952                     0.000000        0.000000         0.000000   \n",
       "80953                     0.000000        0.000000         0.000000   \n",
       "80954                     0.000000        0.000000         0.000000   \n",
       "80955                     0.000000        0.000000         0.000000   \n",
       "\n",
       "       ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "0       0.000039        0.000039      0.000030        0.000030   \n",
       "1       0.000003        0.000003      0.000002        0.000002   \n",
       "2       0.000036        0.000036      0.000026        0.000026   \n",
       "3       0.000004        0.000004      0.000003        0.000003   \n",
       "4       0.000001        0.000001      0.000001        0.000001   \n",
       "...          ...             ...           ...             ...   \n",
       "80951   0.000002        0.000002      0.000004        0.000004   \n",
       "80952   0.000002        0.000002      0.000004        0.000004   \n",
       "80953   0.000002        0.000002      0.000004        0.000004   \n",
       "80954   0.000002        0.000002      0.000004        0.000004   \n",
       "80955   0.000002        0.000002      0.000004        0.000004   \n",
       "\n",
       "       DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \n",
       "0                 0.0              0.000029  \n",
       "1                 0.0              0.000002  \n",
       "2                 0.0              0.000026  \n",
       "3                 0.0              0.000003  \n",
       "4                 0.0              0.000001  \n",
       "...               ...                   ...  \n",
       "80951             0.0              0.000004  \n",
       "80952             0.0              0.000004  \n",
       "80953             0.0              0.000004  \n",
       "80954             0.0              0.000004  \n",
       "80955             0.0              0.000004  \n",
       "\n",
       "[80956 rows x 295 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuse_test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised attack classification (Fusion)\n",
    "\n",
    "We now train a supervised classifier on the fused features to predict multi-class attack labels:\n",
    "- Features: embeddings + raw numeric features from `df_fuse_train`/`df_fuse_test` (without `Label`, `Attacks`).\n",
    "- Target: `Attacks` (encoded integer classes from earlier `LabelEncoder`).\n",
    "- Model: HistGradientBoostingClassifier (fast, strong on tabular data). Class imbalance handled via per-sample weights.\n",
    "- Metrics: macro F1, per-class report, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare supervised train/test for attack classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.utils import class_weight\n",
    "import pickle\n",
    "\n",
    "# Build train features/targets from already prepared fused DataFrames\n",
    "X_sup_train = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_sup_test = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights to mitigate class imbalance on training set\n",
    "classes = np.unique(y_sup_train)\n",
    "class_w = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes, y=y_sup_train\n",
    ")\n",
    "class_to_w = {c: w for c, w in zip(classes, class_w)}\n",
    "sample_weight = y_sup_train.map(class_to_w).values\n",
    "\n",
    "# Feature names to all str\n",
    "X_sup_train.columns = X_sup_train.columns.map(str)\n",
    "X_sup_test.columns = X_sup_test.columns.map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Methods (Fused Features)\n",
    "\n",
    "Now we'll compare multiple classification algorithms on the fused features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:19<00:00, 22.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 20}\n",
      "Best Macro F1: 0.5178\n",
      "Model saved to: best_rf_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2726    0.3111    0.2906       736\n",
      "           1     0.6653    0.0787    0.1408      2070\n",
      "           2     1.0000    1.0000    1.0000     25812\n",
      "           3     0.4084    0.1802    0.2501      3030\n",
      "           4     0.7465    0.7842    0.7648     23290\n",
      "           5     0.6809    0.8963    0.7739     15354\n",
      "           6     0.7602    0.3662    0.4943      2856\n",
      "           7     0.7122    0.6141    0.6595      6774\n",
      "           8     0.4772    0.3729    0.4186       952\n",
      "           9     0.3810    0.3902    0.3855        82\n",
      "\n",
      "    accuracy                         0.7951     80956\n",
      "   macro avg     0.6104    0.4994    0.5178     80956\n",
      "weighted avg     0.7899    0.7951    0.7792     80956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with Grid Search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            rf_clf = RandomForestClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            rf_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_rf = rf_clf.predict(X_sup_test)\n",
    "            rf_f1 = f1_score(y_sup_test, y_pred_rf, average='macro')\n",
    "            \n",
    "            if rf_f1 > score:\n",
    "                score = rf_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = rf_clf\n",
    "                # Save best model\n",
    "                with open('best_rf_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(rf_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_rf_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Random Forest: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [09:55:17] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "100%|██████████| 27/27 [27:42<00:00, 61.58s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.5633\n",
      "Model saved to: best_xgb_classifier_fused.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3165    0.3492    0.3320       736\n",
      "           1     0.3940    0.1213    0.1854      2070\n",
      "           2     1.0000    1.0000    1.0000     25812\n",
      "           3     0.3281    0.4323    0.3731      3030\n",
      "           4     0.8466    0.6687    0.7472     23290\n",
      "           5     0.6977    0.8967    0.7848     15354\n",
      "           6     0.5492    0.6268    0.5854      2856\n",
      "           7     0.6449    0.6822    0.6630      6774\n",
      "           8     0.4604    0.4947    0.4770       952\n",
      "           9     0.4032    0.6098    0.4854        82\n",
      "\n",
      "    accuracy                         0.7894     80956\n",
      "   macro avg     0.5641    0.5882    0.5633     80956\n",
      "weighted avg     0.7991    0.7894    0.7866     80956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with Grid Search\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    import pickle\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST CLASSIFIER (Fused Features)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            xgb_clf = XGBClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                learning_rate=lr,\n",
    "                random_state=13,\n",
    "                tree_method='hist', \n",
    "                device=\"cuda\"\n",
    "            )\n",
    "            \n",
    "            xgb_clf.fit(X_sup_train, y_sup_train, sample_weight=sample_weight)\n",
    "            y_pred_xgb = xgb_clf.predict(X_sup_test)\n",
    "            xgb_f1 = f1_score(y_sup_test, y_pred_xgb, average='macro')\n",
    "            \n",
    "            if xgb_f1 > score:\n",
    "                score = xgb_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = xgb_clf\n",
    "                # Save best model\n",
    "                xgb_clf.save_model('best_xgb_classifier_fused.json')\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_xgb_classifier_fused.json\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed. XGBoost might not support your GPU.\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CatBoost Grid Search (Expanded)...\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 4995 Total: 7833.5625\n",
      "  4%|▎         | 1/27 [00:09<04:07,  9.53s/it]Warning: less than 75% GPU memory available for training. Free: 4993 Total: 7833.5625\n",
      "  7%|▋         | 2/27 [00:18<03:51,  9.28s/it]Warning: less than 75% GPU memory available for training. Free: 4993 Total: 7833.5625\n",
      " 11%|█         | 3/27 [00:27<03:40,  9.17s/it]Warning: less than 75% GPU memory available for training. Free: 4993 Total: 7833.5625\n",
      " 15%|█▍        | 4/27 [00:49<05:24, 14.11s/it]Warning: less than 75% GPU memory available for training. Free: 4993 Total: 7833.5625\n",
      " 19%|█▊        | 5/27 [01:09<06:01, 16.44s/it]Warning: less than 75% GPU memory available for training. Free: 4787 Total: 7833.5625\n",
      " 22%|██▏       | 6/27 [01:26<05:47, 16.54s/it]Warning: less than 75% GPU memory available for training. Free: 4601 Total: 7833.5625\n",
      " 26%|██▌       | 7/27 [02:08<08:14, 24.70s/it]Warning: less than 75% GPU memory available for training. Free: 4435 Total: 7833.5625\n",
      " 30%|██▉       | 8/27 [02:53<09:56, 31.41s/it]Warning: less than 75% GPU memory available for training. Free: 4285 Total: 7833.5625\n",
      " 33%|███▎      | 9/27 [03:25<09:27, 31.50s/it]Warning: less than 75% GPU memory available for training. Free: 4149 Total: 7833.5625\n",
      " 37%|███▋      | 10/27 [03:29<06:30, 22.96s/it]Warning: less than 75% GPU memory available for training. Free: 4149 Total: 7833.5625\n",
      "100%|██████████| 27/27 [11:20<00:00, 25.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BEST CATBOOST HYPERPARAMETERS (Fused Features):\n",
      "{'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.5534\n",
      "============================================================\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_fused.cbm\n",
      "\n",
      "============================================================\n",
      "FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3275    0.5095    0.3987       736\n",
      "           1     0.4052    0.1725    0.2420      2070\n",
      "           2     1.0000    1.0000    1.0000     25812\n",
      "           3     0.2950    0.4264    0.3487      3030\n",
      "           4     0.8347    0.6454    0.7279     23290\n",
      "           5     0.6935    0.8896    0.7794     15354\n",
      "           6     0.5352    0.5886    0.5606      2856\n",
      "           7     0.6873    0.6428    0.6643      6774\n",
      "           8     0.4157    0.5672    0.4798       952\n",
      "           9     0.2184    0.6951    0.3324        82\n",
      "\n",
      "    accuracy                         0.7802     80956\n",
      "   macro avg     0.5413    0.6137    0.5534     80956\n",
      "weighted avg     0.7964    0.7802    0.7803     80956\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost with Grid Search (Expanded, no l2_leaf_reg/border_count, fixed best score logic)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"Starting CatBoost Grid Search (Expanded)...\")\n",
    "    \n",
    "    # Expanded hyperparameter grid\n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'  # Use 'CPU' if GPU not available\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_cat = cat_clf.predict(X_sup_test)\n",
    "            cat_f1 = f1_score(y_sup_test, y_pred_cat, average='macro')\n",
    "            \n",
    "            if cat_f1 > best_score:\n",
    "                best_score = cat_f1\n",
    "                best_params = {\n",
    "                    'iterations': iterations,\n",
    "                    'depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for fused features\n",
    "                best_model_path = \"best_catboost_classifier_fused.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEST CATBOOST HYPERPARAMETERS (Fused Features):\")\n",
    "    print(best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    if best_model_path:\n",
    "        print(f\"\\nBest CatBoost model saved to: {best_model_path}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    y_pred_best = best_model.predict(X_sup_test)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_sup_test, y_pred_best, digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed. Install with: pip install catboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:01<00:00,  6.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 20}\n",
      "Best Macro F1: 0.4859\n",
      "Model saved to: best_et_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3297    0.8709    0.4784       736\n",
      "           1     0.5629    0.1512    0.2384      2070\n",
      "           2     1.0000    1.0000    1.0000     25812\n",
      "           3     0.4207    0.1584    0.2302      3030\n",
      "           4     0.7322    0.7243    0.7282     23290\n",
      "           5     0.6732    0.7992    0.7308     15354\n",
      "           6     0.5679    0.2167    0.3137      2856\n",
      "           7     0.5570    0.6106    0.5826      6774\n",
      "           8     0.2775    0.4643    0.3473       952\n",
      "           9     0.1719    0.2683    0.2095        82\n",
      "\n",
      "    accuracy                         0.7610     80956\n",
      "   macro avg     0.5293    0.5264    0.4859     80956\n",
      "weighted avg     0.7604    0.7610    0.7501     80956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            et_clf = ExtraTreesClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            et_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_et = et_clf.predict(X_sup_test)\n",
    "            et_f1 = f1_score(y_sup_test, y_pred_et, average='macro')\n",
    "            \n",
    "            if et_f1 > score:\n",
    "                score = et_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = et_clf\n",
    "                # Save best model\n",
    "                with open('best_et_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(et_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_et_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Extra Trees: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Features Classification (Comparison Baseline)\n",
    "\n",
    "Now we'll train classifiers on **raw features only** (without graph embeddings) to compare the benefit of multimodal fusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw feature shape - Train: (94447, 39), Test: (40478, 39)\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Prepare raw features (without embeddings)\n",
    "# Use only the original numeric features from X_train/X_test\n",
    "\n",
    "X_raw_train = X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_train = y_train[\"Attack\"].copy()\n",
    "\n",
    "X_raw_test = X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_test = y_test[\"Attack\"].copy()\n",
    "\n",
    "# Encode labels\n",
    "y_raw_train_encoded = lab_enc.transform(y_train[\"Attack\"])\n",
    "y_raw_test_encoded = lab_enc.transform(y_test[\"Attack\"])\n",
    "\n",
    "# Compute sample weights\n",
    "classes_raw = np.unique(y_raw_train_encoded)\n",
    "class_w_raw = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_raw, y=y_raw_train_encoded\n",
    ")\n",
    "class_to_w_raw = {c: w for c, w in zip(classes_raw, class_w_raw)}\n",
    "sample_weight_raw = pd.Series(y_raw_train_encoded).map(class_to_w_raw).values\n",
    "\n",
    "# Feature names to str\n",
    "X_raw_train.columns = X_raw_train.columns.map(str)\n",
    "X_raw_test.columns = X_raw_test.columns.map(str)\n",
    "\n",
    "print(f\"Raw feature shape - Train: {X_raw_train.shape}, Test: {X_raw_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_raw_train_encoded))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Raw Features Only)\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:47<00:00,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 20}\n",
      "Best Macro F1: 0.5528\n",
      "Model saved to: best_rf_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2808    0.9538    0.4339       368\n",
      "           1     0.2365    0.1188    0.1582      1035\n",
      "           2     1.0000    0.9998    0.9999     12906\n",
      "           3     0.4214    0.2779    0.3349      1515\n",
      "           4     0.8209    0.7162    0.7650     11645\n",
      "           5     0.6750    0.8661    0.7587      7677\n",
      "           6     0.6537    0.5539    0.5997      1428\n",
      "           7     0.6625    0.5639    0.6093      3387\n",
      "           8     0.3005    0.4034    0.3444       476\n",
      "           9     0.4355    0.6585    0.5243        41\n",
      "\n",
      "    accuracy                         0.7833     40478\n",
      "   macro avg     0.5487    0.6112    0.5528     40478\n",
      "weighted avg     0.7898    0.7833    0.7800     40478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Raw Features Only)\")\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = rf_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Raw Features Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [03:37<00:00,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.5438\n",
      "Model saved to: best_xgb_classifier_raw.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2872    0.8397    0.4280       368\n",
      "           1     0.1638    0.1932    0.1773      1035\n",
      "           2     0.9996    0.9996    0.9996     12906\n",
      "           3     0.3051    0.3591    0.3299      1515\n",
      "           4     0.8740    0.6400    0.7389     11645\n",
      "           5     0.6890    0.8156    0.7470      7677\n",
      "           6     0.5252    0.5910    0.5562      1428\n",
      "           7     0.6207    0.6005    0.6104      3387\n",
      "           8     0.2758    0.5399    0.3651       476\n",
      "           9     0.4032    0.6098    0.4854        41\n",
      "\n",
      "    accuracy                         0.7616     40478\n",
      "   macro avg     0.5144    0.6188    0.5438     40478\n",
      "weighted avg     0.7932    0.7616    0.7692     40478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Raw Features Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='cuda'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_raw_train, y_raw_train_encoded, sample_weight=sample_weight_raw)\n",
    "        y_pred = xgb_clf.predict(X_raw_test)\n",
    "        f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_raw.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_raw.json\\n\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Raw Features Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [02:50<00:00,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.5030\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_raw.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2687    0.9864    0.4223       368\n",
      "           1     0.1505    0.2483    0.1874      1035\n",
      "           2     0.9993    0.9997    0.9995     12906\n",
      "           3     0.2790    0.4158    0.3340      1515\n",
      "           4     0.8970    0.5468    0.6795     11645\n",
      "           5     0.6896    0.7832    0.7335      7677\n",
      "           6     0.4507    0.6120    0.5192      1428\n",
      "           7     0.6672    0.5737    0.6169      3387\n",
      "           8     0.2127    0.5861    0.3121       476\n",
      "           9     0.1301    0.8537    0.2258        41\n",
      "\n",
      "    accuracy                         0.7328     40478\n",
      "   macro avg     0.4745    0.6606    0.5030     40478\n",
      "weighted avg     0.7986    0.7328    0.7482     40478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Raw Features Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "            y_pred = cat_clf.predict(X_raw_test)\n",
    "            f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for raw features\n",
    "                best_model_path = \"best_catboost_classifier_raw.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Raw Features Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:15<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 30}\n",
      "Best Macro F1: 0.5246\n",
      "Model saved to: best_et_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2865    0.8261    0.4255       368\n",
      "           1     0.1667    0.1014    0.1261      1035\n",
      "           2     1.0000    0.9997    0.9998     12906\n",
      "           3     0.4088    0.2574    0.3159      1515\n",
      "           4     0.7570    0.7532    0.7551     11645\n",
      "           5     0.6751    0.7718    0.7202      7677\n",
      "           6     0.6154    0.5042    0.5543      1428\n",
      "           7     0.6196    0.5430    0.5788      3387\n",
      "           8     0.3410    0.2794    0.3072       476\n",
      "           9     0.4634    0.4634    0.4634        41\n",
      "\n",
      "    accuracy                         0.7685     40478\n",
      "   macro avg     0.5334    0.5500    0.5246     40478\n",
      "weighted avg     0.7649    0.7685    0.7636     40478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Raw Features Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = et_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Only Classification (Graph Features)\n",
    "\n",
    "Now we'll train classifiers on **embeddings only** (graph features without raw features) to isolate the value of graph-based learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape - Train: (188894, 256), Test: (80956, 256)\n",
      "Number of classes: 10\n",
      "Using only graph embeddings (no raw features)\n"
     ]
    }
   ],
   "source": [
    "# Prepare embeddings-only features (graph features without raw data)\n",
    "# Extract only the embedding columns (first 256 dimensions from graph encoder)\n",
    "\n",
    "# From the fused dataframes, extract only embedding columns\n",
    "# df_fuse_train has: [0-255] = embeddings, [256+] = raw features\n",
    "num_embedding_dims = 256  # Based on the DGI encoder output dimension\n",
    "\n",
    "X_emb_train = df_fuse_train.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_emb_test = df_fuse_test.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights\n",
    "classes_emb = np.unique(y_emb_train)\n",
    "class_w_emb = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_emb, y=y_emb_train\n",
    ")\n",
    "class_to_w_emb = {c: w for c, w in zip(classes_emb, class_w_emb)}\n",
    "sample_weight_emb = y_emb_train.map(class_to_w_emb).values\n",
    "\n",
    "# Feature names to str\n",
    "X_emb_train.columns = X_emb_train.columns.map(str)\n",
    "X_emb_test.columns = X_emb_test.columns.map(str)\n",
    "\n",
    "print(f\"Embeddings shape - Train: {X_emb_train.shape}, Test: {X_emb_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_emb_train))}\")\n",
    "print(f\"Using only graph embeddings (no raw features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:32<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 20}\n",
      "Best Macro F1: 0.2069\n",
      "Model saved to: best_rf_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0473    0.8043    0.0894       736\n",
      "           1     0.2039    0.0700    0.1043      2070\n",
      "           2     1.0000    1.0000    1.0000     25812\n",
      "           3     0.0743    0.0396    0.0517      3030\n",
      "           4     0.4965    0.1472    0.2271     23290\n",
      "           5     0.3448    0.1956    0.2496     15354\n",
      "           6     0.0713    0.0641    0.0675      2856\n",
      "           7     0.1604    0.2582    0.1979      6774\n",
      "           8     0.0452    0.2878    0.0781       952\n",
      "           9     0.0016    0.0976    0.0031        82\n",
      "\n",
      "    accuracy                         0.4362     80956\n",
      "   macro avg     0.2445    0.2965    0.2069     80956\n",
      "weighted avg     0.5519    0.4362    0.4568     80956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = rf_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [07:08<00:00, 15.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.2128\n",
      "Model saved to: best_xgb_classifier_embeddings.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0528    0.1834    0.0820       736\n",
      "           1     0.0859    0.1362    0.1053      2070\n",
      "           2     1.0000    1.0000    1.0000     25812\n",
      "           3     0.0864    0.1785    0.1165      3030\n",
      "           4     0.4500    0.1097    0.1763     23290\n",
      "           5     0.3109    0.3520    0.3302     15354\n",
      "           6     0.0697    0.0644    0.0670      2856\n",
      "           7     0.1559    0.1825    0.1681      6774\n",
      "           8     0.0459    0.2731    0.0785       952\n",
      "           9     0.0021    0.0976    0.0042        82\n",
      "\n",
      "    accuracy                         0.4498     80956\n",
      "   macro avg     0.2260    0.2577    0.2128     80956\n",
      "weighted avg     0.5292    0.4498    0.4574     80956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Embeddings Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='gpu'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_emb_train, y_emb_train, sample_weight=sample_weight_emb)\n",
    "        y_pred = xgb_clf.predict(X_emb_test)\n",
    "        f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_embeddings.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_embeddings.json\\n\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Embeddings Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [06:33<00:00, 14.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 200, 'depth': 8, 'learning_rate': 0.05}\n",
      "Best Macro F1: 0.2247\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_embeddings.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0722    0.2323    0.1101       736\n",
      "           1     0.1337    0.1043    0.1172      2070\n",
      "           2     1.0000    1.0000    1.0000     25812\n",
      "           3     0.0916    0.1578    0.1159      3030\n",
      "           4     0.4734    0.1540    0.2324     23290\n",
      "           5     0.3532    0.3008    0.3249     15354\n",
      "           6     0.0720    0.0774    0.0746      2856\n",
      "           7     0.1618    0.1529    0.1572      6774\n",
      "           8     0.0674    0.3183    0.1113       952\n",
      "           9     0.0019    0.2561    0.0037        82\n",
      "\n",
      "    accuracy                         0.4504     80956\n",
      "   macro avg     0.2427    0.2754    0.2247     80956\n",
      "weighted avg     0.5464    0.4504    0.4728     80956\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Embeddings Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_emb_train, y_emb_train)\n",
    "            y_pred = cat_clf.predict(X_emb_test)\n",
    "            f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for embeddings\n",
    "                best_model_path = \"best_catboost_classifier_embeddings.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:22<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 20}\n",
      "Best Macro F1: 0.2033\n",
      "Model saved to: best_et_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0546    0.8967    0.1030       736\n",
      "           1     0.0822    0.0237    0.0368      2070\n",
      "           2     1.0000    1.0000    1.0000     25812\n",
      "           3     0.0743    0.0396    0.0517      3030\n",
      "           4     0.4898    0.1469    0.2261     23290\n",
      "           5     0.4079    0.1822    0.2519     15354\n",
      "           6     0.0667    0.0959    0.0787      2856\n",
      "           7     0.1639    0.2451    0.1964      6774\n",
      "           8     0.0519    0.2500    0.0859       952\n",
      "           9     0.0015    0.1463    0.0029        82\n",
      "\n",
      "    accuracy                         0.4329     80956\n",
      "   macro avg     0.2393    0.3026    0.2033     80956\n",
      "weighted avg     0.5592    0.4329    0.4557     80956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = et_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Comparison Table\n",
    "\n",
    "Create a comparison table of all methods (Fused vs Raw features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\n",
      "===============================================================================================\n",
      "\n",
      "Instructions:\n",
      "1. Run all cells above to get F1 scores for each method\n",
      "2. Record the best Macro F1 score for each method\n",
      "3. Compare three approaches:\n",
      "   - Fused Features: Embeddings + Raw (Multimodal)\n",
      "   - Embeddings Only: Graph features only\n",
      "   - Raw Features: Traditional features only\n",
      "\n",
      "Expected format:\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Method               Fused (Emb+Raw)           Embeddings Only           Raw Only                 \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Random Forest        [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "XGBoost              [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "CatBoost             [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "Extra Trees          [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysis:\n",
      "- Fused features should show best performance (multimodal learning)\n",
      "- Embeddings capture structural/graph patterns\n",
      "- Raw features provide traditional statistical information\n",
      "- Compare to understand the contribution of each modality\n"
     ]
    }
   ],
   "source": [
    "# Create a summary comparison table\n",
    "# NOTE: After running all cells above, manually collect the F1 scores and create a comparison\n",
    "\n",
    "print(\"=\"*95)\n",
    "print(\"PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\")\n",
    "print(\"=\"*95)\n",
    "print(\"\\nInstructions:\")\n",
    "print(\"1. Run all cells above to get F1 scores for each method\")\n",
    "print(\"2. Record the best Macro F1 score for each method\")\n",
    "print(\"3. Compare three approaches:\")\n",
    "print(\"   - Fused Features: Embeddings + Raw (Multimodal)\")\n",
    "print(\"   - Embeddings Only: Graph features only\")\n",
    "print(\"   - Raw Features: Traditional features only\")\n",
    "print(\"\\nExpected format:\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Method':<20} {'Fused (Emb+Raw)':<25} {'Embeddings Only':<25} {'Raw Only':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Random Forest':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'XGBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'CatBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'Extra Trees':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"- Fused features should show best performance (multimodal learning)\")\n",
    "print(\"- Embeddings capture structural/graph patterns\")\n",
    "print(\"- Raw features provide traditional statistical information\")\n",
    "print(\"- Compare to understand the contribution of each modality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights & Interpretation\n",
    "\n",
    "After running all experiments, analyze the results to answer:\n",
    "\n",
    "1. **Which approach performs best overall?**\n",
    "   - Fused features (multimodal) should ideally outperform single modalities\n",
    "   - Compare the magnitude of improvements\n",
    "\n",
    "2. **What is the value of graph embeddings?**\n",
    "   - Compare Embeddings-only vs Raw-only to see if graph structure helps\n",
    "   - If embeddings alone beat raw features, graph learning is beneficial\n",
    "\n",
    "3. **Is multimodal fusion effective?**\n",
    "   - Compare Fused vs (Embeddings + Raw separately)\n",
    "   - Synergy should provide additional gains beyond individual modalities\n",
    "\n",
    "4. **Which classifier is most suitable?**\n",
    "   - Identify the best performing algorithm for each feature type\n",
    "   - Consider computational cost vs accuracy trade-offs\n",
    "\n",
    "5. **Feature contribution analysis:**\n",
    "   - If Fused ≈ Embeddings > Raw: Graph structure dominates\n",
    "   - If Fused ≈ Raw > Embeddings: Traditional features dominate\n",
    "   - If Fused > Both: True synergy from multimodal learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
