{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Hjc3iIihKLn-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from dgl.data import DGLDataset\n",
    "import dgl\n",
    "import time\n",
    "import networkx as nx\n",
    "import category_encoders as ce\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "from typing import *\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SvWHb_BpKsLq"
   },
   "outputs": [],
   "source": [
    "file_name = \"NF-CSE-CIC-IDS2018-v3.parquet\"\n",
    "data = pd.read_parquet(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "fqly1y-LMwYS",
    "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    17514626\n",
       "1     2600903\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3t4OREvSM33h"
   },
   "outputs": [],
   "source": [
    "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
    "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
    "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
    "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bTtHq0XqNXxI"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUNIP-8zNkn9",
    "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'FTP-BruteForce', 'SSH-Bruteforce',\n",
       "       'DoS_attacks-GoldenEye', 'DoS_attacks-Slowloris',\n",
       "       'DoS_attacks-SlowHTTPTest', 'DoS_attacks-Hulk',\n",
       "       'DDoS_attacks-LOIC-HTTP', 'DDOS_attack-LOIC-UDP',\n",
       "       'DDOS_attack-HOIC', 'Brute_Force_-Web', 'Brute_Force_-XSS',\n",
       "       'SQL_Injection', 'Infilteration', 'Bot'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Attack.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    260004\n",
       "0     35116\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the dataset based on your needs (machine capacity) ideally ~ 500k rows\n",
    "data_attack = data[data['Label'] == 1]\n",
    "data_benign = data[data['Label'] == 0].sample(frac=0.02, random_state=13)\n",
    "data = pd.concat([data_attack, data_benign], axis=0)\n",
    "data = data.sample(frac=0.1, random_state=13).reset_index(drop=True)\n",
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "lcfAP6ViOp-J",
    "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLOW_START_MILLISECONDS</th>\n",
       "      <th>FLOW_END_MILLISECONDS</th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>...</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>SRC_TO_DST_IAT_MIN</th>\n",
       "      <th>SRC_TO_DST_IAT_MAX</th>\n",
       "      <th>SRC_TO_DST_IAT_AVG</th>\n",
       "      <th>SRC_TO_DST_IAT_STDDEV</th>\n",
       "      <th>DST_TO_SRC_IAT_MIN</th>\n",
       "      <th>DST_TO_SRC_IAT_MAX</th>\n",
       "      <th>DST_TO_SRC_IAT_AVG</th>\n",
       "      <th>DST_TO_SRC_IAT_STDDEV</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>...</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "      <td>35116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bot</th>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>...</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "      <td>20666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute_Force_-Web</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute_Force_-XSS</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDOS_attack-HOIC</th>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>...</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "      <td>103336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDOS_attack-LOIC-UDP</th>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>...</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDoS_attacks-LOIC-HTTP</th>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>...</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "      <td>28951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS_attacks-GoldenEye</th>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>...</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "      <td>6094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS_attacks-Hulk</th>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>...</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "      <td>9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS_attacks-SlowHTTPTest</th>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>...</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "      <td>10515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS_attacks-Slowloris</th>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>...</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "      <td>3544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTP-BruteForce</th>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>...</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "      <td>38535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infilteration</th>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>...</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "      <td>18974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQL_Injection</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSH-Bruteforce</th>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>...</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "      <td>18886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          FLOW_START_MILLISECONDS  FLOW_END_MILLISECONDS  \\\n",
       "Attack                                                                     \n",
       "Benign                                      35116                  35116   \n",
       "Bot                                         20666                  20666   \n",
       "Brute_Force_-Web                              150                    150   \n",
       "Brute_Force_-XSS                               47                     47   \n",
       "DDOS_attack-HOIC                           103336                 103336   \n",
       "DDOS_attack-LOIC-UDP                          319                    319   \n",
       "DDoS_attacks-LOIC-HTTP                      28951                  28951   \n",
       "DoS_attacks-GoldenEye                        6094                   6094   \n",
       "DoS_attacks-Hulk                             9952                   9952   \n",
       "DoS_attacks-SlowHTTPTest                    10515                  10515   \n",
       "DoS_attacks-Slowloris                        3544                   3544   \n",
       "FTP-BruteForce                              38535                  38535   \n",
       "Infilteration                               18974                  18974   \n",
       "SQL_Injection                                  35                     35   \n",
       "SSH-Bruteforce                              18886                  18886   \n",
       "\n",
       "                          IPV4_SRC_ADDR  IPV4_DST_ADDR  PROTOCOL  L7_PROTO  \\\n",
       "Attack                                                                       \n",
       "Benign                            35116          35116     35116     35116   \n",
       "Bot                               20666          20666     20666     20666   \n",
       "Brute_Force_-Web                    150            150       150       150   \n",
       "Brute_Force_-XSS                     47             47        47        47   \n",
       "DDOS_attack-HOIC                 103336         103336    103336    103336   \n",
       "DDOS_attack-LOIC-UDP                319            319       319       319   \n",
       "DDoS_attacks-LOIC-HTTP            28951          28951     28951     28951   \n",
       "DoS_attacks-GoldenEye              6094           6094      6094      6094   \n",
       "DoS_attacks-Hulk                   9952           9952      9952      9952   \n",
       "DoS_attacks-SlowHTTPTest          10515          10515     10515     10515   \n",
       "DoS_attacks-Slowloris              3544           3544      3544      3544   \n",
       "FTP-BruteForce                    38535          38535     38535     38535   \n",
       "Infilteration                     18974          18974     18974     18974   \n",
       "SQL_Injection                        35             35        35        35   \n",
       "SSH-Bruteforce                    18886          18886     18886     18886   \n",
       "\n",
       "                          IN_BYTES  IN_PKTS  OUT_BYTES  OUT_PKTS  ...  \\\n",
       "Attack                                                            ...   \n",
       "Benign                       35116    35116      35116     35116  ...   \n",
       "Bot                          20666    20666      20666     20666  ...   \n",
       "Brute_Force_-Web               150      150        150       150  ...   \n",
       "Brute_Force_-XSS                47       47         47        47  ...   \n",
       "DDOS_attack-HOIC            103336   103336     103336    103336  ...   \n",
       "DDOS_attack-LOIC-UDP           319      319        319       319  ...   \n",
       "DDoS_attacks-LOIC-HTTP       28951    28951      28951     28951  ...   \n",
       "DoS_attacks-GoldenEye         6094     6094       6094      6094  ...   \n",
       "DoS_attacks-Hulk              9952     9952       9952      9952  ...   \n",
       "DoS_attacks-SlowHTTPTest     10515    10515      10515     10515  ...   \n",
       "DoS_attacks-Slowloris         3544     3544       3544      3544  ...   \n",
       "FTP-BruteForce               38535    38535      38535     38535  ...   \n",
       "Infilteration                18974    18974      18974     18974  ...   \n",
       "SQL_Injection                   35       35         35        35  ...   \n",
       "SSH-Bruteforce               18886    18886      18886     18886  ...   \n",
       "\n",
       "                          FTP_COMMAND_RET_CODE  SRC_TO_DST_IAT_MIN  \\\n",
       "Attack                                                               \n",
       "Benign                                   35116               35116   \n",
       "Bot                                      20666               20666   \n",
       "Brute_Force_-Web                           150                 150   \n",
       "Brute_Force_-XSS                            47                  47   \n",
       "DDOS_attack-HOIC                        103336              103336   \n",
       "DDOS_attack-LOIC-UDP                       319                 319   \n",
       "DDoS_attacks-LOIC-HTTP                   28951               28951   \n",
       "DoS_attacks-GoldenEye                     6094                6094   \n",
       "DoS_attacks-Hulk                          9952                9952   \n",
       "DoS_attacks-SlowHTTPTest                 10515               10515   \n",
       "DoS_attacks-Slowloris                     3544                3544   \n",
       "FTP-BruteForce                           38535               38535   \n",
       "Infilteration                            18974               18974   \n",
       "SQL_Injection                               35                  35   \n",
       "SSH-Bruteforce                           18886               18886   \n",
       "\n",
       "                          SRC_TO_DST_IAT_MAX  SRC_TO_DST_IAT_AVG  \\\n",
       "Attack                                                             \n",
       "Benign                                 35116               35116   \n",
       "Bot                                    20666               20666   \n",
       "Brute_Force_-Web                         150                 150   \n",
       "Brute_Force_-XSS                          47                  47   \n",
       "DDOS_attack-HOIC                      103336              103336   \n",
       "DDOS_attack-LOIC-UDP                     319                 319   \n",
       "DDoS_attacks-LOIC-HTTP                 28951               28951   \n",
       "DoS_attacks-GoldenEye                   6094                6094   \n",
       "DoS_attacks-Hulk                        9952                9952   \n",
       "DoS_attacks-SlowHTTPTest               10515               10515   \n",
       "DoS_attacks-Slowloris                   3544                3544   \n",
       "FTP-BruteForce                         38535               38535   \n",
       "Infilteration                          18974               18974   \n",
       "SQL_Injection                             35                  35   \n",
       "SSH-Bruteforce                         18886               18886   \n",
       "\n",
       "                          SRC_TO_DST_IAT_STDDEV  DST_TO_SRC_IAT_MIN  \\\n",
       "Attack                                                                \n",
       "Benign                                    35116               35116   \n",
       "Bot                                       20666               20666   \n",
       "Brute_Force_-Web                            150                 150   \n",
       "Brute_Force_-XSS                             47                  47   \n",
       "DDOS_attack-HOIC                         103336              103336   \n",
       "DDOS_attack-LOIC-UDP                        319                 319   \n",
       "DDoS_attacks-LOIC-HTTP                    28951               28951   \n",
       "DoS_attacks-GoldenEye                      6094                6094   \n",
       "DoS_attacks-Hulk                           9952                9952   \n",
       "DoS_attacks-SlowHTTPTest                  10515               10515   \n",
       "DoS_attacks-Slowloris                      3544                3544   \n",
       "FTP-BruteForce                            38535               38535   \n",
       "Infilteration                             18974               18974   \n",
       "SQL_Injection                                35                  35   \n",
       "SSH-Bruteforce                            18886               18886   \n",
       "\n",
       "                          DST_TO_SRC_IAT_MAX  DST_TO_SRC_IAT_AVG  \\\n",
       "Attack                                                             \n",
       "Benign                                 35116               35116   \n",
       "Bot                                    20666               20666   \n",
       "Brute_Force_-Web                         150                 150   \n",
       "Brute_Force_-XSS                          47                  47   \n",
       "DDOS_attack-HOIC                      103336              103336   \n",
       "DDOS_attack-LOIC-UDP                     319                 319   \n",
       "DDoS_attacks-LOIC-HTTP                 28951               28951   \n",
       "DoS_attacks-GoldenEye                   6094                6094   \n",
       "DoS_attacks-Hulk                        9952                9952   \n",
       "DoS_attacks-SlowHTTPTest               10515               10515   \n",
       "DoS_attacks-Slowloris                   3544                3544   \n",
       "FTP-BruteForce                         38535               38535   \n",
       "Infilteration                          18974               18974   \n",
       "SQL_Injection                             35                  35   \n",
       "SSH-Bruteforce                         18886               18886   \n",
       "\n",
       "                          DST_TO_SRC_IAT_STDDEV   Label  \n",
       "Attack                                                   \n",
       "Benign                                    35116   35116  \n",
       "Bot                                       20666   20666  \n",
       "Brute_Force_-Web                            150     150  \n",
       "Brute_Force_-XSS                             47      47  \n",
       "DDOS_attack-HOIC                         103336  103336  \n",
       "DDOS_attack-LOIC-UDP                        319     319  \n",
       "DDoS_attacks-LOIC-HTTP                    28951   28951  \n",
       "DoS_attacks-GoldenEye                      6094    6094  \n",
       "DoS_attacks-Hulk                           9952    9952  \n",
       "DoS_attacks-SlowHTTPTest                  10515   10515  \n",
       "DoS_attacks-Slowloris                      3544    3544  \n",
       "FTP-BruteForce                            38535   38535  \n",
       "Infilteration                             18974   18974  \n",
       "SQL_Injection                                35      35  \n",
       "SSH-Bruteforce                            18886   18886  \n",
       "\n",
       "[15 rows x 52 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=\"Attack\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FqRx5xCPOuv8"
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Attack\", \"Label\", \"FLOW_START_MILLISECONDS\", \"FLOW_END_MILLISECONDS\",\n",
    "                       \"SRC_TO_DST_IAT_MIN\", \"SRC_TO_DST_IAT_MAX\", \"SRC_TO_DST_IAT_AVG\",\n",
    "                       \"SRC_TO_DST_IAT_STDDEV\", \"DST_TO_SRC_IAT_MIN\", \"DST_TO_SRC_IAT_MAX\",\n",
    "                       \"DST_TO_SRC_IAT_AVG\", \"DST_TO_SRC_IAT_STDDEV\"])\n",
    "y = data[[\"Attack\", \"Label\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=13, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bPfakXplPGGx"
   },
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
    "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
    "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
    "                                  'FTP_COMMAND_RET_CODE'])\n",
    "encoder.fit(X_train, y_train.Label)\n",
    "\n",
    "# Transform on training set\n",
    "X_train = encoder.transform(X_train)\n",
    "\n",
    "# Transform on testing set\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ibyOfV-8PouK"
   },
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "asDnsSIWPee0"
   },
   "outputs": [],
   "source": [
    "# (Modified)\n",
    "scaler = Normalizer()\n",
    "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
    "scaler.fit(X_train[cols_to_norm])\n",
    "\n",
    "# Transform on training set\n",
    "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
    "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
    "X_train['id'] = X_train.index\n",
    "\n",
    "# Transform on testing set\n",
    "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
    "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
    "X_test['id'] = X_test.index\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "hErQbsnrPluV",
    "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>h</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50789</th>\n",
       "      <td>172.31.69.24</td>\n",
       "      <td>172.31.69.10</td>\n",
       "      <td>2.631269e-06</td>\n",
       "      <td>2.287537e-06</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.302129e-07</td>\n",
       "      <td>2.756679e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.517640e-06</td>\n",
       "      <td>2.517640e-06</td>\n",
       "      <td>2.625166e-06</td>\n",
       "      <td>2.625166e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.502865e-06</td>\n",
       "      <td>[2.6312693592111632e-06, 2.287536914271789e-06...</td>\n",
       "      <td>50789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205303</th>\n",
       "      <td>18.221.219.4</td>\n",
       "      <td>172.31.69.25</td>\n",
       "      <td>1.603789e-06</td>\n",
       "      <td>1.731357e-06</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.727599e-06</td>\n",
       "      <td>1.680227e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>1.600068e-06</td>\n",
       "      <td>1.600068e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.525524e-06</td>\n",
       "      <td>[1.6037885806364524e-06, 1.7313573322146653e-0...</td>\n",
       "      <td>205303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105276</th>\n",
       "      <td>18.216.200.189</td>\n",
       "      <td>172.31.69.28</td>\n",
       "      <td>3.672210e-07</td>\n",
       "      <td>3.904426e-07</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.867913e-07</td>\n",
       "      <td>3.863179e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025983</td>\n",
       "      <td>0.010658</td>\n",
       "      <td>3.513629e-07</td>\n",
       "      <td>3.513629e-07</td>\n",
       "      <td>3.663692e-07</td>\n",
       "      <td>3.663692e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.493008e-07</td>\n",
       "      <td>[3.672210411851743e-07, 3.9044255268104883e-07...</td>\n",
       "      <td>105276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261564</th>\n",
       "      <td>13.59.126.31</td>\n",
       "      <td>172.31.69.25</td>\n",
       "      <td>1.603789e-06</td>\n",
       "      <td>1.731357e-06</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.727599e-06</td>\n",
       "      <td>1.680227e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>1.600068e-06</td>\n",
       "      <td>1.600068e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.525524e-06</td>\n",
       "      <td>[1.6037885806364524e-06, 1.7313573322146653e-0...</td>\n",
       "      <td>261564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227760</th>\n",
       "      <td>18.219.9.1</td>\n",
       "      <td>172.31.69.28</td>\n",
       "      <td>2.659254e-06</td>\n",
       "      <td>2.827415e-06</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.800973e-06</td>\n",
       "      <td>2.797546e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188158</td>\n",
       "      <td>0.077184</td>\n",
       "      <td>2.544417e-06</td>\n",
       "      <td>2.544417e-06</td>\n",
       "      <td>2.653086e-06</td>\n",
       "      <td>2.653086e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.529484e-06</td>\n",
       "      <td>[2.659254491488997e-06, 2.8274145417553674e-06...</td>\n",
       "      <td>227760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         IPV4_SRC_ADDR IPV4_DST_ADDR      PROTOCOL      L7_PROTO  IN_BYTES  \\\n",
       "50789     172.31.69.24  172.31.69.10  2.631269e-06  2.287537e-06  0.000125   \n",
       "205303    18.221.219.4  172.31.69.25  1.603789e-06  1.731357e-06  0.000104   \n",
       "105276  18.216.200.189  172.31.69.28  3.672210e-07  3.904426e-07  0.000207   \n",
       "261564    13.59.126.31  172.31.69.25  1.603789e-06  1.731357e-06  0.000104   \n",
       "227760      18.219.9.1  172.31.69.28  2.659254e-06  2.827415e-06  0.001324   \n",
       "\n",
       "         IN_PKTS  OUT_BYTES  OUT_PKTS     TCP_FLAGS  CLIENT_TCP_FLAGS  ...  \\\n",
       "50789   0.000003   0.000000  0.000000  6.302129e-07      2.756679e-06  ...   \n",
       "205303  0.000002   0.000069  0.000002  1.727599e-06      1.680227e-06  ...   \n",
       "105276  0.000002   0.000455  0.000002  3.867913e-07      3.863179e-07  ...   \n",
       "261564  0.000002   0.000069  0.000002  1.727599e-06      1.680227e-06  ...   \n",
       "227760  0.000014   0.003293  0.000014  2.800973e-06      2.797546e-06  ...   \n",
       "\n",
       "        TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT     ICMP_TYPE  ICMP_IPV4_TYPE  \\\n",
       "50789         0.002909         0.000000  2.517640e-06    2.517640e-06   \n",
       "205303        0.046550         0.000000  1.534530e-06    1.534530e-06   \n",
       "105276        0.025983         0.010658  3.513629e-07    3.513629e-07   \n",
       "261564        0.046550         0.000000  1.534530e-06    1.534530e-06   \n",
       "227760        0.188158         0.077184  2.544417e-06    2.544417e-06   \n",
       "\n",
       "        DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \\\n",
       "50789   2.625166e-06    2.625166e-06             0.0          2.502865e-06   \n",
       "205303  1.600068e-06    1.600068e-06             0.0          1.525524e-06   \n",
       "105276  3.663692e-07    3.663692e-07             0.0          3.493008e-07   \n",
       "261564  1.600068e-06    1.600068e-06             0.0          1.525524e-06   \n",
       "227760  2.653086e-06    2.653086e-06             0.0          2.529484e-06   \n",
       "\n",
       "                                                        h      id  \n",
       "50789   [2.6312693592111632e-06, 2.287536914271789e-06...   50789  \n",
       "205303  [1.6037885806364524e-06, 1.7313573322146653e-0...  205303  \n",
       "105276  [3.672210411851743e-07, 3.9044255268104883e-07...  105276  \n",
       "261564  [1.6037885806364524e-06, 1.7313573322146653e-0...  261564  \n",
       "227760  [2.659254491488997e-06, 2.8274145417553674e-06...  227760  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d_tLtK4WPtrF"
   },
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "lab_enc.fit(data[\"Attack\"])\n",
    "\n",
    "# Transform on training set\n",
    "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
    "\n",
    "# Transform on testing set\n",
    "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8yaicjecP1fZ"
   },
   "outputs": [],
   "source": [
    "# Training graph (Modified)\n",
    "\n",
    "train['id'] = train.index\n",
    "\n",
    "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "           [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "train_g = train_g.to_directed()\n",
    "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
    "train_g.edata['h'].shape[1]])\n",
    "train_g.ndata['h'] = nfeat_weight\n",
    "\n",
    "test['id'] = test.index\n",
    "\n",
    "# Testing graph\n",
    "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "            [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "# print(test_g)\n",
    "test_g = test_g.to_directed()\n",
    "# print(test_g)\n",
    "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
    "test_g.edata['h'].shape[1]])\n",
    "test_g.ndata['h'] = nfeat_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PUV6DgJ9QRaP"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import tqdm\n",
    "import gc\n",
    "\n",
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "      super(SAGELayer, self).__init__()\n",
    "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
    "      self.activation = F.relu\n",
    "      self.W_edge = nn.Linear(128 * 2, 256)\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      gain = nn.init.calculate_gain('relu')\n",
    "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "      return {'m':  edges.data['h']}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "      with g_dgl.local_scope():\n",
    "        g = g_dgl\n",
    "        g.ndata['h'] = nfeats\n",
    "        g.edata['h'] = efeats\n",
    "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "\n",
    "        # Compute edge embeddings\n",
    "        u, v = g.edges()\n",
    "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
    "        return g.ndata['h'], edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_xo-3K4QRGqc"
   },
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
    "      super(SAGE, self).__init__()\n",
    "      self.layers = nn.ModuleList()\n",
    "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
    "\n",
    "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
    "      if corrupt:\n",
    "        e_perm = torch.randperm(g.number_of_edges())\n",
    "        #n_perm = torch.randperm(g.number_of_nodes())\n",
    "        efeats = efeats[e_perm]\n",
    "        #nfeats = nfeats[n_perm]\n",
    "      for i, layer in enumerate(self.layers):\n",
    "        #nfeats = layer(g, nfeats, efeats)\n",
    "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
    "      #return nfeats.sum(1)\n",
    "      return nfeats.sum(1), e_feats.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6uuxRtLuRJQL"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "      super(Discriminator, self).__init__()\n",
    "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def uniform(self, size, tensor):\n",
    "      bound = 1.0 / math.sqrt(size)\n",
    "      if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      size = self.weight.size(0)\n",
    "      self.uniform(size, self.weight)\n",
    "\n",
    "    def forward(self, features, summary):\n",
    "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
    "      return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZPbVjlCyRUco"
   },
   "outputs": [],
   "source": [
    "class DGI(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
    "      super(DGI, self).__init__()\n",
    "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
    "      #self.discriminator = Discriminator(128)\n",
    "      self.discriminator = Discriminator(256)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "\n",
    "      positive = positive[1]\n",
    "      negative = negative[1]\n",
    "\n",
    "      summary = torch.sigmoid(positive.mean(dim=0))\n",
    "\n",
    "      positive = self.discriminator(positive, summary)\n",
    "      negative = self.discriminator(negative, summary)\n",
    "\n",
    "      l1 = self.loss(positive, torch.ones_like(positive))\n",
    "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
    "\n",
    "      return l1 + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sKnfpWFMR19u"
   },
   "outputs": [],
   "source": [
    "ndim_in = train_g.ndata['h'].shape[1]\n",
    "hidden_features = 128\n",
    "ndim_out = 128\n",
    "num_layers = 1\n",
    "edim = train_g.edata['h'].shape[1]\n",
    "learning_rate = 1e-3\n",
    "epochs = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "aSl_9qY8SbA0"
   },
   "outputs": [],
   "source": [
    "dgi = DGI(ndim_in,\n",
    "    ndim_out,\n",
    "    edim,\n",
    "    F.relu)\n",
    "\n",
    "dgi = dgi.to('cuda')\n",
    "\n",
    "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
    "                lr=1e-3,\n",
    "                weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9K6_cOiWSdJA"
   },
   "outputs": [],
   "source": [
    "# Format node and edge features for E-GraphSAGE\n",
    "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
    "                                   (train_g.ndata['h'].shape[0], 1,\n",
    "                                    train_g.ndata['h'].shape[1]))\n",
    "\n",
    "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
    "                                   (train_g.edata['h'].shape[0], 1,\n",
    "                                    train_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "O44auIyWSexg"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "train_g = train_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gZtafIdxSheN"
   },
   "outputs": [],
   "source": [
    "# cnt_wait = 0\n",
    "# best = 1e9\n",
    "# best_t = 0\n",
    "# dur = []\n",
    "# node_features = train_g.ndata['h'] \n",
    "# edge_features = train_g.edata['h']\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     dgi.train()\n",
    "#     if epoch >= 3:\n",
    "#         t0 = time.time()\n",
    "\n",
    "#     dgi_optimizer.zero_grad()\n",
    "#     loss = dgi(train_g, node_features, edge_features)\n",
    "#     loss.backward()\n",
    "#     dgi_optimizer.step()\n",
    "\n",
    "#     if loss < best:\n",
    "#         best = loss\n",
    "#         best_t = epoch\n",
    "#         cnt_wait = 0\n",
    "#         torch.save(dgi.state_dict(), 'best_dgi_CSE_multiclass_v3.pkl')\n",
    "#     else:\n",
    "#         cnt_wait += 1\n",
    "\n",
    "#   # if cnt_wait == patience:\n",
    "#   #     print('Early stopping!')\n",
    "#   #     break\n",
    "\n",
    "#     if epoch >= 3:\n",
    "#         dur.append(time.time() - t0)\n",
    "\n",
    "#     if epoch % 50 == 0:\n",
    "\n",
    "#         print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "#             \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
    "#               loss.item(),\n",
    "#               train_g.num_edges() / np.mean(dur) / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RZ2HAQDAF-4c",
    "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_392861/3950421897.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dgi.load_state_dict(torch.load('best_dgi_CSE_multiclass_v3.pkl'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgi.load_state_dict(torch.load('best_dgi_CSE_multiclass_v3.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6Ek16GkRStKP"
   },
   "outputs": [],
   "source": [
    "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
    "training_emb = training_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-FwaBlOdS4ep"
   },
   "outputs": [],
   "source": [
    "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
    "                                   (test_g.ndata['h'].shape[0], 1,\n",
    "                                    test_g.ndata['h'].shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
    "                                   (test_g.edata['h'].shape[0], 1,\n",
    "                                    test_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SBa-rdivS6cQ"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "test_g = test_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "W12WLjslS-kx"
   },
   "outputs": [],
   "source": [
    "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
    "testing_emb = testing_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal (Fusion) Learning\n",
    "\n",
    "df_train = pd.DataFrame(training_emb,)\n",
    "# map the id to the original data\n",
    "df_train['id'] = train_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "df_raw_train = pd.DataFrame(X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_fuse_train = pd.merge(df_train, df_raw_train, on='id', how='left')\n",
    "df_fuse_train = df_fuse_train.drop(columns=[\"id\"])\n",
    "df_fuse_train[\"Attacks\"] = train_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
    "\n",
    "df_test = pd.DataFrame(testing_emb,)\n",
    "# map the id to the original data\n",
    "df_test['id'] = test_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "df_raw_test = pd.DataFrame(X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_raw_test = pd.merge(df_test, df_raw_test, on='id', how='left')\n",
    "df_fuse_test = df_raw_test.drop(columns=[\"id\"])\n",
    "df_fuse_test[\"Attacks\"] = test_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ScEk1y_TzzX"
   },
   "source": [
    "# Embeddings CBLOF  Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ZYABKzdrTGas"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pyod.models.cblof import CBLOF\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_fuse_train_samples = df_fuse_train[df_fuse_train.Label == 0].drop(columns=[\"Label\", \"Attacks\"])\n",
    "normal_fuse_train_samples = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"])\n",
    "\n",
    "fuse_train_labels = df_fuse_train[\"Label\"]\n",
    "fuse_test_labels = df_fuse_test[\"Label\"]\n",
    "\n",
    "fuse_test_samples = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_512_TO_1024_BYTES</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001735</td>\n",
       "      <td>-0.035615</td>\n",
       "      <td>-0.024079</td>\n",
       "      <td>-0.005690</td>\n",
       "      <td>-0.018998</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>-0.024028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001735</td>\n",
       "      <td>-0.035615</td>\n",
       "      <td>-0.024079</td>\n",
       "      <td>-0.005690</td>\n",
       "      <td>-0.018998</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>-0.024028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001735</td>\n",
       "      <td>-0.035615</td>\n",
       "      <td>-0.024079</td>\n",
       "      <td>-0.005690</td>\n",
       "      <td>-0.018998</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>-0.024028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001735</td>\n",
       "      <td>-0.035615</td>\n",
       "      <td>-0.024079</td>\n",
       "      <td>-0.005690</td>\n",
       "      <td>-0.018998</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>-0.024028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001735</td>\n",
       "      <td>-0.035615</td>\n",
       "      <td>-0.024079</td>\n",
       "      <td>-0.005690</td>\n",
       "      <td>-0.018998</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>-0.024028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>1.534530e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177006</th>\n",
       "      <td>0.006771</td>\n",
       "      <td>-0.037454</td>\n",
       "      <td>-0.016569</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>-0.031881</td>\n",
       "      <td>0.012741</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.021876</td>\n",
       "      <td>-0.013956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.902729</td>\n",
       "      <td>0.253259</td>\n",
       "      <td>2.739762e-05</td>\n",
       "      <td>2.739762e-05</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177007</th>\n",
       "      <td>0.038530</td>\n",
       "      <td>-0.044816</td>\n",
       "      <td>-0.076847</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>-0.083107</td>\n",
       "      <td>0.042522</td>\n",
       "      <td>-0.002000</td>\n",
       "      <td>0.032822</td>\n",
       "      <td>0.043670</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.075034</td>\n",
       "      <td>0.246232</td>\n",
       "      <td>2.238043e-06</td>\n",
       "      <td>2.238043e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177008</th>\n",
       "      <td>0.033170</td>\n",
       "      <td>-0.047174</td>\n",
       "      <td>-0.084769</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>-0.072864</td>\n",
       "      <td>0.044812</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.039064</td>\n",
       "      <td>0.042814</td>\n",
       "      <td>-0.017929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038967</td>\n",
       "      <td>0.138895</td>\n",
       "      <td>8.020868e-07</td>\n",
       "      <td>8.020868e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177009</th>\n",
       "      <td>0.043534</td>\n",
       "      <td>-0.041444</td>\n",
       "      <td>-0.073588</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>-0.096564</td>\n",
       "      <td>0.033553</td>\n",
       "      <td>-0.006187</td>\n",
       "      <td>0.025260</td>\n",
       "      <td>0.048902</td>\n",
       "      <td>0.019138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.039471</td>\n",
       "      <td>0.140691</td>\n",
       "      <td>4.269932e-06</td>\n",
       "      <td>4.269932e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177010</th>\n",
       "      <td>0.045777</td>\n",
       "      <td>-0.052805</td>\n",
       "      <td>-0.060180</td>\n",
       "      <td>0.008166</td>\n",
       "      <td>-0.095905</td>\n",
       "      <td>0.037614</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.019820</td>\n",
       "      <td>0.043430</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.039930</td>\n",
       "      <td>0.142327</td>\n",
       "      <td>4.319603e-06</td>\n",
       "      <td>4.319603e-06</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177011 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0       0.001735 -0.035615 -0.024079 -0.005690 -0.018998  0.013689  0.024161   \n",
       "1       0.001735 -0.035615 -0.024079 -0.005690 -0.018998  0.013689  0.024161   \n",
       "2       0.001735 -0.035615 -0.024079 -0.005690 -0.018998  0.013689  0.024161   \n",
       "3       0.001735 -0.035615 -0.024079 -0.005690 -0.018998  0.013689  0.024161   \n",
       "4       0.001735 -0.035615 -0.024079 -0.005690 -0.018998  0.013689  0.024161   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "177006  0.006771 -0.037454 -0.016569  0.000698 -0.031881  0.012741  0.010300   \n",
       "177007  0.038530 -0.044816 -0.076847  0.004399 -0.083107  0.042522 -0.002000   \n",
       "177008  0.033170 -0.047174 -0.084769  0.003528 -0.072864  0.044812  0.002164   \n",
       "177009  0.043534 -0.041444 -0.073588  0.007070 -0.096564  0.033553 -0.006187   \n",
       "177010  0.045777 -0.052805 -0.060180  0.008166 -0.095905  0.037614  0.005331   \n",
       "\n",
       "               7         8         9  ...  NUM_PKTS_512_TO_1024_BYTES  \\\n",
       "0      -0.011840  0.008700 -0.024028  ...                    0.000000   \n",
       "1      -0.011840  0.008700 -0.024028  ...                    0.000000   \n",
       "2      -0.011840  0.008700 -0.024028  ...                    0.000000   \n",
       "3      -0.011840  0.008700 -0.024028  ...                    0.000000   \n",
       "4      -0.011840  0.008700 -0.024028  ...                    0.000000   \n",
       "...          ...       ...       ...  ...                         ...   \n",
       "177006  0.001602  0.021876 -0.013956  ...                    0.000000   \n",
       "177007  0.032822  0.043670  0.000052  ...                    0.000009   \n",
       "177008  0.039064  0.042814 -0.017929  ...                    0.000000   \n",
       "177009  0.025260  0.048902  0.019138  ...                    0.000010   \n",
       "177010  0.019820  0.043430  0.002952  ...                    0.000005   \n",
       "\n",
       "        NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
       "0                          0.000000        0.046550         0.000000   \n",
       "1                          0.000000        0.046550         0.000000   \n",
       "2                          0.000000        0.046550         0.000000   \n",
       "3                          0.000000        0.046550         0.000000   \n",
       "4                          0.000000        0.046550         0.000000   \n",
       "...                             ...             ...              ...   \n",
       "177006                     0.000000        0.902729         0.253259   \n",
       "177007                     0.000018        0.075034         0.246232   \n",
       "177008                     0.000000        0.038967         0.138895   \n",
       "177009                     0.000111        0.039471         0.140691   \n",
       "177010                     0.000015        0.039930         0.142327   \n",
       "\n",
       "           ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "0       1.534530e-06    1.534530e-06      0.000002        0.000002   \n",
       "1       1.534530e-06    1.534530e-06      0.000002        0.000002   \n",
       "2       1.534530e-06    1.534530e-06      0.000002        0.000002   \n",
       "3       1.534530e-06    1.534530e-06      0.000002        0.000002   \n",
       "4       1.534530e-06    1.534530e-06      0.000002        0.000002   \n",
       "...              ...             ...           ...             ...   \n",
       "177006  2.739762e-05    2.739762e-05      0.000029        0.000029   \n",
       "177007  2.238043e-06    2.238043e-06      0.000008        0.000008   \n",
       "177008  8.020868e-07    8.020868e-07      0.000004        0.000004   \n",
       "177009  4.269932e-06    4.269932e-06      0.000004        0.000004   \n",
       "177010  4.319603e-06    4.319603e-06      0.000005        0.000005   \n",
       "\n",
       "        DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \n",
       "0                  0.0              0.000002  \n",
       "1                  0.0              0.000002  \n",
       "2                  0.0              0.000002  \n",
       "3                  0.0              0.000002  \n",
       "4                  0.0              0.000002  \n",
       "...                ...                   ...  \n",
       "177006             0.0              0.000027  \n",
       "177007             0.0              0.000008  \n",
       "177008             0.0              0.000004  \n",
       "177009             0.0              0.000004  \n",
       "177010             0.0              0.000004  \n",
       "\n",
       "[177011 rows x 295 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuse_test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised attack classification (Fusion)\n",
    "\n",
    "We now train a supervised classifier on the fused features to predict multi-class attack labels:\n",
    "- Features: embeddings + raw numeric features from `df_fuse_train`/`df_fuse_test` (without `Label`, `Attacks`).\n",
    "- Target: `Attacks` (encoded integer classes from earlier `LabelEncoder`).\n",
    "- Model: HistGradientBoostingClassifier (fast, strong on tabular data). Class imbalance handled via per-sample weights.\n",
    "- Metrics: macro F1, per-class report, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare supervised train/test for attack classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.utils import class_weight\n",
    "import pickle\n",
    "\n",
    "# Build train features/targets from already prepared fused DataFrames\n",
    "X_sup_train = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_sup_test = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights to mitigate class imbalance on training set\n",
    "classes = np.unique(y_sup_train)\n",
    "class_w = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes, y=y_sup_train\n",
    ")\n",
    "class_to_w = {c: w for c, w in zip(classes, class_w)}\n",
    "sample_weight = y_sup_train.map(class_to_w).values\n",
    "\n",
    "# Feature names to all str\n",
    "X_sup_train.columns = X_sup_train.columns.map(str)\n",
    "X_sup_test.columns = X_sup_test.columns.map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Methods (Fused Features)\n",
    "\n",
    "Now we'll compare multiple classification algorithms on the fused features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [08:49<00:00, 58.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 10}\n",
      "Best Macro F1: 0.6359\n",
      "Model saved to: best_rf_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9000    0.9617    0.9298    104997\n",
      "           1     0.9997    0.9521    0.9753     12438\n",
      "           2     0.8539    0.7451    0.7958       102\n",
      "           3     0.5455    0.3529    0.4286        34\n",
      "           4     1.0000    1.0000    1.0000     61790\n",
      "           5     1.0000    1.0000    1.0000       188\n",
      "           6     1.0000    0.9544    0.9767     17362\n",
      "           7     1.0000    0.5000    0.6667      3632\n",
      "           8     0.0000    0.0000    0.0000      5890\n",
      "           9     0.0000    0.0000    0.0000      6320\n",
      "          10     0.0000    0.0000    0.0000      2164\n",
      "          11     0.6477    0.5000    0.5644     23242\n",
      "          12     0.7015    0.9516    0.8076     11314\n",
      "          13     0.2667    0.7500    0.3934        32\n",
      "          14     1.0000    0.9998    0.9999     11310\n",
      "\n",
      "    accuracy                         0.8703    260815\n",
      "   macro avg     0.6610    0.6445    0.6359    260815\n",
      "weighted avg     0.8601    0.8703    0.8619    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with Grid Search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            rf_clf = RandomForestClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            rf_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_rf = rf_clf.predict(X_sup_test)\n",
    "            rf_f1 = f1_score(y_sup_test, y_pred_rf, average='macro')\n",
    "            \n",
    "            if rf_f1 > score:\n",
    "                score = rf_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = rf_clf\n",
    "                # Save best model\n",
    "                with open('best_rf_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(rf_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_rf_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Random Forest: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:27:31] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "100%|██████████| 27/27 [13:39<00:00, 30.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7559\n",
      "Model saved to: best_xgb_classifier_fused.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5154    0.9620    0.6711     21009\n",
      "           1     1.0000    0.9997    0.9998     12400\n",
      "           2     0.8824    0.8333    0.8571        90\n",
      "           3     0.7500    0.2143    0.3333        28\n",
      "           4     0.9999    1.0000    1.0000     62002\n",
      "           5     1.0000    1.0000    1.0000       192\n",
      "           6     1.0000    1.0000    1.0000     17370\n",
      "           7     1.0000    0.5711    0.7270      3656\n",
      "           8     1.0000    0.9802    0.9900      5972\n",
      "           9     0.0000    0.0000    0.0000      6310\n",
      "          10     1.0000    0.5000    0.6667      2126\n",
      "          11     0.7856    0.5000    0.6111     23120\n",
      "          12     0.9256    0.8652    0.8944     11384\n",
      "          13     0.4167    1.0000    0.5882        20\n",
      "          14     1.0000    0.9996    0.9998     11332\n",
      "\n",
      "    accuracy                         0.8701    177011\n",
      "   macro avg     0.8184    0.7617    0.7559    177011\n",
      "weighted avg     0.8739    0.8701    0.8575    177011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with Grid Search\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    import pickle\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST CLASSIFIER (Fused Features)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            xgb_clf = XGBClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                learning_rate=lr,\n",
    "                random_state=13,\n",
    "                tree_method='hist', \n",
    "                device=\"cuda\"\n",
    "            )\n",
    "            \n",
    "            xgb_clf.fit(X_sup_train, y_sup_train, sample_weight=sample_weight)\n",
    "            y_pred_xgb = xgb_clf.predict(X_sup_test)\n",
    "            xgb_f1 = f1_score(y_sup_test, y_pred_xgb, average='macro')\n",
    "            \n",
    "            if xgb_f1 > score:\n",
    "                score = xgb_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = xgb_clf\n",
    "                # Save best model\n",
    "                xgb_clf.save_model('best_xgb_classifier_fused.json')\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_xgb_classifier_fused.json\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed. XGBoost might not support your GPU.\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CatBoost Grid Search (Expanded)...\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      "  4%|▎         | 1/27 [00:08<03:36,  8.32s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      "  7%|▋         | 2/27 [00:16<03:24,  8.17s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 11%|█         | 3/27 [00:24<03:14,  8.12s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 15%|█▍        | 4/27 [00:45<05:01, 13.10s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 19%|█▊        | 5/27 [01:04<05:41, 15.51s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 22%|██▏       | 6/27 [01:24<05:53, 16.85s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 26%|██▌       | 7/27 [02:09<08:39, 25.98s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 30%|██▉       | 8/27 [02:52<09:56, 31.41s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 33%|███▎      | 9/27 [03:34<10:28, 34.90s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 37%|███▋      | 10/27 [03:46<07:53, 27.85s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 41%|████      | 11/27 [03:58<06:06, 22.91s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 44%|████▍     | 12/27 [04:10<04:52, 19.52s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 48%|████▊     | 13/27 [04:41<05:21, 22.96s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 52%|█████▏    | 14/27 [05:10<05:22, 24.82s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 56%|█████▌    | 15/27 [05:39<05:11, 25.99s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 59%|█████▉    | 16/27 [06:46<07:02, 38.41s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 63%|██████▎   | 17/27 [07:50<07:40, 46.08s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 67%|██████▋   | 18/27 [08:53<07:40, 51.14s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 70%|███████   | 19/27 [09:12<05:33, 41.67s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 74%|███████▍  | 20/27 [09:31<04:04, 34.87s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 78%|███████▊  | 21/27 [09:50<03:00, 30.14s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 81%|████████▏ | 22/27 [10:40<03:00, 36.06s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 85%|████████▌ | 23/27 [11:28<02:38, 39.55s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 89%|████████▉ | 24/27 [12:15<02:05, 41.88s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 93%|█████████▎| 25/27 [14:05<02:04, 62.33s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      " 96%|█████████▋| 26/27 [15:50<01:15, 75.12s/it]Warning: less than 75% GPU memory available for training. Free: 3921.0625 Total: 7833.5625\n",
      "100%|██████████| 27/27 [17:34<00:00, 39.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BEST CATBOOST HYPERPARAMETERS (Fused Features):\n",
      "{'iterations': 300, 'depth': 4, 'learning_rate': 0.05}\n",
      "Best Macro F1: 0.7763\n",
      "============================================================\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_fused.cbm\n",
      "\n",
      "============================================================\n",
      "FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9985    0.9272    0.9615    104997\n",
      "           1     0.9832    0.9994    0.9913     12438\n",
      "           2     0.2321    0.7647    0.3562       102\n",
      "           3     0.5714    0.2353    0.3333        34\n",
      "           4     0.9999    1.0000    0.9999     61790\n",
      "           5     1.0000    1.0000    1.0000       188\n",
      "           6     0.9973    0.9998    0.9985     17362\n",
      "           7     0.9806    1.0000    0.9902      3632\n",
      "           8     0.9919    0.9980    0.9949      5890\n",
      "           9     0.2138    0.5000    0.2995      6320\n",
      "          10     0.9749    0.9880    0.9814      2164\n",
      "          11     0.7858    0.5000    0.6111     23242\n",
      "          12     0.6151    0.9828    0.7566     11314\n",
      "          13     0.2407    0.8125    0.3714        32\n",
      "          14     0.9958    1.0000    0.9979     11310\n",
      "\n",
      "    accuracy                         0.9129    260815\n",
      "   macro avg     0.7721    0.8472    0.7763    260815\n",
      "weighted avg     0.9423    0.9129    0.9209    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost with Grid Search (Expanded, no l2_leaf_reg/border_count, fixed best score logic)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"Starting CatBoost Grid Search (Expanded)...\")\n",
    "    \n",
    "    # Expanded hyperparameter grid\n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'  # Use 'CPU' if GPU not available\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_cat = cat_clf.predict(X_sup_test)\n",
    "            cat_f1 = f1_score(y_sup_test, y_pred_cat, average='macro')\n",
    "            \n",
    "            if cat_f1 > best_score:\n",
    "                best_score = cat_f1\n",
    "                best_params = {\n",
    "                    'iterations': iterations,\n",
    "                    'depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for fused features\n",
    "                best_model_path = \"best_catboost_classifier_fused.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEST CATBOOST HYPERPARAMETERS (Fused Features):\")\n",
    "    print(best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    if best_model_path:\n",
    "        print(f\"\\nBest CatBoost model saved to: {best_model_path}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    y_pred_best = best_model.predict(X_sup_test)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_sup_test, y_pred_best, digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed. Install with: pip install catboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [06:13<00:00, 41.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10}\n",
      "Best Macro F1: 0.8262\n",
      "Model saved to: best_et_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9986    0.9531    0.9753    104997\n",
      "           1     0.9981    0.9992    0.9986     12438\n",
      "           2     0.8636    0.7451    0.8000       102\n",
      "           3     0.6000    0.3529    0.4444        34\n",
      "           4     1.0000    1.0000    1.0000     61790\n",
      "           5     1.0000    0.9894    0.9947       188\n",
      "           6     1.0000    1.0000    1.0000     17362\n",
      "           7     1.0000    1.0000    1.0000      3632\n",
      "           8     1.0000    1.0000    1.0000      5890\n",
      "           9     0.0000    0.0000    0.0000      6320\n",
      "          10     1.0000    1.0000    1.0000      2164\n",
      "          11     0.7862    1.0000    0.8803     23242\n",
      "          12     0.6957    0.9868    0.8161     11314\n",
      "          13     0.3261    0.9375    0.4839        32\n",
      "          14     1.0000    1.0000    1.0000     11310\n",
      "\n",
      "    accuracy                         0.9561    260815\n",
      "   macro avg     0.8179    0.8643    0.8262    260815\n",
      "weighted avg     0.9427    0.9561    0.9469    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            et_clf = ExtraTreesClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            et_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_et = et_clf.predict(X_sup_test)\n",
    "            et_f1 = f1_score(y_sup_test, y_pred_et, average='macro')\n",
    "            \n",
    "            if et_f1 > score:\n",
    "                score = et_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = et_clf\n",
    "                # Save best model\n",
    "                with open('best_et_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(et_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_et_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Extra Trees: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Features Classification (Comparison Baseline)\n",
    "\n",
    "Now we'll train classifiers on **raw features only** (without graph embeddings) to compare the benefit of multimodal fusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw feature shape - Train: (304665, 39), Test: (130572, 39)\n",
      "Number of classes: 15\n"
     ]
    }
   ],
   "source": [
    "# Prepare raw features (without embeddings)\n",
    "# Use only the original numeric features from X_train/X_test\n",
    "\n",
    "X_raw_train = X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_train = y_train[\"Attack\"].copy()\n",
    "\n",
    "X_raw_test = X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_test = y_test[\"Attack\"].copy()\n",
    "\n",
    "# Encode labels\n",
    "y_raw_train_encoded = lab_enc.transform(y_train[\"Attack\"])\n",
    "y_raw_test_encoded = lab_enc.transform(y_test[\"Attack\"])\n",
    "\n",
    "# Compute sample weights\n",
    "classes_raw = np.unique(y_raw_train_encoded)\n",
    "class_w_raw = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_raw, y=y_raw_train_encoded\n",
    ")\n",
    "class_to_w_raw = {c: w for c, w in zip(classes_raw, class_w_raw)}\n",
    "sample_weight_raw = pd.Series(y_raw_train_encoded).map(class_to_w_raw).values\n",
    "\n",
    "# Feature names to str\n",
    "X_raw_train.columns = X_raw_train.columns.map(str)\n",
    "X_raw_test.columns = X_raw_test.columns.map(str)\n",
    "\n",
    "print(f\"Raw feature shape - Train: {X_raw_train.shape}, Test: {X_raw_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_raw_train_encoded))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Raw Features Only)\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [04:12<00:00, 28.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 30}\n",
      "Best Macro F1: 0.6979\n",
      "Model saved to: best_rf_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9544    0.7950    0.8675     52663\n",
      "           1     1.0000    0.9997    0.9998      6219\n",
      "           2     0.1386    0.4510    0.2120        51\n",
      "           3     0.3846    0.8824    0.5357        17\n",
      "           4     0.9999    1.0000    1.0000     30895\n",
      "           5     0.8440    0.9787    0.9064        94\n",
      "           6     0.9988    0.9980    0.9984      8681\n",
      "           7     0.9994    1.0000    0.9997      1816\n",
      "           8     1.0000    0.9997    0.9998      2945\n",
      "           9     0.2138    1.0000    0.3523      3160\n",
      "          10     1.0000    0.9982    0.9991      1082\n",
      "          11     0.0000    0.0000    0.0000     11621\n",
      "          12     0.2557    0.6470    0.3665      5657\n",
      "          13     0.3000    0.1875    0.2308        16\n",
      "          14     1.0000    1.0000    1.0000      5655\n",
      "\n",
      "    accuracy                         0.8125    130572\n",
      "   macro avg     0.6726    0.7958    0.6979    130572\n",
      "weighted avg     0.8406    0.8125    0.8138    130572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Raw Features Only)\")\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = rf_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Raw Features Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:19:42] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "100%|██████████| 27/27 [05:20<00:00, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7387\n",
      "Model saved to: best_xgb_classifier_raw.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9551    0.7654    0.8498     52663\n",
      "           1     0.9994    1.0000    0.9997      6219\n",
      "           2     0.2500    0.5882    0.3509        51\n",
      "           3     0.3611    0.7647    0.4906        17\n",
      "           4     0.9998    1.0000    0.9999     30895\n",
      "           5     0.8426    0.9681    0.9010        94\n",
      "           6     0.9988    0.9978    0.9983      8681\n",
      "           7     0.9989    1.0000    0.9994      1816\n",
      "           8     1.0000    1.0000    1.0000      2945\n",
      "           9     0.0000    0.0000    0.0000      3160\n",
      "          10     0.9972    0.9991    0.9982      1082\n",
      "          11     0.7862    1.0000    0.8803     11621\n",
      "          12     0.2341    0.6627    0.3460      5657\n",
      "          13     0.2857    0.2500    0.2667        16\n",
      "          14     1.0000    1.0000    1.0000      5655\n",
      "\n",
      "    accuracy                         0.8661    130572\n",
      "   macro avg     0.7139    0.7997    0.7387    130572\n",
      "weighted avg     0.9047    0.8661    0.8756    130572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Raw Features Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='cuda'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_raw_train, y_raw_train_encoded, sample_weight=sample_weight_raw)\n",
    "        y_pred = xgb_clf.predict(X_raw_test)\n",
    "        f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_raw.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_raw.json\\n\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Raw Features Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 3089.3125 Total: 5806.3125\n",
      "  4%|▎         | 1/27 [00:02<01:10,  2.72s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      "  7%|▋         | 2/27 [00:05<01:05,  2.60s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 11%|█         | 3/27 [00:07<01:01,  2.56s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 15%|█▍        | 4/27 [00:13<01:31,  3.99s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 19%|█▊        | 5/27 [00:19<01:42,  4.68s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 22%|██▏       | 6/27 [00:25<01:46,  5.06s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 26%|██▌       | 7/27 [00:38<02:32,  7.63s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 30%|██▉       | 8/27 [00:51<02:55,  9.22s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 33%|███▎      | 9/27 [01:03<03:03, 10.20s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 37%|███▋      | 10/27 [01:07<02:19,  8.23s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 41%|████      | 11/27 [01:10<01:49,  6.82s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 44%|████▍     | 12/27 [01:14<01:27,  5.86s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 48%|████▊     | 13/27 [01:23<01:35,  6.85s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 52%|█████▏    | 14/27 [01:32<01:35,  7.38s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 56%|█████▌    | 15/27 [01:40<01:32,  7.75s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 59%|█████▉    | 16/27 [02:00<02:04, 11.33s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 63%|██████▎   | 17/27 [02:19<02:15, 13.60s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 67%|██████▋   | 18/27 [02:38<02:16, 15.18s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 70%|███████   | 19/27 [02:44<01:39, 12.49s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 74%|███████▍  | 20/27 [02:50<01:13, 10.50s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 78%|███████▊  | 21/27 [02:56<00:54,  9.10s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 81%|████████▏ | 22/27 [03:10<00:53, 10.78s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 85%|████████▌ | 23/27 [03:24<00:46, 11.71s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 89%|████████▉ | 24/27 [03:38<00:37, 12.34s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 93%|█████████▎| 25/27 [04:10<00:36, 18.22s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 96%|█████████▋| 26/27 [04:41<00:21, 21.98s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      "100%|██████████| 27/27 [05:12<00:00, 11.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7170\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_raw.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9556    0.7538    0.8428     52663\n",
      "           1     0.9974    1.0000    0.9987      6219\n",
      "           2     0.1571    0.6471    0.2529        51\n",
      "           3     0.2456    0.8235    0.3784        17\n",
      "           4     0.9997    1.0000    0.9999     30895\n",
      "           5     0.8174    1.0000    0.8995        94\n",
      "           6     0.9982    0.9976    0.9979      8681\n",
      "           7     0.9983    0.9989    0.9986      1816\n",
      "           8     0.9990    0.9980    0.9985      2945\n",
      "           9     0.0000    0.0000    0.0000      3160\n",
      "          10     0.9854    1.0000    0.9927      1082\n",
      "          11     0.7862    1.0000    0.8803     11621\n",
      "          12     0.2289    0.6689    0.3410      5657\n",
      "          13     0.2857    0.1250    0.1739        16\n",
      "          14     1.0000    1.0000    1.0000      5655\n",
      "\n",
      "    accuracy                         0.8617    130572\n",
      "   macro avg     0.6970    0.8008    0.7170    130572\n",
      "weighted avg     0.9043    0.8617    0.8723    130572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Raw Features Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "            y_pred = cat_clf.predict(X_raw_test)\n",
    "            f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for raw features\n",
    "                best_model_path = \"best_catboost_classifier_raw.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Raw Features Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:50<00:00, 18.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 30}\n",
      "Best Macro F1: 0.7311\n",
      "Model saved to: best_et_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9492    0.8420    0.8924     52663\n",
      "           1     0.9997    0.9998    0.9998      6219\n",
      "           2     0.1557    0.3725    0.2197        51\n",
      "           3     0.3684    0.8235    0.5091        17\n",
      "           4     1.0000    1.0000    1.0000     30895\n",
      "           5     0.8542    0.8723    0.8632        94\n",
      "           6     0.9977    0.9984    0.9980      8681\n",
      "           7     1.0000    1.0000    1.0000      1816\n",
      "           8     1.0000    1.0000    1.0000      2945\n",
      "           9     0.0000    0.0000    0.0000      3160\n",
      "          10     0.9991    0.9991    0.9991      1082\n",
      "          11     0.7862    1.0000    0.8803     11621\n",
      "          12     0.2858    0.5816    0.3833      5657\n",
      "          13     0.2727    0.1875    0.2222        16\n",
      "          14     1.0000    1.0000    1.0000      5655\n",
      "\n",
      "    accuracy                         0.8934    130572\n",
      "   macro avg     0.7112    0.7785    0.7311    130572\n",
      "weighted avg     0.9046    0.8934    0.8943    130572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Raw Features Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = et_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Only Classification (Graph Features)\n",
    "\n",
    "Now we'll train classifiers on **embeddings only** (graph features without raw features) to isolate the value of graph-based learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape - Train: (608554, 256), Test: (260815, 256)\n",
      "Number of classes: 15\n",
      "Using only graph embeddings (no raw features)\n"
     ]
    }
   ],
   "source": [
    "# Prepare embeddings-only features (graph features without raw data)\n",
    "# Extract only the embedding columns (first 256 dimensions from graph encoder)\n",
    "\n",
    "# From the fused dataframes, extract only embedding columns\n",
    "# df_fuse_train has: [0-255] = embeddings, [256+] = raw features\n",
    "num_embedding_dims = 256  # Based on the DGI encoder output dimension\n",
    "\n",
    "X_emb_train = df_fuse_train.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_emb_test = df_fuse_test.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights\n",
    "classes_emb = np.unique(y_emb_train)\n",
    "class_w_emb = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_emb, y=y_emb_train\n",
    ")\n",
    "class_to_w_emb = {c: w for c, w in zip(classes_emb, class_w_emb)}\n",
    "sample_weight_emb = y_emb_train.map(class_to_w_emb).values\n",
    "\n",
    "# Feature names to str\n",
    "X_emb_train.columns = X_emb_train.columns.map(str)\n",
    "X_emb_test.columns = X_emb_test.columns.map(str)\n",
    "\n",
    "print(f\"Embeddings shape - Train: {X_emb_train.shape}, Test: {X_emb_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_emb_train))}\")\n",
    "print(f\"Using only graph embeddings (no raw features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [15:00<00:00, 100.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 10}\n",
      "Best Macro F1: 0.4367\n",
      "Model saved to: best_rf_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7489    0.9592    0.8411    104997\n",
      "           1     0.9998    0.9522    0.9755     12438\n",
      "           2     0.8043    0.7255    0.7629       102\n",
      "           3     0.8000    0.1176    0.2051        34\n",
      "           4     0.9970    0.5491    0.7082     61790\n",
      "           5     0.0035    0.4096    0.0070       188\n",
      "           6     1.0000    0.9542    0.9765     17362\n",
      "           7     0.0000    0.0000    0.0000      3632\n",
      "           8     0.0000    0.0000    0.0000      5890\n",
      "           9     0.0000    0.0000    0.0000      6320\n",
      "          10     0.0000    0.0000    0.0000      2164\n",
      "          11     0.7862    0.5000    0.6113     23242\n",
      "          12     0.6843    0.9245    0.7865     11314\n",
      "          13     0.0051    1.0000    0.0101        32\n",
      "          14     1.0000    0.5000    0.6667     11310\n",
      "\n",
      "    accuracy                         0.7322    260815\n",
      "   macro avg     0.5219    0.5061    0.4367    260815\n",
      "weighted avg     0.7955    0.7322    0.7357    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = rf_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [30:41<00:00, 68.21s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "Best Macro F1: 0.5536\n",
      "Model saved to: best_xgb_classifier_embeddings.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8305    0.9623    0.8916    104997\n",
      "           1     0.9999    0.8780    0.9350     12438\n",
      "           2     0.0272    0.8627    0.0528       102\n",
      "           3     0.8000    0.1176    0.2051        34\n",
      "           4     0.9969    0.2991    0.4602     61790\n",
      "           5     0.0032    0.6436    0.0065       188\n",
      "           6     1.0000    1.0000    1.0000     17362\n",
      "           7     1.0000    1.0000    1.0000      3632\n",
      "           8     1.0000    0.5000    0.6667      5890\n",
      "           9     0.0000    0.0000    0.0000      6320\n",
      "          10     1.0000    0.5000    0.6667      2164\n",
      "          11     0.7862    0.5000    0.6113     23242\n",
      "          12     0.6982    0.9220    0.7947     11314\n",
      "          13     0.0066    0.6562    0.0131        32\n",
      "          14     1.0000    1.0000    1.0000     11310\n",
      "\n",
      "    accuracy                         0.7249    260815\n",
      "   macro avg     0.6766    0.6561    0.5536    260815\n",
      "weighted avg     0.8734    0.7249    0.7460    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Embeddings Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='gpu'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_emb_train, y_emb_train, sample_weight=sample_weight_emb)\n",
    "        y_pred = xgb_clf.predict(X_emb_test)\n",
    "        f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_embeddings.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_embeddings.json\\n\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Embeddings Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      "  4%|▎         | 1/27 [00:07<03:08,  7.23s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      "  7%|▋         | 2/27 [00:14<02:54,  7.00s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 11%|█         | 3/27 [00:20<02:45,  6.88s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 15%|█▍        | 4/27 [00:39<04:24, 11.49s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 19%|█▊        | 5/27 [00:56<04:55, 13.44s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 22%|██▏       | 6/27 [01:12<05:02, 14.40s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 26%|██▌       | 7/27 [01:52<07:34, 22.74s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 30%|██▉       | 8/27 [02:29<08:35, 27.16s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 33%|███▎      | 9/27 [03:04<08:54, 29.71s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 37%|███▋      | 10/27 [03:14<06:44, 23.78s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 41%|████      | 11/27 [03:24<05:12, 19.56s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 44%|████▍     | 12/27 [03:34<04:09, 16.62s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 48%|████▊     | 13/27 [04:02<04:38, 19.93s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 52%|█████▏    | 14/27 [04:26<04:37, 21.35s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 56%|█████▌    | 15/27 [04:51<04:26, 22.20s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 59%|█████▉    | 16/27 [05:50<06:08, 33.51s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 63%|██████▎   | 17/27 [06:44<06:36, 39.63s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 67%|██████▋   | 18/27 [07:37<06:31, 43.53s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 70%|███████   | 19/27 [07:54<04:43, 35.49s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 74%|███████▍  | 20/27 [08:10<03:27, 29.70s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 78%|███████▊  | 21/27 [08:26<02:33, 25.61s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 81%|████████▏ | 22/27 [09:09<02:34, 30.97s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 85%|████████▌ | 23/27 [09:49<02:14, 33.71s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 89%|████████▉ | 24/27 [10:29<01:46, 35.47s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 93%|█████████▎| 25/27 [12:04<01:46, 53.47s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 96%|█████████▋| 26/27 [13:32<01:03, 63.81s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      "100%|██████████| 27/27 [14:59<00:00, 33.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7352\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_embeddings.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9933    0.9571    0.9749    104997\n",
      "           1     0.9998    1.0000    0.9999     12438\n",
      "           2     0.8721    0.7353    0.7979       102\n",
      "           3     0.3947    0.8824    0.5455        34\n",
      "           4     0.9970    0.4990    0.6651     61790\n",
      "           5     0.0031    0.5106    0.0061       188\n",
      "           6     1.0000    1.0000    1.0000     17362\n",
      "           7     0.9997    1.0000    0.9999      3632\n",
      "           8     1.0000    1.0000    1.0000      5890\n",
      "           9     0.2138    0.5000    0.2995      6320\n",
      "          10     1.0000    1.0000    1.0000      2164\n",
      "          11     0.7862    0.5000    0.6113     23242\n",
      "          12     0.7049    0.9406    0.8059     11314\n",
      "          13     0.3333    0.3125    0.3226        32\n",
      "          14     1.0000    1.0000    1.0000     11310\n",
      "\n",
      "    accuracy                         0.8042    260815\n",
      "   macro avg     0.7532    0.7892    0.7352    260815\n",
      "weighted avg     0.9448    0.8042    0.8496    260815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Embeddings Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_emb_train, y_emb_train)\n",
    "            y_pred = cat_clf.predict(X_emb_test)\n",
    "            f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for embeddings\n",
    "                best_model_path = \"best_catboost_classifier_embeddings.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [05:23<00:00, 35.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 10}\n",
      "Best Macro F1: 0.6906\n",
      "Model saved to: best_et_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9987    0.9543    0.9760    104997\n",
      "           1     0.9982    0.9761    0.9870     12438\n",
      "           2     0.8636    0.7451    0.8000       102\n",
      "           3     0.8000    0.2353    0.3636        34\n",
      "           4     0.9969    0.5996    0.7488     61790\n",
      "           5     0.0033    0.4415    0.0066       188\n",
      "           6     1.0000    1.0000    1.0000     17362\n",
      "           7     1.0000    1.0000    1.0000      3632\n",
      "           8     1.0000    1.0000    1.0000      5890\n",
      "           9     0.2138    1.0000    0.3523      6320\n",
      "          10     1.0000    1.0000    1.0000      2164\n",
      "          11     0.0000    0.0000    0.0000     23242\n",
      "          12     0.6897    0.9881    0.8123     11314\n",
      "          13     0.2083    0.6250    0.3125        32\n",
      "          14     1.0000    1.0000    1.0000     11310\n",
      "\n",
      "    accuracy                         0.7953    260815\n",
      "   macro avg     0.7182    0.7710    0.6906    260815\n",
      "weighted avg     0.8761    0.7953    0.8163    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = et_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Comparison Table\n",
    "\n",
    "Create a comparison table of all methods (Fused vs Raw features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\n",
      "===============================================================================================\n",
      "\n",
      "Instructions:\n",
      "1. Run all cells above to get F1 scores for each method\n",
      "2. Record the best Macro F1 score for each method\n",
      "3. Compare three approaches:\n",
      "   - Fused Features: Embeddings + Raw (Multimodal)\n",
      "   - Embeddings Only: Graph features only\n",
      "   - Raw Features: Traditional features only\n",
      "\n",
      "Expected format:\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Method               Fused (Emb+Raw)           Embeddings Only           Raw Only                 \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Random Forest        [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "XGBoost              [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "CatBoost             [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "Extra Trees          [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysis:\n",
      "- Fused features should show best performance (multimodal learning)\n",
      "- Embeddings capture structural/graph patterns\n",
      "- Raw features provide traditional statistical information\n",
      "- Compare to understand the contribution of each modality\n"
     ]
    }
   ],
   "source": [
    "# Create a summary comparison table\n",
    "# NOTE: After running all cells above, manually collect the F1 scores and create a comparison\n",
    "\n",
    "print(\"=\"*95)\n",
    "print(\"PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\")\n",
    "print(\"=\"*95)\n",
    "print(\"\\nInstructions:\")\n",
    "print(\"1. Run all cells above to get F1 scores for each method\")\n",
    "print(\"2. Record the best Macro F1 score for each method\")\n",
    "print(\"3. Compare three approaches:\")\n",
    "print(\"   - Fused Features: Embeddings + Raw (Multimodal)\")\n",
    "print(\"   - Embeddings Only: Graph features only\")\n",
    "print(\"   - Raw Features: Traditional features only\")\n",
    "print(\"\\nExpected format:\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Method':<20} {'Fused (Emb+Raw)':<25} {'Embeddings Only':<25} {'Raw Only':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Random Forest':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'XGBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'CatBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'Extra Trees':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"- Fused features should show best performance (multimodal learning)\")\n",
    "print(\"- Embeddings capture structural/graph patterns\")\n",
    "print(\"- Raw features provide traditional statistical information\")\n",
    "print(\"- Compare to understand the contribution of each modality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights & Interpretation\n",
    "\n",
    "After running all experiments, analyze the results to answer:\n",
    "\n",
    "1. **Which approach performs best overall?**\n",
    "   - Fused features (multimodal) should ideally outperform single modalities\n",
    "   - Compare the magnitude of improvements\n",
    "\n",
    "2. **What is the value of graph embeddings?**\n",
    "   - Compare Embeddings-only vs Raw-only to see if graph structure helps\n",
    "   - If embeddings alone beat raw features, graph learning is beneficial\n",
    "\n",
    "3. **Is multimodal fusion effective?**\n",
    "   - Compare Fused vs (Embeddings + Raw separately)\n",
    "   - Synergy should provide additional gains beyond individual modalities\n",
    "\n",
    "4. **Which classifier is most suitable?**\n",
    "   - Identify the best performing algorithm for each feature type\n",
    "   - Consider computational cost vs accuracy trade-offs\n",
    "\n",
    "5. **Feature contribution analysis:**\n",
    "   - If Fused ≈ Embeddings > Raw: Graph structure dominates\n",
    "   - If Fused ≈ Raw > Embeddings: Traditional features dominate\n",
    "   - If Fused > Both: True synergy from multimodal learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
