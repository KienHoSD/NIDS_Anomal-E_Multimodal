{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Hjc3iIihKLn-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from dgl.data import DGLDataset\n",
    "import dgl\n",
    "import time\n",
    "import networkx as nx\n",
    "import category_encoders as ce\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "from typing import *\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvWHb_BpKsLq"
   },
   "outputs": [],
   "source": [
    "# file_name = \"CSE_Netflow.csv\"\n",
    "file_name = \"Self-Collected-NF-CSE-CICIDS.parquet\"\n",
    "data = pd.read_parquet(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "fqly1y-LMwYS",
    "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    636608\n",
       "1    349522\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>L4_SRC_PORT</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>L4_DST_PORT</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>...</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "      <td>636608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute Force -Web</th>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>...</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "      <td>29391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute Force -XSS</th>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>...</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "      <td>16792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-GoldenEye</th>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>...</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "      <td>97869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-Hulk</th>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>...</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "      <td>57463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-SlowHTTPTest</th>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>...</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "      <td>33922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-Slowloris</th>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>...</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "      <td>51557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTP-BruteForce</th>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>...</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "      <td>7202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infilteration</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>...</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQL Injection</th>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>...</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "      <td>4821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSH-Bruteforce</th>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>...</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          IPV4_SRC_ADDR  L4_SRC_PORT  IPV4_DST_ADDR  \\\n",
       "Attack                                                                \n",
       "Benign                           636608       636608         636608   \n",
       "Brute Force -Web                  29391        29391          29391   \n",
       "Brute Force -XSS                  16792        16792          16792   \n",
       "DoS attacks-GoldenEye             97869        97869          97869   \n",
       "DoS attacks-Hulk                  57463        57463          57463   \n",
       "DoS attacks-SlowHTTPTest          33922        33922          33922   \n",
       "DoS attacks-Slowloris             51557        51557          51557   \n",
       "FTP-BruteForce                     7202         7202           7202   \n",
       "Infilteration                     50000        50000          50000   \n",
       "SQL Injection                      4821         4821           4821   \n",
       "SSH-Bruteforce                      505          505            505   \n",
       "\n",
       "                          L4_DST_PORT  PROTOCOL  L7_PROTO  IN_BYTES  IN_PKTS  \\\n",
       "Attack                                                                         \n",
       "Benign                         636608    636608    636608    636608   636608   \n",
       "Brute Force -Web                29391     29391     29391     29391    29391   \n",
       "Brute Force -XSS                16792     16792     16792     16792    16792   \n",
       "DoS attacks-GoldenEye           97869     97869     97869     97869    97869   \n",
       "DoS attacks-Hulk                57463     57463     57463     57463    57463   \n",
       "DoS attacks-SlowHTTPTest        33922     33922     33922     33922    33922   \n",
       "DoS attacks-Slowloris           51557     51557     51557     51557    51557   \n",
       "FTP-BruteForce                   7202      7202      7202      7202     7202   \n",
       "Infilteration                   50000     50000     50000     50000    50000   \n",
       "SQL Injection                    4821      4821      4821      4821     4821   \n",
       "SSH-Bruteforce                    505       505       505       505      505   \n",
       "\n",
       "                          OUT_BYTES  OUT_PKTS  ...  \\\n",
       "Attack                                         ...   \n",
       "Benign                       636608    636608  ...   \n",
       "Brute Force -Web              29391     29391  ...   \n",
       "Brute Force -XSS              16792     16792  ...   \n",
       "DoS attacks-GoldenEye         97869     97869  ...   \n",
       "DoS attacks-Hulk              57463     57463  ...   \n",
       "DoS attacks-SlowHTTPTest      33922     33922  ...   \n",
       "DoS attacks-Slowloris         51557     51557  ...   \n",
       "FTP-BruteForce                 7202      7202  ...   \n",
       "Infilteration                 50000     50000  ...   \n",
       "SQL Injection                  4821      4821  ...   \n",
       "SSH-Bruteforce                  505       505  ...   \n",
       "\n",
       "                          NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  \\\n",
       "Attack                                                                  \n",
       "Benign                                         636608          636608   \n",
       "Brute Force -Web                                29391           29391   \n",
       "Brute Force -XSS                                16792           16792   \n",
       "DoS attacks-GoldenEye                           97869           97869   \n",
       "DoS attacks-Hulk                                57463           57463   \n",
       "DoS attacks-SlowHTTPTest                        33922           33922   \n",
       "DoS attacks-Slowloris                           51557           51557   \n",
       "FTP-BruteForce                                   7202            7202   \n",
       "Infilteration                                   50000           50000   \n",
       "SQL Injection                                    4821            4821   \n",
       "SSH-Bruteforce                                    505             505   \n",
       "\n",
       "                          TCP_WIN_MAX_OUT  ICMP_TYPE  ICMP_IPV4_TYPE  \\\n",
       "Attack                                                                 \n",
       "Benign                             636608     636608          636608   \n",
       "Brute Force -Web                    29391      29391           29391   \n",
       "Brute Force -XSS                    16792      16792           16792   \n",
       "DoS attacks-GoldenEye               97869      97869           97869   \n",
       "DoS attacks-Hulk                    57463      57463           57463   \n",
       "DoS attacks-SlowHTTPTest            33922      33922           33922   \n",
       "DoS attacks-Slowloris               51557      51557           51557   \n",
       "FTP-BruteForce                       7202       7202            7202   \n",
       "Infilteration                       50000      50000           50000   \n",
       "SQL Injection                        4821       4821            4821   \n",
       "SSH-Bruteforce                        505        505             505   \n",
       "\n",
       "                          DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  \\\n",
       "Attack                                                                   \n",
       "Benign                          636608          636608          636608   \n",
       "Brute Force -Web                 29391           29391           29391   \n",
       "Brute Force -XSS                 16792           16792           16792   \n",
       "DoS attacks-GoldenEye            97869           97869           97869   \n",
       "DoS attacks-Hulk                 57463           57463           57463   \n",
       "DoS attacks-SlowHTTPTest         33922           33922           33922   \n",
       "DoS attacks-Slowloris            51557           51557           51557   \n",
       "FTP-BruteForce                    7202            7202            7202   \n",
       "Infilteration                    50000           50000           50000   \n",
       "SQL Injection                     4821            4821            4821   \n",
       "SSH-Bruteforce                     505             505             505   \n",
       "\n",
       "                          FTP_COMMAND_RET_CODE   Label  \n",
       "Attack                                                  \n",
       "Benign                                  636608  636608  \n",
       "Brute Force -Web                         29391   29391  \n",
       "Brute Force -XSS                         16792   16792  \n",
       "DoS attacks-GoldenEye                    97869   97869  \n",
       "DoS attacks-Hulk                         57463   57463  \n",
       "DoS attacks-SlowHTTPTest                 33922   33922  \n",
       "DoS attacks-Slowloris                    51557   51557  \n",
       "FTP-BruteForce                            7202    7202  \n",
       "Infilteration                            50000   50000  \n",
       "SQL Injection                             4821    4821  \n",
       "SSH-Bruteforce                             505     505  \n",
       "\n",
       "[11 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by='Attack').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3t4OREvSM33h"
   },
   "outputs": [],
   "source": [
    "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
    "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
    "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
    "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bTtHq0XqNXxI"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUNIP-8zNkn9",
    "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DoS attacks-GoldenEye', 'Benign', 'FTP-BruteForce',\n",
       "       'DoS attacks-Hulk', 'Infilteration', 'DoS attacks-SlowHTTPTest',\n",
       "       'DoS attacks-Slowloris', 'SQL Injection', 'SSH-Bruteforce',\n",
       "       'Brute Force -Web', 'Brute Force -XSS'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Attack.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlPa58fVN7gB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    174868\n",
       "0     63554\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the dataset based on your needs (machine capacity) ideally ~500k rows\n",
    "\n",
    "# data = data.groupby(by='Attack').sample(frac=0.1, random_state=13)\n",
    "data_attack = data[data['Label'] == 1]\n",
    "data_benign = data[data['Label'] == 0].sample(frac=0.2, random_state=13)\n",
    "data = pd.concat([data_attack, data_benign], axis=0)\n",
    "data = data.sample(frac=0.5, random_state=13).reset_index(drop=True)\n",
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "lcfAP6ViOp-J",
    "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>...</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "      <td>63554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute Force -Web</th>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>...</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "      <td>14510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute Force -XSS</th>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>...</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "      <td>8403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-GoldenEye</th>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>...</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "      <td>49023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-Hulk</th>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>...</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "      <td>28674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-SlowHTTPTest</th>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>...</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "      <td>17043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-Slowloris</th>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>...</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "      <td>25787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTP-BruteForce</th>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>...</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "      <td>3655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infilteration</th>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>...</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "      <td>25097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQL Injection</th>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>...</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "      <td>2428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSH-Bruteforce</th>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>...</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          IPV4_SRC_ADDR  IPV4_DST_ADDR  PROTOCOL  L7_PROTO  \\\n",
       "Attack                                                                       \n",
       "Benign                            63554          63554     63554     63554   \n",
       "Brute Force -Web                  14510          14510     14510     14510   \n",
       "Brute Force -XSS                   8403           8403      8403      8403   \n",
       "DoS attacks-GoldenEye             49023          49023     49023     49023   \n",
       "DoS attacks-Hulk                  28674          28674     28674     28674   \n",
       "DoS attacks-SlowHTTPTest          17043          17043     17043     17043   \n",
       "DoS attacks-Slowloris             25787          25787     25787     25787   \n",
       "FTP-BruteForce                     3655           3655      3655      3655   \n",
       "Infilteration                     25097          25097     25097     25097   \n",
       "SQL Injection                      2428           2428      2428      2428   \n",
       "SSH-Bruteforce                      248            248       248       248   \n",
       "\n",
       "                          IN_BYTES  IN_PKTS  OUT_BYTES  OUT_PKTS  TCP_FLAGS  \\\n",
       "Attack                                                                        \n",
       "Benign                       63554    63554      63554     63554      63554   \n",
       "Brute Force -Web             14510    14510      14510     14510      14510   \n",
       "Brute Force -XSS              8403     8403       8403      8403       8403   \n",
       "DoS attacks-GoldenEye        49023    49023      49023     49023      49023   \n",
       "DoS attacks-Hulk             28674    28674      28674     28674      28674   \n",
       "DoS attacks-SlowHTTPTest     17043    17043      17043     17043      17043   \n",
       "DoS attacks-Slowloris        25787    25787      25787     25787      25787   \n",
       "FTP-BruteForce                3655     3655       3655      3655       3655   \n",
       "Infilteration                25097    25097      25097     25097      25097   \n",
       "SQL Injection                 2428     2428       2428      2428       2428   \n",
       "SSH-Bruteforce                 248      248        248       248        248   \n",
       "\n",
       "                          CLIENT_TCP_FLAGS  ...  NUM_PKTS_1024_TO_1514_BYTES  \\\n",
       "Attack                                      ...                                \n",
       "Benign                               63554  ...                        63554   \n",
       "Brute Force -Web                     14510  ...                        14510   \n",
       "Brute Force -XSS                      8403  ...                         8403   \n",
       "DoS attacks-GoldenEye                49023  ...                        49023   \n",
       "DoS attacks-Hulk                     28674  ...                        28674   \n",
       "DoS attacks-SlowHTTPTest             17043  ...                        17043   \n",
       "DoS attacks-Slowloris                25787  ...                        25787   \n",
       "FTP-BruteForce                        3655  ...                         3655   \n",
       "Infilteration                        25097  ...                        25097   \n",
       "SQL Injection                         2428  ...                         2428   \n",
       "SSH-Bruteforce                         248  ...                          248   \n",
       "\n",
       "                          TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  ICMP_TYPE  \\\n",
       "Attack                                                                 \n",
       "Benign                             63554            63554      63554   \n",
       "Brute Force -Web                   14510            14510      14510   \n",
       "Brute Force -XSS                    8403             8403       8403   \n",
       "DoS attacks-GoldenEye              49023            49023      49023   \n",
       "DoS attacks-Hulk                   28674            28674      28674   \n",
       "DoS attacks-SlowHTTPTest           17043            17043      17043   \n",
       "DoS attacks-Slowloris              25787            25787      25787   \n",
       "FTP-BruteForce                      3655             3655       3655   \n",
       "Infilteration                      25097            25097      25097   \n",
       "SQL Injection                       2428             2428       2428   \n",
       "SSH-Bruteforce                       248              248        248   \n",
       "\n",
       "                          ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "Attack                                                                   \n",
       "Benign                             63554         63554           63554   \n",
       "Brute Force -Web                   14510         14510           14510   \n",
       "Brute Force -XSS                    8403          8403            8403   \n",
       "DoS attacks-GoldenEye              49023         49023           49023   \n",
       "DoS attacks-Hulk                   28674         28674           28674   \n",
       "DoS attacks-SlowHTTPTest           17043         17043           17043   \n",
       "DoS attacks-Slowloris              25787         25787           25787   \n",
       "FTP-BruteForce                      3655          3655            3655   \n",
       "Infilteration                      25097         25097           25097   \n",
       "SQL Injection                       2428          2428            2428   \n",
       "SSH-Bruteforce                       248           248             248   \n",
       "\n",
       "                          DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  Label  \n",
       "Attack                                                                 \n",
       "Benign                             63554                 63554  63554  \n",
       "Brute Force -Web                   14510                 14510  14510  \n",
       "Brute Force -XSS                    8403                  8403   8403  \n",
       "DoS attacks-GoldenEye              49023                 49023  49023  \n",
       "DoS attacks-Hulk                   28674                 28674  28674  \n",
       "DoS attacks-SlowHTTPTest           17043                 17043  17043  \n",
       "DoS attacks-Slowloris              25787                 25787  25787  \n",
       "FTP-BruteForce                      3655                  3655   3655  \n",
       "Infilteration                      25097                 25097  25097  \n",
       "SQL Injection                       2428                  2428   2428  \n",
       "SSH-Bruteforce                       248                   248    248  \n",
       "\n",
       "[11 rows x 42 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=\"Attack\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FqRx5xCPOuv8"
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Attack\", \"Label\"])\n",
    "y = data[[\"Attack\", \"Label\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=13, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bPfakXplPGGx"
   },
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
    "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
    "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
    "                                  'FTP_COMMAND_RET_CODE'])\n",
    "encoder.fit(X_train, y_train.Label)\n",
    "\n",
    "# Transform on training set\n",
    "X_train = encoder.transform(X_train)\n",
    "\n",
    "# Transform on testing set\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ibyOfV-8PouK"
   },
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "asDnsSIWPee0"
   },
   "outputs": [],
   "source": [
    "# (Modified)\n",
    "scaler = Normalizer()\n",
    "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
    "scaler.fit(X_train[cols_to_norm])\n",
    "\n",
    "# Transform on training set\n",
    "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
    "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
    "X_train['id'] = X_train.index\n",
    "\n",
    "# Transform on testing set\n",
    "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
    "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
    "X_test['id'] = X_test.index\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "hErQbsnrPluV",
    "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>h</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107317</th>\n",
       "      <td>145.82.199.44</td>\n",
       "      <td>182.129.67.88</td>\n",
       "      <td>8.380256e-09</td>\n",
       "      <td>1.049606e-08</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>6.512822e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.141009e-08</td>\n",
       "      <td>1.141009e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.380256e-09</td>\n",
       "      <td>8.380256e-09</td>\n",
       "      <td>8.380256e-09</td>\n",
       "      <td>8.380256e-09</td>\n",
       "      <td>-1.142600e-08</td>\n",
       "      <td>8.508713e-09</td>\n",
       "      <td>[8.380256498754423e-09, 1.0496055358705104e-08...</td>\n",
       "      <td>107317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19795</th>\n",
       "      <td>103.57.14.23</td>\n",
       "      <td>182.129.67.88</td>\n",
       "      <td>7.203033e-09</td>\n",
       "      <td>7.035117e-09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.946278e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.706020e-09</td>\n",
       "      <td>8.700784e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.203033e-09</td>\n",
       "      <td>7.203033e-09</td>\n",
       "      <td>7.203033e-09</td>\n",
       "      <td>7.203033e-09</td>\n",
       "      <td>-9.820928e-09</td>\n",
       "      <td>7.313445e-09</td>\n",
       "      <td>[7.203033491054604e-09, 7.035116647613036e-09,...</td>\n",
       "      <td>19795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64122</th>\n",
       "      <td>145.82.199.44</td>\n",
       "      <td>190.201.33.51</td>\n",
       "      <td>3.926327e-07</td>\n",
       "      <td>3.834797e-07</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>2.676662e-06</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>1.070665e-06</td>\n",
       "      <td>2.481116e-07</td>\n",
       "      <td>2.532600e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>3.926327e-07</td>\n",
       "      <td>3.926327e-07</td>\n",
       "      <td>3.926327e-07</td>\n",
       "      <td>3.926327e-07</td>\n",
       "      <td>-5.353325e-07</td>\n",
       "      <td>3.986512e-07</td>\n",
       "      <td>[3.926327369086904e-07, 3.834796974433861e-07,...</td>\n",
       "      <td>64122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7965</th>\n",
       "      <td>145.82.199.44</td>\n",
       "      <td>190.201.33.51</td>\n",
       "      <td>2.586891e-08</td>\n",
       "      <td>2.526585e-08</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.058124e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>7.054158e-08</td>\n",
       "      <td>1.634702e-08</td>\n",
       "      <td>1.668623e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>2.586891e-08</td>\n",
       "      <td>2.586891e-08</td>\n",
       "      <td>2.586891e-08</td>\n",
       "      <td>2.586891e-08</td>\n",
       "      <td>-3.527079e-08</td>\n",
       "      <td>2.626544e-08</td>\n",
       "      <td>[2.5868909498806124e-08, 2.526585446210392e-08...</td>\n",
       "      <td>7965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205381</th>\n",
       "      <td>103.57.14.23</td>\n",
       "      <td>190.201.33.51</td>\n",
       "      <td>7.230443e-08</td>\n",
       "      <td>7.061887e-08</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>4.929149e-07</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.971660e-07</td>\n",
       "      <td>7.816677e-08</td>\n",
       "      <td>7.701239e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>7.230443e-08</td>\n",
       "      <td>7.230443e-08</td>\n",
       "      <td>7.230443e-08</td>\n",
       "      <td>7.230443e-08</td>\n",
       "      <td>-9.858299e-08</td>\n",
       "      <td>7.341275e-08</td>\n",
       "      <td>[7.230442827011002e-08, 7.0618870181696e-08, 3...</td>\n",
       "      <td>205381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        IPV4_SRC_ADDR  IPV4_DST_ADDR      PROTOCOL      L7_PROTO  IN_BYTES  \\\n",
       "107317  145.82.199.44  182.129.67.88  8.380256e-09  1.049606e-08  0.000990   \n",
       "19795    103.57.14.23  182.129.67.88  7.203033e-09  7.035117e-09  0.000002   \n",
       "64122   145.82.199.44  190.201.33.51  3.926327e-07  3.834797e-07  0.000557   \n",
       "7965    145.82.199.44  190.201.33.51  2.586891e-08  2.526585e-08  0.000009   \n",
       "205381   103.57.14.23  190.201.33.51  7.230443e-08  7.061887e-08  0.000038   \n",
       "\n",
       "             IN_PKTS  OUT_BYTES      OUT_PKTS     TCP_FLAGS  CLIENT_TCP_FLAGS  \\\n",
       "107317  6.512822e-07   0.000000  0.000000e+00  1.141009e-08      1.141009e-08   \n",
       "19795   2.946278e-08   0.000000  0.000000e+00  8.706020e-09      8.700784e-09   \n",
       "64122   2.676662e-06   0.000770  1.070665e-06  2.481116e-07      2.532600e-07   \n",
       "7965    1.058124e-07   0.000005  7.054158e-08  1.634702e-08      1.668623e-08   \n",
       "205381  4.929149e-07   0.000016  1.971660e-07  7.816677e-08      7.701239e-08   \n",
       "\n",
       "        ...  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT     ICMP_TYPE  ICMP_IPV4_TYPE  \\\n",
       "107317  ...        0.000000         0.000000  8.380256e-09    8.380256e-09   \n",
       "19795   ...        0.000005         0.000000  7.203033e-09    7.203033e-09   \n",
       "64122   ...        0.000307         0.000268  3.926327e-07    3.926327e-07   \n",
       "7965    ...        0.000018         0.000018  2.586891e-08    2.586891e-08   \n",
       "205381  ...        0.006333         0.006424  7.230443e-08    7.230443e-08   \n",
       "\n",
       "        DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \\\n",
       "107317  8.380256e-09    8.380256e-09   -1.142600e-08          8.508713e-09   \n",
       "19795   7.203033e-09    7.203033e-09   -9.820928e-09          7.313445e-09   \n",
       "64122   3.926327e-07    3.926327e-07   -5.353325e-07          3.986512e-07   \n",
       "7965    2.586891e-08    2.586891e-08   -3.527079e-08          2.626544e-08   \n",
       "205381  7.230443e-08    7.230443e-08   -9.858299e-08          7.341275e-08   \n",
       "\n",
       "                                                        h      id  \n",
       "107317  [8.380256498754423e-09, 1.0496055358705104e-08...  107317  \n",
       "19795   [7.203033491054604e-09, 7.035116647613036e-09,...   19795  \n",
       "64122   [3.926327369086904e-07, 3.834796974433861e-07,...   64122  \n",
       "7965    [2.5868909498806124e-08, 2.526585446210392e-08...    7965  \n",
       "205381  [7.230442827011002e-08, 7.0618870181696e-08, 3...  205381  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "d_tLtK4WPtrF"
   },
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "lab_enc.fit(data[\"Attack\"])\n",
    "\n",
    "# Transform on training set\n",
    "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
    "\n",
    "# Transform on testing set\n",
    "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8yaicjecP1fZ"
   },
   "outputs": [],
   "source": [
    "# Training graph (Modified)\n",
    "\n",
    "train['id'] = train.index\n",
    "\n",
    "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "           [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "train_g = train_g.to_directed()\n",
    "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
    "train_g.edata['h'].shape[1]])\n",
    "train_g.ndata['h'] = nfeat_weight\n",
    "\n",
    "test['id'] = test.index\n",
    "\n",
    "# Testing graph\n",
    "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "            [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "# print(test_g)\n",
    "test_g = test_g.to_directed()\n",
    "# print(test_g)\n",
    "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
    "test_g.edata['h'].shape[1]])\n",
    "test_g.ndata['h'] = nfeat_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PUV6DgJ9QRaP"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import tqdm\n",
    "import gc\n",
    "\n",
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "      super(SAGELayer, self).__init__()\n",
    "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
    "      self.activation = F.relu\n",
    "      self.W_edge = nn.Linear(128 * 2, 256)\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      gain = nn.init.calculate_gain('relu')\n",
    "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "      return {'m':  edges.data['h']}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "      with g_dgl.local_scope():\n",
    "        g = g_dgl\n",
    "        g.ndata['h'] = nfeats\n",
    "        g.edata['h'] = efeats\n",
    "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "\n",
    "        # Compute edge embeddings\n",
    "        u, v = g.edges()\n",
    "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
    "        return g.ndata['h'], edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_xo-3K4QRGqc"
   },
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
    "      super(SAGE, self).__init__()\n",
    "      self.layers = nn.ModuleList()\n",
    "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
    "\n",
    "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
    "      if corrupt:\n",
    "        e_perm = torch.randperm(g.number_of_edges())\n",
    "        #n_perm = torch.randperm(g.number_of_nodes())\n",
    "        efeats = efeats[e_perm]\n",
    "        #nfeats = nfeats[n_perm]\n",
    "      for i, layer in enumerate(self.layers):\n",
    "        #nfeats = layer(g, nfeats, efeats)\n",
    "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
    "      #return nfeats.sum(1)\n",
    "      return nfeats.sum(1), e_feats.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6uuxRtLuRJQL"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "      super(Discriminator, self).__init__()\n",
    "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def uniform(self, size, tensor):\n",
    "      bound = 1.0 / math.sqrt(size)\n",
    "      if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      size = self.weight.size(0)\n",
    "      self.uniform(size, self.weight)\n",
    "\n",
    "    def forward(self, features, summary):\n",
    "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
    "      return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ZPbVjlCyRUco"
   },
   "outputs": [],
   "source": [
    "class DGI(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
    "      super(DGI, self).__init__()\n",
    "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
    "      #self.discriminator = Discriminator(128)\n",
    "      self.discriminator = Discriminator(256)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "\n",
    "      positive = positive[1]\n",
    "      negative = negative[1]\n",
    "\n",
    "      summary = torch.sigmoid(positive.mean(dim=0))\n",
    "\n",
    "      positive = self.discriminator(positive, summary)\n",
    "      negative = self.discriminator(negative, summary)\n",
    "\n",
    "      l1 = self.loss(positive, torch.ones_like(positive))\n",
    "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
    "\n",
    "      return l1 + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "sKnfpWFMR19u"
   },
   "outputs": [],
   "source": [
    "ndim_in = train_g.ndata['h'].shape[1]\n",
    "hidden_features = 128\n",
    "ndim_out = 128\n",
    "num_layers = 1\n",
    "edim = train_g.edata['h'].shape[1]\n",
    "learning_rate = 1e-3\n",
    "epochs = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "aSl_9qY8SbA0"
   },
   "outputs": [],
   "source": [
    "dgi = DGI(ndim_in,\n",
    "    ndim_out,\n",
    "    edim,\n",
    "    F.relu)\n",
    "\n",
    "dgi = dgi.to('cuda')\n",
    "\n",
    "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
    "                lr=1e-3,\n",
    "                weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "9K6_cOiWSdJA"
   },
   "outputs": [],
   "source": [
    "# Format node and edge features for E-GraphSAGE\n",
    "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
    "                                   (train_g.ndata['h'].shape[0], 1,\n",
    "                                    train_g.ndata['h'].shape[1]))\n",
    "\n",
    "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
    "                                   (train_g.edata['h'].shape[0], 1,\n",
    "                                    train_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "O44auIyWSexg"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "train_g = train_g.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZtafIdxSheN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Time(s) nan | Loss 1.4200 | ETputs(KTEPS) nan\n",
      "Epoch 00050 | Time(s) 0.3123 | Loss 1.3968 | ETputs(KTEPS) 1068.68\n",
      "Epoch 00100 | Time(s) 0.3124 | Loss 1.3863 | ETputs(KTEPS) 1068.34\n",
      "Epoch 00150 | Time(s) 0.3126 | Loss 1.3863 | ETputs(KTEPS) 1067.76\n",
      "Epoch 00200 | Time(s) 0.3127 | Loss 1.3863 | ETputs(KTEPS) 1067.44\n",
      "Epoch 00250 | Time(s) 0.3128 | Loss 1.3863 | ETputs(KTEPS) 1067.03\n",
      "Epoch 00300 | Time(s) 0.3130 | Loss 1.3863 | ETputs(KTEPS) 1066.40\n",
      "Epoch 00350 | Time(s) 0.3131 | Loss 1.3863 | ETputs(KTEPS) 1065.95\n",
      "Epoch 00400 | Time(s) 0.3133 | Loss 1.3863 | ETputs(KTEPS) 1065.54\n",
      "Epoch 00450 | Time(s) 0.3134 | Loss 1.3863 | ETputs(KTEPS) 1065.14\n",
      "Epoch 00500 | Time(s) 0.3134 | Loss 1.3863 | ETputs(KTEPS) 1064.90\n",
      "Epoch 00550 | Time(s) 0.3135 | Loss 1.3863 | ETputs(KTEPS) 1064.64\n",
      "Epoch 00600 | Time(s) 0.3136 | Loss 1.3863 | ETputs(KTEPS) 1064.39\n",
      "Epoch 00650 | Time(s) 0.3136 | Loss 1.3863 | ETputs(KTEPS) 1064.23\n",
      "Epoch 00700 | Time(s) 0.3137 | Loss 1.3863 | ETputs(KTEPS) 1064.11\n",
      "Epoch 00750 | Time(s) 0.3137 | Loss 1.3863 | ETputs(KTEPS) 1063.91\n",
      "Epoch 00800 | Time(s) 0.3138 | Loss 1.3863 | ETputs(KTEPS) 1063.79\n",
      "Epoch 00850 | Time(s) 0.3138 | Loss 1.3863 | ETputs(KTEPS) 1063.64\n",
      "Epoch 00900 | Time(s) 0.3139 | Loss 1.3863 | ETputs(KTEPS) 1063.53\n",
      "Epoch 00950 | Time(s) 0.3139 | Loss 1.3863 | ETputs(KTEPS) 1063.41\n",
      "Epoch 01000 | Time(s) 0.3139 | Loss 1.3863 | ETputs(KTEPS) 1063.26\n",
      "Epoch 01050 | Time(s) 0.3140 | Loss 1.3863 | ETputs(KTEPS) 1063.10\n",
      "Epoch 01100 | Time(s) 0.3140 | Loss 1.3863 | ETputs(KTEPS) 1062.99\n",
      "Epoch 01150 | Time(s) 0.3141 | Loss 1.3863 | ETputs(KTEPS) 1062.85\n",
      "Epoch 01200 | Time(s) 0.3141 | Loss 1.3863 | ETputs(KTEPS) 1062.71\n",
      "Epoch 01250 | Time(s) 0.3141 | Loss 1.3863 | ETputs(KTEPS) 1062.55\n",
      "Epoch 01300 | Time(s) 0.3142 | Loss 1.3863 | ETputs(KTEPS) 1062.42\n",
      "Epoch 01350 | Time(s) 0.3142 | Loss 1.3863 | ETputs(KTEPS) 1062.32\n",
      "Epoch 01400 | Time(s) 0.3142 | Loss 1.3863 | ETputs(KTEPS) 1062.27\n",
      "Epoch 01450 | Time(s) 0.3142 | Loss 1.3863 | ETputs(KTEPS) 1062.21\n",
      "Epoch 01500 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1062.17\n",
      "Epoch 01550 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1062.13\n",
      "Epoch 01600 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1062.09\n",
      "Epoch 01650 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1062.07\n",
      "Epoch 01700 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1062.06\n",
      "Epoch 01750 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1062.03\n",
      "Epoch 01800 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1062.01\n",
      "Epoch 01850 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1062.01\n",
      "Epoch 01900 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1062.01\n",
      "Epoch 01950 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1061.99\n",
      "Epoch 02000 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1061.99\n",
      "Epoch 02050 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1061.97\n",
      "Epoch 02100 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1061.94\n",
      "Epoch 02150 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1061.91\n",
      "Epoch 02200 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1061.88\n",
      "Epoch 02250 | Time(s) 0.3143 | Loss 1.3863 | ETputs(KTEPS) 1061.84\n",
      "Epoch 02300 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.80\n",
      "Epoch 02350 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.79\n",
      "Epoch 02400 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.76\n",
      "Epoch 02450 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.72\n",
      "Epoch 02500 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.70\n",
      "Epoch 02550 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.69\n",
      "Epoch 02600 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.66\n",
      "Epoch 02650 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.65\n",
      "Epoch 02700 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.64\n",
      "Epoch 02750 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.63\n",
      "Epoch 02800 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.59\n",
      "Epoch 02850 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.58\n",
      "Epoch 02900 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.54\n",
      "Epoch 02950 | Time(s) 0.3144 | Loss 1.3863 | ETputs(KTEPS) 1061.52\n",
      "Epoch 03000 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.50\n",
      "Epoch 03050 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.49\n",
      "Epoch 03100 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.47\n",
      "Epoch 03150 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.45\n",
      "Epoch 03200 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.44\n",
      "Epoch 03250 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.43\n",
      "Epoch 03300 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.42\n",
      "Epoch 03350 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.40\n",
      "Epoch 03400 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.38\n",
      "Epoch 03450 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.38\n",
      "Epoch 03500 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.38\n",
      "Epoch 03550 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.38\n",
      "Epoch 03600 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.39\n",
      "Epoch 03650 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.38\n",
      "Epoch 03700 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.36\n",
      "Epoch 03750 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.37\n",
      "Epoch 03800 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.37\n",
      "Epoch 03850 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.36\n",
      "Epoch 03900 | Time(s) 0.3145 | Loss 1.3864 | ETputs(KTEPS) 1061.36\n",
      "Epoch 03950 | Time(s) 0.3145 | Loss 1.3863 | ETputs(KTEPS) 1061.35\n"
     ]
    }
   ],
   "source": [
    "cnt_wait = 0\n",
    "best = 1e9\n",
    "best_t = 0\n",
    "dur = []\n",
    "node_features = train_g.ndata['h'] \n",
    "edge_features = train_g.edata['h']\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    dgi.train()\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    dgi_optimizer.zero_grad()\n",
    "    loss = dgi(train_g, node_features, edge_features)\n",
    "    loss.backward()\n",
    "    dgi_optimizer.step()\n",
    "\n",
    "    if loss < best:\n",
    "        best = loss\n",
    "        best_t = epoch\n",
    "        cnt_wait = 0\n",
    "        torch.save(dgi.state_dict(), 'best_dgi_CSE_self_collected.pkl')\n",
    "    else:\n",
    "        cnt_wait += 1\n",
    "\n",
    "  # if cnt_wait == patience:\n",
    "  #     print('Early stopping!')\n",
    "  #     break\n",
    "\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "\n",
    "        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "            \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
    "              loss.item(),\n",
    "              train_g.num_edges() / np.mean(dur) / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZ2HAQDAF-4c",
    "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgi.load_state_dict(torch.load('best_dgi_CSE_self_collected.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "6Ek16GkRStKP"
   },
   "outputs": [],
   "source": [
    "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
    "training_emb = training_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-FwaBlOdS4ep"
   },
   "outputs": [],
   "source": [
    "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
    "                                   (test_g.ndata['h'].shape[0], 1,\n",
    "                                    test_g.ndata['h'].shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
    "                                   (test_g.edata['h'].shape[0], 1,\n",
    "                                    test_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "SBa-rdivS6cQ"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "test_g = test_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "W12WLjslS-kx"
   },
   "outputs": [],
   "source": [
    "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
    "testing_emb = testing_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal (Fusion) Learning\n",
    "\n",
    "df_train = pd.DataFrame(training_emb,)\n",
    "# map the id to the original data\n",
    "df_train['id'] = train_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "df_raw_train = pd.DataFrame(X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_fuse_train = pd.merge(df_train, df_raw_train, on='id', how='left')\n",
    "df_fuse_train = df_fuse_train.drop(columns=[\"id\"])\n",
    "df_fuse_train[\"Attacks\"] = train_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
    "\n",
    "df_test = pd.DataFrame(testing_emb,)\n",
    "# map the id to the original data\n",
    "df_test['id'] = test_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "df_raw_test = pd.DataFrame(X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_raw_test = pd.merge(df_test, df_raw_test, on='id', how='left')\n",
    "df_fuse_test = df_raw_test.drop(columns=[\"id\"])\n",
    "df_fuse_test[\"Attacks\"] = test_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ScEk1y_TzzX"
   },
   "source": [
    "# Embeddings CBLOF  Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ZYABKzdrTGas"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pyod.models.cblof import CBLOF\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_fuse_train_samples = df_fuse_train[df_fuse_train.Label == 0].drop(columns=[\"Label\", \"Attacks\"])\n",
    "normal_fuse_train_samples = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"])\n",
    "\n",
    "fuse_train_labels = df_fuse_train[\"Label\"]\n",
    "fuse_test_labels = df_fuse_test[\"Label\"]\n",
    "\n",
    "fuse_test_samples = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_512_TO_1024_BYTES</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.093841</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>-0.030644</td>\n",
       "      <td>0.054135</td>\n",
       "      <td>0.203464</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.084260</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>...</td>\n",
       "      <td>8.914575e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>3.269140e-07</td>\n",
       "      <td>3.269140e-07</td>\n",
       "      <td>3.269140e-07</td>\n",
       "      <td>3.269140e-07</td>\n",
       "      <td>-4.457287e-07</td>\n",
       "      <td>3.319251e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093841</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>-0.030644</td>\n",
       "      <td>0.054135</td>\n",
       "      <td>0.203464</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.084260</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.080455e-08</td>\n",
       "      <td>1.080455e-08</td>\n",
       "      <td>1.080455e-08</td>\n",
       "      <td>1.080455e-08</td>\n",
       "      <td>-1.473138e-08</td>\n",
       "      <td>1.097016e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.093841</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>-0.030644</td>\n",
       "      <td>0.054135</td>\n",
       "      <td>0.203464</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.084260</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.881213e-08</td>\n",
       "      <td>2.881213e-08</td>\n",
       "      <td>2.881213e-08</td>\n",
       "      <td>2.881213e-08</td>\n",
       "      <td>-3.928371e-08</td>\n",
       "      <td>2.925378e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.093841</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>-0.030644</td>\n",
       "      <td>0.054135</td>\n",
       "      <td>0.203464</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.084260</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.282714e-07</td>\n",
       "      <td>1.282714e-07</td>\n",
       "      <td>1.282714e-07</td>\n",
       "      <td>1.282714e-07</td>\n",
       "      <td>-1.748907e-07</td>\n",
       "      <td>1.302376e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.093841</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>-0.030644</td>\n",
       "      <td>0.054135</td>\n",
       "      <td>0.203464</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>0.084260</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.050899</td>\n",
       "      <td>7.319806e-05</td>\n",
       "      <td>7.319806e-05</td>\n",
       "      <td>7.319806e-05</td>\n",
       "      <td>7.319806e-05</td>\n",
       "      <td>-9.980140e-05</td>\n",
       "      <td>7.432008e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143049</th>\n",
       "      <td>-0.093514</td>\n",
       "      <td>0.027680</td>\n",
       "      <td>-0.055948</td>\n",
       "      <td>0.045657</td>\n",
       "      <td>0.217284</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.023755</td>\n",
       "      <td>0.108654</td>\n",
       "      <td>-0.007281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.668770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.635443e-06</td>\n",
       "      <td>7.635443e-06</td>\n",
       "      <td>7.635443e-06</td>\n",
       "      <td>7.635443e-06</td>\n",
       "      <td>-1.041049e-05</td>\n",
       "      <td>7.752483e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143050</th>\n",
       "      <td>-0.093514</td>\n",
       "      <td>0.027680</td>\n",
       "      <td>-0.055948</td>\n",
       "      <td>0.045657</td>\n",
       "      <td>0.217284</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.023755</td>\n",
       "      <td>0.108654</td>\n",
       "      <td>-0.007281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.758883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.664277e-06</td>\n",
       "      <td>8.664277e-06</td>\n",
       "      <td>8.664277e-06</td>\n",
       "      <td>8.664277e-06</td>\n",
       "      <td>-1.181325e-05</td>\n",
       "      <td>8.797087e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143051</th>\n",
       "      <td>-0.093514</td>\n",
       "      <td>0.027680</td>\n",
       "      <td>-0.055948</td>\n",
       "      <td>0.045657</td>\n",
       "      <td>0.217284</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.023755</td>\n",
       "      <td>0.108654</td>\n",
       "      <td>-0.007281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.175371e-06</td>\n",
       "      <td>1.175371e-06</td>\n",
       "      <td>1.175371e-06</td>\n",
       "      <td>1.175371e-06</td>\n",
       "      <td>-1.602551e-06</td>\n",
       "      <td>1.193387e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143052</th>\n",
       "      <td>-0.093514</td>\n",
       "      <td>0.027680</td>\n",
       "      <td>-0.055948</td>\n",
       "      <td>0.045657</td>\n",
       "      <td>0.217284</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.023755</td>\n",
       "      <td>0.108654</td>\n",
       "      <td>-0.007281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.321789e-08</td>\n",
       "      <td>4.321789e-08</td>\n",
       "      <td>4.321789e-08</td>\n",
       "      <td>4.321789e-08</td>\n",
       "      <td>-5.892514e-08</td>\n",
       "      <td>4.388036e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143053</th>\n",
       "      <td>-0.093514</td>\n",
       "      <td>0.027680</td>\n",
       "      <td>-0.055948</td>\n",
       "      <td>0.045657</td>\n",
       "      <td>0.217284</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.023755</td>\n",
       "      <td>0.108654</td>\n",
       "      <td>-0.007281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.180691e-09</td>\n",
       "      <td>1.180691e-09</td>\n",
       "      <td>1.180691e-09</td>\n",
       "      <td>1.180691e-09</td>\n",
       "      <td>-1.609805e-09</td>\n",
       "      <td>1.198789e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143054 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.093841  0.016038 -0.030644  0.054135  0.203464  0.002625  0.000421   \n",
       "1      -0.093841  0.016038 -0.030644  0.054135  0.203464  0.002625  0.000421   \n",
       "2      -0.093841  0.016038 -0.030644  0.054135  0.203464  0.002625  0.000421   \n",
       "3      -0.093841  0.016038 -0.030644  0.054135  0.203464  0.002625  0.000421   \n",
       "4      -0.093841  0.016038 -0.030644  0.054135  0.203464  0.002625  0.000421   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "143049 -0.093514  0.027680 -0.055948  0.045657  0.217284  0.010354  0.006881   \n",
       "143050 -0.093514  0.027680 -0.055948  0.045657  0.217284  0.010354  0.006881   \n",
       "143051 -0.093514  0.027680 -0.055948  0.045657  0.217284  0.010354  0.006881   \n",
       "143052 -0.093514  0.027680 -0.055948  0.045657  0.217284  0.010354  0.006881   \n",
       "143053 -0.093514  0.027680 -0.055948  0.045657  0.217284  0.010354  0.006881   \n",
       "\n",
       "               7         8         9  ...  NUM_PKTS_512_TO_1024_BYTES  \\\n",
       "0       0.026735  0.084260  0.011204  ...                8.914575e-07   \n",
       "1       0.026735  0.084260  0.011204  ...                0.000000e+00   \n",
       "2       0.026735  0.084260  0.011204  ...                0.000000e+00   \n",
       "3       0.026735  0.084260  0.011204  ...                0.000000e+00   \n",
       "4       0.026735  0.084260  0.011204  ...                0.000000e+00   \n",
       "...          ...       ...       ...  ...                         ...   \n",
       "143049  0.023755  0.108654 -0.007281  ...                0.000000e+00   \n",
       "143050  0.023755  0.108654 -0.007281  ...                0.000000e+00   \n",
       "143051  0.023755  0.108654 -0.007281  ...                0.000000e+00   \n",
       "143052  0.023755  0.108654 -0.007281  ...                0.000000e+00   \n",
       "143053  0.023755  0.108654 -0.007281  ...                0.000000e+00   \n",
       "\n",
       "        NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
       "0                               0.0        0.000255         0.000223   \n",
       "1                               0.0        0.000946         0.000000   \n",
       "2                               0.0        0.000020         0.000000   \n",
       "3                               0.0        0.000179         0.000000   \n",
       "4                               0.0        0.050100         0.050899   \n",
       "...                             ...             ...              ...   \n",
       "143049                          0.0        0.668770         0.000000   \n",
       "143050                          0.0        0.758883         0.000000   \n",
       "143051                          0.0        0.105023         0.000000   \n",
       "143052                          0.0        0.003785         0.000000   \n",
       "143053                          0.0        0.000103         0.000000   \n",
       "\n",
       "           ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "0       3.269140e-07    3.269140e-07  3.269140e-07    3.269140e-07   \n",
       "1       1.080455e-08    1.080455e-08  1.080455e-08    1.080455e-08   \n",
       "2       2.881213e-08    2.881213e-08  2.881213e-08    2.881213e-08   \n",
       "3       1.282714e-07    1.282714e-07  1.282714e-07    1.282714e-07   \n",
       "4       7.319806e-05    7.319806e-05  7.319806e-05    7.319806e-05   \n",
       "...              ...             ...           ...             ...   \n",
       "143049  7.635443e-06    7.635443e-06  7.635443e-06    7.635443e-06   \n",
       "143050  8.664277e-06    8.664277e-06  8.664277e-06    8.664277e-06   \n",
       "143051  1.175371e-06    1.175371e-06  1.175371e-06    1.175371e-06   \n",
       "143052  4.321789e-08    4.321789e-08  4.321789e-08    4.321789e-08   \n",
       "143053  1.180691e-09    1.180691e-09  1.180691e-09    1.180691e-09   \n",
       "\n",
       "        DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \n",
       "0        -4.457287e-07          3.319251e-07  \n",
       "1        -1.473138e-08          1.097016e-08  \n",
       "2        -3.928371e-08          2.925378e-08  \n",
       "3        -1.748907e-07          1.302376e-07  \n",
       "4        -9.980140e-05          7.432008e-05  \n",
       "...                ...                   ...  \n",
       "143049   -1.041049e-05          7.752483e-06  \n",
       "143050   -1.181325e-05          8.797087e-06  \n",
       "143051   -1.602551e-06          1.193387e-06  \n",
       "143052   -5.892514e-08          4.388036e-08  \n",
       "143053   -1.609805e-09          1.198789e-09  \n",
       "\n",
       "[143054 rows x 295 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuse_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "62BUDLtO4mla"
   },
   "outputs": [],
   "source": [
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "2i48uLj74mla",
    "outputId": "a0dd33ee-824d-4328-a960-e656e3aaf0ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:39<00:00, 11.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 10, 'con': 0.05}\n",
      "0.632313073914295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9237    0.9497    0.9366    381966\n",
      "           1     0.3846    0.2860    0.3281     41942\n",
      "\n",
      "    accuracy                         0.8841    423908\n",
      "   macro avg     0.6542    0.6179    0.6323    423908\n",
      "weighted avg     0.8704    0.8841    0.8764    423908\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,6,7,9,10] # cant be lower than 5 or 4\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    try:\n",
    "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
    "        clf_if.fit(benign_fuse_train_samples)\n",
    "    except Exception as e:\n",
    "        print(n_est)\n",
    "        continue\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "rK-Rng9q4mla",
    "outputId": "1796db22-cfb8-4bf8-9004-6420c08c3399"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:36<03:31,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:29<00:00, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 9, 'con': 0.2}\n",
      "0.5451412481676391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9188    0.8144    0.8634    381966\n",
      "           1     0.1692    0.3441    0.2268     41942\n",
      "\n",
      "    accuracy                         0.7679    423908\n",
      "   macro avg     0.5440    0.5793    0.5451    423908\n",
      "weighted avg     0.8446    0.7679    0.8005    423908\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,6,7,9,10]\n",
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    try:\n",
    "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
    "        clf_if.fit(normal_fuse_train_samples)\n",
    "    except Exception as e:\n",
    "        print(n_est)\n",
    "        continue\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "nd0-H7UT4mlc"
   },
   "outputs": [],
   "source": [
    "# HBOS  Embeddings+Raw (Multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "sDquxErU4mld"
   },
   "outputs": [],
   "source": [
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "xLBIT-Rc4mld",
    "outputId": "8162929e-4879-40e2-a040-afc57eafe7c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 7/36 [01:18<05:25, 11.22s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m clf_if \u001b[38;5;241m=\u001b[39m HBOS(n_bins\u001b[38;5;241m=\u001b[39mn_est, contamination\u001b[38;5;241m=\u001b[39mcon)\n\u001b[1;32m     10\u001b[0m clf_if\u001b[38;5;241m.\u001b[39mfit(benign_fuse_train_samples)\n\u001b[0;32m---> 11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mclf_if\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuse_test_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m y_pred\n\u001b[1;32m     14\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(fuse_test_labels, test_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/pyod/models/base.py:162\u001b[0m, in \u001b[0;36mBaseDetector.predict\u001b[0;34m(self, X, return_confidence)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict if a particular sample is an outlier or not.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    Only if return_confidence is set to True.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecision_scores_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 162\u001b[0m pred_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontamination, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m    165\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m (pred_score \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold_)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/pyod/models/hbos.py:176\u001b[0m, in \u001b[0;36mHBOS.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    171\u001b[0m     outlier_scores \u001b[38;5;241m=\u001b[39m _calculate_outlier_scores_auto(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbin_edges_,\n\u001b[1;32m    172\u001b[0m                                                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhist_,\n\u001b[1;32m    173\u001b[0m                                                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha,\n\u001b[1;32m    174\u001b[0m                                                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m check_parameter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_bins, low\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, high\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39minf):\n\u001b[0;32m--> 176\u001b[0m     outlier_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_calculate_outlier_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbin_edges_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m                                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhist_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m                                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_bins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m                                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m invert_order(np\u001b[38;5;241m.\u001b[39msum(outlier_scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/numba/core/serialize.py:30\u001b[0m, in \u001b[0;36m_numba_unpickle\u001b[0;34m(address, bytedata, hashed)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Keep unpickled object via `numba_unpickle` alive.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m _unpickled_memo \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_numba_unpickle\u001b[39m(address, bytedata, hashed):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Used by `numba_unpickle` from _helperlib.c\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m        unpickled object\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     key \u001b[38;5;241m=\u001b[39m (address, hashed)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "n_est = [5,10,15,20,25,30]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    \n",
    "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDcX0mma4mld",
    "outputId": "a2b64cfc-d413-4ba0-9f24-b4935343c315"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:52<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'con': 0.01}\n",
      "0.4893857068710194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6379    0.6315    0.6347     38196\n",
      "           1     0.3410    0.3472    0.3441     20972\n",
      "\n",
      "    accuracy                         0.5307     59168\n",
      "   macro avg     0.4895    0.4894    0.4894     59168\n",
      "weighted avg     0.5327    0.5307    0.5317     59168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,10,15,20,25,30]\n",
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    \n",
    "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbDOqrcy4mle"
   },
   "outputs": [],
   "source": [
    "##  PCA  Emb+Raw (Multimodal/Fusion) Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nga82Fw_4mle",
    "outputId": "0fe52043-af21-45c1-a404-040ab5845efc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:50<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'con': 0.04}\n",
      "0.4521499568535427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6238    0.3855    0.4765     38196\n",
      "           1     0.3400    0.5766    0.4278     20972\n",
      "\n",
      "    accuracy                         0.4532     59168\n",
      "   macro avg     0.4819    0.4810    0.4521     59168\n",
      "weighted avg     0.5232    0.4532    0.4592     59168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.pca import PCA\n",
    "n_est = [5,10,15,20,25,30]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = PCA(n_components=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sg6AcAUW4mlf",
    "outputId": "a9949458-96cf-44dc-b4f6-c73458cb2719"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:01<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'con': 0.05}\n",
      "0.43776217172464377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5956    0.5155    0.5526     38196\n",
      "           1     0.2911    0.3624    0.3229     20972\n",
      "\n",
      "    accuracy                         0.4612     59168\n",
      "   macro avg     0.4433    0.4390    0.4378     59168\n",
      "weighted avg     0.4877    0.4612    0.4712     59168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,10,15,20,25,30]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = PCA(n_components=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yi8SO3tL4mlg"
   },
   "outputs": [],
   "source": [
    "##  IF  Emb+Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(benign_fuse_train_samples.columns)):\n",
    "    benign_fuse_train_samples.rename(columns={benign_fuse_train_samples.columns[i]: f\"feature {i}\"}, inplace=True)\n",
    "\n",
    "for i in range(len(normal_fuse_train_samples.columns)):\n",
    "    normal_fuse_train_samples.rename(columns={normal_fuse_train_samples.columns[i]: f\"feature {i}\"}, inplace=True)\n",
    "\n",
    "for i in range(len(fuse_test_samples.columns)):\n",
    "    fuse_test_samples.rename(columns={fuse_test_samples.columns[i]: f\"feature {i}\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9D0m4vb04mlg",
    "outputId": "bd5a55e6-ac70-4943-9b28-92474b5fb9e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "  4%|▍         | 1/24 [00:00<00:11,  2.09it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "  8%|▊         | 2/24 [00:00<00:09,  2.30it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 12%|█▎        | 3/24 [00:01<00:08,  2.37it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 17%|█▋        | 4/24 [00:01<00:08,  2.40it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 21%|██        | 5/24 [00:02<00:07,  2.40it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 25%|██▌       | 6/24 [00:02<00:07,  2.44it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 29%|██▉       | 7/24 [00:03<00:07,  2.14it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 33%|███▎      | 8/24 [00:03<00:07,  2.02it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 38%|███▊      | 9/24 [00:04<00:08,  1.84it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 42%|████▏     | 10/24 [00:04<00:07,  1.75it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 46%|████▌     | 11/24 [00:05<00:07,  1.71it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 50%|█████     | 12/24 [00:06<00:06,  1.72it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 54%|█████▍    | 13/24 [00:07<00:07,  1.49it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 58%|█████▊    | 14/24 [00:07<00:07,  1.38it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 62%|██████▎   | 15/24 [00:08<00:06,  1.31it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 67%|██████▋   | 16/24 [00:09<00:06,  1.27it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 71%|███████   | 17/24 [00:10<00:05,  1.22it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 75%|███████▌  | 18/24 [00:11<00:04,  1.20it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 79%|███████▉  | 19/24 [00:12<00:04,  1.07it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 83%|████████▎ | 20/24 [00:13<00:03,  1.01it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 21/24 [00:14<00:03,  1.03s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 22/24 [00:15<00:02,  1.07s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 23/24 [00:16<00:01,  1.08s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "100%|██████████| 24/24 [00:18<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'con': 0.01}\n",
      "0.39985799202747224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6452    0.9885    0.7807     38196\n",
      "           1     0.3183    0.0098    0.0190     20972\n",
      "\n",
      "    accuracy                         0.6416     59168\n",
      "   macro avg     0.4817    0.4991    0.3999     59168\n",
      "weighted avg     0.5293    0.6416    0.5107     59168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "n_est = [20, 50, 100, 150]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples.to_numpy())\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCj-3u4t4mlg",
    "outputId": "5f6b1720-9662-4704-ba96-dd57ee32a900"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:20<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 150, 'con': 0.01}\n",
      "0.4000915949078085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6445    0.9844    0.7790     38196\n",
      "           1     0.2797    0.0110    0.0212     20972\n",
      "\n",
      "    accuracy                         0.6394     59168\n",
      "   macro avg     0.4621    0.4977    0.4001     59168\n",
      "weighted avg     0.5152    0.6394    0.5104     59168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "n_est = [20, 50, 100, 150]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised attack classification (Fusion)\n",
    "\n",
    "We now train a supervised classifier on the fused features to predict multi-class attack labels:\n",
    "- Features: embeddings + raw numeric features from `df_fuse_train`/`df_fuse_test` (without `Label`, `Attacks`).\n",
    "- Target: `Attacks` (encoded integer classes from earlier `LabelEncoder`).\n",
    "- Model: HistGradientBoostingClassifier (fast, strong on tabular data). Class imbalance handled via per-sample weights.\n",
    "- Metrics: macro F1, per-class report, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare supervised train/test for attack classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.utils import class_weight\n",
    "import pickle\n",
    "\n",
    "# Build train features/targets from already prepared fused DataFrames\n",
    "X_sup_train = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_sup_test = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights to mitigate class imbalance on training set\n",
    "classes = np.unique(y_sup_train)\n",
    "class_w = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes, y=y_sup_train\n",
    ")\n",
    "class_to_w = {c: w for c, w in zip(classes, class_w)}\n",
    "sample_weight = y_sup_train.map(class_to_w).values\n",
    "\n",
    "# Feature names to all str\n",
    "X_sup_train.columns = X_sup_train.columns.map(str)\n",
    "X_sup_test.columns = X_sup_test.columns.map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Methods (Fused Features)\n",
    "\n",
    "Now we'll compare multiple classification algorithms on the fused features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [05:17<00:00, 35.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 30}\n",
      "Best Macro F1: 0.8009\n",
      "Model saved to: best_rf_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9604    0.9487    0.9545     38132\n",
      "           1     0.7617    0.9584    0.8488      8706\n",
      "           2     0.6714    0.6501    0.6606      5042\n",
      "           3     0.8349    0.6868    0.7536     29414\n",
      "           4     1.0000    1.0000    1.0000     17204\n",
      "           5     0.3836    0.5801    0.4618     10226\n",
      "           6     0.6436    0.5827    0.6116     15472\n",
      "           7     0.9877    0.8769    0.9290      2194\n",
      "           8     1.0000    0.9995    0.9998     15058\n",
      "           9     0.7393    0.7956    0.7664      1458\n",
      "          10     0.9813    0.7095    0.8235       148\n",
      "\n",
      "    accuracy                         0.8276    143054\n",
      "   macro avg     0.8149    0.7989    0.8009    143054\n",
      "weighted avg     0.8439    0.8276    0.8319    143054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with Grid Search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            rf_clf = RandomForestClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            rf_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_rf = rf_clf.predict(X_sup_test)\n",
    "            rf_f1 = f1_score(y_sup_test, y_pred_rf, average='macro')\n",
    "            \n",
    "            if rf_f1 > score:\n",
    "                score = rf_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = rf_clf\n",
    "                # Save best model\n",
    "                with open('best_rf_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(rf_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_rf_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Random Forest: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:04:04] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "100%|██████████| 27/27 [21:42<00:00, 48.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.8174\n",
      "Model saved to: best_xgb_classifier_fused.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9632    0.9604    0.9618     38132\n",
      "           1     0.8167    0.9257    0.8678      8706\n",
      "           2     0.6247    0.7515    0.6823      5042\n",
      "           3     0.9258    0.6528    0.7657     29414\n",
      "           4     0.9999    1.0000    0.9999     17204\n",
      "           5     0.3879    0.6467    0.4849     10226\n",
      "           6     0.6301    0.6061    0.6179     15472\n",
      "           7     0.9893    0.9230    0.9550      2194\n",
      "           8     1.0000    1.0000    1.0000     15058\n",
      "           9     0.6479    0.8772    0.7453      1458\n",
      "          10     0.9236    0.8986    0.9110       148\n",
      "\n",
      "    accuracy                         0.8344    143054\n",
      "   macro avg     0.8099    0.8402    0.8174    143054\n",
      "weighted avg     0.8629    0.8344    0.8409    143054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with Grid Search\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    import pickle\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST CLASSIFIER (Fused Features)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            xgb_clf = XGBClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                learning_rate=lr,\n",
    "                random_state=13,\n",
    "                tree_method='hist', \n",
    "                device=\"cuda\"\n",
    "            )\n",
    "            \n",
    "            xgb_clf.fit(X_sup_train, y_sup_train, sample_weight=sample_weight)\n",
    "            y_pred_xgb = xgb_clf.predict(X_sup_test)\n",
    "            xgb_f1 = f1_score(y_sup_test, y_pred_xgb, average='macro')\n",
    "            \n",
    "            if xgb_f1 > score:\n",
    "                score = xgb_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = xgb_clf\n",
    "                # Save best model\n",
    "                xgb_clf.save_model('best_xgb_classifier_fused.json')\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_xgb_classifier_fused.json\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed. XGBoost might not support your GPU.\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CatBoost Grid Search (Expanded)...\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      "  4%|▎         | 1/27 [00:03<01:42,  3.94s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      "  7%|▋         | 2/27 [00:07<01:34,  3.80s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 11%|█         | 3/27 [00:11<01:29,  3.73s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 15%|█▍        | 4/27 [00:19<02:07,  5.53s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 19%|█▊        | 5/27 [00:27<02:22,  6.48s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 22%|██▏       | 6/27 [00:35<02:27,  7.01s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 26%|██▌       | 7/27 [00:52<03:26, 10.34s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 30%|██▉       | 8/27 [01:09<03:54, 12.36s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 33%|███▎      | 9/27 [01:26<04:07, 13.74s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 37%|███▋      | 10/27 [01:31<03:09, 11.16s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 41%|████      | 11/27 [01:36<02:29,  9.33s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 44%|████▍     | 12/27 [01:42<02:00,  8.07s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 48%|████▊     | 13/27 [01:54<02:10,  9.34s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 52%|█████▏    | 14/27 [02:06<02:11, 10.08s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 56%|█████▌    | 15/27 [02:18<02:07, 10.60s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 59%|█████▉    | 16/27 [02:43<02:46, 15.10s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 63%|██████▎   | 17/27 [03:08<02:59, 17.99s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 67%|██████▋   | 18/27 [03:33<03:01, 20.13s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 70%|███████   | 19/27 [03:41<02:12, 16.61s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 74%|███████▍  | 20/27 [03:50<01:38, 14.10s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 78%|███████▊  | 21/27 [03:58<01:14, 12.34s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 81%|████████▏ | 22/27 [04:18<01:12, 14.55s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 85%|████████▌ | 23/27 [04:37<01:03, 15.97s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 89%|████████▉ | 24/27 [04:56<00:51, 17.07s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 93%|█████████▎| 25/27 [05:38<00:48, 24.37s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      " 96%|█████████▋| 26/27 [06:19<00:29, 29.35s/it]Warning: less than 75% GPU memory available for training. Free: 2595.25 Total: 5806.3125\n",
      "100%|██████████| 27/27 [07:01<00:00, 15.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BEST CATBOOST HYPERPARAMETERS (Fused Features):\n",
      "{'iterations': 500, 'depth': 8, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7692\n",
      "============================================================\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_fused.cbm\n",
      "\n",
      "============================================================\n",
      "FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9774    0.9475    0.9622     38132\n",
      "           1     0.5668    0.9444    0.7084      8706\n",
      "           2     0.5250    0.7077    0.6028      5042\n",
      "           3     0.9261    0.5330    0.6766     29414\n",
      "           4     0.9999    1.0000    0.9999     17204\n",
      "           5     0.3978    0.6468    0.4926     10226\n",
      "           6     0.6450    0.6011    0.6223     15472\n",
      "           7     0.9930    0.9079    0.9486      2194\n",
      "           8     0.9999    1.0000    0.9999     15058\n",
      "           9     0.5702    0.9026    0.6989      1458\n",
      "          10     0.6147    0.9595    0.7493       148\n",
      "\n",
      "    accuracy                         0.8055    143054\n",
      "   macro avg     0.7469    0.8319    0.7692    143054\n",
      "weighted avg     0.8493    0.8055    0.8104    143054\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost with Grid Search (Expanded, no l2_leaf_reg/border_count, fixed best score logic)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"Starting CatBoost Grid Search (Expanded)...\")\n",
    "    \n",
    "    # Expanded hyperparameter grid\n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'  # Use 'CPU' if GPU not available\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_cat = cat_clf.predict(X_sup_test)\n",
    "            cat_f1 = f1_score(y_sup_test, y_pred_cat, average='macro')\n",
    "            \n",
    "            if cat_f1 > best_score:\n",
    "                best_score = cat_f1\n",
    "                best_params = {\n",
    "                    'iterations': iterations,\n",
    "                    'depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for fused features\n",
    "                best_model_path = \"best_catboost_classifier_fused.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEST CATBOOST HYPERPARAMETERS (Fused Features):\")\n",
    "    print(best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    if best_model_path:\n",
    "        print(f\"\\nBest CatBoost model saved to: {best_model_path}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    y_pred_best = best_model.predict(X_sup_test)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_sup_test, y_pred_best, digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed. Install with: pip install catboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:49<00:00, 25.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 30}\n",
      "Best Macro F1: 0.6911\n",
      "Model saved to: best_et_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9367    0.9039    0.9200     38132\n",
      "           1     0.4624    0.9150    0.6144      8706\n",
      "           2     0.5263    0.6656    0.5878      5042\n",
      "           3     0.7532    0.2664    0.3936     29414\n",
      "           4     1.0000    0.9999    0.9999     17204\n",
      "           5     0.2525    0.6657    0.3661     10226\n",
      "           6     0.6318    0.5217    0.5715     15472\n",
      "           7     0.9886    0.6691    0.7980      2194\n",
      "           8     0.9999    0.7872    0.8809     15058\n",
      "           9     0.6158    0.7894    0.6919      1458\n",
      "          10     0.9174    0.6757    0.7782       148\n",
      "\n",
      "    accuracy                         0.7010    143054\n",
      "   macro avg     0.7350    0.7145    0.6911    143054\n",
      "weighted avg     0.7855    0.7010    0.7053    143054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            et_clf = ExtraTreesClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            et_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_et = et_clf.predict(X_sup_test)\n",
    "            et_f1 = f1_score(y_sup_test, y_pred_et, average='macro')\n",
    "            \n",
    "            if et_f1 > score:\n",
    "                score = et_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = et_clf\n",
    "                # Save best model\n",
    "                with open('best_et_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(et_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_et_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Extra Trees: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Features Classification (Comparison Baseline)\n",
    "\n",
    "Now we'll train classifiers on **raw features only** (without graph embeddings) to compare the benefit of multimodal fusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw feature shape - Train: (166895, 39), Test: (71527, 39)\n",
      "Number of classes: 11\n"
     ]
    }
   ],
   "source": [
    "# Prepare raw features (without embeddings)\n",
    "# Use only the original numeric features from X_train/X_test\n",
    "\n",
    "X_raw_train = X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_train = y_train[\"Attack\"].copy()\n",
    "\n",
    "X_raw_test = X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_test = y_test[\"Attack\"].copy()\n",
    "\n",
    "# Encode labels\n",
    "y_raw_train_encoded = lab_enc.transform(y_train[\"Attack\"])\n",
    "y_raw_test_encoded = lab_enc.transform(y_test[\"Attack\"])\n",
    "\n",
    "# Compute sample weights\n",
    "classes_raw = np.unique(y_raw_train_encoded)\n",
    "class_w_raw = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_raw, y=y_raw_train_encoded\n",
    ")\n",
    "class_to_w_raw = {c: w for c, w in zip(classes_raw, class_w_raw)}\n",
    "sample_weight_raw = pd.Series(y_raw_train_encoded).map(class_to_w_raw).values\n",
    "\n",
    "# Feature names to str\n",
    "X_raw_train.columns = X_raw_train.columns.map(str)\n",
    "X_raw_test.columns = X_raw_test.columns.map(str)\n",
    "\n",
    "print(f\"Raw feature shape - Train: {X_raw_train.shape}, Test: {X_raw_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_raw_train_encoded))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Raw Features Only)\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:35<00:00, 10.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 30}\n",
      "Best Macro F1: 0.8325\n",
      "Model saved to: best_rf_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9861    0.9560    0.9708     19066\n",
      "           1     0.9070    0.9302    0.9185      4353\n",
      "           2     0.8229    0.7703    0.7957      2521\n",
      "           3     0.8519    0.8654    0.8586     14707\n",
      "           4     0.9999    1.0000    0.9999      8602\n",
      "           5     0.4479    0.6294    0.5234      5113\n",
      "           6     0.7173    0.5379    0.6148      7736\n",
      "           7     0.9701    0.9754    0.9727      1097\n",
      "           8     0.9996    0.9997    0.9997      7529\n",
      "           9     0.6381    0.8491    0.7287       729\n",
      "          10     0.7209    0.8378    0.7750        74\n",
      "\n",
      "    accuracy                         0.8697     71527\n",
      "   macro avg     0.8238    0.8501    0.8325     71527\n",
      "weighted avg     0.8794    0.8697    0.8718     71527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Raw Features Only)\")\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = rf_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Raw Features Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [04:23<00:00,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.8480\n",
      "Model saved to: best_xgb_classifier_raw.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9902    0.9601    0.9749     19066\n",
      "           1     0.8626    0.9228    0.8917      4353\n",
      "           2     0.7595    0.7541    0.7568      2521\n",
      "           3     0.9111    0.8542    0.8817     14707\n",
      "           4     0.9999    1.0000    0.9999      8602\n",
      "           5     0.4884    0.6773    0.5676      5113\n",
      "           6     0.6889    0.5911    0.6363      7736\n",
      "           7     0.9801    0.9891    0.9846      1097\n",
      "           8     1.0000    1.0000    1.0000      7529\n",
      "           9     0.6166    0.8848    0.7268       729\n",
      "          10     0.8846    0.9324    0.9079        74\n",
      "\n",
      "    accuracy                         0.8773     71527\n",
      "   macro avg     0.8347    0.8696    0.8480     71527\n",
      "weighted avg     0.8877    0.8773    0.8805     71527\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Raw Features Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='cuda'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_raw_train, y_raw_train_encoded, sample_weight=sample_weight_raw)\n",
    "        y_pred = xgb_clf.predict(X_raw_test)\n",
    "        f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_raw.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_raw.json\\n\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Raw Features Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      "  4%|▎         | 1/27 [00:01<00:34,  1.34s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      "  7%|▋         | 2/27 [00:02<00:32,  1.31s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 11%|█         | 3/27 [00:03<00:31,  1.31s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 15%|█▍        | 4/27 [00:07<00:50,  2.18s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 19%|█▊        | 5/27 [00:10<00:58,  2.67s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 22%|██▏       | 6/27 [00:14<01:02,  2.95s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 26%|██▌       | 7/27 [00:22<01:33,  4.68s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 30%|██▉       | 8/27 [00:30<01:50,  5.79s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 33%|███▎      | 9/27 [00:39<01:58,  6.56s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 37%|███▋      | 10/27 [00:41<01:26,  5.11s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 41%|████      | 11/27 [00:42<01:05,  4.10s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 44%|████▍     | 12/27 [00:44<00:51,  3.41s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 48%|████▊     | 13/27 [00:49<00:55,  3.95s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 52%|█████▏    | 14/27 [00:54<00:56,  4.31s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 56%|█████▌    | 15/27 [01:00<00:54,  4.54s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 59%|█████▉    | 16/27 [01:12<01:15,  6.85s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 63%|██████▎   | 17/27 [01:24<01:24,  8.44s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 67%|██████▋   | 18/27 [01:36<01:26,  9.60s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 70%|███████   | 19/27 [01:39<01:00,  7.60s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 74%|███████▍  | 20/27 [01:42<00:43,  6.19s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 78%|███████▊  | 21/27 [01:45<00:31,  5.21s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 81%|████████▏ | 22/27 [01:53<00:30,  6.20s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 85%|████████▌ | 23/27 [02:02<00:27,  6.84s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 89%|████████▉ | 24/27 [02:10<00:21,  7.30s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 93%|█████████▎| 25/27 [02:30<00:22, 11.12s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      " 96%|█████████▋| 26/27 [02:50<00:13, 13.76s/it]Warning: less than 75% GPU memory available for training. Free: 2597.25 Total: 5806.3125\n",
      "100%|██████████| 27/27 [03:10<00:00,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.8183\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_raw.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9867    0.9503    0.9682     19066\n",
      "           1     0.7465    0.9341    0.8298      4353\n",
      "           2     0.7122    0.7057    0.7089      2521\n",
      "           3     0.9133    0.8229    0.8657     14707\n",
      "           4     0.9999    1.0000    0.9999      8602\n",
      "           5     0.4925    0.6626    0.5650      5113\n",
      "           6     0.7024    0.6003    0.6473      7736\n",
      "           7     0.9518    0.9909    0.9710      1097\n",
      "           8     0.9997    1.0000    0.9999      7529\n",
      "           9     0.6020    0.8944    0.7196       729\n",
      "          10     0.5882    0.9459    0.7254        74\n",
      "\n",
      "    accuracy                         0.8673     71527\n",
      "   macro avg     0.7905    0.8643    0.8183     71527\n",
      "weighted avg     0.8793    0.8673    0.8704     71527\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Raw Features Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "            y_pred = cat_clf.predict(X_raw_test)\n",
    "            f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for raw features\n",
    "                best_model_path = \"best_catboost_classifier_raw.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Raw Features Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:50<00:00,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 30}\n",
      "Best Macro F1: 0.8407\n",
      "Model saved to: best_et_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9897    0.9770    0.9833     19066\n",
      "           1     0.9172    0.9410    0.9289      4353\n",
      "           2     0.8161    0.7798    0.7976      2521\n",
      "           3     0.8932    0.8736    0.8833     14707\n",
      "           4     1.0000    1.0000    1.0000      8602\n",
      "           5     0.4798    0.6789    0.5622      5113\n",
      "           6     0.7375    0.5606    0.6370      7736\n",
      "           7     0.9737    0.9781    0.9759      1097\n",
      "           8     0.9997    0.9997    0.9997      7529\n",
      "           9     0.6170    0.8573    0.7176       729\n",
      "          10     0.7093    0.8243    0.7625        74\n",
      "\n",
      "    accuracy                         0.8840     71527\n",
      "   macro avg     0.8303    0.8609    0.8407     71527\n",
      "weighted avg     0.8936    0.8840    0.8860     71527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Raw Features Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = et_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Only Classification (Graph Features)\n",
    "\n",
    "Now we'll train classifiers on **embeddings only** (graph features without raw features) to isolate the value of graph-based learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape - Train: (333790, 256), Test: (143054, 256)\n",
      "Number of classes: 11\n",
      "Using only graph embeddings (no raw features)\n"
     ]
    }
   ],
   "source": [
    "# Prepare embeddings-only features (graph features without raw data)\n",
    "# Extract only the embedding columns (first 256 dimensions from graph encoder)\n",
    "\n",
    "# From the fused dataframes, extract only embedding columns\n",
    "# df_fuse_train has: [0-255] = embeddings, [256+] = raw features\n",
    "num_embedding_dims = 256  # Based on the DGI encoder output dimension\n",
    "\n",
    "X_emb_train = df_fuse_train.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_emb_test = df_fuse_test.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights\n",
    "classes_emb = np.unique(y_emb_train)\n",
    "class_w_emb = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_emb, y=y_emb_train\n",
    ")\n",
    "class_to_w_emb = {c: w for c, w in zip(classes_emb, class_w_emb)}\n",
    "sample_weight_emb = y_emb_train.map(class_to_w_emb).values\n",
    "\n",
    "# Feature names to str\n",
    "X_emb_train.columns = X_emb_train.columns.map(str)\n",
    "X_emb_test.columns = X_emb_test.columns.map(str)\n",
    "\n",
    "print(f\"Embeddings shape - Train: {X_emb_train.shape}, Test: {X_emb_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_emb_train))}\")\n",
    "print(f\"Using only graph embeddings (no raw features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:30<00:00, 10.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 10}\n",
      "Best Macro F1: 0.0221\n",
      "Model saved to: best_rf_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000     38132\n",
      "           1     0.0000    0.0000    0.0000      8706\n",
      "           2     0.9921    0.0500    0.0952      5042\n",
      "           3     0.0000    0.0000    0.0000     29414\n",
      "           4     0.0064    0.0163    0.0092     17204\n",
      "           5     0.0000    0.0000    0.0000     10226\n",
      "           6     0.0000    0.0000    0.0000     15472\n",
      "           7     0.0109    0.2484    0.0210      2194\n",
      "           8     0.0771    0.2507    0.1179     15058\n",
      "           9     0.0000    0.0000    0.0000      1458\n",
      "          10     0.0000    0.0000    0.0000       148\n",
      "\n",
      "    accuracy                         0.0339    143054\n",
      "   macro avg     0.0988    0.0514    0.0221    143054\n",
      "weighted avg     0.0440    0.0339    0.0172    143054\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = rf_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [12:04<00:00, 26.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "Best Macro F1: 0.0397\n",
      "Model saved to: best_xgb_classifier_embeddings.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3230    0.1174    0.1722     38132\n",
      "           1     0.0000    0.0000    0.0000      8706\n",
      "           2     1.0000    0.0452    0.0865      5042\n",
      "           3     0.0000    0.0000    0.0000     29414\n",
      "           4     0.1009    0.7565    0.1781     17204\n",
      "           5     0.0000    0.0000    0.0000     10226\n",
      "           6     0.0000    0.0000    0.0000     15472\n",
      "           7     0.0000    0.0000    0.0000      2194\n",
      "           8     0.0000    0.0000    0.0000     15058\n",
      "           9     0.0000    0.0000    0.0000      1458\n",
      "          10     0.0000    0.0000    0.0000       148\n",
      "\n",
      "    accuracy                         0.1239    143054\n",
      "   macro avg     0.1294    0.0836    0.0397    143054\n",
      "weighted avg     0.1335    0.1239    0.0704    143054\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Embeddings Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='gpu'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_emb_train, y_emb_train, sample_weight=sample_weight_emb)\n",
    "        y_pred = xgb_clf.predict(X_emb_test)\n",
    "        f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_embeddings.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_embeddings.json\\n\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Embeddings Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      "  4%|▎         | 1/27 [00:03<01:22,  3.19s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      "  7%|▋         | 2/27 [00:06<01:19,  3.18s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 11%|█         | 3/27 [00:09<01:16,  3.18s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 15%|█▍        | 4/27 [00:15<01:38,  4.28s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 19%|█▊        | 5/27 [00:21<01:47,  4.90s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 22%|██▏       | 6/27 [00:27<01:50,  5.27s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 26%|██▌       | 7/27 [00:39<02:29,  7.49s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 30%|██▉       | 8/27 [00:51<02:50,  8.97s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 33%|███▎      | 9/27 [01:03<02:59,  9.98s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 37%|███▋      | 10/27 [01:08<02:20,  8.28s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 41%|████      | 11/27 [01:12<01:54,  7.13s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 44%|████▍     | 12/27 [01:17<01:35,  6.35s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 48%|████▊     | 13/27 [01:26<01:38,  7.07s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 52%|█████▏    | 14/27 [01:34<01:38,  7.59s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 56%|█████▌    | 15/27 [01:43<01:35,  7.92s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 59%|█████▉    | 16/27 [02:01<02:00, 10.96s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 63%|██████▎   | 17/27 [02:19<02:11, 13.11s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 67%|██████▋   | 18/27 [02:37<02:11, 14.59s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 70%|███████   | 19/27 [02:45<01:39, 12.38s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 74%|███████▍  | 20/27 [02:52<01:15, 10.85s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 78%|███████▊  | 21/27 [02:59<00:58,  9.77s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 81%|████████▏ | 22/27 [03:13<00:55, 11.12s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 85%|████████▌ | 23/27 [03:28<00:48, 12.06s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 89%|████████▉ | 24/27 [03:42<00:38, 12.70s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 93%|█████████▎| 25/27 [04:12<00:35, 17.83s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      " 96%|█████████▋| 26/27 [04:41<00:21, 21.42s/it]Warning: less than 75% GPU memory available for training. Free: 2593.25 Total: 5806.3125\n",
      "100%|██████████| 27/27 [05:11<00:00, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 200, 'depth': 8, 'learning_rate': 0.01}\n",
      "Best Macro F1: 0.0439\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_embeddings.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000     38132\n",
      "           1     0.0000    0.0000    0.0000      8706\n",
      "           2     0.0412    0.4090    0.0749      5042\n",
      "           3     0.1579    0.2629    0.1973     29414\n",
      "           4     0.0058    0.0074    0.0065     17204\n",
      "           5     0.0000    0.0000    0.0000     10226\n",
      "           6     0.0000    0.0000    0.0000     15472\n",
      "           7     0.0000    0.0000    0.0000      2194\n",
      "           8     0.1717    0.2507    0.2038     15058\n",
      "           9     0.0000    0.0000    0.0000      1458\n",
      "          10     0.0000    0.0000    0.0000       148\n",
      "\n",
      "    accuracy                         0.0957    143054\n",
      "   macro avg     0.0342    0.0845    0.0439    143054\n",
      "weighted avg     0.0527    0.0957    0.0654    143054\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Embeddings Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_emb_train, y_emb_train)\n",
    "            y_pred = cat_clf.predict(X_emb_test)\n",
    "            f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for embeddings\n",
    "                best_model_path = \"best_catboost_classifier_embeddings.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:35<00:00, 10.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 10}\n",
      "Best Macro F1: 0.0208\n",
      "Model saved to: best_et_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000     38132\n",
      "           1     0.0000    0.0000    0.0000      8706\n",
      "           2     0.9921    0.0500    0.0952      5042\n",
      "           3     0.0000    0.0000    0.0000     29414\n",
      "           4     0.0767    0.5130    0.1334     17204\n",
      "           5     0.0000    0.0000    0.0000     10226\n",
      "           6     0.0000    0.0000    0.0000     15472\n",
      "           7     0.0000    0.0000    0.0000      2194\n",
      "           8     0.0000    0.0000    0.0000     15058\n",
      "           9     0.0000    0.0000    0.0000      1458\n",
      "          10     0.0000    0.0000    0.0000       148\n",
      "\n",
      "    accuracy                         0.0635    143054\n",
      "   macro avg     0.0972    0.0512    0.0208    143054\n",
      "weighted avg     0.0442    0.0635    0.0194    143054\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = et_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Comparison Table\n",
    "\n",
    "Create a comparison table of all methods (Fused vs Raw features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\n",
      "===============================================================================================\n",
      "\n",
      "Instructions:\n",
      "1. Run all cells above to get F1 scores for each method\n",
      "2. Record the best Macro F1 score for each method\n",
      "3. Compare three approaches:\n",
      "   - Fused Features: Embeddings + Raw (Multimodal)\n",
      "   - Embeddings Only: Graph features only\n",
      "   - Raw Features: Traditional features only\n",
      "\n",
      "Expected format:\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Method               Fused (Emb+Raw)           Embeddings Only           Raw Only                 \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Random Forest        [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "XGBoost              [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "CatBoost             [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "Extra Trees          [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysis:\n",
      "- Fused features should show best performance (multimodal learning)\n",
      "- Embeddings capture structural/graph patterns\n",
      "- Raw features provide traditional statistical information\n",
      "- Compare to understand the contribution of each modality\n"
     ]
    }
   ],
   "source": [
    "# Create a summary comparison table\n",
    "# NOTE: After running all cells above, manually collect the F1 scores and create a comparison\n",
    "\n",
    "print(\"=\"*95)\n",
    "print(\"PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\")\n",
    "print(\"=\"*95)\n",
    "print(\"\\nInstructions:\")\n",
    "print(\"1. Run all cells above to get F1 scores for each method\")\n",
    "print(\"2. Record the best Macro F1 score for each method\")\n",
    "print(\"3. Compare three approaches:\")\n",
    "print(\"   - Fused Features: Embeddings + Raw (Multimodal)\")\n",
    "print(\"   - Embeddings Only: Graph features only\")\n",
    "print(\"   - Raw Features: Traditional features only\")\n",
    "print(\"\\nExpected format:\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Method':<20} {'Fused (Emb+Raw)':<25} {'Embeddings Only':<25} {'Raw Only':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Random Forest':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'XGBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'CatBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'Extra Trees':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"- Fused features should show best performance (multimodal learning)\")\n",
    "print(\"- Embeddings capture structural/graph patterns\")\n",
    "print(\"- Raw features provide traditional statistical information\")\n",
    "print(\"- Compare to understand the contribution of each modality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights & Interpretation\n",
    "\n",
    "After running all experiments, analyze the results to answer:\n",
    "\n",
    "1. **Which approach performs best overall?**\n",
    "   - Fused features (multimodal) should ideally outperform single modalities\n",
    "   - Compare the magnitude of improvements\n",
    "\n",
    "2. **What is the value of graph embeddings?**\n",
    "   - Compare Embeddings-only vs Raw-only to see if graph structure helps\n",
    "   - If embeddings alone beat raw features, graph learning is beneficial\n",
    "\n",
    "3. **Is multimodal fusion effective?**\n",
    "   - Compare Fused vs (Embeddings + Raw separately)\n",
    "   - Synergy should provide additional gains beyond individual modalities\n",
    "\n",
    "4. **Which classifier is most suitable?**\n",
    "   - Identify the best performing algorithm for each feature type\n",
    "   - Consider computational cost vs accuracy trade-offs\n",
    "\n",
    "5. **Feature contribution analysis:**\n",
    "   - If Fused ≈ Embeddings > Raw: Graph structure dominates\n",
    "   - If Fused ≈ Raw > Embeddings: Traditional features dominate\n",
    "   - If Fused > Both: True synergy from multimodal learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
