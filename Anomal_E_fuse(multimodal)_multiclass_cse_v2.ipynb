{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Hjc3iIihKLn-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from dgl.data import DGLDataset\n",
    "import dgl\n",
    "import time\n",
    "import networkx as nx\n",
    "import category_encoders as ce\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "from typing import *\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "SvWHb_BpKsLq"
   },
   "outputs": [],
   "source": [
    "# file_name = \"CSE_Netflow.csv\"\n",
    "file_name = \"NF-CSE-CIC-IDS2018-v2.parquet\"\n",
    "data = pd.read_parquet(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "fqly1y-LMwYS",
    "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    16635567\n",
       "1     2258141\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>L4_SRC_PORT</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>L4_DST_PORT</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>...</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "      <td>16635567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bot</th>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>...</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "      <td>143097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute Force -Web</th>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>...</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "      <td>2143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute Force -XSS</th>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>...</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDOS attack-HOIC</th>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>...</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "      <td>1080858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDOS attack-LOIC-UDP</th>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>...</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "      <td>2112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDoS attacks-LOIC-HTTP</th>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>...</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "      <td>307300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-GoldenEye</th>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>...</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "      <td>27723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-Hulk</th>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>...</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "      <td>432648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-SlowHTTPTest</th>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>...</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "      <td>14116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-Slowloris</th>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>...</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "      <td>9512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTP-BruteForce</th>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>...</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "      <td>25933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infilteration</th>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>...</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "      <td>116361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQL Injection</th>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>...</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSH-Bruteforce</th>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>...</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "      <td>94979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          IPV4_SRC_ADDR  L4_SRC_PORT  IPV4_DST_ADDR  \\\n",
       "Attack                                                                \n",
       "Benign                         16635567     16635567       16635567   \n",
       "Bot                              143097       143097         143097   \n",
       "Brute Force -Web                   2143         2143           2143   \n",
       "Brute Force -XSS                    927          927            927   \n",
       "DDOS attack-HOIC                1080858      1080858        1080858   \n",
       "DDOS attack-LOIC-UDP               2112         2112           2112   \n",
       "DDoS attacks-LOIC-HTTP           307300       307300         307300   \n",
       "DoS attacks-GoldenEye             27723        27723          27723   \n",
       "DoS attacks-Hulk                 432648       432648         432648   \n",
       "DoS attacks-SlowHTTPTest          14116        14116          14116   \n",
       "DoS attacks-Slowloris              9512         9512           9512   \n",
       "FTP-BruteForce                    25933        25933          25933   \n",
       "Infilteration                    116361       116361         116361   \n",
       "SQL Injection                       432          432            432   \n",
       "SSH-Bruteforce                    94979        94979          94979   \n",
       "\n",
       "                          L4_DST_PORT  PROTOCOL  L7_PROTO  IN_BYTES   IN_PKTS  \\\n",
       "Attack                                                                          \n",
       "Benign                       16635567  16635567  16635567  16635567  16635567   \n",
       "Bot                            143097    143097    143097    143097    143097   \n",
       "Brute Force -Web                 2143      2143      2143      2143      2143   \n",
       "Brute Force -XSS                  927       927       927       927       927   \n",
       "DDOS attack-HOIC              1080858   1080858   1080858   1080858   1080858   \n",
       "DDOS attack-LOIC-UDP             2112      2112      2112      2112      2112   \n",
       "DDoS attacks-LOIC-HTTP         307300    307300    307300    307300    307300   \n",
       "DoS attacks-GoldenEye           27723     27723     27723     27723     27723   \n",
       "DoS attacks-Hulk               432648    432648    432648    432648    432648   \n",
       "DoS attacks-SlowHTTPTest        14116     14116     14116     14116     14116   \n",
       "DoS attacks-Slowloris            9512      9512      9512      9512      9512   \n",
       "FTP-BruteForce                  25933     25933     25933     25933     25933   \n",
       "Infilteration                  116361    116361    116361    116361    116361   \n",
       "SQL Injection                     432       432       432       432       432   \n",
       "SSH-Bruteforce                  94979     94979     94979     94979     94979   \n",
       "\n",
       "                          OUT_BYTES  OUT_PKTS  ...  \\\n",
       "Attack                                         ...   \n",
       "Benign                     16635567  16635567  ...   \n",
       "Bot                          143097    143097  ...   \n",
       "Brute Force -Web               2143      2143  ...   \n",
       "Brute Force -XSS                927       927  ...   \n",
       "DDOS attack-HOIC            1080858   1080858  ...   \n",
       "DDOS attack-LOIC-UDP           2112      2112  ...   \n",
       "DDoS attacks-LOIC-HTTP       307300    307300  ...   \n",
       "DoS attacks-GoldenEye         27723     27723  ...   \n",
       "DoS attacks-Hulk             432648    432648  ...   \n",
       "DoS attacks-SlowHTTPTest      14116     14116  ...   \n",
       "DoS attacks-Slowloris          9512      9512  ...   \n",
       "FTP-BruteForce                25933     25933  ...   \n",
       "Infilteration                116361    116361  ...   \n",
       "SQL Injection                   432       432  ...   \n",
       "SSH-Bruteforce                94979     94979  ...   \n",
       "\n",
       "                          NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  \\\n",
       "Attack                                                                  \n",
       "Benign                                       16635567        16635567   \n",
       "Bot                                            143097          143097   \n",
       "Brute Force -Web                                 2143            2143   \n",
       "Brute Force -XSS                                  927             927   \n",
       "DDOS attack-HOIC                              1080858         1080858   \n",
       "DDOS attack-LOIC-UDP                             2112            2112   \n",
       "DDoS attacks-LOIC-HTTP                         307300          307300   \n",
       "DoS attacks-GoldenEye                           27723           27723   \n",
       "DoS attacks-Hulk                               432648          432648   \n",
       "DoS attacks-SlowHTTPTest                        14116           14116   \n",
       "DoS attacks-Slowloris                            9512            9512   \n",
       "FTP-BruteForce                                  25933           25933   \n",
       "Infilteration                                  116361          116361   \n",
       "SQL Injection                                     432             432   \n",
       "SSH-Bruteforce                                  94979           94979   \n",
       "\n",
       "                          TCP_WIN_MAX_OUT  ICMP_TYPE  ICMP_IPV4_TYPE  \\\n",
       "Attack                                                                 \n",
       "Benign                           16635567   16635567        16635567   \n",
       "Bot                                143097     143097          143097   \n",
       "Brute Force -Web                     2143       2143            2143   \n",
       "Brute Force -XSS                      927        927             927   \n",
       "DDOS attack-HOIC                  1080858    1080858         1080858   \n",
       "DDOS attack-LOIC-UDP                 2112       2112            2112   \n",
       "DDoS attacks-LOIC-HTTP             307300     307300          307300   \n",
       "DoS attacks-GoldenEye               27723      27723           27723   \n",
       "DoS attacks-Hulk                   432648     432648          432648   \n",
       "DoS attacks-SlowHTTPTest            14116      14116           14116   \n",
       "DoS attacks-Slowloris                9512       9512            9512   \n",
       "FTP-BruteForce                      25933      25933           25933   \n",
       "Infilteration                      116361     116361          116361   \n",
       "SQL Injection                         432        432             432   \n",
       "SSH-Bruteforce                      94979      94979           94979   \n",
       "\n",
       "                          DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  \\\n",
       "Attack                                                                   \n",
       "Benign                        16635567        16635567        16635567   \n",
       "Bot                             143097          143097          143097   \n",
       "Brute Force -Web                  2143            2143            2143   \n",
       "Brute Force -XSS                   927             927             927   \n",
       "DDOS attack-HOIC               1080858         1080858         1080858   \n",
       "DDOS attack-LOIC-UDP              2112            2112            2112   \n",
       "DDoS attacks-LOIC-HTTP          307300          307300          307300   \n",
       "DoS attacks-GoldenEye            27723           27723           27723   \n",
       "DoS attacks-Hulk                432648          432648          432648   \n",
       "DoS attacks-SlowHTTPTest         14116           14116           14116   \n",
       "DoS attacks-Slowloris             9512            9512            9512   \n",
       "FTP-BruteForce                   25933           25933           25933   \n",
       "Infilteration                   116361          116361          116361   \n",
       "SQL Injection                      432             432             432   \n",
       "SSH-Bruteforce                   94979           94979           94979   \n",
       "\n",
       "                          FTP_COMMAND_RET_CODE     Label  \n",
       "Attack                                                    \n",
       "Benign                                16635567  16635567  \n",
       "Bot                                     143097    143097  \n",
       "Brute Force -Web                          2143      2143  \n",
       "Brute Force -XSS                           927       927  \n",
       "DDOS attack-HOIC                       1080858   1080858  \n",
       "DDOS attack-LOIC-UDP                      2112      2112  \n",
       "DDoS attacks-LOIC-HTTP                  307300    307300  \n",
       "DoS attacks-GoldenEye                    27723     27723  \n",
       "DoS attacks-Hulk                        432648    432648  \n",
       "DoS attacks-SlowHTTPTest                 14116     14116  \n",
       "DoS attacks-Slowloris                     9512      9512  \n",
       "FTP-BruteForce                           25933     25933  \n",
       "Infilteration                           116361    116361  \n",
       "SQL Injection                              432       432  \n",
       "SSH-Bruteforce                           94979     94979  \n",
       "\n",
       "[15 rows x 44 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by='Attack').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "3t4OREvSM33h"
   },
   "outputs": [],
   "source": [
    "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
    "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
    "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
    "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "bTtHq0XqNXxI"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUNIP-8zNkn9",
    "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SSH-Bruteforce', 'Benign', 'DDoS attacks-LOIC-HTTP',\n",
       "       'DDOS attack-HOIC', 'DoS attacks-Slowloris', 'DoS attacks-Hulk',\n",
       "       'FTP-BruteForce', 'Infilteration', 'Bot', 'DoS attacks-GoldenEye',\n",
       "       'Brute Force -Web', 'DoS attacks-SlowHTTPTest', 'SQL Injection',\n",
       "       'DDOS attack-LOIC-UDP', 'Brute Force -XSS'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Attack.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlPa58fVN7gB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    332711\n",
       "1     45163\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the dataset based on your needs (machine capacity) ideally ~500k rows\n",
    "\n",
    "data = data.groupby(by='Attack').sample(frac=0.02, random_state=13)\n",
    "# data_attack = data[data['Label'] == 1]\n",
    "# data_benign = data[data['Label'] == 0].sample(frac=0.1, random_state=13)\n",
    "# data = pd.concat([data_attack, data_benign], axis=0)\n",
    "# data = data.sample(frac=0.1, random_state=13).reset_index(drop=True)\n",
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "lcfAP6ViOp-J",
    "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>...</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "      <td>332711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bot</th>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>...</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "      <td>2862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute Force -Web</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute Force -XSS</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDOS attack-HOIC</th>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>...</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "      <td>21617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDOS attack-LOIC-UDP</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDoS attacks-LOIC-HTTP</th>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>...</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "      <td>6146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-GoldenEye</th>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>...</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-Hulk</th>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>...</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "      <td>8653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-SlowHTTPTest</th>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>...</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS attacks-Slowloris</th>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTP-BruteForce</th>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>...</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infilteration</th>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>...</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "      <td>2327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQL Injection</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSH-Bruteforce</th>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>...</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          IPV4_SRC_ADDR  IPV4_DST_ADDR  PROTOCOL  L7_PROTO  \\\n",
       "Attack                                                                       \n",
       "Benign                           332711         332711    332711    332711   \n",
       "Bot                                2862           2862      2862      2862   \n",
       "Brute Force -Web                     43             43        43        43   \n",
       "Brute Force -XSS                     19             19        19        19   \n",
       "DDOS attack-HOIC                  21617          21617     21617     21617   \n",
       "DDOS attack-LOIC-UDP                 42             42        42        42   \n",
       "DDoS attacks-LOIC-HTTP             6146           6146      6146      6146   \n",
       "DoS attacks-GoldenEye               554            554       554       554   \n",
       "DoS attacks-Hulk                   8653           8653      8653      8653   \n",
       "DoS attacks-SlowHTTPTest            282            282       282       282   \n",
       "DoS attacks-Slowloris               190            190       190       190   \n",
       "FTP-BruteForce                      519            519       519       519   \n",
       "Infilteration                      2327           2327      2327      2327   \n",
       "SQL Injection                         9              9         9         9   \n",
       "SSH-Bruteforce                     1900           1900      1900      1900   \n",
       "\n",
       "                          IN_BYTES  IN_PKTS  OUT_BYTES  OUT_PKTS  TCP_FLAGS  \\\n",
       "Attack                                                                        \n",
       "Benign                      332711   332711     332711    332711     332711   \n",
       "Bot                           2862     2862       2862      2862       2862   \n",
       "Brute Force -Web                43       43         43        43         43   \n",
       "Brute Force -XSS                19       19         19        19         19   \n",
       "DDOS attack-HOIC             21617    21617      21617     21617      21617   \n",
       "DDOS attack-LOIC-UDP            42       42         42        42         42   \n",
       "DDoS attacks-LOIC-HTTP        6146     6146       6146      6146       6146   \n",
       "DoS attacks-GoldenEye          554      554        554       554        554   \n",
       "DoS attacks-Hulk              8653     8653       8653      8653       8653   \n",
       "DoS attacks-SlowHTTPTest       282      282        282       282        282   \n",
       "DoS attacks-Slowloris          190      190        190       190        190   \n",
       "FTP-BruteForce                 519      519        519       519        519   \n",
       "Infilteration                 2327     2327       2327      2327       2327   \n",
       "SQL Injection                    9        9          9         9          9   \n",
       "SSH-Bruteforce                1900     1900       1900      1900       1900   \n",
       "\n",
       "                          CLIENT_TCP_FLAGS  ...  NUM_PKTS_1024_TO_1514_BYTES  \\\n",
       "Attack                                      ...                                \n",
       "Benign                              332711  ...                       332711   \n",
       "Bot                                   2862  ...                         2862   \n",
       "Brute Force -Web                        43  ...                           43   \n",
       "Brute Force -XSS                        19  ...                           19   \n",
       "DDOS attack-HOIC                     21617  ...                        21617   \n",
       "DDOS attack-LOIC-UDP                    42  ...                           42   \n",
       "DDoS attacks-LOIC-HTTP                6146  ...                         6146   \n",
       "DoS attacks-GoldenEye                  554  ...                          554   \n",
       "DoS attacks-Hulk                      8653  ...                         8653   \n",
       "DoS attacks-SlowHTTPTest               282  ...                          282   \n",
       "DoS attacks-Slowloris                  190  ...                          190   \n",
       "FTP-BruteForce                         519  ...                          519   \n",
       "Infilteration                         2327  ...                         2327   \n",
       "SQL Injection                            9  ...                            9   \n",
       "SSH-Bruteforce                        1900  ...                         1900   \n",
       "\n",
       "                          TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  ICMP_TYPE  \\\n",
       "Attack                                                                 \n",
       "Benign                            332711           332711     332711   \n",
       "Bot                                 2862             2862       2862   \n",
       "Brute Force -Web                      43               43         43   \n",
       "Brute Force -XSS                      19               19         19   \n",
       "DDOS attack-HOIC                   21617            21617      21617   \n",
       "DDOS attack-LOIC-UDP                  42               42         42   \n",
       "DDoS attacks-LOIC-HTTP              6146             6146       6146   \n",
       "DoS attacks-GoldenEye                554              554        554   \n",
       "DoS attacks-Hulk                    8653             8653       8653   \n",
       "DoS attacks-SlowHTTPTest             282              282        282   \n",
       "DoS attacks-Slowloris                190              190        190   \n",
       "FTP-BruteForce                       519              519        519   \n",
       "Infilteration                       2327             2327       2327   \n",
       "SQL Injection                          9                9          9   \n",
       "SSH-Bruteforce                      1900             1900       1900   \n",
       "\n",
       "                          ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "Attack                                                                   \n",
       "Benign                            332711        332711          332711   \n",
       "Bot                                 2862          2862            2862   \n",
       "Brute Force -Web                      43            43              43   \n",
       "Brute Force -XSS                      19            19              19   \n",
       "DDOS attack-HOIC                   21617         21617           21617   \n",
       "DDOS attack-LOIC-UDP                  42            42              42   \n",
       "DDoS attacks-LOIC-HTTP              6146          6146            6146   \n",
       "DoS attacks-GoldenEye                554           554             554   \n",
       "DoS attacks-Hulk                    8653          8653            8653   \n",
       "DoS attacks-SlowHTTPTest             282           282             282   \n",
       "DoS attacks-Slowloris                190           190             190   \n",
       "FTP-BruteForce                       519           519             519   \n",
       "Infilteration                       2327          2327            2327   \n",
       "SQL Injection                          9             9               9   \n",
       "SSH-Bruteforce                      1900          1900            1900   \n",
       "\n",
       "                          DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE   Label  \n",
       "Attack                                                                  \n",
       "Benign                            332711                332711  332711  \n",
       "Bot                                 2862                  2862    2862  \n",
       "Brute Force -Web                      43                    43      43  \n",
       "Brute Force -XSS                      19                    19      19  \n",
       "DDOS attack-HOIC                   21617                 21617   21617  \n",
       "DDOS attack-LOIC-UDP                  42                    42      42  \n",
       "DDoS attacks-LOIC-HTTP              6146                  6146    6146  \n",
       "DoS attacks-GoldenEye                554                   554     554  \n",
       "DoS attacks-Hulk                    8653                  8653    8653  \n",
       "DoS attacks-SlowHTTPTest             282                   282     282  \n",
       "DoS attacks-Slowloris                190                   190     190  \n",
       "FTP-BruteForce                       519                   519     519  \n",
       "Infilteration                       2327                  2327    2327  \n",
       "SQL Injection                          9                     9       9  \n",
       "SSH-Bruteforce                      1900                  1900    1900  \n",
       "\n",
       "[15 rows x 42 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=\"Attack\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "FqRx5xCPOuv8"
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Attack\", \"Label\"])\n",
    "y = data[[\"Attack\", \"Label\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=13, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "bPfakXplPGGx"
   },
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
    "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
    "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
    "                                  'FTP_COMMAND_RET_CODE'])\n",
    "encoder.fit(X_train, y_train.Label)\n",
    "\n",
    "# Transform on training set\n",
    "X_train = encoder.transform(X_train)\n",
    "\n",
    "# Transform on testing set\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "ibyOfV-8PouK"
   },
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "asDnsSIWPee0"
   },
   "outputs": [],
   "source": [
    "# (Modified)\n",
    "scaler = Normalizer()\n",
    "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
    "scaler.fit(X_train[cols_to_norm])\n",
    "\n",
    "# Transform on training set\n",
    "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
    "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
    "X_train['id'] = X_train.index\n",
    "\n",
    "# Transform on testing set\n",
    "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
    "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
    "X_test['id'] = X_test.index\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "hErQbsnrPluV",
    "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>h</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9910620</th>\n",
       "      <td>172.31.65.112</td>\n",
       "      <td>172.217.15.65</td>\n",
       "      <td>6.210352e-09</td>\n",
       "      <td>1.019912e-10</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>5.354863e-07</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>4.094895e-07</td>\n",
       "      <td>1.624410e-08</td>\n",
       "      <td>1.157705e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>3.704528e-09</td>\n",
       "      <td>3.704528e-09</td>\n",
       "      <td>6.190550e-09</td>\n",
       "      <td>6.190550e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.764741e-09</td>\n",
       "      <td>[6.210351872620525e-09, 1.019912495558199e-10,...</td>\n",
       "      <td>9910620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17557027</th>\n",
       "      <td>18.218.11.51</td>\n",
       "      <td>172.31.69.28</td>\n",
       "      <td>4.579454e-08</td>\n",
       "      <td>1.543672e-07</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>1.161360e-06</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>1.161360e-06</td>\n",
       "      <td>1.197824e-07</td>\n",
       "      <td>8.536806e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015222</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>2.731684e-08</td>\n",
       "      <td>2.731684e-08</td>\n",
       "      <td>4.564852e-08</td>\n",
       "      <td>4.564852e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.776084e-08</td>\n",
       "      <td>[4.57945440200515e-08, 1.5436721751920067e-07,...</td>\n",
       "      <td>17557027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4328285</th>\n",
       "      <td>190.38.79.218</td>\n",
       "      <td>172.31.64.101</td>\n",
       "      <td>4.079400e-08</td>\n",
       "      <td>1.778170e-09</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>1.034545e-06</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>8.276362e-07</td>\n",
       "      <td>1.644264e-09</td>\n",
       "      <td>2.215507e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>2.433397e-08</td>\n",
       "      <td>2.433397e-08</td>\n",
       "      <td>4.066392e-08</td>\n",
       "      <td>4.066392e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.472949e-08</td>\n",
       "      <td>[4.079399803822932e-08, 1.778169602167593e-09,...</td>\n",
       "      <td>4328285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287389</th>\n",
       "      <td>172.31.68.15</td>\n",
       "      <td>172.31.0.2</td>\n",
       "      <td>6.533832e-09</td>\n",
       "      <td>5.154645e-09</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>5.997981e-07</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>5.997981e-07</td>\n",
       "      <td>6.565366e-09</td>\n",
       "      <td>6.565366e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.054050e-08</td>\n",
       "      <td>7.054050e-08</td>\n",
       "      <td>6.235997e-08</td>\n",
       "      <td>5.346222e-09</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>7.168706e-08</td>\n",
       "      <td>[6.5338315603211064e-09, 5.154645331031908e-09...</td>\n",
       "      <td>1287389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4527816</th>\n",
       "      <td>172.31.66.21</td>\n",
       "      <td>172.31.0.2</td>\n",
       "      <td>1.168657e-08</td>\n",
       "      <td>9.219721e-09</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>1.072813e-06</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>1.072813e-06</td>\n",
       "      <td>1.174297e-08</td>\n",
       "      <td>1.174297e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.261704e-07</td>\n",
       "      <td>1.261704e-07</td>\n",
       "      <td>1.115385e-07</td>\n",
       "      <td>9.562381e-09</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1.282212e-07</td>\n",
       "      <td>[1.1686566408769841e-08, 9.219721141969458e-09...</td>\n",
       "      <td>4527816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          IPV4_SRC_ADDR  IPV4_DST_ADDR      PROTOCOL      L7_PROTO  IN_BYTES  \\\n",
       "9910620   172.31.65.112  172.217.15.65  6.210352e-09  1.019912e-10  0.000043   \n",
       "17557027   18.218.11.51   172.31.69.28  4.579454e-08  1.543672e-07  0.000122   \n",
       "4328285   190.38.79.218  172.31.64.101  4.079400e-08  1.778170e-09  0.000103   \n",
       "1287389    172.31.68.15     172.31.0.2  6.533832e-09  5.154645e-09  0.000038   \n",
       "4527816    172.31.66.21     172.31.0.2  1.168657e-08  9.219721e-09  0.000079   \n",
       "\n",
       "               IN_PKTS  OUT_BYTES      OUT_PKTS     TCP_FLAGS  \\\n",
       "9910620   5.354863e-07   0.000117  4.094895e-07  1.624410e-08   \n",
       "17557027  1.161360e-06   0.000266  1.161360e-06  1.197824e-07   \n",
       "4328285   1.034545e-06   0.000071  8.276362e-07  1.644264e-09   \n",
       "1287389   5.997981e-07   0.000067  5.997981e-07  6.565366e-09   \n",
       "4527816   1.072813e-06   0.000097  1.072813e-06  1.174297e-08   \n",
       "\n",
       "          CLIENT_TCP_FLAGS  ...  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
       "9910620       1.157705e-08  ...        0.000258         0.001348   \n",
       "17557027      8.536806e-08  ...        0.015222         0.006244   \n",
       "4328285       2.215507e-09  ...        0.003398         0.001695   \n",
       "1287389       6.565366e-09  ...        0.000000         0.000000   \n",
       "4527816       1.174297e-08  ...        0.000000         0.000000   \n",
       "\n",
       "             ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "9910620   3.704528e-09    3.704528e-09  6.190550e-09    6.190550e-09   \n",
       "17557027  2.731684e-08    2.731684e-08  4.564852e-08    4.564852e-08   \n",
       "4328285   2.433397e-08    2.433397e-08  4.066392e-08    4.066392e-08   \n",
       "1287389   7.054050e-08    7.054050e-08  6.235997e-08    5.346222e-09   \n",
       "4527816   1.261704e-07    1.261704e-07  1.115385e-07    9.562381e-09   \n",
       "\n",
       "          DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \\\n",
       "9910620         0.000000          3.764741e-09   \n",
       "17557027        0.000000          2.776084e-08   \n",
       "4328285         0.000000          2.472949e-08   \n",
       "1287389         0.000036          7.168706e-08   \n",
       "4527816         0.000064          1.282212e-07   \n",
       "\n",
       "                                                          h        id  \n",
       "9910620   [6.210351872620525e-09, 1.019912495558199e-10,...   9910620  \n",
       "17557027  [4.57945440200515e-08, 1.5436721751920067e-07,...  17557027  \n",
       "4328285   [4.079399803822932e-08, 1.778169602167593e-09,...   4328285  \n",
       "1287389   [6.5338315603211064e-09, 5.154645331031908e-09...   1287389  \n",
       "4527816   [1.1686566408769841e-08, 9.219721141969458e-09...   4527816  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "d_tLtK4WPtrF"
   },
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "lab_enc.fit(data[\"Attack\"])\n",
    "\n",
    "# Transform on training set\n",
    "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
    "\n",
    "# Transform on testing set\n",
    "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8yaicjecP1fZ"
   },
   "outputs": [],
   "source": [
    "# Training graph (Modified)\n",
    "\n",
    "train['id'] = train.index\n",
    "\n",
    "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "           [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "train_g = train_g.to_directed()\n",
    "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
    "train_g.edata['h'].shape[1]])\n",
    "train_g.ndata['h'] = nfeat_weight\n",
    "\n",
    "test['id'] = test.index\n",
    "\n",
    "# Testing graph\n",
    "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "            [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "# print(test_g)\n",
    "test_g = test_g.to_directed()\n",
    "# print(test_g)\n",
    "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
    "test_g.edata['h'].shape[1]])\n",
    "test_g.ndata['h'] = nfeat_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUV6DgJ9QRaP"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import tqdm\n",
    "import gc\n",
    "\n",
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "      super(SAGELayer, self).__init__()\n",
    "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
    "      self.activation = F.relu\n",
    "      self.W_edge = nn.Linear(128 * 2, 256)\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      gain = nn.init.calculate_gain('relu')\n",
    "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "      return {'m':  edges.data['h']}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "      with g_dgl.local_scope():\n",
    "        g = g_dgl\n",
    "        g.ndata['h'] = nfeats\n",
    "        g.edata['h'] = efeats\n",
    "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "\n",
    "        # Compute edge embeddings\n",
    "        u, v = g.edges()\n",
    "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
    "        return g.ndata['h'], edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xo-3K4QRGqc"
   },
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
    "      super(SAGE, self).__init__()\n",
    "      self.layers = nn.ModuleList()\n",
    "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
    "\n",
    "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
    "      if corrupt:\n",
    "        e_perm = torch.randperm(g.number_of_edges())\n",
    "        #n_perm = torch.randperm(g.number_of_nodes())\n",
    "        efeats = efeats[e_perm]\n",
    "        #nfeats = nfeats[n_perm]\n",
    "      for i, layer in enumerate(self.layers):\n",
    "        #nfeats = layer(g, nfeats, efeats)\n",
    "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
    "      #return nfeats.sum(1)\n",
    "      return nfeats.sum(1), e_feats.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uuxRtLuRJQL"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "      super(Discriminator, self).__init__()\n",
    "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def uniform(self, size, tensor):\n",
    "      bound = 1.0 / math.sqrt(size)\n",
    "      if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      size = self.weight.size(0)\n",
    "      self.uniform(size, self.weight)\n",
    "\n",
    "    def forward(self, features, summary):\n",
    "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
    "      return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPbVjlCyRUco"
   },
   "outputs": [],
   "source": [
    "class DGI(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
    "      super(DGI, self).__init__()\n",
    "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
    "      #self.discriminator = Discriminator(128)\n",
    "      self.discriminator = Discriminator(256)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "\n",
    "      positive = positive[1]\n",
    "      negative = negative[1]\n",
    "\n",
    "      summary = torch.sigmoid(positive.mean(dim=0))\n",
    "\n",
    "      positive = self.discriminator(positive, summary)\n",
    "      negative = self.discriminator(negative, summary)\n",
    "\n",
    "      l1 = self.loss(positive, torch.ones_like(positive))\n",
    "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
    "\n",
    "      return l1 + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKnfpWFMR19u"
   },
   "outputs": [],
   "source": [
    "ndim_in = train_g.ndata['h'].shape[1]\n",
    "hidden_features = 128\n",
    "ndim_out = 128\n",
    "num_layers = 1\n",
    "edim = train_g.edata['h'].shape[1]\n",
    "learning_rate = 1e-3\n",
    "epochs = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSl_9qY8SbA0"
   },
   "outputs": [],
   "source": [
    "dgi = DGI(ndim_in,\n",
    "    ndim_out,\n",
    "    edim,\n",
    "    F.relu)\n",
    "\n",
    "dgi = dgi.to('cuda')\n",
    "\n",
    "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
    "                lr=1e-3,\n",
    "                weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9K6_cOiWSdJA"
   },
   "outputs": [],
   "source": [
    "# Format node and edge features for E-GraphSAGE\n",
    "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
    "                                   (train_g.ndata['h'].shape[0], 1,\n",
    "                                    train_g.ndata['h'].shape[1]))\n",
    "\n",
    "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
    "                                   (train_g.edata['h'].shape[0], 1,\n",
    "                                    train_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O44auIyWSexg"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "train_g = train_g.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZtafIdxSheN"
   },
   "outputs": [],
   "source": [
    "cnt_wait = 0\n",
    "best = 1e9\n",
    "best_t = 0\n",
    "dur = []\n",
    "node_features = train_g.ndata['h'] \n",
    "edge_features = train_g.edata['h']\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    dgi.train()\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    dgi_optimizer.zero_grad()\n",
    "    loss = dgi(train_g, node_features, edge_features)\n",
    "    loss.backward()\n",
    "    dgi_optimizer.step()\n",
    "\n",
    "    if loss < best:\n",
    "        best = loss\n",
    "        best_t = epoch\n",
    "        cnt_wait = 0\n",
    "        torch.save(dgi.state_dict(), 'best_dgi_CSE_v2.pkl')\n",
    "    else:\n",
    "        cnt_wait += 1\n",
    "\n",
    "  # if cnt_wait == patience:\n",
    "  #     print('Early stopping!')\n",
    "  #     break\n",
    "\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "\n",
    "        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "            \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
    "              loss.item(),\n",
    "              train_g.num_edges() / np.mean(dur) / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "RZ2HAQDAF-4c",
    "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26694/1688994637.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dgi.load_state_dict(torch.load('best_dgi_CSE_v2.pkl'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgi.load_state_dict(torch.load('best_dgi_CSE_v2.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "6Ek16GkRStKP"
   },
   "outputs": [],
   "source": [
    "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
    "training_emb = training_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-FwaBlOdS4ep"
   },
   "outputs": [],
   "source": [
    "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
    "                                   (test_g.ndata['h'].shape[0], 1,\n",
    "                                    test_g.ndata['h'].shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
    "                                   (test_g.edata['h'].shape[0], 1,\n",
    "                                    test_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "SBa-rdivS6cQ"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "test_g = test_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "W12WLjslS-kx"
   },
   "outputs": [],
   "source": [
    "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
    "testing_emb = testing_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal (Fusion) Learning\n",
    "\n",
    "df_train = pd.DataFrame(training_emb,)\n",
    "# map the id to the original data\n",
    "df_train['id'] = train_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "df_raw_train = pd.DataFrame(X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_fuse_train = pd.merge(df_train, df_raw_train, on='id', how='left')\n",
    "df_fuse_train = df_fuse_train.drop(columns=[\"id\"])\n",
    "df_fuse_train[\"Attacks\"] = train_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
    "\n",
    "df_test = pd.DataFrame(testing_emb,)\n",
    "# map the id to the original data\n",
    "df_test['id'] = test_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "df_raw_test = pd.DataFrame(X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_raw_test = pd.merge(df_test, df_raw_test, on='id', how='left')\n",
    "df_fuse_test = df_raw_test.drop(columns=[\"id\"])\n",
    "df_fuse_test[\"Attacks\"] = test_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ScEk1y_TzzX"
   },
   "source": [
    "# Embeddings CBLOF  Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ZYABKzdrTGas"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pyod.models.cblof import CBLOF\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_fuse_train_samples = df_fuse_train[df_fuse_train.Label == 0].drop(columns=[\"Label\", \"Attacks\"])\n",
    "normal_fuse_train_samples = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"])\n",
    "\n",
    "fuse_train_labels = df_fuse_train[\"Label\"]\n",
    "fuse_test_labels = df_fuse_test[\"Label\"]\n",
    "\n",
    "fuse_test_samples = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_512_TO_1024_BYTES</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.065264</td>\n",
       "      <td>0.141264</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.109434</td>\n",
       "      <td>0.149380</td>\n",
       "      <td>-0.002307</td>\n",
       "      <td>0.054591</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>0.162122</td>\n",
       "      <td>0.157876</td>\n",
       "      <td>...</td>\n",
       "      <td>9.947912e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>5.697104e-08</td>\n",
       "      <td>5.697104e-08</td>\n",
       "      <td>7.056873e-08</td>\n",
       "      <td>7.056873e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.731920e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.065264</td>\n",
       "      <td>0.141264</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.109434</td>\n",
       "      <td>0.149380</td>\n",
       "      <td>-0.002307</td>\n",
       "      <td>0.054591</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>0.162122</td>\n",
       "      <td>0.157876</td>\n",
       "      <td>...</td>\n",
       "      <td>9.834285e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>5.632030e-08</td>\n",
       "      <td>5.632030e-08</td>\n",
       "      <td>6.976268e-08</td>\n",
       "      <td>6.976268e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.666449e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.065264</td>\n",
       "      <td>0.141264</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.109434</td>\n",
       "      <td>0.149380</td>\n",
       "      <td>-0.002307</td>\n",
       "      <td>0.054591</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>0.162122</td>\n",
       "      <td>0.157876</td>\n",
       "      <td>...</td>\n",
       "      <td>9.948407e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>5.697387e-08</td>\n",
       "      <td>5.697387e-08</td>\n",
       "      <td>7.057224e-08</td>\n",
       "      <td>7.057224e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.732205e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.065264</td>\n",
       "      <td>0.141264</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.109434</td>\n",
       "      <td>0.149380</td>\n",
       "      <td>-0.002307</td>\n",
       "      <td>0.054591</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>0.162122</td>\n",
       "      <td>0.157876</td>\n",
       "      <td>...</td>\n",
       "      <td>9.947826e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>5.697055e-08</td>\n",
       "      <td>5.697055e-08</td>\n",
       "      <td>7.056812e-08</td>\n",
       "      <td>7.056812e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.731871e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.065264</td>\n",
       "      <td>0.141264</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.109434</td>\n",
       "      <td>0.149380</td>\n",
       "      <td>-0.002307</td>\n",
       "      <td>0.054591</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>0.162122</td>\n",
       "      <td>0.157876</td>\n",
       "      <td>...</td>\n",
       "      <td>9.948407e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>5.697388e-08</td>\n",
       "      <td>5.697388e-08</td>\n",
       "      <td>7.057224e-08</td>\n",
       "      <td>7.057224e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.732205e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235125</th>\n",
       "      <td>-0.021808</td>\n",
       "      <td>-0.025892</td>\n",
       "      <td>0.180949</td>\n",
       "      <td>0.047172</td>\n",
       "      <td>0.121170</td>\n",
       "      <td>0.099557</td>\n",
       "      <td>0.064873</td>\n",
       "      <td>0.177384</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>-0.003861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.025841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.789069e-06</td>\n",
       "      <td>1.789069e-06</td>\n",
       "      <td>2.216079e-06</td>\n",
       "      <td>2.216079e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800003e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235126</th>\n",
       "      <td>-0.057339</td>\n",
       "      <td>-0.015571</td>\n",
       "      <td>0.208725</td>\n",
       "      <td>0.030920</td>\n",
       "      <td>0.098021</td>\n",
       "      <td>0.099891</td>\n",
       "      <td>0.055402</td>\n",
       "      <td>0.196728</td>\n",
       "      <td>0.098082</td>\n",
       "      <td>-0.046024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.010997</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>3.834516e-07</td>\n",
       "      <td>3.834516e-07</td>\n",
       "      <td>4.749727e-07</td>\n",
       "      <td>4.749727e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857949e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235127</th>\n",
       "      <td>-0.057188</td>\n",
       "      <td>-0.026571</td>\n",
       "      <td>0.210925</td>\n",
       "      <td>0.032160</td>\n",
       "      <td>0.099595</td>\n",
       "      <td>0.103495</td>\n",
       "      <td>0.055317</td>\n",
       "      <td>0.188349</td>\n",
       "      <td>0.093165</td>\n",
       "      <td>-0.051476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.011180</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>3.834508e-07</td>\n",
       "      <td>3.834508e-07</td>\n",
       "      <td>4.749717e-07</td>\n",
       "      <td>4.749717e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857941e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235128</th>\n",
       "      <td>-0.049498</td>\n",
       "      <td>-0.006132</td>\n",
       "      <td>0.184719</td>\n",
       "      <td>0.031591</td>\n",
       "      <td>0.085903</td>\n",
       "      <td>0.082838</td>\n",
       "      <td>0.063280</td>\n",
       "      <td>0.197226</td>\n",
       "      <td>0.120594</td>\n",
       "      <td>-0.037659</td>\n",
       "      <td>...</td>\n",
       "      <td>6.958279e-08</td>\n",
       "      <td>4.638853e-08</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>8.881348e-09</td>\n",
       "      <td>8.881348e-09</td>\n",
       "      <td>1.645360e-08</td>\n",
       "      <td>1.645360e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.336438e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235129</th>\n",
       "      <td>-0.051314</td>\n",
       "      <td>0.013629</td>\n",
       "      <td>0.175130</td>\n",
       "      <td>0.031941</td>\n",
       "      <td>0.084564</td>\n",
       "      <td>0.070928</td>\n",
       "      <td>0.062039</td>\n",
       "      <td>0.204197</td>\n",
       "      <td>0.129361</td>\n",
       "      <td>-0.022337</td>\n",
       "      <td>...</td>\n",
       "      <td>1.482543e-08</td>\n",
       "      <td>7.412714e-08</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>8.490426e-09</td>\n",
       "      <td>8.490426e-09</td>\n",
       "      <td>1.051690e-08</td>\n",
       "      <td>1.051690e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.542312e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235130 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.065264  0.141264  0.006424  0.109434  0.149380 -0.002307  0.054591   \n",
       "1      -0.065264  0.141264  0.006424  0.109434  0.149380 -0.002307  0.054591   \n",
       "2      -0.065264  0.141264  0.006424  0.109434  0.149380 -0.002307  0.054591   \n",
       "3      -0.065264  0.141264  0.006424  0.109434  0.149380 -0.002307  0.054591   \n",
       "4      -0.065264  0.141264  0.006424  0.109434  0.149380 -0.002307  0.054591   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "235125 -0.021808 -0.025892  0.180949  0.047172  0.121170  0.099557  0.064873   \n",
       "235126 -0.057339 -0.015571  0.208725  0.030920  0.098021  0.099891  0.055402   \n",
       "235127 -0.057188 -0.026571  0.210925  0.032160  0.099595  0.103495  0.055317   \n",
       "235128 -0.049498 -0.006132  0.184719  0.031591  0.085903  0.082838  0.063280   \n",
       "235129 -0.051314  0.013629  0.175130  0.031941  0.084564  0.070928  0.062039   \n",
       "\n",
       "               7         8         9  ...  NUM_PKTS_512_TO_1024_BYTES  \\\n",
       "0       0.073480  0.162122  0.157876  ...                9.947912e-08   \n",
       "1       0.073480  0.162122  0.157876  ...                9.834285e-08   \n",
       "2       0.073480  0.162122  0.157876  ...                9.948407e-08   \n",
       "3       0.073480  0.162122  0.157876  ...                9.947826e-08   \n",
       "4       0.073480  0.162122  0.157876  ...                9.948407e-08   \n",
       "...          ...       ...       ...  ...                         ...   \n",
       "235125  0.177384  0.085333 -0.003861  ...                0.000000e+00   \n",
       "235126  0.196728  0.098082 -0.046024  ...                0.000000e+00   \n",
       "235127  0.188349  0.093165 -0.051476  ...                0.000000e+00   \n",
       "235128  0.197226  0.120594 -0.037659  ...                6.958279e-08   \n",
       "235129  0.204197  0.129361 -0.022337  ...                1.482543e-08   \n",
       "\n",
       "        NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
       "0                      0.000000e+00        0.000815         0.002674   \n",
       "1                      0.000000e+00        0.000806         0.002644   \n",
       "2                      0.000000e+00        0.000815         0.002674   \n",
       "3                      0.000000e+00        0.000815         0.002674   \n",
       "4                      0.000000e+00        0.000815         0.002674   \n",
       "...                             ...             ...              ...   \n",
       "235125                 0.000000e+00        0.025841         0.000000   \n",
       "235126                 0.000000e+00        0.010997         0.005485   \n",
       "235127                 0.000000e+00        0.011180         0.005485   \n",
       "235128                 4.638853e-08        0.000190         0.000677   \n",
       "235129                 7.412714e-08        0.000121         0.000121   \n",
       "\n",
       "           ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "0       5.697104e-08    5.697104e-08  7.056873e-08    7.056873e-08   \n",
       "1       5.632030e-08    5.632030e-08  6.976268e-08    6.976268e-08   \n",
       "2       5.697387e-08    5.697387e-08  7.057224e-08    7.057224e-08   \n",
       "3       5.697055e-08    5.697055e-08  7.056812e-08    7.056812e-08   \n",
       "4       5.697388e-08    5.697388e-08  7.057224e-08    7.057224e-08   \n",
       "...              ...             ...           ...             ...   \n",
       "235125  1.789069e-06    1.789069e-06  2.216079e-06    2.216079e-06   \n",
       "235126  3.834516e-07    3.834516e-07  4.749727e-07    4.749727e-07   \n",
       "235127  3.834508e-07    3.834508e-07  4.749717e-07    4.749717e-07   \n",
       "235128  8.881348e-09    8.881348e-09  1.645360e-08    1.645360e-08   \n",
       "235129  8.490426e-09    8.490426e-09  1.051690e-08    1.051690e-08   \n",
       "\n",
       "        DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \n",
       "0                  0.0          5.731920e-08  \n",
       "1                  0.0          5.666449e-08  \n",
       "2                  0.0          5.732205e-08  \n",
       "3                  0.0          5.731871e-08  \n",
       "4                  0.0          5.732205e-08  \n",
       "...                ...                   ...  \n",
       "235125             0.0          1.800003e-06  \n",
       "235126             0.0          3.857949e-07  \n",
       "235127             0.0          3.857941e-07  \n",
       "235128             0.0          1.336438e-08  \n",
       "235129             0.0          8.542312e-09  \n",
       "\n",
       "[235130 rows x 295 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuse_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "62BUDLtO4mla"
   },
   "outputs": [],
   "source": [
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "2i48uLj74mla",
    "outputId": "a0dd33ee-824d-4328-a960-e656e3aaf0ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:46<00:00,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 6, 'con': 0.05}\n",
      "0.9352821093560512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9021    0.9532    0.9269     99552\n",
      "           1     0.9641    0.9240    0.9436    135578\n",
      "\n",
      "    accuracy                         0.9364    235130\n",
      "   macro avg     0.9331    0.9386    0.9353    235130\n",
      "weighted avg     0.9379    0.9364    0.9366    235130\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,6,7,9,10] # cant be lower than 5 or 4\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    try:\n",
    "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
    "        clf_if.fit(benign_fuse_train_samples)\n",
    "    except Exception as e:\n",
    "        print(n_est)\n",
    "        continue\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "rK-Rng9q4mla",
    "outputId": "1796db22-cfb8-4bf8-9004-6420c08c3399"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [04:56<00:00,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 10, 'con': 0.2}\n",
      "0.5270590016541896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4822    0.8993    0.6278     99552\n",
      "           1     0.7974    0.2909    0.4263    135578\n",
      "\n",
      "    accuracy                         0.5485    235130\n",
      "   macro avg     0.6398    0.5951    0.5271    235130\n",
      "weighted avg     0.6639    0.5485    0.5116    235130\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,6,7,9,10]\n",
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    try:\n",
    "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
    "        clf_if.fit(normal_fuse_train_samples)\n",
    "    except Exception as e:\n",
    "        print(n_est)\n",
    "        continue\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "nd0-H7UT4mlc"
   },
   "outputs": [],
   "source": [
    "# HBOS  Embeddings+Raw (Multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "sDquxErU4mld"
   },
   "outputs": [],
   "source": [
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLBIT-Rc4mld",
    "outputId": "8162929e-4879-40e2-a040-afc57eafe7c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 17/36 [00:59<01:08,  3.62s/it]"
     ]
    }
   ],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "n_est = [5,10,15,20,25,30]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    \n",
    "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDcX0mma4mld",
    "outputId": "a2b64cfc-d413-4ba0-9f24-b4935343c315"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:52<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'con': 0.01}\n",
      "0.4893857068710194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6379    0.6315    0.6347     38196\n",
      "           1     0.3410    0.3472    0.3441     20972\n",
      "\n",
      "    accuracy                         0.5307     59168\n",
      "   macro avg     0.4895    0.4894    0.4894     59168\n",
      "weighted avg     0.5327    0.5307    0.5317     59168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,10,15,20,25,30]\n",
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    \n",
    "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbDOqrcy4mle"
   },
   "outputs": [],
   "source": [
    "##  PCA  Emb+Raw (Multimodal/Fusion) Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nga82Fw_4mle",
    "outputId": "0fe52043-af21-45c1-a404-040ab5845efc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:50<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'con': 0.04}\n",
      "0.4521499568535427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6238    0.3855    0.4765     38196\n",
      "           1     0.3400    0.5766    0.4278     20972\n",
      "\n",
      "    accuracy                         0.4532     59168\n",
      "   macro avg     0.4819    0.4810    0.4521     59168\n",
      "weighted avg     0.5232    0.4532    0.4592     59168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.pca import PCA\n",
    "n_est = [5,10,15,20,25,30]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = PCA(n_components=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sg6AcAUW4mlf",
    "outputId": "a9949458-96cf-44dc-b4f6-c73458cb2719"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:01<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'con': 0.05}\n",
      "0.43776217172464377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5956    0.5155    0.5526     38196\n",
      "           1     0.2911    0.3624    0.3229     20972\n",
      "\n",
      "    accuracy                         0.4612     59168\n",
      "   macro avg     0.4433    0.4390    0.4378     59168\n",
      "weighted avg     0.4877    0.4612    0.4712     59168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,10,15,20,25,30]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = PCA(n_components=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yi8SO3tL4mlg"
   },
   "outputs": [],
   "source": [
    "##  IF  Emb+Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(benign_fuse_train_samples.columns)):\n",
    "    benign_fuse_train_samples.rename(columns={benign_fuse_train_samples.columns[i]: f\"feature {i}\"}, inplace=True)\n",
    "\n",
    "for i in range(len(normal_fuse_train_samples.columns)):\n",
    "    normal_fuse_train_samples.rename(columns={normal_fuse_train_samples.columns[i]: f\"feature {i}\"}, inplace=True)\n",
    "\n",
    "for i in range(len(fuse_test_samples.columns)):\n",
    "    fuse_test_samples.rename(columns={fuse_test_samples.columns[i]: f\"feature {i}\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9D0m4vb04mlg",
    "outputId": "bd5a55e6-ac70-4943-9b28-92474b5fb9e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "  4%|▍         | 1/24 [00:00<00:11,  2.09it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "  8%|▊         | 2/24 [00:00<00:09,  2.30it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 12%|█▎        | 3/24 [00:01<00:08,  2.37it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 17%|█▋        | 4/24 [00:01<00:08,  2.40it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 21%|██        | 5/24 [00:02<00:07,  2.40it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 25%|██▌       | 6/24 [00:02<00:07,  2.44it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 29%|██▉       | 7/24 [00:03<00:07,  2.14it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 33%|███▎      | 8/24 [00:03<00:07,  2.02it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 38%|███▊      | 9/24 [00:04<00:08,  1.84it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 42%|████▏     | 10/24 [00:04<00:07,  1.75it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 46%|████▌     | 11/24 [00:05<00:07,  1.71it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 50%|█████     | 12/24 [00:06<00:06,  1.72it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 54%|█████▍    | 13/24 [00:07<00:07,  1.49it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 58%|█████▊    | 14/24 [00:07<00:07,  1.38it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 62%|██████▎   | 15/24 [00:08<00:06,  1.31it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 67%|██████▋   | 16/24 [00:09<00:06,  1.27it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 71%|███████   | 17/24 [00:10<00:05,  1.22it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 75%|███████▌  | 18/24 [00:11<00:04,  1.20it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 79%|███████▉  | 19/24 [00:12<00:04,  1.07it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 83%|████████▎ | 20/24 [00:13<00:03,  1.01it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 21/24 [00:14<00:03,  1.03s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 22/24 [00:15<00:02,  1.07s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 23/24 [00:16<00:01,  1.08s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "100%|██████████| 24/24 [00:18<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'con': 0.01}\n",
      "0.39985799202747224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6452    0.9885    0.7807     38196\n",
      "           1     0.3183    0.0098    0.0190     20972\n",
      "\n",
      "    accuracy                         0.6416     59168\n",
      "   macro avg     0.4817    0.4991    0.3999     59168\n",
      "weighted avg     0.5293    0.6416    0.5107     59168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "n_est = [20, 50, 100, 150]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples.to_numpy())\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCj-3u4t4mlg",
    "outputId": "5f6b1720-9662-4704-ba96-dd57ee32a900"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:20<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 150, 'con': 0.01}\n",
      "0.4000915949078085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6445    0.9844    0.7790     38196\n",
      "           1     0.2797    0.0110    0.0212     20972\n",
      "\n",
      "    accuracy                         0.6394     59168\n",
      "   macro avg     0.4621    0.4977    0.4001     59168\n",
      "weighted avg     0.5152    0.6394    0.5104     59168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "n_est = [20, 50, 100, 150]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised attack classification (Fusion)\n",
    "\n",
    "We now train a supervised classifier on the fused features to predict multi-class attack labels:\n",
    "- Features: embeddings + raw numeric features from `df_fuse_train`/`df_fuse_test` (without `Label`, `Attacks`).\n",
    "- Target: `Attacks` (encoded integer classes from earlier `LabelEncoder`).\n",
    "- Model: HistGradientBoostingClassifier (fast, strong on tabular data). Class imbalance handled via per-sample weights.\n",
    "- Metrics: macro F1, per-class report, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare supervised train/test for attack classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.utils import class_weight\n",
    "import pickle\n",
    "\n",
    "# Build train features/targets from already prepared fused DataFrames\n",
    "X_sup_train = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_sup_test = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights to mitigate class imbalance on training set\n",
    "classes = np.unique(y_sup_train)\n",
    "class_w = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes, y=y_sup_train\n",
    ")\n",
    "class_to_w = {c: w for c, w in zip(classes, class_w)}\n",
    "sample_weight = y_sup_train.map(class_to_w).values\n",
    "\n",
    "# Feature names to all str\n",
    "X_sup_train.columns = X_sup_train.columns.map(str)\n",
    "X_sup_test.columns = X_sup_test.columns.map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Methods (Fused Features)\n",
    "\n",
    "Now we'll compare multiple classification algorithms on the fused features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [14:55<00:00, 99.50s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 30}\n",
      "Best Macro F1: 0.7520\n",
      "Model saved to: best_rf_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9323    0.9943    0.9623     99552\n",
      "           1     1.0000    0.8857    0.9394      8524\n",
      "           2     0.0224    0.4531    0.0427       128\n",
      "           3     0.0203    0.2143    0.0371        56\n",
      "           4     0.9986    0.9488    0.9731     65118\n",
      "           5     0.9508    1.0000    0.9748       116\n",
      "           6     0.9999    1.0000    0.9999     18324\n",
      "           7     1.0000    1.0000    1.0000      1668\n",
      "           8     1.0000    1.0000    1.0000     26008\n",
      "           9     1.0000    1.0000    1.0000       856\n",
      "          10     1.0000    0.9910    0.9955       554\n",
      "          11     1.0000    1.0000    1.0000      1518\n",
      "          12     0.8666    0.5192    0.6494      7018\n",
      "          13     0.0216    0.2143    0.0392        28\n",
      "          14     1.0000    0.5000    0.6667      5662\n",
      "\n",
      "    accuracy                         0.9523    235130\n",
      "   macro avg     0.7875    0.7814    0.7520    235130\n",
      "weighted avg     0.9661    0.9523    0.9550    235130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with Grid Search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            rf_clf = RandomForestClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            rf_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_rf = rf_clf.predict(X_sup_test)\n",
    "            rf_f1 = f1_score(y_sup_test, y_pred_rf, average='macro')\n",
    "            \n",
    "            if rf_f1 > score:\n",
    "                score = rf_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = rf_clf\n",
    "                # Save best model\n",
    "                with open('best_rf_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(rf_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_rf_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Random Forest: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [19:51:17] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "100%|██████████| 27/27 [32:18<00:00, 71.80s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7172\n",
      "Model saved to: best_xgb_classifier_fused.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8674    0.9934    0.9261     99552\n",
      "           1     1.0000    0.9999    0.9999      8524\n",
      "           2     0.0235    0.2891    0.0434       128\n",
      "           3     0.0190    0.1429    0.0335        56\n",
      "           4     0.9976    0.9661    0.9816     65118\n",
      "           5     0.9508    1.0000    0.9748       116\n",
      "           6     0.9996    1.0000    0.9998     18324\n",
      "           7     0.9982    1.0000    0.9991      1668\n",
      "           8     0.9999    0.6658    0.7993     26008\n",
      "           9     1.0000    1.0000    1.0000       856\n",
      "          10     1.0000    0.4892    0.6570       554\n",
      "          11     1.0000    1.0000    1.0000      1518\n",
      "          12     0.8506    0.5266    0.6505      7018\n",
      "          13     0.0142    0.1429    0.0258        28\n",
      "          14     1.0000    0.5000    0.6667      5662\n",
      "\n",
      "    accuracy                         0.9227    235130\n",
      "   macro avg     0.7814    0.7144    0.7172    235130\n",
      "weighted avg     0.9378    0.9227    0.9213    235130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with Grid Search\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    import pickle\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST CLASSIFIER (Fused Features)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            xgb_clf = XGBClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                learning_rate=lr,\n",
    "                random_state=13,\n",
    "                tree_method='hist', \n",
    "                device=\"cuda\"\n",
    "            )\n",
    "            \n",
    "            xgb_clf.fit(X_sup_train, y_sup_train, sample_weight=sample_weight)\n",
    "            y_pred_xgb = xgb_clf.predict(X_sup_test)\n",
    "            xgb_f1 = f1_score(y_sup_test, y_pred_xgb, average='macro')\n",
    "            \n",
    "            if xgb_f1 > score:\n",
    "                score = xgb_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = xgb_clf\n",
    "                # Save best model\n",
    "                xgb_clf.save_model('best_xgb_classifier_fused.json')\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_xgb_classifier_fused.json\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed. XGBoost might not support your GPU.\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CatBoost Grid Search (Expanded)...\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      "  4%|▎         | 1/27 [00:07<03:17,  7.60s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      "  7%|▋         | 2/27 [00:14<03:05,  7.44s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 11%|█         | 3/27 [00:22<02:56,  7.37s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 15%|█▍        | 4/27 [00:40<04:29, 11.70s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 19%|█▊        | 5/27 [00:58<05:05, 13.90s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 22%|██▏       | 6/27 [01:15<05:17, 15.12s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 26%|██▌       | 7/27 [01:56<07:48, 23.42s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 30%|██▉       | 8/27 [02:35<09:02, 28.55s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 33%|███▎      | 9/27 [03:14<09:32, 31.80s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 37%|███▋      | 10/27 [03:25<07:11, 25.37s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 41%|████      | 11/27 [03:36<05:34, 20.89s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 44%|████▍     | 12/27 [03:47<04:27, 17.81s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 48%|████▊     | 13/27 [04:14<04:50, 20.78s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 52%|█████▏    | 14/27 [04:41<04:51, 22.41s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 56%|█████▌    | 15/27 [05:06<04:41, 23.42s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 59%|█████▉    | 16/27 [06:08<06:22, 34.78s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 63%|██████▎   | 17/27 [07:06<06:59, 41.96s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 67%|██████▋   | 18/27 [08:04<07:00, 46.67s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 70%|███████   | 19/27 [08:22<05:03, 37.99s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 74%|███████▍  | 20/27 [08:39<03:42, 31.84s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 78%|███████▊  | 21/27 [08:57<02:45, 27.52s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 81%|████████▏ | 22/27 [09:41<02:43, 32.70s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 85%|████████▌ | 23/27 [10:24<02:23, 35.77s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 89%|████████▉ | 24/27 [11:07<01:53, 37.73s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 93%|█████████▎| 25/27 [12:47<01:52, 56.44s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      " 96%|█████████▋| 26/27 [14:23<01:08, 68.36s/it]Warning: less than 75% GPU memory available for training. Free: 5214.1875 Total: 7833.5625\n",
      "100%|██████████| 27/27 [15:57<00:00, 35.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BEST CATBOOST HYPERPARAMETERS (Fused Features):\n",
      "{'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7804\n",
      "============================================================\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_fused.cbm\n",
      "\n",
      "============================================================\n",
      "FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9814    0.9750    0.9782     99552\n",
      "           1     1.0000    0.9995    0.9998      8524\n",
      "           2     0.0249    0.5469    0.0476       128\n",
      "           3     0.0110    0.1786    0.0207        56\n",
      "           4     0.9991    0.9318    0.9643     65118\n",
      "           5     0.9355    1.0000    0.9667       116\n",
      "           6     1.0000    1.0000    1.0000     18324\n",
      "           7     1.0000    0.9988    0.9994      1668\n",
      "           8     0.9993    1.0000    0.9997     26008\n",
      "           9     1.0000    1.0000    1.0000       856\n",
      "          10     1.0000    1.0000    1.0000       554\n",
      "          11     1.0000    1.0000    1.0000      1518\n",
      "          12     0.6778    0.7395    0.7073      7018\n",
      "          13     0.0115    0.3571    0.0223        28\n",
      "          14     0.9998    0.9996    0.9997      5662\n",
      "\n",
      "    accuracy                         0.9622    235130\n",
      "   macro avg     0.7760    0.8485    0.7804    235130\n",
      "weighted avg     0.9813    0.9622    0.9712    235130\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost with Grid Search (Expanded, no l2_leaf_reg/border_count, fixed best score logic)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"Starting CatBoost Grid Search (Expanded)...\")\n",
    "    \n",
    "    # Expanded hyperparameter grid\n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'  # Use 'CPU' if GPU not available\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_cat = cat_clf.predict(X_sup_test)\n",
    "            cat_f1 = f1_score(y_sup_test, y_pred_cat, average='macro')\n",
    "            \n",
    "            if cat_f1 > best_score:\n",
    "                best_score = cat_f1\n",
    "                best_params = {\n",
    "                    'iterations': iterations,\n",
    "                    'depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for fused features\n",
    "                best_model_path = \"best_catboost_classifier_fused.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEST CATBOOST HYPERPARAMETERS (Fused Features):\")\n",
    "    print(best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    if best_model_path:\n",
    "        print(f\"\\nBest CatBoost model saved to: {best_model_path}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    y_pred_best = best_model.predict(X_sup_test)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_sup_test, y_pred_best, digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed. Install with: pip install catboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [05:22<00:00, 35.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10}\n",
      "Best Macro F1: 0.7950\n",
      "Model saved to: best_et_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9816    0.9669    0.9742     99552\n",
      "           1     0.9973    1.0000    0.9987      8524\n",
      "           2     1.0000    0.1250    0.2222       128\n",
      "           3     0.1951    0.1429    0.1649        56\n",
      "           4     1.0000    0.9004    0.9476     65118\n",
      "           5     0.8855    1.0000    0.9393       116\n",
      "           6     0.9999    1.0000    0.9999     18324\n",
      "           7     1.0000    1.0000    1.0000      1668\n",
      "           8     0.9993    1.0000    0.9997     26008\n",
      "           9     1.0000    1.0000    1.0000       856\n",
      "          10     1.0000    1.0000    1.0000       554\n",
      "          11     1.0000    1.0000    1.0000      1518\n",
      "          12     0.6143    0.7415    0.6720      7018\n",
      "          13     0.0033    0.7857    0.0066        28\n",
      "          14     1.0000    1.0000    1.0000      5662\n",
      "\n",
      "    accuracy                         0.9500    235130\n",
      "   macro avg     0.8451    0.8442    0.7950    235130\n",
      "weighted avg     0.9802    0.9500    0.9639    235130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            et_clf = ExtraTreesClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            et_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_et = et_clf.predict(X_sup_test)\n",
    "            et_f1 = f1_score(y_sup_test, y_pred_et, average='macro')\n",
    "            \n",
    "            if et_f1 > score:\n",
    "                score = et_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = et_clf\n",
    "                # Save best model\n",
    "                with open('best_et_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(et_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_et_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Extra Trees: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Features Classification (Comparison Baseline)\n",
    "\n",
    "Now we'll train classifiers on **raw features only** (without graph embeddings) to compare the benefit of multimodal fusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw feature shape - Train: (274519, 39), Test: (117651, 39)\n",
      "Number of classes: 15\n"
     ]
    }
   ],
   "source": [
    "# Prepare raw features (without embeddings)\n",
    "# Use only the original numeric features from X_train/X_test\n",
    "\n",
    "X_raw_train = X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_train = y_train[\"Attack\"].copy()\n",
    "\n",
    "X_raw_test = X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_test = y_test[\"Attack\"].copy()\n",
    "\n",
    "# Encode labels\n",
    "y_raw_train_encoded = lab_enc.transform(y_train[\"Attack\"])\n",
    "y_raw_test_encoded = lab_enc.transform(y_test[\"Attack\"])\n",
    "\n",
    "# Compute sample weights\n",
    "classes_raw = np.unique(y_raw_train_encoded)\n",
    "class_w_raw = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_raw, y=y_raw_train_encoded\n",
    ")\n",
    "class_to_w_raw = {c: w for c, w in zip(classes_raw, class_w_raw)}\n",
    "sample_weight_raw = pd.Series(y_raw_train_encoded).map(class_to_w_raw).values\n",
    "\n",
    "# Feature names to str\n",
    "X_raw_train.columns = X_raw_train.columns.map(str)\n",
    "X_raw_test.columns = X_raw_test.columns.map(str)\n",
    "\n",
    "print(f\"Raw feature shape - Train: {X_raw_train.shape}, Test: {X_raw_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_raw_train_encoded))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Raw Features Only)\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:06<00:00, 20.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 30}\n",
      "Best Macro F1: 0.7320\n",
      "Model saved to: best_rf_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9758    0.6785    0.8004     49862\n",
      "           1     0.9998    0.9993    0.9995      4262\n",
      "           2     0.0054    0.1562    0.0104        64\n",
      "           3     0.0043    0.1429    0.0083        28\n",
      "           4     0.9974    0.8941    0.9429     32559\n",
      "           5     0.9508    1.0000    0.9748        58\n",
      "           6     0.9995    0.9999    0.9997      9162\n",
      "           7     1.0000    0.9940    0.9970       834\n",
      "           8     0.9995    1.0000    0.9998     13004\n",
      "           9     1.0000    1.0000    1.0000       428\n",
      "          10     1.0000    0.9964    0.9982       277\n",
      "          11     1.0000    1.0000    1.0000       759\n",
      "          12     0.1431    0.7623    0.2409      3509\n",
      "          13     0.0044    0.2143    0.0087        14\n",
      "          14     0.9993    1.0000    0.9996      2831\n",
      "\n",
      "    accuracy                         0.8265    117651\n",
      "   macro avg     0.7386    0.7892    0.7320    117651\n",
      "weighted avg     0.9624    0.8265    0.8760    117651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Raw Features Only)\")\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = rf_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Raw Features Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [05:22<00:00, 11.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7370\n",
      "Model saved to: best_xgb_classifier_raw.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9680    0.7717    0.8587     49862\n",
      "           1     0.9998    0.9991    0.9994      4262\n",
      "           2     0.0055    0.1875    0.0108        64\n",
      "           3     0.0060    0.1786    0.0117        28\n",
      "           4     0.9973    0.8876    0.9392     32559\n",
      "           5     0.9508    1.0000    0.9748        58\n",
      "           6     0.9996    0.9999    0.9997      9162\n",
      "           7     0.9988    0.9976    0.9982       834\n",
      "           8     0.9998    0.9998    0.9998     13004\n",
      "           9     1.0000    1.0000    1.0000       428\n",
      "          10     0.9928    1.0000    0.9964       277\n",
      "          11     1.0000    1.0000    1.0000       759\n",
      "          12     0.1644    0.6375    0.2614      3509\n",
      "          13     0.0029    0.1429    0.0056        14\n",
      "          14     0.9979    1.0000    0.9989      2831\n",
      "\n",
      "    accuracy                         0.8605    117651\n",
      "   macro avg     0.7389    0.7868    0.7370    117651\n",
      "weighted avg     0.9597    0.8605    0.9003    117651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Raw Features Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='cuda'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_raw_train, y_raw_train_encoded, sample_weight=sample_weight_raw)\n",
    "        y_pred = xgb_clf.predict(X_raw_test)\n",
    "        f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_raw.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_raw.json\\n\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Raw Features Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      "  4%|▎         | 1/27 [00:02<01:07,  2.60s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      "  7%|▋         | 2/27 [00:05<01:03,  2.53s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 11%|█         | 3/27 [00:07<01:00,  2.52s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 15%|█▍        | 4/27 [00:13<01:29,  3.91s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 19%|█▊        | 5/27 [00:19<01:41,  4.59s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 22%|██▏       | 6/27 [00:25<01:44,  4.95s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 26%|██▌       | 7/27 [00:37<02:31,  7.55s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 30%|██▉       | 8/27 [00:50<02:51,  9.03s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 33%|███▎      | 9/27 [01:02<03:00, 10.00s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 37%|███▋      | 10/27 [01:05<02:16,  8.05s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 41%|████      | 11/27 [01:09<01:46,  6.67s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 44%|████▍     | 12/27 [01:13<01:25,  5.73s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 48%|████▊     | 13/27 [01:21<01:33,  6.65s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 52%|█████▏    | 14/27 [01:30<01:33,  7.18s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 56%|█████▌    | 15/27 [01:38<01:30,  7.55s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 59%|█████▉    | 16/27 [01:57<02:01, 11.01s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 63%|██████▎   | 17/27 [02:15<02:11, 13.15s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 67%|██████▋   | 18/27 [02:34<02:12, 14.67s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 70%|███████   | 19/27 [02:39<01:35, 12.00s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 74%|███████▍  | 20/27 [02:45<01:10, 10.12s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 78%|███████▊  | 21/27 [02:51<00:52,  8.82s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 81%|████████▏ | 22/27 [03:05<00:52, 10.44s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 85%|████████▌ | 23/27 [03:19<00:45, 11.41s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 89%|████████▉ | 24/27 [03:32<00:36, 12.10s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 93%|█████████▎| 25/27 [04:03<00:35, 17.67s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      " 96%|█████████▋| 26/27 [04:33<00:21, 21.30s/it]Warning: less than 75% GPU memory available for training. Free: 3326.375 Total: 5806.3125\n",
      "100%|██████████| 27/27 [05:03<00:00, 11.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7106\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_raw.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9662    0.7583    0.8498     49862\n",
      "           1     0.9998    0.9991    0.9994      4262\n",
      "           2     0.0044    0.2812    0.0086        64\n",
      "           3     0.0037    0.2500    0.0073        28\n",
      "           4     0.9976    0.7663    0.8668     32559\n",
      "           5     0.5524    1.0000    0.7117        58\n",
      "           6     0.9921    0.9953    0.9937      9162\n",
      "           7     0.9811    0.9976    0.9893       834\n",
      "           8     0.9912    0.9989    0.9951     13004\n",
      "           9     1.0000    1.0000    1.0000       428\n",
      "          10     0.9822    0.9964    0.9892       277\n",
      "          11     1.0000    1.0000    1.0000       759\n",
      "          12     0.1559    0.6227    0.2494      3509\n",
      "          13     0.0018    0.2143    0.0036        14\n",
      "          14     0.9919    0.9993    0.9956      2831\n",
      "\n",
      "    accuracy                         0.8204    117651\n",
      "   macro avg     0.7080    0.7920    0.7106    117651\n",
      "weighted avg     0.9568    0.8204    0.8748    117651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Raw Features Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "            y_pred = cat_clf.predict(X_raw_test)\n",
    "            f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for raw features\n",
    "                best_model_path = \"best_catboost_classifier_raw.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Raw Features Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:30<00:00, 16.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 30}\n",
      "Best Macro F1: 0.7410\n",
      "Model saved to: best_et_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9656    0.8323    0.8940     49862\n",
      "           1     1.0000    0.9993    0.9996      4262\n",
      "           2     0.0052    0.2031    0.0101        64\n",
      "           3     0.0038    0.1429    0.0075        28\n",
      "           4     0.9974    0.8704    0.9296     32559\n",
      "           5     0.9508    1.0000    0.9748        58\n",
      "           6     0.9996    0.9999    0.9997      9162\n",
      "           7     1.0000    0.9988    0.9994       834\n",
      "           8     0.9998    1.0000    0.9999     13004\n",
      "           9     1.0000    1.0000    1.0000       428\n",
      "          10     1.0000    0.9964    0.9982       277\n",
      "          11     1.0000    1.0000    1.0000       759\n",
      "          12     0.1962    0.5811    0.2934      3509\n",
      "          13     0.0043    0.2143    0.0084        14\n",
      "          14     1.0000    1.0000    1.0000      2831\n",
      "\n",
      "    accuracy                         0.8798    117651\n",
      "   macro avg     0.7415    0.7892    0.7410    117651\n",
      "weighted avg     0.9598    0.8798    0.9136    117651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Raw Features Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = et_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Only Classification (Graph Features)\n",
    "\n",
    "Now we'll train classifiers on **embeddings only** (graph features without raw features) to isolate the value of graph-based learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape - Train: (548687, 256), Test: (235130, 256)\n",
      "Number of classes: 15\n",
      "Using only graph embeddings (no raw features)\n"
     ]
    }
   ],
   "source": [
    "# Prepare embeddings-only features (graph features without raw data)\n",
    "# Extract only the embedding columns (first 256 dimensions from graph encoder)\n",
    "\n",
    "# From the fused dataframes, extract only embedding columns\n",
    "# df_fuse_train has: [0-255] = embeddings, [256+] = raw features\n",
    "num_embedding_dims = 256  # Based on the DGI encoder output dimension\n",
    "\n",
    "X_emb_train = df_fuse_train.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_emb_test = df_fuse_test.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights\n",
    "classes_emb = np.unique(y_emb_train)\n",
    "class_w_emb = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_emb, y=y_emb_train\n",
    ")\n",
    "class_to_w_emb = {c: w for c, w in zip(classes_emb, class_w_emb)}\n",
    "sample_weight_emb = y_emb_train.map(class_to_w_emb).values\n",
    "\n",
    "# Feature names to str\n",
    "X_emb_train.columns = X_emb_train.columns.map(str)\n",
    "X_emb_test.columns = X_emb_test.columns.map(str)\n",
    "\n",
    "print(f\"Embeddings shape - Train: {X_emb_train.shape}, Test: {X_emb_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_emb_train))}\")\n",
    "print(f\"Using only graph embeddings (no raw features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [14:14<00:00, 94.89s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 10}\n",
      "Best Macro F1: 0.6199\n",
      "Model saved to: best_rf_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9379    0.9635    0.9506     99552\n",
      "           1     1.0000    0.8857    0.9394      8524\n",
      "           2     0.0000    0.0000    0.0000       128\n",
      "           3     1.0000    0.0179    0.0351        56\n",
      "           4     0.9983    0.5990    0.7487     65118\n",
      "           5     0.0012    0.0690    0.0024       116\n",
      "           6     0.9999    1.0000    0.9999     18324\n",
      "           7     1.0000    1.0000    1.0000      1668\n",
      "           8     0.9993    1.0000    0.9997     26008\n",
      "           9     0.5300    1.0000    0.6928       856\n",
      "          10     1.0000    1.0000    1.0000       554\n",
      "          11     1.0000    0.5000    0.6667      1518\n",
      "          12     0.5543    0.6382    0.5933      7018\n",
      "          13     0.0014    1.0000    0.0028        28\n",
      "          14     1.0000    0.5000    0.6667      5662\n",
      "\n",
      "    accuracy                         0.8421    235130\n",
      "   macro avg     0.7348    0.6782    0.6199    235130\n",
      "weighted avg     0.9570    0.8421    0.8824    235130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = rf_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [27:05<00:00, 60.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.5433\n",
      "Model saved to: best_xgb_classifier_embeddings.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8395    0.9885    0.9079     99552\n",
      "           1     1.0000    1.0000    1.0000      8524\n",
      "           2     0.0000    0.0000    0.0000       128\n",
      "           3     0.0000    0.0000    0.0000        56\n",
      "           4     0.9980    0.6514    0.7883     65118\n",
      "           5     0.0012    0.1379    0.0025       116\n",
      "           6     0.9998    1.0000    0.9999     18324\n",
      "           7     1.0000    1.0000    1.0000      1668\n",
      "           8     0.9992    0.5000    0.6665     26008\n",
      "           9     0.0000    0.0000    0.0000       856\n",
      "          10     1.0000    0.5000    0.6667       554\n",
      "          11     0.6394    1.0000    0.7801      1518\n",
      "          12     0.7823    0.5755    0.6632      7018\n",
      "          13     0.0042    1.0000    0.0083        28\n",
      "          14     1.0000    0.5000    0.6667      5662\n",
      "\n",
      "    accuracy                         0.8125    235130\n",
      "   macro avg     0.6176    0.5902    0.5433    235130\n",
      "weighted avg     0.9175    0.8125    0.8401    235130\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Embeddings Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='gpu'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_emb_train, y_emb_train, sample_weight=sample_weight_emb)\n",
    "        y_pred = xgb_clf.predict(X_emb_test)\n",
    "        f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_embeddings.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_embeddings.json\\n\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Embeddings Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      "  4%|▎         | 1/27 [00:11<04:55, 11.38s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      "  7%|▋         | 2/27 [00:21<04:32, 10.90s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 11%|█         | 3/27 [00:32<04:13, 10.54s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 15%|█▍        | 4/27 [00:57<06:13, 16.25s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 19%|█▊        | 5/27 [01:18<06:40, 18.19s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 22%|██▏       | 6/27 [01:39<06:40, 19.08s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 26%|██▌       | 7/27 [02:29<09:44, 29.24s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 30%|██▉       | 8/27 [03:14<10:49, 34.20s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 33%|███▎      | 9/27 [03:58<11:09, 37.20s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 37%|███▋      | 10/27 [04:14<08:44, 30.83s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 41%|████      | 11/27 [04:29<06:55, 25.96s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 44%|████▍     | 12/27 [04:44<05:37, 22.47s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 48%|████▊     | 13/27 [05:20<06:14, 26.77s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 52%|█████▏    | 14/27 [05:52<06:05, 28.10s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 56%|█████▌    | 15/27 [06:22<05:45, 28.77s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 59%|█████▉    | 16/27 [07:35<07:44, 42.19s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 63%|██████▎   | 17/27 [08:41<08:12, 49.27s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 67%|██████▋   | 18/27 [09:46<08:05, 53.91s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 70%|███████   | 19/27 [10:12<06:04, 45.57s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 74%|███████▍  | 20/27 [10:35<04:32, 38.98s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 78%|███████▊  | 21/27 [10:59<03:25, 34.27s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 81%|████████▏ | 22/27 [11:56<03:25, 41.03s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 85%|████████▌ | 23/27 [12:46<02:54, 43.74s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 89%|████████▉ | 24/27 [13:35<02:16, 45.39s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 93%|█████████▎| 25/27 [15:31<02:13, 66.70s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      " 96%|█████████▋| 26/27 [17:19<01:18, 78.93s/it]Warning: less than 75% GPU memory available for training. Free: 3320.375 Total: 5806.3125\n",
      "100%|██████████| 27/27 [19:05<00:00, 42.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 300, 'depth': 8, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.6786\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_embeddings.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9831    0.9480    0.9652     99552\n",
      "           1     0.9893    1.0000    0.9946      8524\n",
      "           2     0.0000    0.0000    0.0000       128\n",
      "           3     1.0000    0.0357    0.0690        56\n",
      "           4     0.9981    0.3562    0.5250     65118\n",
      "           5     0.0018    0.5603    0.0036       116\n",
      "           6     0.9999    1.0000    0.9999     18324\n",
      "           7     0.9994    1.0000    0.9997      1668\n",
      "           8     0.9993    1.0000    0.9997     26008\n",
      "           9     1.0000    1.0000    1.0000       856\n",
      "          10     1.0000    1.0000    1.0000       554\n",
      "          11     1.0000    1.0000    1.0000      1518\n",
      "          12     0.5124    0.7639    0.6134      7018\n",
      "          13     0.0042    1.0000    0.0083        28\n",
      "          14     1.0000    1.0000    1.0000      5662\n",
      "\n",
      "    accuracy                         0.7916    235130\n",
      "   macro avg     0.7658    0.7776    0.6786    235130\n",
      "weighted avg     0.9761    0.7916    0.8406    235130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Embeddings Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_emb_train, y_emb_train)\n",
    "            y_pred = cat_clf.predict(X_emb_test)\n",
    "            f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for embeddings\n",
    "                best_model_path = \"best_catboost_classifier_embeddings.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [04:44<00:00, 31.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 20}\n",
      "Best Macro F1: 0.6813\n",
      "Model saved to: best_et_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9601    0.9899    0.9748     99552\n",
      "           1     1.0000    0.9429    0.9706      8524\n",
      "           2     0.0000    0.0000    0.0000       128\n",
      "           3     0.0000    0.0000    0.0000        56\n",
      "           4     0.9983    0.5002    0.6665     65118\n",
      "           5     0.0018    0.3621    0.0036       116\n",
      "           6     0.9999    1.0000    0.9999     18324\n",
      "           7     1.0000    1.0000    1.0000      1668\n",
      "           8     0.9993    1.0000    0.9997     26008\n",
      "           9     1.0000    1.0000    1.0000       856\n",
      "          10     1.0000    1.0000    1.0000       554\n",
      "          11     1.0000    1.0000    1.0000      1518\n",
      "          12     0.7768    0.4869    0.5986      7018\n",
      "          13     0.0028    1.0000    0.0056        28\n",
      "          14     1.0000    1.0000    1.0000      5662\n",
      "\n",
      "    accuracy                         0.8388    235130\n",
      "   macro avg     0.7159    0.7521    0.6813    235130\n",
      "weighted avg     0.9745    0.8388    0.8825    235130\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = et_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Comparison Table\n",
    "\n",
    "Create a comparison table of all methods (Fused vs Raw features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\n",
      "===============================================================================================\n",
      "\n",
      "Instructions:\n",
      "1. Run all cells above to get F1 scores for each method\n",
      "2. Record the best Macro F1 score for each method\n",
      "3. Compare three approaches:\n",
      "   - Fused Features: Embeddings + Raw (Multimodal)\n",
      "   - Embeddings Only: Graph features only\n",
      "   - Raw Features: Traditional features only\n",
      "\n",
      "Expected format:\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Method               Fused (Emb+Raw)           Embeddings Only           Raw Only                 \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Random Forest        [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "XGBoost              [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "CatBoost             [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "Extra Trees          [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysis:\n",
      "- Fused features should show best performance (multimodal learning)\n",
      "- Embeddings capture structural/graph patterns\n",
      "- Raw features provide traditional statistical information\n",
      "- Compare to understand the contribution of each modality\n"
     ]
    }
   ],
   "source": [
    "# Create a summary comparison table\n",
    "# NOTE: After running all cells above, manually collect the F1 scores and create a comparison\n",
    "\n",
    "print(\"=\"*95)\n",
    "print(\"PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\")\n",
    "print(\"=\"*95)\n",
    "print(\"\\nInstructions:\")\n",
    "print(\"1. Run all cells above to get F1 scores for each method\")\n",
    "print(\"2. Record the best Macro F1 score for each method\")\n",
    "print(\"3. Compare three approaches:\")\n",
    "print(\"   - Fused Features: Embeddings + Raw (Multimodal)\")\n",
    "print(\"   - Embeddings Only: Graph features only\")\n",
    "print(\"   - Raw Features: Traditional features only\")\n",
    "print(\"\\nExpected format:\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Method':<20} {'Fused (Emb+Raw)':<25} {'Embeddings Only':<25} {'Raw Only':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Random Forest':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'XGBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'CatBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'Extra Trees':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"- Fused features should show best performance (multimodal learning)\")\n",
    "print(\"- Embeddings capture structural/graph patterns\")\n",
    "print(\"- Raw features provide traditional statistical information\")\n",
    "print(\"- Compare to understand the contribution of each modality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights & Interpretation\n",
    "\n",
    "After running all experiments, analyze the results to answer:\n",
    "\n",
    "1. **Which approach performs best overall?**\n",
    "   - Fused features (multimodal) should ideally outperform single modalities\n",
    "   - Compare the magnitude of improvements\n",
    "\n",
    "2. **What is the value of graph embeddings?**\n",
    "   - Compare Embeddings-only vs Raw-only to see if graph structure helps\n",
    "   - If embeddings alone beat raw features, graph learning is beneficial\n",
    "\n",
    "3. **Is multimodal fusion effective?**\n",
    "   - Compare Fused vs (Embeddings + Raw separately)\n",
    "   - Synergy should provide additional gains beyond individual modalities\n",
    "\n",
    "4. **Which classifier is most suitable?**\n",
    "   - Identify the best performing algorithm for each feature type\n",
    "   - Consider computational cost vs accuracy trade-offs\n",
    "\n",
    "5. **Feature contribution analysis:**\n",
    "   - If Fused ≈ Embeddings > Raw: Graph structure dominates\n",
    "   - If Fused ≈ Raw > Embeddings: Traditional features dominate\n",
    "   - If Fused > Both: True synergy from multimodal learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
