{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Hjc3iIihKLn-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from dgl.data import DGLDataset\n",
    "import dgl\n",
    "import time\n",
    "import networkx as nx\n",
    "import category_encoders as ce\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "from typing import *\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import socket\n",
    "import struct\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SvWHb_BpKsLq"
   },
   "outputs": [],
   "source": [
    "file_name = \"NF-CSE-CIC-IDS2018-v3.parquet\"\n",
    "# file_name = \"final.csv\"\n",
    "data = pd.read_parquet(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "fqly1y-LMwYS",
    "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    17514626\n",
       "1     2600903\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3t4OREvSM33h"
   },
   "outputs": [],
   "source": [
    "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
    "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
    "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
    "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bTtHq0XqNXxI"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUNIP-8zNkn9",
    "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'FTP-BruteForce', 'SSH-Bruteforce',\n",
       "       'DoS_attacks-GoldenEye', 'DoS_attacks-Slowloris',\n",
       "       'DoS_attacks-SlowHTTPTest', 'DoS_attacks-Hulk',\n",
       "       'DDoS_attacks-LOIC-HTTP', 'DDOS_attack-LOIC-UDP',\n",
       "       'DDOS_attack-HOIC', 'Brute_Force_-Web', 'Brute_Force_-XSS',\n",
       "       'SQL_Injection', 'Infilteration', 'Bot'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Attack.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    259694\n",
       "0    175543\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the dataset based on your needs (machine capacity) ideally ~ 500k rows\n",
    "\n",
    "# data = data.groupby(by='Attack').sample(frac=0.02, random_state=13)\n",
    "data_attack = data[data['Label'] == 1]\n",
    "data_benign = data[data['Label'] == 0].sample(frac=0.1, random_state=13)\n",
    "data = pd.concat([data_attack, data_benign], axis=0)\n",
    "data = data.sample(frac=0.1, random_state=13).reset_index(drop=True)\n",
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "lcfAP6ViOp-J",
    "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLOW_START_MILLISECONDS</th>\n",
       "      <th>FLOW_END_MILLISECONDS</th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>...</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>SRC_TO_DST_IAT_MIN</th>\n",
       "      <th>SRC_TO_DST_IAT_MAX</th>\n",
       "      <th>SRC_TO_DST_IAT_AVG</th>\n",
       "      <th>SRC_TO_DST_IAT_STDDEV</th>\n",
       "      <th>DST_TO_SRC_IAT_MIN</th>\n",
       "      <th>DST_TO_SRC_IAT_MAX</th>\n",
       "      <th>DST_TO_SRC_IAT_AVG</th>\n",
       "      <th>DST_TO_SRC_IAT_STDDEV</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>...</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "      <td>175543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bot</th>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>...</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "      <td>20730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute_Force_-Web</th>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>...</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brute_Force_-XSS</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDOS_attack-HOIC</th>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>...</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "      <td>102984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDOS_attack-LOIC-UDP</th>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDoS_attacks-LOIC-HTTP</th>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>...</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "      <td>28935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS_attacks-GoldenEye</th>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>...</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "      <td>6053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS_attacks-Hulk</th>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>...</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "      <td>9818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS_attacks-SlowHTTPTest</th>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>...</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "      <td>10535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoS_attacks-Slowloris</th>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>...</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "      <td>3607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTP-BruteForce</th>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>...</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "      <td>38735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infilteration</th>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>...</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "      <td>18857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQL_Injection</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSH-Bruteforce</th>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>...</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "      <td>18850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          FLOW_START_MILLISECONDS  FLOW_END_MILLISECONDS  \\\n",
       "Attack                                                                     \n",
       "Benign                                     175543                 175543   \n",
       "Bot                                         20730                  20730   \n",
       "Brute_Force_-Web                              169                    169   \n",
       "Brute_Force_-XSS                               56                     56   \n",
       "DDOS_attack-HOIC                           102984                 102984   \n",
       "DDOS_attack-LOIC-UDP                          313                    313   \n",
       "DDoS_attacks-LOIC-HTTP                      28935                  28935   \n",
       "DoS_attacks-GoldenEye                        6053                   6053   \n",
       "DoS_attacks-Hulk                             9818                   9818   \n",
       "DoS_attacks-SlowHTTPTest                    10535                  10535   \n",
       "DoS_attacks-Slowloris                        3607                   3607   \n",
       "FTP-BruteForce                              38735                  38735   \n",
       "Infilteration                               18857                  18857   \n",
       "SQL_Injection                                  52                     52   \n",
       "SSH-Bruteforce                              18850                  18850   \n",
       "\n",
       "                          IPV4_SRC_ADDR  IPV4_DST_ADDR  PROTOCOL  L7_PROTO  \\\n",
       "Attack                                                                       \n",
       "Benign                           175543         175543    175543    175543   \n",
       "Bot                               20730          20730     20730     20730   \n",
       "Brute_Force_-Web                    169            169       169       169   \n",
       "Brute_Force_-XSS                     56             56        56        56   \n",
       "DDOS_attack-HOIC                 102984         102984    102984    102984   \n",
       "DDOS_attack-LOIC-UDP                313            313       313       313   \n",
       "DDoS_attacks-LOIC-HTTP            28935          28935     28935     28935   \n",
       "DoS_attacks-GoldenEye              6053           6053      6053      6053   \n",
       "DoS_attacks-Hulk                   9818           9818      9818      9818   \n",
       "DoS_attacks-SlowHTTPTest          10535          10535     10535     10535   \n",
       "DoS_attacks-Slowloris              3607           3607      3607      3607   \n",
       "FTP-BruteForce                    38735          38735     38735     38735   \n",
       "Infilteration                     18857          18857     18857     18857   \n",
       "SQL_Injection                        52             52        52        52   \n",
       "SSH-Bruteforce                    18850          18850     18850     18850   \n",
       "\n",
       "                          IN_BYTES  IN_PKTS  OUT_BYTES  OUT_PKTS  ...  \\\n",
       "Attack                                                            ...   \n",
       "Benign                      175543   175543     175543    175543  ...   \n",
       "Bot                          20730    20730      20730     20730  ...   \n",
       "Brute_Force_-Web               169      169        169       169  ...   \n",
       "Brute_Force_-XSS                56       56         56        56  ...   \n",
       "DDOS_attack-HOIC            102984   102984     102984    102984  ...   \n",
       "DDOS_attack-LOIC-UDP           313      313        313       313  ...   \n",
       "DDoS_attacks-LOIC-HTTP       28935    28935      28935     28935  ...   \n",
       "DoS_attacks-GoldenEye         6053     6053       6053      6053  ...   \n",
       "DoS_attacks-Hulk              9818     9818       9818      9818  ...   \n",
       "DoS_attacks-SlowHTTPTest     10535    10535      10535     10535  ...   \n",
       "DoS_attacks-Slowloris         3607     3607       3607      3607  ...   \n",
       "FTP-BruteForce               38735    38735      38735     38735  ...   \n",
       "Infilteration                18857    18857      18857     18857  ...   \n",
       "SQL_Injection                   52       52         52        52  ...   \n",
       "SSH-Bruteforce               18850    18850      18850     18850  ...   \n",
       "\n",
       "                          FTP_COMMAND_RET_CODE  SRC_TO_DST_IAT_MIN  \\\n",
       "Attack                                                               \n",
       "Benign                                  175543              175543   \n",
       "Bot                                      20730               20730   \n",
       "Brute_Force_-Web                           169                 169   \n",
       "Brute_Force_-XSS                            56                  56   \n",
       "DDOS_attack-HOIC                        102984              102984   \n",
       "DDOS_attack-LOIC-UDP                       313                 313   \n",
       "DDoS_attacks-LOIC-HTTP                   28935               28935   \n",
       "DoS_attacks-GoldenEye                     6053                6053   \n",
       "DoS_attacks-Hulk                          9818                9818   \n",
       "DoS_attacks-SlowHTTPTest                 10535               10535   \n",
       "DoS_attacks-Slowloris                     3607                3607   \n",
       "FTP-BruteForce                           38735               38735   \n",
       "Infilteration                            18857               18857   \n",
       "SQL_Injection                               52                  52   \n",
       "SSH-Bruteforce                           18850               18850   \n",
       "\n",
       "                          SRC_TO_DST_IAT_MAX  SRC_TO_DST_IAT_AVG  \\\n",
       "Attack                                                             \n",
       "Benign                                175543              175543   \n",
       "Bot                                    20730               20730   \n",
       "Brute_Force_-Web                         169                 169   \n",
       "Brute_Force_-XSS                          56                  56   \n",
       "DDOS_attack-HOIC                      102984              102984   \n",
       "DDOS_attack-LOIC-UDP                     313                 313   \n",
       "DDoS_attacks-LOIC-HTTP                 28935               28935   \n",
       "DoS_attacks-GoldenEye                   6053                6053   \n",
       "DoS_attacks-Hulk                        9818                9818   \n",
       "DoS_attacks-SlowHTTPTest               10535               10535   \n",
       "DoS_attacks-Slowloris                   3607                3607   \n",
       "FTP-BruteForce                         38735               38735   \n",
       "Infilteration                          18857               18857   \n",
       "SQL_Injection                             52                  52   \n",
       "SSH-Bruteforce                         18850               18850   \n",
       "\n",
       "                          SRC_TO_DST_IAT_STDDEV  DST_TO_SRC_IAT_MIN  \\\n",
       "Attack                                                                \n",
       "Benign                                   175543              175543   \n",
       "Bot                                       20730               20730   \n",
       "Brute_Force_-Web                            169                 169   \n",
       "Brute_Force_-XSS                             56                  56   \n",
       "DDOS_attack-HOIC                         102984              102984   \n",
       "DDOS_attack-LOIC-UDP                        313                 313   \n",
       "DDoS_attacks-LOIC-HTTP                    28935               28935   \n",
       "DoS_attacks-GoldenEye                      6053                6053   \n",
       "DoS_attacks-Hulk                           9818                9818   \n",
       "DoS_attacks-SlowHTTPTest                  10535               10535   \n",
       "DoS_attacks-Slowloris                      3607                3607   \n",
       "FTP-BruteForce                            38735               38735   \n",
       "Infilteration                             18857               18857   \n",
       "SQL_Injection                                52                  52   \n",
       "SSH-Bruteforce                            18850               18850   \n",
       "\n",
       "                          DST_TO_SRC_IAT_MAX  DST_TO_SRC_IAT_AVG  \\\n",
       "Attack                                                             \n",
       "Benign                                175543              175543   \n",
       "Bot                                    20730               20730   \n",
       "Brute_Force_-Web                         169                 169   \n",
       "Brute_Force_-XSS                          56                  56   \n",
       "DDOS_attack-HOIC                      102984              102984   \n",
       "DDOS_attack-LOIC-UDP                     313                 313   \n",
       "DDoS_attacks-LOIC-HTTP                 28935               28935   \n",
       "DoS_attacks-GoldenEye                   6053                6053   \n",
       "DoS_attacks-Hulk                        9818                9818   \n",
       "DoS_attacks-SlowHTTPTest               10535               10535   \n",
       "DoS_attacks-Slowloris                   3607                3607   \n",
       "FTP-BruteForce                         38735               38735   \n",
       "Infilteration                          18857               18857   \n",
       "SQL_Injection                             52                  52   \n",
       "SSH-Bruteforce                         18850               18850   \n",
       "\n",
       "                          DST_TO_SRC_IAT_STDDEV   Label  \n",
       "Attack                                                   \n",
       "Benign                                   175543  175543  \n",
       "Bot                                       20730   20730  \n",
       "Brute_Force_-Web                            169     169  \n",
       "Brute_Force_-XSS                             56      56  \n",
       "DDOS_attack-HOIC                         102984  102984  \n",
       "DDOS_attack-LOIC-UDP                        313     313  \n",
       "DDoS_attacks-LOIC-HTTP                    28935   28935  \n",
       "DoS_attacks-GoldenEye                      6053    6053  \n",
       "DoS_attacks-Hulk                           9818    9818  \n",
       "DoS_attacks-SlowHTTPTest                  10535   10535  \n",
       "DoS_attacks-Slowloris                      3607    3607  \n",
       "FTP-BruteForce                            38735   38735  \n",
       "Infilteration                             18857   18857  \n",
       "SQL_Injection                                52      52  \n",
       "SSH-Bruteforce                            18850   18850  \n",
       "\n",
       "[15 rows x 52 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=\"Attack\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "FqRx5xCPOuv8"
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Attack\", \"Label\", \"FLOW_START_MILLISECONDS\", \"FLOW_END_MILLISECONDS\",\n",
    "                       \"SRC_TO_DST_IAT_MIN\", \"SRC_TO_DST_IAT_MAX\", \"SRC_TO_DST_IAT_AVG\",\n",
    "                       \"SRC_TO_DST_IAT_STDDEV\", \"DST_TO_SRC_IAT_MIN\", \"DST_TO_SRC_IAT_MAX\",\n",
    "                       \"DST_TO_SRC_IAT_AVG\", \"DST_TO_SRC_IAT_STDDEV\"])\n",
    "y = data[[\"Attack\", \"Label\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=13, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bPfakXplPGGx"
   },
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
    "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
    "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
    "                                  'FTP_COMMAND_RET_CODE'])\n",
    "encoder.fit(X_train, y_train.Label)\n",
    "\n",
    "# Transform on training set\n",
    "X_train = encoder.transform(X_train)\n",
    "\n",
    "# Transform on testing set\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ibyOfV-8PouK"
   },
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "asDnsSIWPee0"
   },
   "outputs": [],
   "source": [
    "# (Modified)\n",
    "scaler = Normalizer()\n",
    "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
    "scaler.fit(X_train[cols_to_norm])\n",
    "\n",
    "# Transform on training set\n",
    "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
    "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
    "X_train['id'] = X_train.index\n",
    "\n",
    "# Transform on testing set\n",
    "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
    "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
    "X_test['id'] = X_test.index\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "hErQbsnrPluV",
    "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>CLIENT_TCP_FLAGS</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "      <th>h</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237065</th>\n",
       "      <td>172.31.66.5</td>\n",
       "      <td>172.31.0.2</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.709650e-06</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>[3.7774454035072763e-06, 3.709650241148367e-06...</td>\n",
       "      <td>237065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15205</th>\n",
       "      <td>172.31.66.40</td>\n",
       "      <td>172.31.0.2</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.517947e-05</td>\n",
       "      <td>0.008051</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.015380</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.007209</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>[1.545688427322976e-05, 1.5179474048347746e-05...</td>\n",
       "      <td>15205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312483</th>\n",
       "      <td>18.221.219.4</td>\n",
       "      <td>172.31.69.25</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.730706e-06</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>[1.2394324546138451e-06, 1.7307060387105932e-0...</td>\n",
       "      <td>312483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277386</th>\n",
       "      <td>82.212.17.186</td>\n",
       "      <td>172.31.64.68</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5.376285e-07</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125240</td>\n",
       "      <td>0.978439</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>[1.094307220318909e-05, 5.3762845853957e-07, 0...</td>\n",
       "      <td>277386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19084</th>\n",
       "      <td>172.31.69.13</td>\n",
       "      <td>172.31.69.7</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.448487e-07</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>[1.5046602182805569e-06, 9.448487146716061e-07...</td>\n",
       "      <td>19084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        IPV4_SRC_ADDR IPV4_DST_ADDR  PROTOCOL      L7_PROTO  IN_BYTES  \\\n",
       "237065    172.31.66.5    172.31.0.2  0.000004  3.709650e-06  0.001821   \n",
       "15205    172.31.66.40    172.31.0.2  0.000015  1.517947e-05  0.008051   \n",
       "312483   18.221.219.4  172.31.69.25  0.000001  1.730706e-06  0.000104   \n",
       "277386  82.212.17.186  172.31.64.68  0.000011  5.376285e-07  0.002645   \n",
       "19084    172.31.69.13   172.31.69.7  0.000002  9.448487e-07  0.000092   \n",
       "\n",
       "         IN_PKTS  OUT_BYTES  OUT_PKTS  TCP_FLAGS  CLIENT_TCP_FLAGS  ...  \\\n",
       "237065  0.000029   0.004522  0.000029   0.000004          0.000004  ...   \n",
       "15205   0.000120   0.015380  0.000120   0.000015          0.000015  ...   \n",
       "312483  0.000002   0.000069  0.000002   0.000002          0.000002  ...   \n",
       "277386  0.000046   0.001407  0.000031   0.000002          0.000003  ...   \n",
       "19084   0.000002   0.000084  0.000002   0.000002          0.000002  ...   \n",
       "\n",
       "        TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  ICMP_TYPE  ICMP_IPV4_TYPE  \\\n",
       "237065        0.000000         0.000000   0.000018        0.000018   \n",
       "15205         0.000000         0.000000   0.000073        0.000073   \n",
       "312483        0.046550         0.000000   0.000001        0.000001   \n",
       "277386        0.125240         0.978439   0.000009        0.000009   \n",
       "19084         0.002153         0.000000   0.000001        0.000001   \n",
       "\n",
       "        DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \\\n",
       "237065      0.000015        0.000004        0.000558              0.000018   \n",
       "15205       0.000062        0.000015        0.007209              0.000072   \n",
       "312483      0.000001        0.000001        0.000000              0.000001   \n",
       "277386      0.000011        0.000011        0.000000              0.000009   \n",
       "19084       0.000001        0.000001        0.000000              0.000001   \n",
       "\n",
       "                                                        h      id  \n",
       "237065  [3.7774454035072763e-06, 3.709650241148367e-06...  237065  \n",
       "15205   [1.545688427322976e-05, 1.5179474048347746e-05...   15205  \n",
       "312483  [1.2394324546138451e-06, 1.7307060387105932e-0...  312483  \n",
       "277386  [1.094307220318909e-05, 5.3762845853957e-07, 0...  277386  \n",
       "19084   [1.5046602182805569e-06, 9.448487146716061e-07...   19084  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "d_tLtK4WPtrF"
   },
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "lab_enc.fit(data[\"Attack\"])\n",
    "\n",
    "# Transform on training set\n",
    "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
    "\n",
    "# Transform on testing set\n",
    "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8yaicjecP1fZ"
   },
   "outputs": [],
   "source": [
    "# Training graph (Modified)\n",
    "\n",
    "train['id'] = train.index\n",
    "\n",
    "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "           [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "train_g = train_g.to_directed()\n",
    "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
    "train_g.edata['h'].shape[1]])\n",
    "train_g.ndata['h'] = nfeat_weight\n",
    "\n",
    "test['id'] = test.index\n",
    "\n",
    "# Testing graph\n",
    "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
    "            [\"h\", \"Label\", \"Attack\", \"id\"], create_using=nx.MultiGraph())\n",
    "# print(test_g)\n",
    "test_g = test_g.to_directed()\n",
    "# print(test_g)\n",
    "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label', \"id\"])\n",
    "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
    "test_g.edata['h'].shape[1]])\n",
    "test_g.ndata['h'] = nfeat_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PUV6DgJ9QRaP"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import tqdm\n",
    "import gc\n",
    "\n",
    "class SAGELayer(nn.Module):\n",
    "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
    "      super(SAGELayer, self).__init__()\n",
    "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
    "      self.activation = F.relu\n",
    "      self.W_edge = nn.Linear(128 * 2, 256)\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      gain = nn.init.calculate_gain('relu')\n",
    "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
    "\n",
    "    def message_func(self, edges):\n",
    "      return {'m':  edges.data['h']}\n",
    "\n",
    "    def forward(self, g_dgl, nfeats, efeats):\n",
    "      with g_dgl.local_scope():\n",
    "        g = g_dgl\n",
    "        g.ndata['h'] = nfeats\n",
    "        g.edata['h'] = efeats\n",
    "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
    "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
    "\n",
    "        # Compute edge embeddings\n",
    "        u, v = g.edges()\n",
    "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
    "        return g.ndata['h'], edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_xo-3K4QRGqc"
   },
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
    "      super(SAGE, self).__init__()\n",
    "      self.layers = nn.ModuleList()\n",
    "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
    "\n",
    "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
    "      if corrupt:\n",
    "        e_perm = torch.randperm(g.number_of_edges())\n",
    "        #n_perm = torch.randperm(g.number_of_nodes())\n",
    "        efeats = efeats[e_perm]\n",
    "        #nfeats = nfeats[n_perm]\n",
    "      for i, layer in enumerate(self.layers):\n",
    "        #nfeats = layer(g, nfeats, efeats)\n",
    "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
    "      #return nfeats.sum(1)\n",
    "      return nfeats.sum(1), e_feats.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6uuxRtLuRJQL"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "      super(Discriminator, self).__init__()\n",
    "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
    "      self.reset_parameters()\n",
    "\n",
    "    def uniform(self, size, tensor):\n",
    "      bound = 1.0 / math.sqrt(size)\n",
    "      if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "      size = self.weight.size(0)\n",
    "      self.uniform(size, self.weight)\n",
    "\n",
    "    def forward(self, features, summary):\n",
    "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
    "      return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZPbVjlCyRUco"
   },
   "outputs": [],
   "source": [
    "class DGI(nn.Module):\n",
    "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
    "      super(DGI, self).__init__()\n",
    "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
    "      #self.discriminator = Discriminator(128)\n",
    "      self.discriminator = Discriminator(256)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "      self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, g, n_features, e_features):\n",
    "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
    "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
    "\n",
    "      positive = positive[1]\n",
    "      negative = negative[1]\n",
    "\n",
    "      summary = torch.sigmoid(positive.mean(dim=0))\n",
    "\n",
    "      positive = self.discriminator(positive, summary)\n",
    "      negative = self.discriminator(negative, summary)\n",
    "\n",
    "      l1 = self.loss(positive, torch.ones_like(positive))\n",
    "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
    "\n",
    "      return l1 + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "sKnfpWFMR19u"
   },
   "outputs": [],
   "source": [
    "ndim_in = train_g.ndata['h'].shape[1]\n",
    "hidden_features = 128\n",
    "ndim_out = 128\n",
    "num_layers = 1\n",
    "edim = train_g.edata['h'].shape[1]\n",
    "learning_rate = 1e-3\n",
    "epochs = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aSl_9qY8SbA0"
   },
   "outputs": [],
   "source": [
    "dgi = DGI(ndim_in,\n",
    "    ndim_out,\n",
    "    edim,\n",
    "    F.relu)\n",
    "\n",
    "dgi = dgi.to('cuda')\n",
    "\n",
    "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
    "                lr=1e-3,\n",
    "                weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9K6_cOiWSdJA"
   },
   "outputs": [],
   "source": [
    "# Format node and edge features for E-GraphSAGE\n",
    "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
    "                                   (train_g.ndata['h'].shape[0], 1,\n",
    "                                    train_g.ndata['h'].shape[1]))\n",
    "\n",
    "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
    "                                   (train_g.edata['h'].shape[0], 1,\n",
    "                                    train_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "O44auIyWSexg"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "train_g = train_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "gZtafIdxSheN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Time(s) nan | Loss 3.0305 | ETputs(KTEPS) nan\n",
      "Epoch 00050 | Time(s) 0.3231 | Loss 1.3469 | ETputs(KTEPS) 1883.64\n",
      "Epoch 00100 | Time(s) 0.3237 | Loss 0.8218 | ETputs(KTEPS) 1880.04\n",
      "Epoch 00150 | Time(s) 0.3237 | Loss 0.3332 | ETputs(KTEPS) 1880.10\n",
      "Epoch 00200 | Time(s) 0.3239 | Loss 0.2518 | ETputs(KTEPS) 1879.08\n",
      "Epoch 00250 | Time(s) 0.3240 | Loss 0.2208 | ETputs(KTEPS) 1878.13\n",
      "Epoch 00300 | Time(s) 0.3241 | Loss 0.2058 | ETputs(KTEPS) 1877.63\n",
      "Epoch 00350 | Time(s) 0.3241 | Loss 0.2063 | ETputs(KTEPS) 1877.55\n",
      "Epoch 00400 | Time(s) 0.3243 | Loss 0.1807 | ETputs(KTEPS) 1876.78\n",
      "Epoch 00450 | Time(s) 0.3242 | Loss 1.1748 | ETputs(KTEPS) 1876.82\n",
      "Epoch 00500 | Time(s) 0.3242 | Loss 0.8848 | ETputs(KTEPS) 1877.16\n",
      "Epoch 00550 | Time(s) 0.3241 | Loss 0.2972 | ETputs(KTEPS) 1877.43\n",
      "Epoch 00600 | Time(s) 0.3241 | Loss 0.2497 | ETputs(KTEPS) 1877.52\n",
      "Epoch 00650 | Time(s) 0.3241 | Loss 0.2239 | ETputs(KTEPS) 1877.65\n",
      "Epoch 00700 | Time(s) 0.3241 | Loss 0.2108 | ETputs(KTEPS) 1877.78\n",
      "Epoch 00750 | Time(s) 0.3241 | Loss 0.1987 | ETputs(KTEPS) 1877.75\n",
      "Epoch 00800 | Time(s) 0.3241 | Loss 0.1942 | ETputs(KTEPS) 1877.81\n",
      "Epoch 00850 | Time(s) 0.3241 | Loss 0.1671 | ETputs(KTEPS) 1877.77\n",
      "Epoch 00900 | Time(s) 0.3241 | Loss 0.1429 | ETputs(KTEPS) 1877.55\n",
      "Epoch 00950 | Time(s) 0.3241 | Loss 0.1285 | ETputs(KTEPS) 1877.55\n",
      "Epoch 01000 | Time(s) 0.3241 | Loss 0.1189 | ETputs(KTEPS) 1877.56\n",
      "Epoch 01050 | Time(s) 0.3241 | Loss 0.1136 | ETputs(KTEPS) 1877.48\n",
      "Epoch 01100 | Time(s) 0.3241 | Loss 0.1035 | ETputs(KTEPS) 1877.44\n",
      "Epoch 01150 | Time(s) 0.3242 | Loss 0.1191 | ETputs(KTEPS) 1877.37\n",
      "Epoch 01200 | Time(s) 0.3242 | Loss 0.1144 | ETputs(KTEPS) 1877.33\n",
      "Epoch 01250 | Time(s) 0.3241 | Loss 1.1863 | ETputs(KTEPS) 1877.45\n",
      "Epoch 01300 | Time(s) 0.3241 | Loss 0.6150 | ETputs(KTEPS) 1877.50\n",
      "Epoch 01350 | Time(s) 0.3241 | Loss 0.3071 | ETputs(KTEPS) 1877.57\n",
      "Epoch 01400 | Time(s) 0.3241 | Loss 0.2537 | ETputs(KTEPS) 1877.62\n",
      "Epoch 01450 | Time(s) 0.3241 | Loss 0.2288 | ETputs(KTEPS) 1877.71\n",
      "Epoch 01500 | Time(s) 0.3241 | Loss 0.2092 | ETputs(KTEPS) 1877.75\n",
      "Epoch 01550 | Time(s) 0.3241 | Loss 0.1939 | ETputs(KTEPS) 1877.76\n",
      "Epoch 01600 | Time(s) 0.3241 | Loss 0.1814 | ETputs(KTEPS) 1877.81\n",
      "Epoch 01650 | Time(s) 0.3241 | Loss 0.1659 | ETputs(KTEPS) 1877.88\n",
      "Epoch 01700 | Time(s) 0.3241 | Loss 0.1526 | ETputs(KTEPS) 1877.95\n",
      "Epoch 01750 | Time(s) 0.3240 | Loss 0.1391 | ETputs(KTEPS) 1878.05\n",
      "Epoch 01800 | Time(s) 0.3240 | Loss 0.1409 | ETputs(KTEPS) 1878.12\n",
      "Epoch 01850 | Time(s) 0.3240 | Loss 0.1190 | ETputs(KTEPS) 1878.22\n",
      "Epoch 01900 | Time(s) 0.3240 | Loss 0.1086 | ETputs(KTEPS) 1878.21\n",
      "Epoch 01950 | Time(s) 0.3240 | Loss 0.0961 | ETputs(KTEPS) 1878.25\n",
      "Epoch 02000 | Time(s) 0.3240 | Loss 0.0950 | ETputs(KTEPS) 1878.28\n",
      "Epoch 02050 | Time(s) 0.3240 | Loss 0.0870 | ETputs(KTEPS) 1878.34\n",
      "Epoch 02100 | Time(s) 0.3240 | Loss 0.0759 | ETputs(KTEPS) 1878.36\n",
      "Epoch 02150 | Time(s) 0.3240 | Loss 0.1016 | ETputs(KTEPS) 1878.37\n",
      "Epoch 02200 | Time(s) 0.3240 | Loss 0.0662 | ETputs(KTEPS) 1878.35\n",
      "Epoch 02250 | Time(s) 0.3240 | Loss 0.0638 | ETputs(KTEPS) 1878.38\n",
      "Epoch 02300 | Time(s) 0.3240 | Loss 0.0653 | ETputs(KTEPS) 1878.39\n",
      "Epoch 02350 | Time(s) 0.3240 | Loss 0.0577 | ETputs(KTEPS) 1878.38\n",
      "Epoch 02400 | Time(s) 0.3240 | Loss 0.0637 | ETputs(KTEPS) 1878.43\n",
      "Epoch 02450 | Time(s) 0.3240 | Loss 0.0479 | ETputs(KTEPS) 1878.46\n",
      "Epoch 02500 | Time(s) 0.3240 | Loss 9.2818 | ETputs(KTEPS) 1878.48\n",
      "Epoch 02550 | Time(s) 0.3240 | Loss 1.3816 | ETputs(KTEPS) 1878.46\n",
      "Epoch 02600 | Time(s) 0.3240 | Loss 1.3553 | ETputs(KTEPS) 1878.47\n",
      "Epoch 02650 | Time(s) 0.3240 | Loss 1.3451 | ETputs(KTEPS) 1878.46\n",
      "Epoch 02700 | Time(s) 0.3240 | Loss 1.2828 | ETputs(KTEPS) 1878.49\n",
      "Epoch 02750 | Time(s) 0.3239 | Loss 0.9966 | ETputs(KTEPS) 1878.56\n",
      "Epoch 02800 | Time(s) 0.3239 | Loss 0.7922 | ETputs(KTEPS) 1878.58\n",
      "Epoch 02850 | Time(s) 0.3239 | Loss 0.4066 | ETputs(KTEPS) 1878.61\n",
      "Epoch 02900 | Time(s) 0.3239 | Loss 0.3183 | ETputs(KTEPS) 1878.62\n",
      "Epoch 02950 | Time(s) 0.3239 | Loss 0.3042 | ETputs(KTEPS) 1878.61\n",
      "Epoch 03000 | Time(s) 0.3239 | Loss 0.2953 | ETputs(KTEPS) 1878.63\n",
      "Epoch 03050 | Time(s) 0.3239 | Loss 0.2904 | ETputs(KTEPS) 1878.66\n",
      "Epoch 03100 | Time(s) 0.3239 | Loss 0.2847 | ETputs(KTEPS) 1878.68\n",
      "Epoch 03150 | Time(s) 0.3239 | Loss 0.2820 | ETputs(KTEPS) 1878.70\n",
      "Epoch 03200 | Time(s) 0.3239 | Loss 0.2754 | ETputs(KTEPS) 1878.70\n",
      "Epoch 03250 | Time(s) 0.3239 | Loss 0.2692 | ETputs(KTEPS) 1878.74\n",
      "Epoch 03300 | Time(s) 0.3239 | Loss 0.2619 | ETputs(KTEPS) 1878.77\n",
      "Epoch 03350 | Time(s) 0.3239 | Loss 0.2606 | ETputs(KTEPS) 1878.79\n",
      "Epoch 03400 | Time(s) 0.3239 | Loss 0.2542 | ETputs(KTEPS) 1878.82\n",
      "Epoch 03450 | Time(s) 0.3239 | Loss 0.2504 | ETputs(KTEPS) 1878.84\n",
      "Epoch 03500 | Time(s) 0.3239 | Loss 0.2482 | ETputs(KTEPS) 1878.85\n",
      "Epoch 03550 | Time(s) 0.3239 | Loss 0.2438 | ETputs(KTEPS) 1878.86\n",
      "Epoch 03600 | Time(s) 0.3239 | Loss 0.2396 | ETputs(KTEPS) 1878.87\n",
      "Epoch 03650 | Time(s) 0.3239 | Loss 0.2350 | ETputs(KTEPS) 1878.87\n",
      "Epoch 03700 | Time(s) 0.3239 | Loss 0.2338 | ETputs(KTEPS) 1878.89\n",
      "Epoch 03750 | Time(s) 0.3239 | Loss 0.2325 | ETputs(KTEPS) 1878.92\n",
      "Epoch 03800 | Time(s) 0.3239 | Loss 0.2288 | ETputs(KTEPS) 1878.95\n",
      "Epoch 03850 | Time(s) 0.3239 | Loss 0.2282 | ETputs(KTEPS) 1878.98\n",
      "Epoch 03900 | Time(s) 0.3239 | Loss 0.2238 | ETputs(KTEPS) 1878.99\n",
      "Epoch 03950 | Time(s) 0.3239 | Loss 0.2177 | ETputs(KTEPS) 1879.00\n"
     ]
    }
   ],
   "source": [
    "cnt_wait = 0\n",
    "best = 1e9\n",
    "best_t = 0\n",
    "dur = []\n",
    "node_features = train_g.ndata['h'] \n",
    "edge_features = train_g.edata['h']\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    dgi.train()\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    dgi_optimizer.zero_grad()\n",
    "    loss = dgi(train_g, node_features, edge_features)\n",
    "    loss.backward()\n",
    "    dgi_optimizer.step()\n",
    "\n",
    "    if loss < best:\n",
    "        best = loss\n",
    "        best_t = epoch\n",
    "        cnt_wait = 0\n",
    "        torch.save(dgi.state_dict(), 'best_dgi_CSE_v3.pkl')\n",
    "    else:\n",
    "        cnt_wait += 1\n",
    "\n",
    "  # if cnt_wait == patience:\n",
    "  #     print('Early stopping!')\n",
    "  #     break\n",
    "\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "\n",
    "        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "            \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
    "              loss.item(),\n",
    "              train_g.num_edges() / np.mean(dur) / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RZ2HAQDAF-4c",
    "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37330/204607001.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dgi.load_state_dict(torch.load('best_dgi_CSE_v3.pkl'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgi.load_state_dict(torch.load('best_dgi_CSE_v3.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "6Ek16GkRStKP"
   },
   "outputs": [],
   "source": [
    "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
    "training_emb = training_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-FwaBlOdS4ep"
   },
   "outputs": [],
   "source": [
    "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
    "                                   (test_g.ndata['h'].shape[0], 1,\n",
    "                                    test_g.ndata['h'].shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
    "                                   (test_g.edata['h'].shape[0], 1,\n",
    "                                    test_g.edata['h'].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "SBa-rdivS6cQ"
   },
   "outputs": [],
   "source": [
    "# Convert to GPU\n",
    "test_g = test_g.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "W12WLjslS-kx"
   },
   "outputs": [],
   "source": [
    "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
    "testing_emb = testing_emb.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal (Fusion) Learning\n",
    "\n",
    "df_train = pd.DataFrame(training_emb,)\n",
    "# map the id to the original data\n",
    "df_train['id'] = train_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "df_raw_train = pd.DataFrame(X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_fuse_train = pd.merge(df_train, df_raw_train, on='id', how='left')\n",
    "df_fuse_train = df_fuse_train.drop(columns=[\"id\"])\n",
    "df_fuse_train[\"Attacks\"] = train_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
    "\n",
    "df_test = pd.DataFrame(testing_emb,)\n",
    "# map the id to the original data\n",
    "df_test['id'] = test_g.edata['id'].detach().cpu().numpy()\n",
    "\n",
    "df_raw_test = pd.DataFrame(X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\"]))\n",
    "df_raw_test = pd.merge(df_test, df_raw_test, on='id', how='left')\n",
    "df_fuse_test = df_raw_test.drop(columns=[\"id\"])\n",
    "df_fuse_test[\"Attacks\"] = test_g.edata['Attack'].detach().cpu().numpy()\n",
    "df_fuse_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ScEk1y_TzzX"
   },
   "source": [
    "# Embeddings CBLOF  Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ZYABKzdrTGas"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pyod.models.cblof import CBLOF\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_fuse_train_samples = df_fuse_train[df_fuse_train.Label == 0].drop(columns=[\"Label\", \"Attacks\"])\n",
    "normal_fuse_train_samples = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"])\n",
    "\n",
    "fuse_train_labels = df_fuse_train[\"Label\"]\n",
    "fuse_test_labels = df_fuse_test[\"Label\"]\n",
    "\n",
    "fuse_test_samples = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_PKTS_512_TO_1024_BYTES</th>\n",
       "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
       "      <th>TCP_WIN_MAX_IN</th>\n",
       "      <th>TCP_WIN_MAX_OUT</th>\n",
       "      <th>ICMP_TYPE</th>\n",
       "      <th>ICMP_IPV4_TYPE</th>\n",
       "      <th>DNS_QUERY_ID</th>\n",
       "      <th>DNS_QUERY_TYPE</th>\n",
       "      <th>DNS_TTL_ANSWER</th>\n",
       "      <th>FTP_COMMAND_RET_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012272</td>\n",
       "      <td>0.049754</td>\n",
       "      <td>0.037376</td>\n",
       "      <td>-0.057863</td>\n",
       "      <td>0.045666</td>\n",
       "      <td>0.052595</td>\n",
       "      <td>0.128874</td>\n",
       "      <td>0.029061</td>\n",
       "      <td>0.023510</td>\n",
       "      <td>0.029213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.039284</td>\n",
       "      <td>0.205148</td>\n",
       "      <td>6.460231e-07</td>\n",
       "      <td>6.460231e-07</td>\n",
       "      <td>9.441403e-07</td>\n",
       "      <td>9.441403e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.200296e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021169</td>\n",
       "      <td>0.018282</td>\n",
       "      <td>0.034445</td>\n",
       "      <td>-0.073610</td>\n",
       "      <td>0.018512</td>\n",
       "      <td>0.034474</td>\n",
       "      <td>0.132494</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.019381</td>\n",
       "      <td>-0.017057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038075</td>\n",
       "      <td>0.026982</td>\n",
       "      <td>2.019403e-05</td>\n",
       "      <td>2.019403e-05</td>\n",
       "      <td>2.951287e-05</td>\n",
       "      <td>2.951287e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.938150e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022352</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>-0.063682</td>\n",
       "      <td>-0.022877</td>\n",
       "      <td>0.072588</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>0.129679</td>\n",
       "      <td>0.028414</td>\n",
       "      <td>-0.064747</td>\n",
       "      <td>0.029395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.124720</td>\n",
       "      <td>0.974379</td>\n",
       "      <td>2.051016e-06</td>\n",
       "      <td>2.051016e-06</td>\n",
       "      <td>2.997489e-06</td>\n",
       "      <td>2.997489e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.968491e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022352</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>-0.063682</td>\n",
       "      <td>-0.022877</td>\n",
       "      <td>0.072588</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>0.129679</td>\n",
       "      <td>0.028414</td>\n",
       "      <td>-0.064747</td>\n",
       "      <td>0.029395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.702095</td>\n",
       "      <td>0.699472</td>\n",
       "      <td>1.472351e-06</td>\n",
       "      <td>1.472351e-06</td>\n",
       "      <td>2.151790e-06</td>\n",
       "      <td>2.151790e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.413109e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052005</td>\n",
       "      <td>-0.009472</td>\n",
       "      <td>0.013403</td>\n",
       "      <td>-0.035060</td>\n",
       "      <td>0.066267</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>0.095307</td>\n",
       "      <td>0.021834</td>\n",
       "      <td>-0.001620</td>\n",
       "      <td>-0.034225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.919235e-07</td>\n",
       "      <td>1.919235e-07</td>\n",
       "      <td>1.580721e-07</td>\n",
       "      <td>2.044919e-08</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.842012e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240747</th>\n",
       "      <td>0.011691</td>\n",
       "      <td>-0.048981</td>\n",
       "      <td>0.082830</td>\n",
       "      <td>-0.106598</td>\n",
       "      <td>0.033035</td>\n",
       "      <td>0.078462</td>\n",
       "      <td>0.092463</td>\n",
       "      <td>0.061608</td>\n",
       "      <td>-0.015809</td>\n",
       "      <td>-0.014878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.502245</td>\n",
       "      <td>0.502245</td>\n",
       "      <td>8.259376e-06</td>\n",
       "      <td>8.259376e-06</td>\n",
       "      <td>1.207079e-05</td>\n",
       "      <td>1.207079e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.927051e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240748</th>\n",
       "      <td>0.058499</td>\n",
       "      <td>0.035029</td>\n",
       "      <td>-0.018861</td>\n",
       "      <td>-0.028614</td>\n",
       "      <td>-0.007317</td>\n",
       "      <td>0.008847</td>\n",
       "      <td>0.151085</td>\n",
       "      <td>-0.060317</td>\n",
       "      <td>-0.055841</td>\n",
       "      <td>-0.036982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.785920e-07</td>\n",
       "      <td>3.785920e-07</td>\n",
       "      <td>5.532990e-07</td>\n",
       "      <td>5.532990e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.633589e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240749</th>\n",
       "      <td>0.022840</td>\n",
       "      <td>-0.067292</td>\n",
       "      <td>0.068563</td>\n",
       "      <td>-0.088919</td>\n",
       "      <td>0.012151</td>\n",
       "      <td>0.100710</td>\n",
       "      <td>0.078976</td>\n",
       "      <td>0.043141</td>\n",
       "      <td>-0.040467</td>\n",
       "      <td>-0.016786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583955</td>\n",
       "      <td>0.291249</td>\n",
       "      <td>4.789559e-06</td>\n",
       "      <td>4.789559e-06</td>\n",
       "      <td>6.999774e-06</td>\n",
       "      <td>6.999774e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.596846e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240750</th>\n",
       "      <td>0.054009</td>\n",
       "      <td>-0.040630</td>\n",
       "      <td>0.086194</td>\n",
       "      <td>-0.087538</td>\n",
       "      <td>0.017969</td>\n",
       "      <td>0.065003</td>\n",
       "      <td>0.106513</td>\n",
       "      <td>0.036058</td>\n",
       "      <td>-0.100818</td>\n",
       "      <td>-0.016475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.447120</td>\n",
       "      <td>0.873094</td>\n",
       "      <td>1.837817e-06</td>\n",
       "      <td>1.837817e-06</td>\n",
       "      <td>2.685905e-06</td>\n",
       "      <td>2.685905e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.763870e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240751</th>\n",
       "      <td>0.061196</td>\n",
       "      <td>-0.069640</td>\n",
       "      <td>0.101769</td>\n",
       "      <td>-0.085983</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.076572</td>\n",
       "      <td>0.101590</td>\n",
       "      <td>0.019125</td>\n",
       "      <td>-0.079480</td>\n",
       "      <td>-0.044918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.851757</td>\n",
       "      <td>0.417870</td>\n",
       "      <td>6.871833e-06</td>\n",
       "      <td>6.871833e-06</td>\n",
       "      <td>1.004295e-05</td>\n",
       "      <td>1.004295e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.595337e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240752 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0       0.012272  0.049754  0.037376 -0.057863  0.045666  0.052595  0.128874   \n",
       "1       0.021169  0.018282  0.034445 -0.073610  0.018512  0.034474  0.132494   \n",
       "2       0.022352  0.026855 -0.063682 -0.022877  0.072588  0.021886  0.129679   \n",
       "3       0.022352  0.026855 -0.063682 -0.022877  0.072588  0.021886  0.129679   \n",
       "4       0.052005 -0.009472  0.013403 -0.035060  0.066267  0.037680  0.095307   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "240747  0.011691 -0.048981  0.082830 -0.106598  0.033035  0.078462  0.092463   \n",
       "240748  0.058499  0.035029 -0.018861 -0.028614 -0.007317  0.008847  0.151085   \n",
       "240749  0.022840 -0.067292  0.068563 -0.088919  0.012151  0.100710  0.078976   \n",
       "240750  0.054009 -0.040630  0.086194 -0.087538  0.017969  0.065003  0.106513   \n",
       "240751  0.061196 -0.069640  0.101769 -0.085983  0.006225  0.076572  0.101590   \n",
       "\n",
       "               7         8         9  ...  NUM_PKTS_512_TO_1024_BYTES  \\\n",
       "0       0.029061  0.023510  0.029213  ...                    0.000010   \n",
       "1       0.009300  0.019381 -0.017057  ...                    0.000000   \n",
       "2       0.028414 -0.064747  0.029395  ...                    0.000015   \n",
       "3       0.028414 -0.064747  0.029395  ...                    0.000011   \n",
       "4       0.021834 -0.001620 -0.034225  ...                    0.000000   \n",
       "...          ...       ...       ...  ...                         ...   \n",
       "240747  0.061608 -0.015809 -0.014878  ...                    0.000000   \n",
       "240748 -0.060317 -0.055841 -0.036982  ...                    0.000000   \n",
       "240749  0.043141 -0.040467 -0.016786  ...                    0.000000   \n",
       "240750  0.036058 -0.100818 -0.016475  ...                    0.000014   \n",
       "240751  0.019125 -0.079480 -0.044918  ...                    0.000000   \n",
       "\n",
       "        NUM_PKTS_1024_TO_1514_BYTES  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT  \\\n",
       "0                          0.000010        0.039284         0.205148   \n",
       "1                          0.000000        0.038075         0.026982   \n",
       "2                          0.000015        0.124720         0.974379   \n",
       "3                          0.000011        0.702095         0.699472   \n",
       "4                          0.000000        0.000000         0.000000   \n",
       "...                             ...             ...              ...   \n",
       "240747                     0.000123        0.502245         0.502245   \n",
       "240748                     0.000000        0.146438         0.000000   \n",
       "240749                     0.000000        0.583955         0.291249   \n",
       "240750                     0.000014        0.447120         0.873094   \n",
       "240751                     0.000000        0.851757         0.417870   \n",
       "\n",
       "           ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
       "0       6.460231e-07    6.460231e-07  9.441403e-07    9.441403e-07   \n",
       "1       2.019403e-05    2.019403e-05  2.951287e-05    2.951287e-05   \n",
       "2       2.051016e-06    2.051016e-06  2.997489e-06    2.997489e-06   \n",
       "3       1.472351e-06    1.472351e-06  2.151790e-06    2.151790e-06   \n",
       "4       1.919235e-07    1.919235e-07  1.580721e-07    2.044919e-08   \n",
       "...              ...             ...           ...             ...   \n",
       "240747  8.259376e-06    8.259376e-06  1.207079e-05    1.207079e-05   \n",
       "240748  3.785920e-07    3.785920e-07  5.532990e-07    5.532990e-07   \n",
       "240749  4.789559e-06    4.789559e-06  6.999774e-06    6.999774e-06   \n",
       "240750  1.837817e-06    1.837817e-06  2.685905e-06    2.685905e-06   \n",
       "240751  6.871833e-06    6.871833e-06  1.004295e-05    1.004295e-05   \n",
       "\n",
       "        DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \n",
       "0             0.000000          6.200296e-07  \n",
       "1             0.000000          1.938150e-05  \n",
       "2             0.000000          1.968491e-06  \n",
       "3             0.000000          1.413109e-06  \n",
       "4             0.000085          1.842012e-07  \n",
       "...                ...                   ...  \n",
       "240747        0.000000          7.927051e-06  \n",
       "240748        0.000000          3.633589e-07  \n",
       "240749        0.000000          4.596846e-06  \n",
       "240750        0.000000          1.763870e-06  \n",
       "240751        0.000000          6.595337e-06  \n",
       "\n",
       "[240752 rows x 295 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuse_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "62BUDLtO4mla"
   },
   "outputs": [],
   "source": [
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "2i48uLj74mla",
    "outputId": "a0dd33ee-824d-4328-a960-e656e3aaf0ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:19<01:04,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:45<00:00,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 7, 'con': 0.2}\n",
      "0.6936377703621189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5906    0.7880    0.6752    104997\n",
      "           1     0.8156    0.6319    0.7121    155818\n",
      "\n",
      "    accuracy                         0.6948    260815\n",
      "   macro avg     0.7031    0.7100    0.6936    260815\n",
      "weighted avg     0.7250    0.6948    0.6972    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,6,7,9,10] # cant be lower than 5 or 4\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    try:\n",
    "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
    "        clf_if.fit(benign_fuse_train_samples)\n",
    "    except Exception as e:\n",
    "        print(n_est)\n",
    "        continue\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "rK-Rng9q4mla",
    "outputId": "1796db22-cfb8-4bf8-9004-6420c08c3399"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:11<02:30,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:21<02:02,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:29<01:43,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:14<00:00,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 9, 'con': 0.1}\n",
      "0.37825055031847954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4095    0.9144    0.5657    104997\n",
      "           1     0.6592    0.1116    0.1908    155818\n",
      "\n",
      "    accuracy                         0.4348    260815\n",
      "   macro avg     0.5343    0.5130    0.3783    260815\n",
      "weighted avg     0.5587    0.4348    0.3417    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,6,7,9,10]\n",
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    try:\n",
    "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
    "        clf_if.fit(normal_fuse_train_samples)\n",
    "    except Exception as e:\n",
    "        print(n_est)\n",
    "        continue\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nd0-H7UT4mlc"
   },
   "outputs": [],
   "source": [
    "# HBOS  Embeddings+Raw (Multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDquxErU4mld"
   },
   "outputs": [],
   "source": [
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLBIT-Rc4mld",
    "outputId": "8162929e-4879-40e2-a040-afc57eafe7c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [05:45<00:00,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'con': 0.05}\n",
      "0.8471039149382792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9177    0.9571    374702\n",
      "           1     0.5837    1.0000    0.7371     43236\n",
      "\n",
      "    accuracy                         0.9262    417938\n",
      "   macro avg     0.7918    0.9588    0.8471    417938\n",
      "weighted avg     0.9569    0.9262    0.9343    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "n_est = [5,10,15,20,25,30]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    \n",
    "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDcX0mma4mld",
    "outputId": "a2b64cfc-d413-4ba0-9f24-b4935343c315"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [06:05<00:00, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 25, 'con': 0.1}\n",
      "0.8471039149382792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9177    0.9571    374702\n",
      "           1     0.5837    1.0000    0.7371     43236\n",
      "\n",
      "    accuracy                         0.9262    417938\n",
      "   macro avg     0.7918    0.9588    0.8471    417938\n",
      "weighted avg     0.9569    0.9262    0.9343    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,10,15,20,25,30]\n",
    "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, contamination))\n",
    "score = -1\n",
    "bs = None\n",
    "for n_est, con in tqdm(params):\n",
    "    \n",
    "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbDOqrcy4mle"
   },
   "outputs": [],
   "source": [
    "##  PCA  Emb+Raw (Multimodal/Fusion) Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nga82Fw_4mle",
    "outputId": "0fe52043-af21-45c1-a404-040ab5845efc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [05:07<00:00,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'con': 0.1}\n",
      "0.8207887532486517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8987    0.9466    374702\n",
      "           1     0.5325    1.0000    0.6949     43236\n",
      "\n",
      "    accuracy                         0.9092    417938\n",
      "   macro avg     0.7662    0.9493    0.8208    417938\n",
      "weighted avg     0.9516    0.9092    0.9206    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.pca import PCA\n",
    "n_est = [5,10,15,20,25,30]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = PCA(n_components=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sg6AcAUW4mlf",
    "outputId": "a9949458-96cf-44dc-b4f6-c73458cb2719"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [05:49<00:00,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 15, 'con': 0.2}\n",
      "0.8085873162698853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8893    0.9414    374702\n",
      "           1     0.5103    1.0000    0.6758     43236\n",
      "\n",
      "    accuracy                         0.9007    417938\n",
      "   macro avg     0.7552    0.9446    0.8086    417938\n",
      "weighted avg     0.9493    0.9007    0.9139    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_est = [5,10,15,20,25,30]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = PCA(n_components=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = y_pred\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yi8SO3tL4mlg"
   },
   "outputs": [],
   "source": [
    "##  IF  Emb+Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(benign_fuse_train_samples.columns)):\n",
    "    benign_fuse_train_samples.rename(columns={benign_fuse_train_samples.columns[i]: f\"feature {i}\"}, inplace=True)\n",
    "\n",
    "for i in range(len(normal_fuse_train_samples.columns)):\n",
    "    normal_fuse_train_samples.rename(columns={normal_fuse_train_samples.columns[i]: f\"feature {i}\"}, inplace=True)\n",
    "\n",
    "for i in range(len(fuse_test_samples.columns)):\n",
    "    fuse_test_samples.rename(columns={fuse_test_samples.columns[i]: f\"feature {i}\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9D0m4vb04mlg",
    "outputId": "bd5a55e6-ac70-4943-9b28-92474b5fb9e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "  4%|▍         | 1/24 [00:02<00:54,  2.36s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "  8%|▊         | 2/24 [00:04<00:51,  2.34s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 12%|█▎        | 3/24 [00:07<00:48,  2.33s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 17%|█▋        | 4/24 [00:09<00:46,  2.31s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 21%|██        | 5/24 [00:11<00:44,  2.32s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 25%|██▌       | 6/24 [00:13<00:40,  2.27s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 29%|██▉       | 7/24 [00:16<00:43,  2.56s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 33%|███▎      | 8/24 [00:20<00:44,  2.77s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 38%|███▊      | 9/24 [00:23<00:43,  2.90s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 42%|████▏     | 10/24 [00:26<00:41,  2.99s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 46%|████▌     | 11/24 [00:29<00:39,  3.06s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 50%|█████     | 12/24 [00:32<00:37,  3.11s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 54%|█████▍    | 13/24 [00:38<00:41,  3.78s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 58%|█████▊    | 14/24 [00:43<00:42,  4.22s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 62%|██████▎   | 15/24 [00:48<00:40,  4.50s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 67%|██████▋   | 16/24 [00:53<00:36,  4.58s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 71%|███████   | 17/24 [00:58<00:33,  4.81s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 75%|███████▌  | 18/24 [01:03<00:29,  4.91s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 79%|███████▉  | 19/24 [01:10<00:27,  5.50s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 83%|████████▎ | 20/24 [01:17<00:23,  5.85s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 88%|████████▊ | 21/24 [01:24<00:18,  6.10s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 92%|█████████▏| 22/24 [01:30<00:12,  6.29s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      " 96%|█████████▌| 23/24 [01:37<00:06,  6.42s/it]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but IsolationForest was fitted without feature names\n",
      "  warnings.warn(\n",
      "100%|██████████| 24/24 [01:44<00:00,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50, 'con': 0.1}\n",
      "0.820368662501618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8984    0.9465    374702\n",
      "           1     0.5317    1.0000    0.6943     43236\n",
      "\n",
      "    accuracy                         0.9089    417938\n",
      "   macro avg     0.7659    0.9492    0.8204    417938\n",
      "weighted avg     0.9516    0.9089    0.9204    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "n_est = [20, 50, 100, 150]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
    "    clf_if.fit(benign_fuse_train_samples.to_numpy())\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCj-3u4t4mlg",
    "outputId": "5f6b1720-9662-4704-ba96-dd57ee32a900"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:52<00:00,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 150, 'con': 0.2}\n",
      "0.802806141381684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9991    0.8861    0.9392    374702\n",
      "           1     0.5015    0.9928    0.6664     43236\n",
      "\n",
      "    accuracy                         0.8972    417938\n",
      "   macro avg     0.7503    0.9395    0.8028    417938\n",
      "weighted avg     0.9476    0.8972    0.9110    417938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "n_est = [20, 50, 100, 150]\n",
    "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
    "params = list(itertools.product(n_est, cont))\n",
    "score = -1\n",
    "bs = None\n",
    "\n",
    "for n_est, con in tqdm(params):\n",
    "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
    "    clf_if.fit(normal_fuse_train_samples)\n",
    "    y_pred = clf_if.predict(fuse_test_samples)\n",
    "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
    "\n",
    "    f1 = f1_score(fuse_test_labels, test_pred, average='macro')\n",
    "\n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est,\n",
    "                       \"con\": con\n",
    "                }\n",
    "        bs = test_pred\n",
    "    del clf_if\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "print(score)\n",
    "print(classification_report(fuse_test_labels, bs, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised attack classification (Fusion)\n",
    "\n",
    "We now train a supervised classifier on the fused features to predict multi-class attack labels:\n",
    "- Features: embeddings + raw numeric features from `df_fuse_train`/`df_fuse_test` (without `Label`, `Attacks`).\n",
    "- Target: `Attacks` (encoded integer classes from earlier `LabelEncoder`).\n",
    "- Model: HistGradientBoostingClassifier (fast, strong on tabular data). Class imbalance handled via per-sample weights.\n",
    "- Metrics: macro F1, per-class report, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare supervised train/test for attack classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.utils import class_weight\n",
    "import pickle\n",
    "\n",
    "# Build train features/targets from already prepared fused DataFrames\n",
    "X_sup_train = df_fuse_train.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_sup_test = df_fuse_test.drop(columns=[\"Label\", \"Attacks\"]).copy()\n",
    "y_sup_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights to mitigate class imbalance on training set\n",
    "classes = np.unique(y_sup_train)\n",
    "class_w = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes, y=y_sup_train\n",
    ")\n",
    "class_to_w = {c: w for c, w in zip(classes, class_w)}\n",
    "sample_weight = y_sup_train.map(class_to_w).values\n",
    "\n",
    "# Feature names to all str\n",
    "X_sup_train.columns = X_sup_train.columns.map(str)\n",
    "X_sup_test.columns = X_sup_test.columns.map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Methods (Fused Features)\n",
    "\n",
    "Now we'll compare multiple classification algorithms on the fused features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [08:49<00:00, 58.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 10}\n",
      "Best Macro F1: 0.6359\n",
      "Model saved to: best_rf_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9000    0.9617    0.9298    104997\n",
      "           1     0.9997    0.9521    0.9753     12438\n",
      "           2     0.8539    0.7451    0.7958       102\n",
      "           3     0.5455    0.3529    0.4286        34\n",
      "           4     1.0000    1.0000    1.0000     61790\n",
      "           5     1.0000    1.0000    1.0000       188\n",
      "           6     1.0000    0.9544    0.9767     17362\n",
      "           7     1.0000    0.5000    0.6667      3632\n",
      "           8     0.0000    0.0000    0.0000      5890\n",
      "           9     0.0000    0.0000    0.0000      6320\n",
      "          10     0.0000    0.0000    0.0000      2164\n",
      "          11     0.6477    0.5000    0.5644     23242\n",
      "          12     0.7015    0.9516    0.8076     11314\n",
      "          13     0.2667    0.7500    0.3934        32\n",
      "          14     1.0000    0.9998    0.9999     11310\n",
      "\n",
      "    accuracy                         0.8703    260815\n",
      "   macro avg     0.6610    0.6445    0.6359    260815\n",
      "weighted avg     0.8601    0.8703    0.8619    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/miniforge3/envs/nlp-env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with Grid Search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            rf_clf = RandomForestClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            rf_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_rf = rf_clf.predict(X_sup_test)\n",
    "            rf_f1 = f1_score(y_sup_test, y_pred_rf, average='macro')\n",
    "            \n",
    "            if rf_f1 > score:\n",
    "                score = rf_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = rf_clf\n",
    "                # Save best model\n",
    "                with open('best_rf_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(rf_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_rf_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Random Forest: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [09:34:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "100%|██████████| 27/27 [29:03<00:00, 64.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7945\n",
      "Model saved to: best_xgb_classifier_fused.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9368    0.9688    0.9525     62919\n",
      "           1     1.0000    1.0000    1.0000     12304\n",
      "           2     0.8706    0.7708    0.8177        96\n",
      "           3     0.3830    0.5625    0.4557        32\n",
      "           4     1.0000    1.0000    1.0000     62294\n",
      "           5     1.0000    1.0000    1.0000       200\n",
      "           6     1.0000    0.9443    0.9714     17396\n",
      "           7     1.0000    0.5000    0.6667      3620\n",
      "           8     1.0000    0.9998    0.9999      5930\n",
      "           9     0.2144    0.5000    0.3001      6334\n",
      "          10     1.0000    0.9830    0.9914      2116\n",
      "          11     0.7856    0.5000    0.6111     23204\n",
      "          12     0.8363    0.8847    0.8598     11248\n",
      "          13     0.2581    0.3333    0.2909        24\n",
      "          14     1.0000    1.0000    1.0000     11236\n",
      "\n",
      "    accuracy                         0.9046    218953\n",
      "   macro avg     0.8190    0.7965    0.7945    218953\n",
      "weighted avg     0.9277    0.9046    0.9096    218953\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# XGBoost with Grid Search\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    import pickle\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST CLASSIFIER (Fused Features)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            xgb_clf = XGBClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                learning_rate=lr,\n",
    "                random_state=13,\n",
    "                tree_method='hist', \n",
    "                device=\"cuda\"\n",
    "            )\n",
    "            \n",
    "            xgb_clf.fit(X_sup_train, y_sup_train, sample_weight=sample_weight)\n",
    "            y_pred_xgb = xgb_clf.predict(X_sup_test)\n",
    "            xgb_f1 = f1_score(y_sup_test, y_pred_xgb, average='macro')\n",
    "            \n",
    "            if xgb_f1 > score:\n",
    "                score = xgb_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = xgb_clf\n",
    "                # Save best model\n",
    "                xgb_clf.save_model('best_xgb_classifier_fused.json')\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_xgb_classifier_fused.json\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed. XGBoost might not support your GPU.\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CatBoost Grid Search (Expanded)...\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 3762.4375 Total: 7833.5625\n"
     ]
    }
   ],
   "source": [
    "# CatBoost with Grid Search (Expanded, no l2_leaf_reg/border_count, fixed best score logic)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"Starting CatBoost Grid Search (Expanded)...\")\n",
    "    \n",
    "    # Expanded hyperparameter grid\n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'  # Use 'CPU' if GPU not available\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_cat = cat_clf.predict(X_sup_test)\n",
    "            cat_f1 = f1_score(y_sup_test, y_pred_cat, average='macro')\n",
    "            \n",
    "            if cat_f1 > best_score:\n",
    "                best_score = cat_f1\n",
    "                best_params = {\n",
    "                    'iterations': iterations,\n",
    "                    'depth': depth,\n",
    "                    'learning_rate': lr\n",
    "                }\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for fused features\n",
    "                best_model_path = \"best_catboost_classifier_fused.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEST CATBOOST HYPERPARAMETERS (Fused Features):\")\n",
    "    print(best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    if best_model_path:\n",
    "        print(f\"\\nBest CatBoost model saved to: {best_model_path}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    y_pred_best = best_model.predict(X_sup_test)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL CLASSIFICATION REPORT (Best CatBoost - Fused):\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_sup_test, y_pred_best, digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed. Install with: pip install catboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES CLASSIFIER (Fused Features)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [06:13<00:00, 41.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 10}\n",
      "Best Macro F1: 0.8262\n",
      "Model saved to: best_et_classifier_fused.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9986    0.9531    0.9753    104997\n",
      "           1     0.9981    0.9992    0.9986     12438\n",
      "           2     0.8636    0.7451    0.8000       102\n",
      "           3     0.6000    0.3529    0.4444        34\n",
      "           4     1.0000    1.0000    1.0000     61790\n",
      "           5     1.0000    0.9894    0.9947       188\n",
      "           6     1.0000    1.0000    1.0000     17362\n",
      "           7     1.0000    1.0000    1.0000      3632\n",
      "           8     1.0000    1.0000    1.0000      5890\n",
      "           9     0.0000    0.0000    0.0000      6320\n",
      "          10     1.0000    1.0000    1.0000      2164\n",
      "          11     0.7862    1.0000    0.8803     23242\n",
      "          12     0.6957    0.9868    0.8161     11314\n",
      "          13     0.3261    0.9375    0.4839        32\n",
      "          14     1.0000    1.0000    1.0000     11310\n",
      "\n",
      "    accuracy                         0.9561    260815\n",
      "   macro avg     0.8179    0.8643    0.8262    260815\n",
      "weighted avg     0.9427    0.9561    0.9469    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES CLASSIFIER (Fused Features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [10, 20, 30]\n",
    "\n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "    for n_est, depth in tqdm(params):\n",
    "        try:\n",
    "            et_clf = ExtraTreesClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                class_weight='balanced',\n",
    "                random_state=13,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            et_clf.fit(X_sup_train, y_sup_train)\n",
    "            y_pred_et = et_clf.predict(X_sup_test)\n",
    "            et_f1 = f1_score(y_sup_test, y_pred_et, average='macro')\n",
    "            \n",
    "            if et_f1 > score:\n",
    "                score = et_f1\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth\n",
    "                }\n",
    "                best_model = et_clf\n",
    "                # Save best model\n",
    "                with open('best_et_classifier_fused.pkl', 'wb') as f:\n",
    "                    pickle.dump(et_clf, f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (n={n_est}, d={depth}): {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if best_model is not None:\n",
    "        print(\"\\nBest Parameters:\", best_params)\n",
    "        print(f\"Best Macro F1: {score:.4f}\")\n",
    "        print(\"Model saved to: best_et_classifier_fused.pkl\\n\")\n",
    "        print(classification_report(y_sup_test, best_model.predict(X_sup_test), digits=4))\n",
    "    else:\n",
    "        print(\"\\nAll configurations failed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error in Extra Trees: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Features Classification (Comparison Baseline)\n",
    "\n",
    "Now we'll train classifiers on **raw features only** (without graph embeddings) to compare the benefit of multimodal fusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw feature shape - Train: (304665, 39), Test: (130572, 39)\n",
      "Number of classes: 15\n"
     ]
    }
   ],
   "source": [
    "# Prepare raw features (without embeddings)\n",
    "# Use only the original numeric features from X_train/X_test\n",
    "\n",
    "X_raw_train = X_train.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_train = y_train[\"Attack\"].copy()\n",
    "\n",
    "X_raw_test = X_test.drop(columns=[\"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\", \"h\", \"id\"]).copy()\n",
    "y_raw_test = y_test[\"Attack\"].copy()\n",
    "\n",
    "# Encode labels\n",
    "y_raw_train_encoded = lab_enc.transform(y_train[\"Attack\"])\n",
    "y_raw_test_encoded = lab_enc.transform(y_test[\"Attack\"])\n",
    "\n",
    "# Compute sample weights\n",
    "classes_raw = np.unique(y_raw_train_encoded)\n",
    "class_w_raw = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_raw, y=y_raw_train_encoded\n",
    ")\n",
    "class_to_w_raw = {c: w for c, w in zip(classes_raw, class_w_raw)}\n",
    "sample_weight_raw = pd.Series(y_raw_train_encoded).map(class_to_w_raw).values\n",
    "\n",
    "# Feature names to str\n",
    "X_raw_train.columns = X_raw_train.columns.map(str)\n",
    "X_raw_test.columns = X_raw_test.columns.map(str)\n",
    "\n",
    "print(f\"Raw feature shape - Train: {X_raw_train.shape}, Test: {X_raw_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_raw_train_encoded))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Raw Features Only)\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [04:12<00:00, 28.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 30}\n",
      "Best Macro F1: 0.6979\n",
      "Model saved to: best_rf_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9544    0.7950    0.8675     52663\n",
      "           1     1.0000    0.9997    0.9998      6219\n",
      "           2     0.1386    0.4510    0.2120        51\n",
      "           3     0.3846    0.8824    0.5357        17\n",
      "           4     0.9999    1.0000    1.0000     30895\n",
      "           5     0.8440    0.9787    0.9064        94\n",
      "           6     0.9988    0.9980    0.9984      8681\n",
      "           7     0.9994    1.0000    0.9997      1816\n",
      "           8     1.0000    0.9997    0.9998      2945\n",
      "           9     0.2138    1.0000    0.3523      3160\n",
      "          10     1.0000    0.9982    0.9991      1082\n",
      "          11     0.0000    0.0000    0.0000     11621\n",
      "          12     0.2557    0.6470    0.3665      5657\n",
      "          13     0.3000    0.1875    0.2308        16\n",
      "          14     1.0000    1.0000    1.0000      5655\n",
      "\n",
      "    accuracy                         0.8125    130572\n",
      "   macro avg     0.6726    0.7958    0.6979    130572\n",
      "weighted avg     0.8406    0.8125    0.8138    130572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Raw Features Only)\")\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = rf_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Raw Features Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:19:42] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "100%|██████████| 27/27 [05:20<00:00, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7387\n",
      "Model saved to: best_xgb_classifier_raw.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9551    0.7654    0.8498     52663\n",
      "           1     0.9994    1.0000    0.9997      6219\n",
      "           2     0.2500    0.5882    0.3509        51\n",
      "           3     0.3611    0.7647    0.4906        17\n",
      "           4     0.9998    1.0000    0.9999     30895\n",
      "           5     0.8426    0.9681    0.9010        94\n",
      "           6     0.9988    0.9978    0.9983      8681\n",
      "           7     0.9989    1.0000    0.9994      1816\n",
      "           8     1.0000    1.0000    1.0000      2945\n",
      "           9     0.0000    0.0000    0.0000      3160\n",
      "          10     0.9972    0.9991    0.9982      1082\n",
      "          11     0.7862    1.0000    0.8803     11621\n",
      "          12     0.2341    0.6627    0.3460      5657\n",
      "          13     0.2857    0.2500    0.2667        16\n",
      "          14     1.0000    1.0000    1.0000      5655\n",
      "\n",
      "    accuracy                         0.8661    130572\n",
      "   macro avg     0.7139    0.7997    0.7387    130572\n",
      "weighted avg     0.9047    0.8661    0.8756    130572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Raw Features Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='cuda'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_raw_train, y_raw_train_encoded, sample_weight=sample_weight_raw)\n",
    "        y_pred = xgb_clf.predict(X_raw_test)\n",
    "        f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_raw.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_raw.json\\n\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Raw Features Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 3089.3125 Total: 5806.3125\n",
      "  4%|▎         | 1/27 [00:02<01:10,  2.72s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      "  7%|▋         | 2/27 [00:05<01:05,  2.60s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 11%|█         | 3/27 [00:07<01:01,  2.56s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 15%|█▍        | 4/27 [00:13<01:31,  3.99s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 19%|█▊        | 5/27 [00:19<01:42,  4.68s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 22%|██▏       | 6/27 [00:25<01:46,  5.06s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 26%|██▌       | 7/27 [00:38<02:32,  7.63s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 30%|██▉       | 8/27 [00:51<02:55,  9.22s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 33%|███▎      | 9/27 [01:03<03:03, 10.20s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 37%|███▋      | 10/27 [01:07<02:19,  8.23s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 41%|████      | 11/27 [01:10<01:49,  6.82s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 44%|████▍     | 12/27 [01:14<01:27,  5.86s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 48%|████▊     | 13/27 [01:23<01:35,  6.85s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 52%|█████▏    | 14/27 [01:32<01:35,  7.38s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 56%|█████▌    | 15/27 [01:40<01:32,  7.75s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 59%|█████▉    | 16/27 [02:00<02:04, 11.33s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 63%|██████▎   | 17/27 [02:19<02:15, 13.60s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 67%|██████▋   | 18/27 [02:38<02:16, 15.18s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 70%|███████   | 19/27 [02:44<01:39, 12.49s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 74%|███████▍  | 20/27 [02:50<01:13, 10.50s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 78%|███████▊  | 21/27 [02:56<00:54,  9.10s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 81%|████████▏ | 22/27 [03:10<00:53, 10.78s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 85%|████████▌ | 23/27 [03:24<00:46, 11.71s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 89%|████████▉ | 24/27 [03:38<00:37, 12.34s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 93%|█████████▎| 25/27 [04:10<00:36, 18.22s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      " 96%|█████████▋| 26/27 [04:41<00:21, 21.98s/it]Warning: less than 75% GPU memory available for training. Free: 3087.3125 Total: 5806.3125\n",
      "100%|██████████| 27/27 [05:12<00:00, 11.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7170\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_raw.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9556    0.7538    0.8428     52663\n",
      "           1     0.9974    1.0000    0.9987      6219\n",
      "           2     0.1571    0.6471    0.2529        51\n",
      "           3     0.2456    0.8235    0.3784        17\n",
      "           4     0.9997    1.0000    0.9999     30895\n",
      "           5     0.8174    1.0000    0.8995        94\n",
      "           6     0.9982    0.9976    0.9979      8681\n",
      "           7     0.9983    0.9989    0.9986      1816\n",
      "           8     0.9990    0.9980    0.9985      2945\n",
      "           9     0.0000    0.0000    0.0000      3160\n",
      "          10     0.9854    1.0000    0.9927      1082\n",
      "          11     0.7862    1.0000    0.8803     11621\n",
      "          12     0.2289    0.6689    0.3410      5657\n",
      "          13     0.2857    0.1250    0.1739        16\n",
      "          14     1.0000    1.0000    1.0000      5655\n",
      "\n",
      "    accuracy                         0.8617    130572\n",
      "   macro avg     0.6970    0.8008    0.7170    130572\n",
      "weighted avg     0.9043    0.8617    0.8723    130572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Raw Features Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "            y_pred = cat_clf.predict(X_raw_test)\n",
    "            f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for raw features\n",
    "                best_model_path = \"best_catboost_classifier_raw.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Raw Features Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:50<00:00, 18.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 30}\n",
      "Best Macro F1: 0.7311\n",
      "Model saved to: best_et_classifier_raw.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9492    0.8420    0.8924     52663\n",
      "           1     0.9997    0.9998    0.9998      6219\n",
      "           2     0.1557    0.3725    0.2197        51\n",
      "           3     0.3684    0.8235    0.5091        17\n",
      "           4     1.0000    1.0000    1.0000     30895\n",
      "           5     0.8542    0.8723    0.8632        94\n",
      "           6     0.9977    0.9984    0.9980      8681\n",
      "           7     1.0000    1.0000    1.0000      1816\n",
      "           8     1.0000    1.0000    1.0000      2945\n",
      "           9     0.0000    0.0000    0.0000      3160\n",
      "          10     0.9991    0.9991    0.9991      1082\n",
      "          11     0.7862    1.0000    0.8803     11621\n",
      "          12     0.2858    0.5816    0.3833      5657\n",
      "          13     0.2727    0.1875    0.2222        16\n",
      "          14     1.0000    1.0000    1.0000      5655\n",
      "\n",
      "    accuracy                         0.8934    130572\n",
      "   macro avg     0.7112    0.7785    0.7311    130572\n",
      "weighted avg     0.9046    0.8934    0.8943    130572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Raw Features - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Raw Features Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_raw_train, y_raw_train_encoded)\n",
    "    y_pred = et_clf.predict(X_raw_test)\n",
    "    f1 = f1_score(y_raw_test_encoded, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_raw.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_raw.pkl\\n\")\n",
    "print(classification_report(y_raw_test_encoded, best_model.predict(X_raw_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Only Classification (Graph Features)\n",
    "\n",
    "Now we'll train classifiers on **embeddings only** (graph features without raw features) to isolate the value of graph-based learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape - Train: (608554, 256), Test: (260815, 256)\n",
      "Number of classes: 15\n",
      "Using only graph embeddings (no raw features)\n"
     ]
    }
   ],
   "source": [
    "# Prepare embeddings-only features (graph features without raw data)\n",
    "# Extract only the embedding columns (first 256 dimensions from graph encoder)\n",
    "\n",
    "# From the fused dataframes, extract only embedding columns\n",
    "# df_fuse_train has: [0-255] = embeddings, [256+] = raw features\n",
    "num_embedding_dims = 256  # Based on the DGI encoder output dimension\n",
    "\n",
    "X_emb_train = df_fuse_train.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_train = df_fuse_train[\"Attacks\"].copy()\n",
    "\n",
    "X_emb_test = df_fuse_test.iloc[:, :num_embedding_dims].copy()\n",
    "y_emb_test = df_fuse_test[\"Attacks\"].copy()\n",
    "\n",
    "# Compute sample weights\n",
    "classes_emb = np.unique(y_emb_train)\n",
    "class_w_emb = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_emb, y=y_emb_train\n",
    ")\n",
    "class_to_w_emb = {c: w for c, w in zip(classes_emb, class_w_emb)}\n",
    "sample_weight_emb = y_emb_train.map(class_to_w_emb).values\n",
    "\n",
    "# Feature names to str\n",
    "X_emb_train.columns = X_emb_train.columns.map(str)\n",
    "X_emb_test.columns = X_emb_test.columns.map(str)\n",
    "\n",
    "print(f\"Embeddings shape - Train: {X_emb_train.shape}, Test: {X_emb_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_emb_train))}\")\n",
    "print(f\"Using only graph embeddings (no raw features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [15:00<00:00, 100.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 10}\n",
      "Best Macro F1: 0.4367\n",
      "Model saved to: best_rf_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7489    0.9592    0.8411    104997\n",
      "           1     0.9998    0.9522    0.9755     12438\n",
      "           2     0.8043    0.7255    0.7629       102\n",
      "           3     0.8000    0.1176    0.2051        34\n",
      "           4     0.9970    0.5491    0.7082     61790\n",
      "           5     0.0035    0.4096    0.0070       188\n",
      "           6     1.0000    0.9542    0.9765     17362\n",
      "           7     0.0000    0.0000    0.0000      3632\n",
      "           8     0.0000    0.0000    0.0000      5890\n",
      "           9     0.0000    0.0000    0.0000      6320\n",
      "          10     0.0000    0.0000    0.0000      2164\n",
      "          11     0.7862    0.5000    0.6113     23242\n",
      "          12     0.6843    0.9245    0.7865     11314\n",
      "          13     0.0051    1.0000    0.0101        32\n",
      "          14     1.0000    0.5000    0.6667     11310\n",
      "\n",
      "    accuracy                         0.7322    260815\n",
      "   macro avg     0.5219    0.5061    0.4367    260815\n",
      "weighted avg     0.7955    0.7322    0.7357    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = rf_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = rf_clf\n",
    "        # Save best model\n",
    "        with open('best_rf_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(rf_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_rf_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "XGBOOST (Embeddings Only)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [30:41<00:00, 68.21s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05}\n",
      "Best Macro F1: 0.5536\n",
      "Model saved to: best_xgb_classifier_embeddings.json\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8305    0.9623    0.8916    104997\n",
      "           1     0.9999    0.8780    0.9350     12438\n",
      "           2     0.0272    0.8627    0.0528       102\n",
      "           3     0.8000    0.1176    0.2051        34\n",
      "           4     0.9969    0.2991    0.4602     61790\n",
      "           5     0.0032    0.6436    0.0065       188\n",
      "           6     1.0000    1.0000    1.0000     17362\n",
      "           7     1.0000    1.0000    1.0000      3632\n",
      "           8     1.0000    0.5000    0.6667      5890\n",
      "           9     0.0000    0.0000    0.0000      6320\n",
      "          10     1.0000    0.5000    0.6667      2164\n",
      "          11     0.7862    0.5000    0.6113     23242\n",
      "          12     0.6982    0.9220    0.7947     11314\n",
      "          13     0.0066    0.6562    0.0131        32\n",
      "          14     1.0000    1.0000    1.0000     11310\n",
      "\n",
      "    accuracy                         0.7249    260815\n",
      "   macro avg     0.6766    0.6561    0.5536    260815\n",
      "weighted avg     0.8734    0.7249    0.7460    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBOOST (Embeddings Only)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_estimators_grid = [100, 200, 300]\n",
    "    max_depth_grid = [6, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(n_estimators_grid, max_depth_grid, learning_rate_grid))\n",
    "    \n",
    "    score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for n_est, depth, lr in tqdm(params):\n",
    "        xgb_clf = XGBClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth,\n",
    "            learning_rate=lr,\n",
    "            random_state=13,\n",
    "            tree_method='hist',\n",
    "            device='gpu'\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_emb_train, y_emb_train, sample_weight=sample_weight_emb)\n",
    "        y_pred = xgb_clf.predict(X_emb_test)\n",
    "        f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "        \n",
    "        if f1 > score:\n",
    "            score = f1\n",
    "            best_params = {'n_estimators': n_est, 'max_depth': depth, 'learning_rate': lr}\n",
    "            best_model = xgb_clf\n",
    "            # Save best model\n",
    "            xgb_clf.save_model('best_xgb_classifier_embeddings.json')\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {score:.4f}\")\n",
    "    print(\"Model saved to: best_xgb_classifier_embeddings.json\\n\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST (Embeddings Only, Expanded)\n",
      "============================================================\n",
      "Testing 27 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      "  4%|▎         | 1/27 [00:07<03:08,  7.23s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      "  7%|▋         | 2/27 [00:14<02:54,  7.00s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 11%|█         | 3/27 [00:20<02:45,  6.88s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 15%|█▍        | 4/27 [00:39<04:24, 11.49s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 19%|█▊        | 5/27 [00:56<04:55, 13.44s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 22%|██▏       | 6/27 [01:12<05:02, 14.40s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 26%|██▌       | 7/27 [01:52<07:34, 22.74s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 30%|██▉       | 8/27 [02:29<08:35, 27.16s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 33%|███▎      | 9/27 [03:04<08:54, 29.71s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 37%|███▋      | 10/27 [03:14<06:44, 23.78s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 41%|████      | 11/27 [03:24<05:12, 19.56s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 44%|████▍     | 12/27 [03:34<04:09, 16.62s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 48%|████▊     | 13/27 [04:02<04:38, 19.93s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 52%|█████▏    | 14/27 [04:26<04:37, 21.35s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 56%|█████▌    | 15/27 [04:51<04:26, 22.20s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 59%|█████▉    | 16/27 [05:50<06:08, 33.51s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 63%|██████▎   | 17/27 [06:44<06:36, 39.63s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 67%|██████▋   | 18/27 [07:37<06:31, 43.53s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 70%|███████   | 19/27 [07:54<04:43, 35.49s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 74%|███████▍  | 20/27 [08:10<03:27, 29.70s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 78%|███████▊  | 21/27 [08:26<02:33, 25.61s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 81%|████████▏ | 22/27 [09:09<02:34, 30.97s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 85%|████████▌ | 23/27 [09:49<02:14, 33.71s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 89%|████████▉ | 24/27 [10:29<01:46, 35.47s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 93%|█████████▎| 25/27 [12:04<01:46, 53.47s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      " 96%|█████████▋| 26/27 [13:32<01:03, 63.81s/it]Warning: less than 75% GPU memory available for training. Free: 4944.1875 Total: 7831.5625\n",
      "100%|██████████| 27/27 [14:59<00:00, 33.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'iterations': 500, 'depth': 10, 'learning_rate': 0.1}\n",
      "Best Macro F1: 0.7352\n",
      "\n",
      "Best CatBoost model saved to: best_catboost_classifier_embeddings.cbm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9933    0.9571    0.9749    104997\n",
      "           1     0.9998    1.0000    0.9999     12438\n",
      "           2     0.8721    0.7353    0.7979       102\n",
      "           3     0.3947    0.8824    0.5455        34\n",
      "           4     0.9970    0.4990    0.6651     61790\n",
      "           5     0.0031    0.5106    0.0061       188\n",
      "           6     1.0000    1.0000    1.0000     17362\n",
      "           7     0.9997    1.0000    0.9999      3632\n",
      "           8     1.0000    1.0000    1.0000      5890\n",
      "           9     0.2138    0.5000    0.2995      6320\n",
      "          10     1.0000    1.0000    1.0000      2164\n",
      "          11     0.7862    0.5000    0.6113     23242\n",
      "          12     0.7049    0.9406    0.8059     11314\n",
      "          13     0.3333    0.3125    0.3226        32\n",
      "          14     1.0000    1.0000    1.0000     11310\n",
      "\n",
      "    accuracy                         0.8042    260815\n",
      "   macro avg     0.7532    0.7892    0.7352    260815\n",
      "weighted avg     0.9448    0.8042    0.8496    260815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - CatBoost (Expanded grid, no l2_leaf_reg/border_count)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CATBOOST (Embeddings Only, Expanded)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    iterations_grid = [200, 300, 500]\n",
    "    depth_grid = [4, 8, 10]\n",
    "    learning_rate_grid = [0.01, 0.05, 0.1]\n",
    "    \n",
    "    params = list(itertools.product(iterations_grid, depth_grid, learning_rate_grid))\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_model_path = None\n",
    "    \n",
    "    print(f\"Testing {len(params)} configurations...\")\n",
    "    \n",
    "    for iterations, depth, lr in tqdm(params):\n",
    "        try:\n",
    "            cat_clf = CatBoostClassifier(\n",
    "                iterations=iterations,\n",
    "                depth=depth,\n",
    "                learning_rate=lr,\n",
    "                auto_class_weights='Balanced',\n",
    "                random_seed=13,\n",
    "                verbose=False,\n",
    "                task_type='GPU'\n",
    "            )\n",
    "            \n",
    "            cat_clf.fit(X_emb_train, y_emb_train)\n",
    "            y_pred = cat_clf.predict(X_emb_test)\n",
    "            f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "            \n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_params = {'iterations': iterations, 'depth': depth, 'learning_rate': lr}\n",
    "                best_model = cat_clf\n",
    "                # Save the best model with unique name for embeddings\n",
    "                best_model_path = \"best_catboost_classifier_embeddings.cbm\"\n",
    "                best_model.save_model(best_model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError with params (it={iterations}, d={depth}, lr={lr}): {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f\"Best Macro F1: {best_score:.4f}\\n\")\n",
    "    if best_model_path:\n",
    "        print(f\"Best CatBoost model saved to: {best_model_path}\")\n",
    "    print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"CatBoost not installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRA TREES (Embeddings Only)\n",
      "============================================================\n",
      "Testing 9 configurations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [05:23<00:00, 35.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'n_estimators': 200, 'max_depth': 10}\n",
      "Best Macro F1: 0.6906\n",
      "Model saved to: best_et_classifier_embeddings.pkl\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9987    0.9543    0.9760    104997\n",
      "           1     0.9982    0.9761    0.9870     12438\n",
      "           2     0.8636    0.7451    0.8000       102\n",
      "           3     0.8000    0.2353    0.3636        34\n",
      "           4     0.9969    0.5996    0.7488     61790\n",
      "           5     0.0033    0.4415    0.0066       188\n",
      "           6     1.0000    1.0000    1.0000     17362\n",
      "           7     1.0000    1.0000    1.0000      3632\n",
      "           8     1.0000    1.0000    1.0000      5890\n",
      "           9     0.2138    1.0000    0.3523      6320\n",
      "          10     1.0000    1.0000    1.0000      2164\n",
      "          11     0.0000    0.0000    0.0000     23242\n",
      "          12     0.6897    0.9881    0.8123     11314\n",
      "          13     0.2083    0.6250    0.3125        32\n",
      "          14     1.0000    1.0000    1.0000     11310\n",
      "\n",
      "    accuracy                         0.7953    260815\n",
      "   macro avg     0.7182    0.7710    0.6906    260815\n",
      "weighted avg     0.8761    0.7953    0.8163    260815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kienho/D/DesktopFiles/Hoc/DACN/paper_codes/Anomal-E/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Embeddings Only - Extra Trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXTRA TREES (Embeddings Only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_estimators_grid = [100, 200, 300]\n",
    "max_depth_grid = [10, 20, 30]\n",
    "\n",
    "params = list(itertools.product(n_estimators_grid, max_depth_grid))\n",
    "\n",
    "score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(f\"Testing {len(params)} configurations...\")\n",
    "\n",
    "for n_est, depth in tqdm(params):\n",
    "    et_clf = ExtraTreesClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=depth,\n",
    "        class_weight='balanced',\n",
    "        random_state=13,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    et_clf.fit(X_emb_train, y_emb_train)\n",
    "    y_pred = et_clf.predict(X_emb_test)\n",
    "    f1 = f1_score(y_emb_test, y_pred, average='macro')\n",
    "    \n",
    "    if f1 > score:\n",
    "        score = f1\n",
    "        best_params = {'n_estimators': n_est, 'max_depth': depth}\n",
    "        best_model = et_clf\n",
    "        # Save best model\n",
    "        with open('best_et_classifier_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(et_clf, f)\n",
    "\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Macro F1: {score:.4f}\")\n",
    "print(\"Model saved to: best_et_classifier_embeddings.pkl\\n\")\n",
    "print(classification_report(y_emb_test, best_model.predict(X_emb_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Comparison Table\n",
    "\n",
    "Create a comparison table of all methods (Fused vs Raw features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\n",
      "===============================================================================================\n",
      "\n",
      "Instructions:\n",
      "1. Run all cells above to get F1 scores for each method\n",
      "2. Record the best Macro F1 score for each method\n",
      "3. Compare three approaches:\n",
      "   - Fused Features: Embeddings + Raw (Multimodal)\n",
      "   - Embeddings Only: Graph features only\n",
      "   - Raw Features: Traditional features only\n",
      "\n",
      "Expected format:\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Method               Fused (Emb+Raw)           Embeddings Only           Raw Only                 \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Random Forest        [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "XGBoost              [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "CatBoost             [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "Extra Trees          [INSERT SCORE]            [INSERT SCORE]            [INSERT SCORE]           \n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "Analysis:\n",
      "- Fused features should show best performance (multimodal learning)\n",
      "- Embeddings capture structural/graph patterns\n",
      "- Raw features provide traditional statistical information\n",
      "- Compare to understand the contribution of each modality\n"
     ]
    }
   ],
   "source": [
    "# Create a summary comparison table\n",
    "# NOTE: After running all cells above, manually collect the F1 scores and create a comparison\n",
    "\n",
    "print(\"=\"*95)\n",
    "print(\"PERFORMANCE COMPARISON: FUSED vs EMBEDDINGS vs RAW FEATURES\")\n",
    "print(\"=\"*95)\n",
    "print(\"\\nInstructions:\")\n",
    "print(\"1. Run all cells above to get F1 scores for each method\")\n",
    "print(\"2. Record the best Macro F1 score for each method\")\n",
    "print(\"3. Compare three approaches:\")\n",
    "print(\"   - Fused Features: Embeddings + Raw (Multimodal)\")\n",
    "print(\"   - Embeddings Only: Graph features only\")\n",
    "print(\"   - Raw Features: Traditional features only\")\n",
    "print(\"\\nExpected format:\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Method':<20} {'Fused (Emb+Raw)':<25} {'Embeddings Only':<25} {'Raw Only':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Random Forest':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'XGBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'CatBoost':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(f\"{'Extra Trees':<20} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25} {'[INSERT SCORE]':<25}\")\n",
    "print(\"-\" * 95)\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"- Fused features should show best performance (multimodal learning)\")\n",
    "print(\"- Embeddings capture structural/graph patterns\")\n",
    "print(\"- Raw features provide traditional statistical information\")\n",
    "print(\"- Compare to understand the contribution of each modality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights & Interpretation\n",
    "\n",
    "After running all experiments, analyze the results to answer:\n",
    "\n",
    "1. **Which approach performs best overall?**\n",
    "   - Fused features (multimodal) should ideally outperform single modalities\n",
    "   - Compare the magnitude of improvements\n",
    "\n",
    "2. **What is the value of graph embeddings?**\n",
    "   - Compare Embeddings-only vs Raw-only to see if graph structure helps\n",
    "   - If embeddings alone beat raw features, graph learning is beneficial\n",
    "\n",
    "3. **Is multimodal fusion effective?**\n",
    "   - Compare Fused vs (Embeddings + Raw separately)\n",
    "   - Synergy should provide additional gains beyond individual modalities\n",
    "\n",
    "4. **Which classifier is most suitable?**\n",
    "   - Identify the best performing algorithm for each feature type\n",
    "   - Consider computational cost vs accuracy trade-offs\n",
    "\n",
    "5. **Feature contribution analysis:**\n",
    "   - If Fused ≈ Embeddings > Raw: Graph structure dominates\n",
    "   - If Fused ≈ Raw > Embeddings: Traditional features dominate\n",
    "   - If Fused > Both: True synergy from multimodal learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
